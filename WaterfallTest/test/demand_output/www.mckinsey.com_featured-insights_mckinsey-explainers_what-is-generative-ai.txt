"What is ChatGPT, DALL-E, and generative AI? | McKinsey\n\nSkip to main contentIndustriesCapabilitiesFeatured InsightsLearn About our people, values, commitment and moreExplore our featured insightsTrending TopicsAgile OrganizationsArtificial Intelligence & Gen AIBusiness ResilienceClimate ChangeDiversity and InclusionFuture of AsiaInflationMcKinsey ThemesSpeeding up in a slowing economySustainable, Inclusive GrowthThe Rise of Quantum ComputingWell-being in the WorkplaceFeaturedMcKinsey QuarterlyOur flagship business publication has been defining and informing the senior-management agenda since 1964.McKinsey Global InstituteOur mission is to help leaders in multiple sectors develop a deeper understanding of the global economy.McKinsey Insights AppTimely insights on the go: Download the app, choose your topics, get a personalized feed.LocationsCareersAbout UsMcKinsey BlogMorePlease use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.SearchSign In|SubscribeWhat is generative AI?SharePrintDownloadSaveWhat is generative AI?April 2, 2024 | ArticleSharePrintDownloadSaveGenerative artificial intelligence (AI) describes algorithms (such as ChatGPT) that can be used to create new content, including audio, code, images, text, simulations, and videos. Recent breakthroughs in the field have the potential to drastically change the way we approach content creation.A green apple split into 3 parts on a gray background. Half of the apple is made out of a digital blue wireframe mesh. \n\nDOWNLOADSArticle (5 pages)\nIn the months and years since ChatGPT burst on the scene in November 2022, generative AI (gen AI) has come a long way. Every month sees the launch of new tools, rules, or iterative technological advancements. While many have reacted to ChatGPT (and AI and machine learning more broadly) with fear, machine learning clearly has the potential for good. In the years since its wide deployment, machine learning has demonstrated impact in a number of industries, accomplishing things like medical imaging analysis and high-resolution weather forecasts. A 2022 McKinsey survey shows that AI adoption has more than doubled over the past five years, and investment in AI is increasing apace. It’s clear that generative AI tools like ChatGPT (the GPT stands for generative pretrained transformer) and image generator DALL-E (its name a mashup of the surrealist artist Salvador Dalí and the lovable Pixar robot WALL-E) have the potential to change how a range of jobs are performed. The full scope of that impact, though, is still unknown—as are the risks.\n\nGet to know and directly engage with McKinsey's senior experts on generative AI\nAamer Baig is a senior partner in McKinsey’s Chicago office; Lareina Yee is a senior partner in the Bay Area office; and senior partners Alex Singla and Alexander Sukharevsky, global leaders of QuantumBlack, AI by McKinsey, are based in the Chicago and London offices, respectively.We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com\nStill, organizations of all stripes have raced to incorporate gen AI tools into their business models, looking to capture a piece of a sizable prize. McKinsey research indicates that gen AI applications stand to add up to $4.4 trillion to the global economy—annually. Indeed, it seems possible that within the next three years, anything in the technology, media, and telecommunications space not connected to AI will be considered obsolete or ineffective. \nBut before all that value can be raked in, we need to get a few things straight: What is gen AI, how was it developed, and what does it mean for people and organizations? Read on to get the download.\nTo stay up to date on this critical topic, sign up for email alerts on “artificial intelligence” here. \nLearn more about QuantumBlack, AI by McKinsey. \nWhat every CEO should know about generative AIRead the article\nWhat’s the difference between machine learning and artificial intelligence?\nShare SidebarAbout QuantumBlack, AI by McKinseyQuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe.\nArtificial intelligence is pretty much just what it sounds like—the practice of getting machines to mimic human intelligence to perform tasks. You’ve probably interacted with AI even if you don’t realize it—voice assistants like Siri and Alexa are founded on AI technology, as are customer service chatbots that pop up to help you navigate websites. \nMachine learning is a type of artificial intelligence. Through machine learning, practitioners develop artificial intelligence through models that can “learn” from data patterns without human direction. The unmanageably huge volume and complexity of data (unmanageable by humans, anyway) that is now being generated has increased machine learning’s potential, as well as the need for it.\nWhat are the main types of machine learning models?\nMachine learning is founded on a number of building blocks, starting with classical statistical techniques developed between the 18th and 20th centuries for small data sets. In the 1930s and 1940s, the pioneers of computing—including theoretical mathematician Alan Turing—began working on the basic techniques for machine learning. But these techniques were limited to laboratories until the late 1970s, when scientists first developed computers powerful enough to mount them. \nUntil recently, machine learning was largely limited to predictive models, used to observe and classify patterns in content. For example, a classic machine learning problem is to start with an image or several images of, say, adorable cats. The program would then identify patterns among the images, and then scrutinize random images for ones that would match the adorable cat pattern. Generative AI was a breakthrough. Rather than simply perceive and classify a photo of a cat, machine learning is now able to create an image or text description of a cat on demand. \nIntroducing McKinsey Explainers: Direct answers to complex questionsExplore the series\nHow do text-based machine learning models work? How are they trained?\nWe strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com\nChatGPT may be getting all the headlines now, but it’s not the first text-based machine learning model to make a splash. OpenAI’s GPT-3 and Google’s BERT both launched in recent years to some fanfare.\nBut before ChatGPT, which by most accounts works pretty well most of the time (though it’s still being evaluated), AI chatbots didn’t always get the best reviews. GPT-3 is “by turns super impressive and super disappointing,” said New York Times tech reporter Cade Metz in a video where he and food writer Priya Krishna asked GPT-3 to write recipes for a (rather disastrous) Thanksgiving dinner. \nThe first machine learning models to work with text were trained by humans to classify various inputs according to labels set by researchers. One example would be a model trained to label social media posts as either positive or negative. This type of training is known as supervised learning because a human is in charge of “teaching” the model what to do. \nThe next generation of text-based machine learning models rely on what’s known as self-supervised learning. This type of training involves feeding a model a massive amount of text so it becomes able to generate predictions. For example, some models can predict, based on a few words, how a sentence will end. With the right amount of sample text—say, a broad swath of the internet—these text models become quite accurate. We’re seeing just how accurate with the success of tools like ChatGPT. \nWhat does it take to build a generative AI model?\nMost Popular InsightsMcKinsey technology trends outlook 2024What to read next: McKinsey’s 2024 annual book recommendationsThe loneliest job? How top CEOs manage dilemmas and vulnerabilityThe hard stuff: Navigating the physical realities of the energy transitionThe state of AI in early 2024: Gen AI adoption spikes and starts to generate value\nBuilding a generative AI model has for the most part been a major undertaking, to the extent that only a few well-resourced tech heavyweights have made an attempt. OpenAI, the company behind ChatGPT, former GPT models, and DALL-E, has billions in funding from bold-face-name donors. DeepMind is a subsidiary of Alphabet, the parent company of Google, and even Meta has dipped a toe into the generative AI model pool with its Make-A-Video product. These companies employ some of the world’s best computer scientists and engineers. \nBut it’s not just talent. When you’re asking a model to train using nearly the entire internet, it’s going to cost you. OpenAI hasn’t released exact costs, but estimates indicate that GPT-3 was trained on around 45 terabytes of text data—that’s about one million feet of bookshelf space, or a quarter of the entire Library of Congress—at an estimated cost of several million dollars. These aren’t resources your garden-variety start-up can access. \nWhat kinds of output can a generative AI model produce?\nAs you may have noticed above, outputs from generative AI models can be indistinguishable from human-generated content, or they can seem a little uncanny. The results depend on the quality of the model—as we’ve seen, ChatGPT’s outputs so far appear superior to those of its predecessors—and the match between the model and the use case, or input. \nChatGPT can produce what one commentator called a “solid A-” essay comparing theories of nationalism from Benedict Anderson and Ernest Gellner—in ten seconds. It also produced an already famous passage describing how to remove a peanut butter sandwich from a VCR in the style of the King James Bible. Image-generating AI models like DALL-E 2 can create strange, beautiful images on demand, like a Raphael painting of a Madonna and child, eating pizza. Other generative AI models can produce code, video, audio, or business simulations. \nBut the outputs aren’t always accurate—or appropriate. When Priya Krishna asked DALL-E 2 to come up with an image for Thanksgiving dinner, it produced a scene where the turkey was garnished with whole limes, set next to a bowl of what appeared to be guacamole. For its part, ChatGPT seems to have trouble counting, or solving basic algebra problems—or, indeed, overcoming the sexist and racist bias that lurks in the undercurrents of the internet and society more broadly. \nGenerative AI outputs are carefully calibrated combinations of the data used to train the algorithms. Because the amount of data used to train these algorithms is so incredibly massive—as noted, GPT-3 was trained on 45 terabytes of text data—the models can appear to be “creative” when producing outputs. What’s more, the models usually have random elements, which means they can produce a variety of outputs from one input request—making them seem even more lifelike. \nWhat kinds of problems can a generative AI model solve?\nThe opportunity for businesses is clear. Generative AI tools can produce a wide variety of credible writing in seconds, then respond to criticism to make the writing more fit for purpose. This has implications for a wide variety of industries, from IT and software organizations that can benefit from the instantaneous, largely correct code generated by AI models to organizations in need of marketing copy. In short, any organization that needs to produce clear written materials potentially stands to benefit. Organizations can also use generative AI to create more technical materials, such as higher-resolution versions of medical images. And with the time and resources saved here, organizations can pursue new business opportunities and the chance to create more value.\nWe’ve seen that developing a generative AI model is so resource intensive that it is out of the question for all but the biggest and best-resourced companies. Companies looking to put generative AI to work have the option to either use generative AI out of the box or fine-tune them to perform a specific task. If you need to prepare slides according to a specific style, for example, you could ask the model to “learn” how headlines are normally written based on the data in the slides, then feed it slide data and ask it to write appropriate headlines. \nWhat are the limitations of AI models? How can these potentially be overcome?\nBecause they are so new, we have yet to see the long tail effect of generative AI models. This means there are some inherent risks involved in using them—some known and some unknown.\nThe outputs generative AI models produce may often sound extremely convincing. This is by design. But sometimes the information they generate is just plain wrong. Worse, sometimes it’s biased (because it’s built on the gender, racial, and myriad other biases of the internet and society more generally) and can be manipulated to enable unethical or criminal activity. For example, ChatGPT won’t give you instructions on how to hotwire a car, but if you say you need to hotwire a car to save a baby, the algorithm is happy to comply. Organizations that rely on generative AI models should reckon with reputational and legal risks involved in unintentionally publishing biased, offensive, or copyrighted content. \nThese risks can be mitigated, however, in a few ways. For one, it’s crucial to carefully select the initial data used to train these models to avoid including toxic or biased content. Next, rather than employing an off-the-shelf generative AI model, organizations could consider using smaller, specialized models. Organizations with more resources could also customize a general model based on their own data to fit their needs and minimize biases. Organizations should also keep a human in the loop (that is, to make sure a real human checks the output of a generative AI model before it is published or used) and avoid using generative AI models for critical decisions, such as those involving significant resources or human welfare. \nIt can’t be emphasized enough that this is a new field. The landscape of risks and opportunities is likely to change rapidly in coming weeks, months, and years. New use cases are being tested monthly, and new models are likely to be developed in the coming years. As generative AI becomes increasingly, and seamlessly, incorporated into business, society, and our personal lives, we can also expect a new regulatory climate to take shape. As organizations begin experimenting—and creating value—with these tools, leaders will do well to keep a finger on the pulse of regulation and risk. \nPop quiz\nBreak the internetHow many people signed up to use ChatGPT in the first five days after launch in November 2022?How do you measure up? Only 0% of readers got this right.Sorry, that’s not it.OpenAI, the organization behind ChatGPT, released the model for testing by the general public in November 2022. In just five days, over a million people signed up to use it. And already, it’s considered the best AI chatbot ever.Take more quizzesData PointsA - More than 10 millionB - More than 2 millionC - More than 1 millionShow us what you gotMachine learning has achieved many amazing things. Which of the following is NOT one of them?How do you measure up? Only 0% of readers got this right.Sorry, that’s not it.While many have reacted to ChatGPT (and AI and machine learning more broadly) with fear, machine learning clearly has the potential for good. In the years since its wide deployment, machine learning has demonstrated impact in a number of industries, accomplishing things like medical imaging analysis and high-resolution weather forecasts.Take more quizzesData PointsA - Medical imaging analysisB - High-resolution weather forecastsC - Space junk harpoon launchThe bandwagon is getting crowdedOver the past five years, AI use has:How do you measure up? Only 0% of readers got this right.Sorry, that’s not it.A 2022 McKinsey survey shows that AI adoption has more than doubled over the past five years, and investment in AI is increasing apace.Take more quizzesData PointsA - More than doubledB - More than tripledC - More than quadrupled\nArticles referenced include:\n\n\"Implementing generative AI with speed and safety,” March 13, 2024, Oliver Bevan, Michael Chui, Ida Kristensen, Brittany Presten, and Lareina Yee\n“Beyond the hype: Capturing the potential of AI and gen AI in tech, media, and telecom,” February 22, 2024, Venkat Atluri, Peter Dahlström, Brendan Gaffey, Víctor García de la Torre, Noshir Kaka, Tomás Lajous, Alex Singla, Alex Sukharevsky, Andrea Travasoni, and Benjamim Vieira\n“As gen AI advances, regulators—and risk functions—rush to keep pace,” December 21, 2023, Andreas Kremer, Angela Luget, Daniel Mikkelsen, Henning Soller, Malin Strandell-Jansson, and Sheila Zingg\n“The economic potential of generative AI: The next productivity frontier,” June 14, 2023, Michael Chui, Eric Hazan, Roger Roberts, Alex Singla, Kate Smaje, Alex Sukharevsky, Lareina Yee, and Rodney Zemmel\n“What every CEO should know about generative AI,” May 12, 2023, Michael Chui, Roger Roberts, Tanya Rodchenko, Alex Singla, Alex Sukharevsky, Lareina Yee, and Delphine Zurkiya\n“Exploring opportunities in the generative AI value chain,” April 26, 2023, Tobias Härlin, Gardar Björnsson Rova, Alex Singla, Oleg Sokolov, and Alex Sukharevsky\n“The state of AI in 2022—and a half decade in review,” December 6, 2022, Michael Chui, Bryce Hall, Helen Mayhew, Alex Singla, and Alex Sukharevsky\n“McKinsey Technology Trends Outlook 2023,” July 20, 2023, Michael Chui, Mena Issler, Roger Roberts, and Lareina Yee \n“An executive’s guide to AI,” Michael Chui, Vishnu Kamalnath, and Brian McCarthy\n“What AI can and can’t do (yet) for your business,” January 11, 2018, Michael Chui, James Manyika, and Mehdi Miremadi\n\nThis article was updated in April 2024; it was originally published in January 2023.\nWant to know more about generative AI?Talk to usRelated ArticlesArticleThe data dividend: Fueling generative AIPodcastDon’t wait—create, with generative AISign up for our Monthly Highlights newsletterDon't miss this roundup of our newest and most distinctive insightsSubscribeSign up for our Monthly Highlights newsletterWe use cookies to give you the best possible experience with mckinsey.com. Some are essential for this site to function; others help us understand how you use the site, so we can improve it. We may also use cookies for targeting purposes. Click “Accept all cookies” to proceed as specified, “Decline optional cookies” to accept only essential cookies, or click “Manage my preferences” to choose what cookie types you will accept.Cookie NoticeAccept All CookiesDecline optional cookies Manage my preferencesPrivacy Preference CenterMcKinsey and our trusted partners use cookies and similar technologies to access and use your data for the purposes listed below. Please provide your consent for cookie usage on this website. Enable one or more of the cookie types listed below, and then save your preferences.\n            Cookie NoticeAccept all cookies Manage Consent PreferencesPerformance Cookies  Performance Cookies These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site and app. They help us to know which pages are the most and least popular and see how visitors move around the site and app. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site or app, and will not be able to monitor its performance.Cookie details‎Functional Cookies  Functional Cookies These cookies enable the website and app to provide enhanced functionality and personalization. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.Cookie details‎Targeting Cookies  Targeting Cookies These cookies may be set through our site or app by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.Cookie details‎Strictly Necessary CookiesAlways ActiveThese cookies are necessary for the website and app to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site and app will not then work. These cookies do not store any personally identifiable information.Cookie details‎Back ButtonPerformance Cookies  Search IconFilter IconClear checkbox label labelApply CancelConsent Leg.Interest checkbox label label checkbox label label checkbox label labelView CookiesNamecookie name Save my preferences"