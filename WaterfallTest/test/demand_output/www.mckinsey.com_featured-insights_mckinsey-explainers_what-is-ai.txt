"What is AI (artificial intelligence)? | McKinsey\n\nSkip to main contentIndustriesCapabilitiesFeatured InsightsLearn About our people, values, commitment and moreExplore our featured insightsTrending TopicsAgile OrganizationsArtificial Intelligence & Gen AIBusiness ResilienceClimate ChangeDiversity and InclusionFuture of AsiaInflationMcKinsey ThemesSpeeding up in a slowing economySustainable, Inclusive GrowthThe Rise of Quantum ComputingWell-being in the WorkplaceFeaturedMcKinsey QuarterlyOur flagship business publication has been defining and informing the senior-management agenda since 1964.McKinsey Global InstituteOur mission is to help leaders in multiple sectors develop a deeper understanding of the global economy.McKinsey Insights AppTimely insights on the go: Download the app, choose your topics, get a personalized feed.LocationsCareersAbout UsMcKinsey BlogMorePlease use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.SearchSign In|SubscribeWhat is AI (artificial intelligence)?SharePrintDownloadSaveWhat is AI (artificial intelligence)?April 3, 2024 | ArticleSharePrintDownloadSaveArtificial intelligence is a machine’s ability to perform some cognitive functions we usually associate with human minds.3D robotics hand\n\nDOWNLOADSArticle (10 pages)\nHumans and machines: a match made in productivity heaven. Our species wouldn’t have gotten very far without our mechanized workhorses. From the wheel that revolutionized agriculture to the screw that held together increasingly complex construction projects to the robot-enabled assembly lines of today, machines have made life as we know it possible. And yet, despite their seemingly endless utility, humans have long feared machines—more specifically, the possibility that machines might someday acquire human intelligence and strike out on their own. \n\nGet to know and directly engage with senior McKinsey experts on AI\nSven Blumberg is a senior partner in McKinsey’s Düsseldorf office; Michael Chui is a partner at the McKinsey Global Institute and is based in the Bay Area office, where Lareina Yee is a senior partner; Kia Javanmardian is a senior partner in the Chicago office, where Alex Singla, the global leader of QuantumBlack, AI by McKinsey, is also a senior partner; Kate Smaje and Alex Sukharevsky are senior partners in the London office.We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com\nBut we tend to view the possibility of sentient machines with fascination as well as fear. This curiosity has helped turn science fiction into actual science. Twentieth-century theoreticians, like computer scientist and mathematician Alan Turing, envisioned a future where machines could perform functions faster than humans. The work of Turing and others soon made this a reality. Personal calculators became widely available in the 1970s, and by 2016, the US census showed that 89 percent of American households had a computer. Machines—smart machines at that—are now just an ordinary part of our lives and culture. \nThose smart machines are also getting faster and more complex. Some computers have now crossed the exascale threshold, meaning they can perform as many calculations in a single second as an individual could in 31,688,765,000 years. And beyond computation, which machines have long been faster at than we have, computers and other devices are now acquiring skills and perception that were once unique to humans and a few other species.\nShare SidebarAbout QuantumBlack, AI by McKinseyQuantumBlack, McKinsey’s AI arm, helps companies transform using the power of technology, technical expertise, and industry experts. With thousands of practitioners at QuantumBlack (data engineers, data scientists, product managers, designers, and software engineers) and McKinsey (industry and domain experts), we are working to solve the world’s most important AI challenges. QuantumBlack Labs is our center of technology development and client innovation, which has been driving cutting-edge advancements and developments in AI through locations across the globe.\nAI is a machine’s ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting with the environment, problem-solving, and even exercising creativity. You’ve probably interacted with AI even if you don’t realize it—voice assistants like Siri and Alexa are founded on AI technology, as are some customer service chatbots that pop up to help you navigate websites.\nApplied AI—simply, artificial intelligence applied to real-world problems—has serious implications for the business world. By using artificial intelligence, companies have the potential to make business more efficient and profitable. But ultimately, the value of AI isn’t in the systems themselves. Rather, it’s in how companies use these systems to assist humans—and their ability to explain to shareholders and the public what these systems do—in a way that builds trust and confidence.\nFor more about AI, its history, its future, and how to apply it in business, read on.\nLearn more about QuantumBlack, AI by McKinsey.\nIntroducing McKinsey Explainers: Direct answers to complex questionsExplore the series\nWhat is machine learning?\nMachine learning is a form of artificial intelligence that can adapt to a wide range of inputs, including large sets of historical data, synthesized data, or human inputs. (Some machine learning algorithms are specialized in training themselves to detect patterns; this is called deep learning. See Exhibit 1.) These algorithms can detect patterns and learn how to make predictions and recommendations by processing data, rather than by receiving explicit programming instruction. Some algorithms can also adapt in response to new data and experiences to improve over time.\nExhibit 1We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com\nThe volume and complexity of data that is now being generated, too vast for humans to process and apply efficiently, has increased the potential of machine learning, as well as the need for it. In the years since its widespread deployment, which began in the 1970s, machine learning has had an impact on a number of industries, including achievements in medical-imaging analysis and high-resolution weather forecasting.\nThe volume and complexity of data that is now being generated, too vast for humans to process and apply efficiently, has increased the potential of machine learning, as well as the need for it.\nWhat is deep learning?\nDeep learning is a more advanced version of machine learning that is particularly adept at processing a wider range of data resources (text as well as unstructured data including images), requires even less human intervention, and can often produce more accurate results than traditional machine learning. Deep learning uses neural networks—based on the ways neurons interact in the human brain—to ingest data and process it through multiple neuron layers that recognize increasingly complex features of the data. For example, an early layer might recognize something as being in a specific shape; building on this knowledge, a later layer might be able to identify the shape as a stop sign.  Similar to machine learning, deep learning uses iteration to self-correct and improve its prediction capabilities. For example, once it “learns” what a stop sign looks like, it can recognize a stop sign in a new image.\nLearn more about QuantumBlack, AI by McKinsey.\nWhat is generative AI?\nShare SidebarCase study: Vistra and the Martin Lake Power PlantVistra is a large power producer in the United States, operating plants in 12 states with a capacity to power nearly 20 million homes. Vistra has committed to achieving net-zero emissions by 2050. In support of this goal, as well as to improve overall efficiency, QuantumBlack, AI by McKinsey worked with Vistra to build and deploy an AI-powered heat rate optimizer (HRO) at one of its plants.\n“Heat rate” is a measure of the thermal efficiency of the plant; in other words, it’s the amount of fuel required to produce each unit of electricity. To reach the optimal heat rate, plant operators continuously monitor and tune hundreds of variables, such as steam temperatures, pressures, oxygen levels, and fan speeds.\nVistra and a McKinsey team, including data scientists and machine learning engineers, built a multilayered neural network model. The model combed through two years’ worth of data at the plant and learned which combination of factors would attain the most efficient heat rate at any point in time. When the models were accurate to 99 percent or higher and run through a rigorous set of real-world tests, the team converted them into an AI-powered engine that generates recommendations every 30 minutes for operators to improve the plant’s heat rate efficiency. One seasoned operations manager at the company’s plant in Odessa, Texas, said, “There are things that took me 20 years to learn about these power plants. This model learned them in an afternoon.”\nOverall, the AI-powered HRO helped Vistra achieve the following:\n\napproximately 1.6 million metric tons of carbon abated annually\n67 power generators optimized\n$60 million saved in about a year\n\nRead more about the Vistra story here.\nGenerative AI (gen AI) is an AI model that generates content in response to a prompt. It’s clear that generative AI tools like ChatGPT and DALL-E (a tool for AI-generated art) have the potential to change how a range of jobs are performed. Much is still unknown about gen AI’s potential, but there are some questions we can answer—like how gen AI models are built, what kinds of problems they are best suited to solve, and how they fit into the broader category of AI and machine learning.\nFor more on generative AI and how it stands to affect business and society, check out our Explainer “What is generative AI?”\nWhat is the history of AI?\nThe term “artificial intelligence” was coined in 1956 by computer scientist John McCarthy for a workshop at Dartmouth. But he wasn’t the first to write about the concepts we now describe as AI.\nAlan Turing introduced the concept of the “imitation game” in a 1950 paper. That’s the test of a machine’s ability to exhibit intelligent behavior, now known as the “Turing test.” He believed researchers should focus on areas that don’t require too much sensing and action, things like games and language translation. Research communities dedicated to concepts like computer vision, natural language understanding, and neural networks are, in many cases, several decades old.\nMIT physicist Rodney Brooks shared details on the four previous stages of AI:\n\n\nSymbolic AI (1956). Symbolic AI is also known as classical AI, or even GOFAI (good old-fashioned AI). The key concept here is the use of symbols and logical reasoning to solve problems. For example, we know a German shepherd is a dog, which is a mammal; all mammals are warm-blooded; therefore, a German shepherd should be warm-blooded.\nThe main problem with symbolic AI is that humans still need to manually encode their knowledge of the world into the symbolic AI system, rather than allowing it to observe and encode relationships on its own. As a result, symbolic AI systems struggle with situations involving real-world complexity. They also lack the ability to learn from large amounts of data.\nSymbolic AI was the dominant paradigm of AI research until the late 1980s.\n\n\nNeural networks (1954, 1969, 1986, 2012). Neural networks are the technology behind the recent explosive growth of gen AI. Loosely modeling the ways neurons interact in the human brain, neural networks ingest data and process it through multiple iterations that learn increasingly complex features of the data. The neural network can then make determinations about the data, learn whether a determination is correct, and use what it has learned to make determinations about new data. For example, once it “learns” what an object looks like, it can recognize the object in a new image.\nNeural networks were first proposed in 1943 in an academic paper by neurophysiologist Warren McCulloch and logician Walter Pitts. Decades later, in 1969, two MIT researchers mathematically demonstrated that neural networks could perform only very basic tasks. In 1986, there was another reversal, when computer scientist and cognitive psychologist Geoffrey Hinton and colleagues solved the neural network problem presented by the MIT researchers. In the 1990s, computer scientist Yann LeCun made major advancements in neural networks’ use in computer vision, while Jürgen Schmidhuber advanced the application of recurrent neural networks as used in language processing.\nIn 2012, Hinton and two of his students highlighted the power of deep learning. They applied Hinton’s algorithm to neural networks with many more layers than was typical, sparking a new focus on deep neural networks. These have been the main AI approaches of recent years.\n\n\nTraditional robotics (1968). During the first few decades of AI, researchers built robots to advance research. Some robots were mobile, moving around on wheels, while others were fixed, with articulated arms. Robots used the earliest attempts at computer vision to identify and navigate through their environments or to understand the geometry of objects and maneuver them. This could include moving around blocks of various shapes and colors. Most of these robots, just like the ones that have been used in factories for decades, rely on highly controlled environments with thoroughly scripted behaviors that they perform repeatedly. They have not contributed significantly to the advancement of AI itself.\nBut traditional robotics did have significant impact in one area, through a process called “simultaneous localization and mapping” (SLAM). SLAM algorithms helped contribute to self-driving cars and are used in consumer products like vacuum cleaning robots and quadcopter drones. Today, this work has evolved into behavior-based robotics, also referred to as haptic technology because it responds to human touch.\n\nBehavior-based robotics (1985). In the real world, there aren’t always clear instructions for navigation, decision making, or problem-solving. Insects, researchers observed, navigate very well (and are evolutionarily very successful) with few neurons. Behavior-based robotics researchers took inspiration from this, looking for ways robots could solve problems with partial knowledge and conflicting instructions. These behavior-based robots are embedded with neural networks.\n\nLearn more about QuantumBlack, AI by McKinsey.\nWhat is artificial general intelligence?\nThe term “artificial general intelligence” (AGI) was coined to describe AI systems that possess capabilities comparable to those of a human. In theory, AGI could someday replicate human-like cognitive abilities including reasoning, problem-solving, perception, learning, and language comprehension. But let’s not get ahead of ourselves: the key word here is “someday.” Most researchers and academics believe we are decades away from realizing AGI; some even predict we won’t see AGI this century, or ever. Rodney Brooks, an MIT roboticist and cofounder of iRobot, doesn’t believe AGI will arrive until the year 2300.\nThe timing of AGI’s emergence may be uncertain. But when it does emerge—and it likely will—it’s going to be a very big deal, in every aspect of our lives. Executives should begin working to understand the path to machines achieving human-level intelligence now and making the transition to a more automated world.\nFor more on AGI, including the four previous attempts at AGI, read our Explainer.\nWhat is narrow AI?\nNarrow AI is the application of AI techniques to a specific and well-defined problem, such as chatbots like ChatGPT, algorithms that spot fraud in credit card transactions, and natural-language-processing engines that quickly process thousands of legal documents. Most current AI applications fall into the category of narrow AI. AGI is, by contrast, AI that’s intelligent enough to perform a broad range of tasks.\nLearn more about QuantumBlack, AI by McKinsey.\nHow is the use of AI expanding?\nAI is a big story for all kinds of businesses, but some companies are clearly moving ahead of the pack. Our state of AI in 2022 survey showed that adoption of AI models has more than doubled since 2017—and investment has increased apace. What’s more, the specific areas in which companies see value from AI have evolved, from manufacturing and risk to the following:\n\nmarketing and sales\nproduct and service development \nstrategy and corporate finance\n\nOne group of companies is pulling ahead of its competitors. Leaders of these organizations consistently make larger investments in AI, level up their practices to scale faster, and hire and upskill the best AI talent. More specifically, they link AI strategy to business outcomes and “industrialize” AI operations by designing modular data architecture that can quickly accommodate new applications.\nWhat are the limitations of AI models? How can these potentially be overcome?\nWe have yet to see the longtail effect of gen AI models. This means there are some inherent risks involved in using them—both known and unknown.\nThe outputs gen AI models produce may often sound extremely convincing. This is by design. But sometimes the information they generate is just plain wrong. Worse, sometimes it’s biased (because it’s built on the gender, racial, and other biases of the internet and society more generally).\nIt can also be manipulated to enable unethical or criminal activity. Since gen AI models burst onto the scene, organizations have become aware of users trying to “jailbreak” the models—that means trying to get them to break their own rules and deliver biased, harmful, misleading, or even illegal content. Gen AI organizations are responding to this threat in two ways: for one thing, they’re collecting feedback from users on inappropriate content. They’re also combing through their databases, identifying prompts that led to inappropriate content, and training the model against these types of generations.\nBut awareness and even action don’t guarantee that harmful content won’t slip the dragnet. Organizations that rely on gen AI models should be aware of the reputational and legal risks involved in unintentionally publishing biased, offensive, or copyrighted content.\nThese risks can be mitigated, however, in a few ways. “Whenever you use a model,” says McKinsey partner Marie El Hoyek, “you need to be able to counter biases and instruct it not to use inappropriate or flawed sources, or things you don’t trust.” How? For one thing, it’s crucial to carefully select the initial data used to train these models to avoid including toxic or biased content. Next, rather than employing an off-the-shelf gen AI model, organizations could consider using smaller, specialized models. Organizations with more resources could also customize a general model based on their own data to fit their needs and minimize biases. \nIt’s also important to keep a human in the loop (that is, to make sure a real human checks the output of a gen AI model before it is published or used) and avoid using gen AI models for critical decisions, such as those involving significant resources or human welfare.\nIt can’t be emphasized enough that this is a new field. The landscape of risks and opportunities is likely to continue to change rapidly in the coming years. As gen AI becomes increasingly incorporated into business, society, and our personal lives, we can also expect a new regulatory climate to take shape. As organizations experiment—and create value—with these tools, leaders will do well to keep a finger on the pulse of regulation and risk.\nLearn more about QuantumBlack, AI by McKinsey.\nWhat is the AI Bill of Rights?\nThe Blueprint for an AI Bill of Rights, prepared by the US government in 2022, provides a framework for how government, technology companies, and citizens can collectively ensure more accountable AI. As AI has become more ubiquitous, concerns have surfaced about a potential lack of transparency surrounding the functioning of gen AI systems, the data used to train them, issues of bias and fairness, potential intellectual property infringements, privacy violations, and more. The Blueprint comprises five principles that the White House says should “guide the design, use, and deployment of automated systems to protect [users] in the age of artificial intelligence.” They are as follows:\n\nThe right to safe and effective systems. Systems should undergo predeployment testing, risk identification and mitigation, and ongoing monitoring to demonstrate that they are adhering to their intended use.\nProtections against discrimination by algorithms. Algorithmic discrimination is when automated systems contribute to unjustified different treatment of people based on their race, color, ethnicity, sex, religion, age, and more.\nProtections against abusive data practices, via built-in safeguards. Users should also have agency over how their data is used.\nThe right to know that an automated system is being used, and a clear explanation of how and why it contributes to outcomes that affect the user.\nThe right to opt out, and access to a human who can quickly consider and fix problems.\n\nAt present, more than 60 countries or blocs have national strategies governing the responsible use of AI (Exhibit 2). These include Brazil, China, the European Union, Singapore, South Korea, and the United States. The approaches taken vary from guidelines-based approaches, such as the Blueprint for an AI Bill of Rights in the United States, to comprehensive AI regulations that align with existing data protection and cybersecurity regulations, such as the EU’s AI Act, due in 2024.\nExhibit 2We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com\nThere are also collaborative efforts between countries to set out standards for AI use. The US–EU Trade and Technology Council is working toward greater alignment between Europe and the United States. The Global Partnership on Artificial Intelligence, formed in 2020, has 29 members including Brazil, Canada, Japan, the United States, and several European countries.\nEven though AI regulations are still being developed, organizations should act now to avoid legal, reputational, organizational, and financial risks. In an environment of public concern, a misstep could be costly. Here are four no-regrets, preemptive actions organizations can implement today:\n\nTransparency. Create an inventory of models, classifying them in accordance with regulation, and record all usage across the organization that is clear to those inside and outside the organization.\nGovernance. Implement a governance structure for AI and gen AI that ensures sufficient oversight, authority, and accountability both within the organization and with third parties and regulators.\nData, model, and technology management.\n\nData management. Proper data management includes awareness of data sources, data classification, data quality and lineage, intellectual property, and privacy management.\nModel management. Organizations should establish principles and guardrails for AI development and use them to ensure all AI models uphold fairness and bias controls.\nCybersecurity and technology management. Establish strong cybersecurity and technology to ensure a secure environment where unauthorized access or misuse is prevented.\n\n\nIndividual rights. Make users aware when they are interacting with an AI system, and provide clear instructions for use.\n\nHow can organizations scale up their AI efforts from ad hoc projects to full integration?\nMost organizations are dipping a toe into the AI pool—not cannonballing. Slow progress toward widespread adoption is likely due to cultural and organizational barriers. But leaders who effectively break down these barriers will be best placed to capture the opportunities of the AI era. And—crucially—companies that can’t take full advantage of AI are already being sidelined by those that can, in industries like auto manufacturing and financial services.\nTo scale up AI, organizations can make three major shifts:\n\nMove from siloed work to interdisciplinary collaboration. AI projects shouldn’t be limited to discrete pockets of organizations. Rather, AI has the biggest impact when it’s employed by cross-functional teams with a mix of skills and perspectives, enabling AI to address broad business priorities.\nEmpower frontline data-based decision making. AI has the potential to enable faster, better decisions at all levels of an organization. But for this to work, people at all levels need to trust the algorithms’ suggestions and feel empowered to make decisions. (Equally, people should be able to override the algorithm or make suggestions for improvement when necessary.)\nAdopt and bolster an agile mindset. The agile test-and-learn mindset will help reframe mistakes as sources of discovery, allaying the fear of failure and speeding up development.\n\nLearn more about QuantumBlack, AI by McKinsey, and check out AI-related job opportunities if you’re interested in working at McKinsey.\nPop quiz\nThey grow up so fastBy 2022, adoption of AI had grown by how much since 2017?How do you measure up? Only 0% of readers got this right.Sorry, that’s not it.In 2017, companies using AI saw the most value in manufacturing and risk management. By 2022, they were seeing the most value in marketing and sales, product and service development, and strategy and corporate finance.Take more quizzesData PointsA - More than 1.5 timesB - More than 2 timesC - More than 2.5 timesShifting gearsTo scale up AI, organizations can make three major shifts. Which of the following is NOT one of them?How do you measure up? Only 0% of readers got this right.Sorry, that’s not it.Organizations should shift from siloed work to interdisciplinary collaboration. AI is most effective when it’s being used by different teams with a range of varied talents to address broad business priorities.Take more quizzesData PointsA - Move toward a more direct collaboration between individuals and AI tools.B - Empower frontline, data-based decision making.C - Adopt and bolster an agile mindset.A new kind of networkThere are three types of artificial neural networks used in machine learning. Which of the following is NOT one of them?How do you measure up? Only 0% of readers got this right.Sorry, that’s not it.Feed-forward, convolutional, and recurrent neural networks are all based on the ways neurons interact in the human brain, ingesting data and processing it through multiple iterations that learn increasingly complex features.Take more quizzesData PointsA - Feed-forward neural networksB - Convolutional neural networks C - Abbreviated neural networks\nArticles referenced:\n\n“As gen AI advances, regulators—and risk functions—rush to keep pace,” December 21, 2023, Andreas Kremer, Angela Luget, Daniel Mikkelsen, Henning Soller, Malin Strandell-Jansson, and Sheila Zingg\n“What is generative AI?,” January 19, 2023\n“Tech highlights from 2022—in eight charts,” December 22, 2022 \n“Generative AI is here: How tools like ChatGPT could change your business,” December 20, 2022, Michael Chui, Roger Roberts, and Lareina Yee \n“The state of AI in 2022—and a half decade in review,” December 6, 2022, Michael Chui, Bryce Hall, Helen Mayhew, Alex Singla, and Alex Sukharevsky \n“Why businesses need explainable AI—and how to deliver it,” September 29, 2022, Liz Grennan, Andreas Kremer, Alex Singla, and Peter Zipparo \n“Why digital trust truly matters,” September 12, 2022, Jim Boehm, Liz Grennan, Alex Singla, and Kate Smaje\n“McKinsey Technology Trends Outlook 2023,” July 20, 2023, Michael Chui, Mena Issler, Roger Roberts, and Lareina Yee \n“An AI power play: Fueling the next wave of innovation in the energy sector,” May 12, 2022, Barry Boswell, Sean Buckley, Ben Elliott, Matias Melero, and Micah Smith \n“Scaling AI like a tech native: The CEO’s role,” October 13, 2021, Jacomo Corbo, David Harvey, Nicolas Hohn, Kia Javanmardian, and Nayur Khan\n“What the draft European Union AI regulations mean for business,” August 10, 2021, Misha Benjamin, Kevin Buehler, Rachel Dooley, and Peter Zipparo\n“Winning with AI is a state of mind,” April 30, 2021, Thomas Meakin, Jeremy Palmer, Valentina Sartori, and Jamie Vickers \n“Breaking through data-architecture gridlock to scale AI,” January 26, 2021, Sven Blumberg, Jorge Machado, Henning Soller, and Asin Tavakoli \n“An executive’s guide to AI,” November 17, 2020, Michael Chui, Brian McCarthy, and Vishnu Kamalnath\n“Executive’s guide to developing AI at scale,” October 28, 2020, Nayur Khan, Brian McCarthy, and Adi Pradhan\n“An executive primer on artificial general intelligence,” April 29, 2020, Federico Berruti, Pieter Nel, and Rob Whiteman\n“The analytics academy: Bridging the gap between human and artificial intelligence,” McKinsey Quarterly, September 25, 2019, Solly Brown, Darshit Gandhi, Louise Herring, and Ankur Puri \n\nThis article was updated in April 2024; it was originally published in April 2023.\nWant to know more about AI?Talk to usRelated ArticlesArticleTen unsung digital and AI ideas shaping businessPodcastDriving innovation with generative AIArticleAs gen AI advances, regulators—and risk functions—rush to keep paceSign up for our Monthly Highlights newsletterDon't miss this roundup of our newest and most distinctive insightsSubscribeSign up for our Monthly Highlights newsletterWe use cookies to give you the best possible experience with mckinsey.com. Some are essential for this site to function; others help us understand how you use the site, so we can improve it. We may also use cookies for targeting purposes. Click “Accept all cookies” to proceed as specified, “Decline optional cookies” to accept only essential cookies, or click “Manage my preferences” to choose what cookie types you will accept.Cookie NoticeAccept All CookiesDecline optional cookies Manage my preferencesPrivacy Preference CenterMcKinsey and our trusted partners use cookies and similar technologies to access and use your data for the purposes listed below. Please provide your consent for cookie usage on this website. Enable one or more of the cookie types listed below, and then save your preferences.\n            Cookie NoticeAccept all cookies Manage Consent PreferencesPerformance Cookies  Performance Cookies These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site and app. They help us to know which pages are the most and least popular and see how visitors move around the site and app. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site or app, and will not be able to monitor its performance.Cookie details‎Functional Cookies  Functional Cookies These cookies enable the website and app to provide enhanced functionality and personalization. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.Cookie details‎Targeting Cookies  Targeting Cookies These cookies may be set through our site or app by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.Cookie details‎Strictly Necessary CookiesAlways ActiveThese cookies are necessary for the website and app to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site and app will not then work. These cookies do not store any personally identifiable information.Cookie details‎Back ButtonPerformance Cookies  Search IconFilter IconClear checkbox label labelApply CancelConsent Leg.Interest checkbox label label checkbox label label checkbox label labelView CookiesNamecookie name Save my preferences"