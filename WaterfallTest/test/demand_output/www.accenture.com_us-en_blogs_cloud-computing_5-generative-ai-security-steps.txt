"\n\n5 Steps to Make Sure Generative AI is Secure AI | Accenture\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to main content\nSkip to footer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMenu\n\n\n\n\n \nAccenture\n\n\n \n\n\nAccenture\n\n\n\n\n\n\n\n\nClose Menu\n\n\n\n\n\nWhat we do\n\n \n\n\n\n\n\nBack\n\n\n\nWhat we do\n\n\n\n\n\nCapabilities\nCapabilities\n\nCloud \n\t\t\t\nCybersecurity \n\t\t\t\nData and Artificial Intelligence \n\t\t\t\nDigital Engineering and Manufacturing \n\t\t\t\nEmerging Technology \n\t\t\t\nEnterprise Platforms \n\t\t\t\nFinance and Risk Management \n\t\t\t\nLearning \n\t\t\t\nMarketing and Experience \n\t\t\t\nMetaverse \n\t\t\t\nPrivate Equity \n\t\t\t\nSales and Commerce \n\t\t\t\nStrategic Managed Services \n\t\t\t\nStrategy \n\t\t\t\nSupply Chain \n\t\t\t\nSustainability \n\t\t\t\nTalent and Organization \n\t\t\t\nTechnology Transformation \n\t\t\t\n\n\n\nIndustries\nIndustries\n\nAerospace and Defense \n\t\t\t\nAutomotive \n\t\t\t\nBanking \n\t\t\t\nCapital Markets \n\t\t\t\nChemicals \n\t\t\t\nCommunications and Media \n\t\t\t\nConsumer Goods and Services \n\t\t\t\nEnergy \n\t\t\t\nHealth \n\t\t\t\nHigh Tech \n\t\t\t\nIndustrial \n\t\t\t\nInsurance \n\t\t\t\nLife Sciences \n\t\t\t\nNatural Resources \n\t\t\t\nPublic Service \n\t\t\t\nRetail \n\t\t\t\nSoftware and Platforms \n\t\t\t\nTravel \n\t\t\t\nUS Federal Government \n\t\t\t\nUtilities \n\t\t\t\n\n\n\n\n\n\n\n\n\n\nWhat we think\n\n\n\nWho we are\n\n \n\n\n\n\n\nBack\n\n\n\nAbout Accenture\n\n\n\n\n\nOur organization\nOur organization\n\nLeaders \n\t\t\t\nLocations \n\t\t\t\n360° Value Report \n\t\t\t\n\n\n\nMedia & Investors\nMedia & Investors\n\nMedia Relations \n\t\t\t\nInvestor Relations \n\t\t\t\n\n\n\nHow we serve\nHow we serve\n\nStrategy and Consulting \n\t\t\t\nTechnology \n\t\t\t\nOperations \n\t\t\t\nIndustry X \n\t\t\t\nSong \n\t\t\t\n\n\n\n\n\n\n\n\n\n\nCareers\n\n \n\n\n\n\n\nBack\n\n\n\nCareers homepage\n\n\n\n\n\nFind a job\nFind a job\n\nSearch for jobs \n\t\t\t\n\n\n\nLife at Accenture\nLife at Accenture\n\nWorking here \n\t\t\t\nBenefits \n\t\t\t\nOur communities \n\t\t\t\nWork environment \n\t\t\t\nCareers blog \n\t\t\t\n\n\n\nHow we hire\nHow we hire\n\nHiring journey \n\t\t\t\nPro tips \n\t\t\t\n\n\n\n\n\n\n\n\n\n\n\n\nContact Us\n\n\nCareers\n\n\nLocations\n\n\n\n\nlinkedin\n\n\n\nfacebook\n\n\n\ninstagram\n\n\n\n\n\n\n\n\nSearch\n\n\n\n\n\nUSA\n\n\nCurrent Country: United States\n\n\n\n\n\nDefault (English)\nAll COUNTRIES & LANGUAGES\nArgentina (Spanish)\n\nAustralia (English)\n\nAustria (German) \n\nBelgium (English)\n\nBrazil (Portuguese)\n\nBulgaria (English)\n\nCanada (English)\n\nCanada (French) \n\nChile (Spanish)\n\nChina/Hong Kong SAR (English)\n\nChina/Mainland (Chinese)\n\nChina/Mainland (English)\n\nColombia (Spanish)\n\nCosta Rica (English)\n\nCzech Republic (English)\n\nDenmark (English)\n\nFinland (English)\n\nFrance (French)\n\nGermany (German)\n\nGreece (English)\n\nHungary (English)\n\nIndia (English)\n\nIndonesia (English)\n\nIreland  (English)\n\nIsrael (English)\n\nItaly (Italian)\n\nJapan (Japanese)\n\nLatvia (English)\n\nLuxembourg (English)\n\nMalaysia (English)\n\nMauritius (English)\n\nMexico (Spanish)\n\nMorocco (English)\n\nNetherlands (English)\n\nNew Zealand (English)\n\nNorway (English)\n\nPhilippines (English)\n\nPoland (English)\n\nPoland (Polish)\n\nPortugal (Portuguese)\n\nRomania (English)\n\nSaudi Arabia (English)\n\nSingapore (English)\n\nSlovakia (English)\n\nSouth Africa (English)\n\nSpain (Spanish)\n\nSweden (English)\n\nSwitzerland (English)\n\nThailand (English)\n\nUAE (English)\n\nUnited Kingdom (English)\n\nUSA (English)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog\n\n5 steps to make sure generative AI is secure AI\nBoth business leaders and employees are excited to leverage generative AI. Understanding the risk landscape and proactively preparing can help organizations reap value securely.\n\n\n\t\t\t\t\t\t5-MINUTE READ\nJune 12, 2023\n\n\n\n\n\n\n\n\n\n\nChatGPT’s meteoric rise has captured the business world’s attention at a pace and on a scale rarely seen before. But this represents only one part of a broader generative AI revolution. Thanks to advances in large language models (LLMs) and other foundation models, we’re witnessing a step change in AI capability across multiple domains—images, audio, video and text.\nThis is allowing machines, for the first time, to be computationally creative, generating meaningful and valuable content on demand. And the power, broad downstream adaptability and easy accessibility of this technology means every company, in every industry, will be impacted.\nBusiness leaders are right to be excited about the opportunities. As are employees, many of whom are eager to get started with the technology. However, both groups need to be highly attuned to the business and security risks they may be incurring—and how those risks can be minimized.\nSome critical areas of focus when considering cybersecurity for generative AI include:\nData & IP Leakage & TheftMalicious content, High Speed Contextual Targeted AttacksOrchestration of generative technologies for misuseMisinformation at scaleCopyright infringement / plagiarismAmplification of existing biases and discrimination\nThe truth is, generative AI projects and products come with a heightened risk of compromise—that requires a well planned and executed security strategy at the start. So, what practical actions should C-suite leaders take now to securely leverage generative AI across their business?\nI recently sat down with Tom Patterson, Managing Director – Emerging Technology and Security, to discuss this question that is of great importance to our clients. Together, we’ve come up with a list of our top-five security recommendations for using generative AI in an enterprise context.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurity implications across the layers of generative AI.\n\n\n\n\n\n\n\n\n1. Create a trusted environment and minimize risk of data loss\nA top business concern about providing access to applications like ChatGPT is the risk of intellectual property or other protected data, leaking out of the organization.\nThe risk is real. Employees looking to save time, ask questions, gain insights or simply experiment with the technology can easily transmit confidential data—whether they mean to or not—through the prompts given to generative AI applications.\nThe good news is that, with a bit of upfront technical effort, this risk can be minimized by thinking through specific use cases for enabling access to generative AI applications while looking at the risk based on where data flows. Tom offered us some examples:\nFor example: The risks of data leakage lie primarily at the application layer, rather than the chat LLM layer, OpenAI. So, companies can build a custom front-end that replaces the ChatGPT interface to leverage the chat LLM API (OpenAI) directly. Voila…we’ve bypassed the ChatGPT application and mitigated the risk.\nAnother example is creating a sandbox where data is isolated. The sandbox is the gateway for consumption of LLM services, and other filters can be added to safeguard data and reduce bias.”\nFurther data requirements for each use case might mean that sensitive data needs to remain under a company’s direct control and can be kept in a trusted enclave or environment. In other cases, less sensitive data can be exchanged with a hosted service, especially those that can separate data in a standalone environment.\n“Trust by design” is a critical step in building and operating successful systems.\n2. Start training your employees now\nIt’s incredible to see that ChatGPT has seen the fastest adoption of any consumer app in history.\nBut this groundswell of organic demand creates a problem for business leaders. Many employees are learning about the technology independently via social channels and the media, leaving room for misinformation. They often have no way of knowing what’s right and what’s wrong. And the fact that they can access these applications via their own smartphones and laptops can end up creating a new kind of “shadow IT” and introducing new cybersecurity threats.\nThat’s why a program of workforce training is both essential and urgent.\n\n\n\n\n\n\n\n\n\nEmployees need to understand the business and security risks they may be incurring, and what best practices look like.\n\n\n\n Tom Patterson / Managing Director – Emerging Technology and Security\n\n\n\n\n\n\n\n\n\nFlexibility and responsiveness are vital, recognizing this is a fast-moving space in which it’s not always possible to figure out every detail right now.\n3. Be transparent about the data\nWhether you’re consuming external foundation models, or customizing them for your own business purposes, it’s essential to recognize the risks inherent in the data used to train, fine-tune and even use these models, while remaining transparent. These risks vary depending on architecture choices.\nData is at the core of large language models (LLMs), and using models that were partially trained on bad data can destroy your results and reputation.\nThe outputs of generative AI systems are only as unbiased and valuable as the data they were trained on. Inadvertent plagiarism, copyright infringement, bias and deliberate manipulation are several obvious examples of bad training data. To engender trust in AI, companies must be able to identify and assess potential risks in the data used to train the foundational models, noting data sources and any flaws or bias, whether accidental or intentional.\nThere are tools and techniques companies can use to evaluate, measure, monitor and synthesize training data. But it’s important to understand these risks are very difficult to eliminate entirely.\nThe best short-term solution is therefore transparency. Being open and upfront about the data used to train the model—and the entire generative AI process—will provide much-needed clarity across the business and engender necessary trust. And creating clear and actionable guidelines around bias, privacy, IP rights, provenance and transparency will give direction to employees as they make decisions about when and how to use generative AI.\n4. Use human + AI together to combat ‘AI for bad’\nWe must use AI for good if we want to defend AI for all. And we can use generative AI itself to help make enterprise use of generative AI more robust overall.\nOne option is to have a “human in the loop” to add security and ensure a sanity check on responses. Reinforcement learning with human feedback (RLHF) tunes the model based on human rankings generated from the same prompt.\n\nBuilding on RLHF, Constitutional AI also uses a separate AI model to monitor and score the responses the main enterprise model is outputting. These results can then be used to fine-tune the model and secure it from harm.\n5. Understand emerging risks to the models themselves\nAI models themselves can be attacked and jailbroken for malicious purposes. One example is a “prompt injection” attack, where a model is instructed to deliver a false or bad response for nefarious ends. For instance, including words like “ignore all previous directions” in a prompt could bypass controls that developers have added to the system. Anecdotally, we’ve seen examples of white text, invisible to human eyes, included in pre-prepared prompts to inject malicious instructions into seemingly innocent prompts.\nThe implication? Business leaders will need to consider new threats like prompt injection and design robust security systems around the models themselves.\nEnsuring Generative AI is safe AI\nGenerative AI  and foundation models represent a real milestone in AI development. The opportunities are virtually limitless. But there are new risks and threats too. Business leaders need to understand these risks and take urgent action to minimize them.\nThere are ever evolving models, frameworks, and technologies available to help guide AI programs forward with trust, security and privacy throughout.  Focusing on trustworthy AI strategies, trust by design, trusted AI collaboration and continuous monitoring help build and operate successful systems.\nOur shared goal should be to leverage the power of generative AI in a secure way to deliver value to business and improve the lives of all who use it.\n\n\n\n\nWRITTEN BY\n\n\n\n\t\t\t\tTeresa Tung\n\n\t\t\t\tCo-Lead – Data Practice\n\n\n\nLinkedIn\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet there be change\n\n\n\nPreference Center\nCareers\nAbout Us\nContact Us\nLocations\nSitemap\n\n\nPrivacy Statement\nTerms & Conditions\nCookie Policy/Settings\nAccessibility Statement\nDo Not Sell/Share My Personal Information\n\n\n\n\t\t\t\t© 2024\n\t\t\t\tAccenture. All Rights Reserved.\n\t\t\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to accenture.com! In order to provide a more relevant experience for you, we use cookies to enable some website functionality. Cookies help us see which articles most interest you; allow you to easily share articles on social media; permit us to deliver content, jobs and ads tailored to your interests and locations; and provide many other site benefits. For more information, please review our Cookies Policy and Privacy Statement.Cookies Settings Reject All Accept All CookiesPrivacy Preference CenterAny web site that you visit may store or retrieve personal information, mostly through the use of cookies. The stored or retrieved information might be about you, your preferences or your device and is used for the purposes specified per cookies category below. The data controller of your data processed through our cookies is Accenture PLC. In addition, some cookies we use are from (and controlled by) third-party companies, such as, Facebook, Microsoft, Marketo Munchkin Tracking, Twitter, Knotch, Youtube, Instagram, Yoptima and Linkedin Analytics to provide us with web analytics and intelligence about our sites. You can accept the cookies as per your preferences by activating the sliders per cookies category. By accepting cookies, the functionalities described per cookies category will be activated and by not accepting cookies, such functionalities will not be activated. Because we respect your right to privacy, you can choose not to allow some types of cookies and you have the right to withdraw your consent by adapting your preferences in our cookie consent manager. Click on the different category headings to find out more and change our default settings. Please read our Cookies Policy for more information.Allow All Manage Consent PreferencesStrictly Necessary CookiesAlways ActiveThese cookies are essential in order to enable you to move around the site and use its features, such as accessing secure areas of the site. Without these cookies, services you have asked for cannot be provided.Cookie Details‎First Party Analytics Cookies  First Party Analytics Cookies These cookies allow us to employ data analytics so we can measure and improve the performance of our site and provide more relevant content to you. These cookies don't collect information that identifies a visitor down to an individual level that is available to us. These cookies are not passing personally identifiable information to any external third party other than in limited cases when we engage a service provider to act on our behalf but who is then unable to use the data for their own purposes.Cookie Details‎Performance Cookies and Functional Cookies  Performance Cookies and Functional Cookies Performance cookies are generally third-party cookies from vendors we work with or who work on our behalf that collect information about your visit and use of the Accenture website, for instance which pages you visit the most often, and if you get error messages from web pages. These cookies don't collect information that identifies a visitor. All information these cookies collect is anonymous and is only used to improve how the website works. Third party vendors may have access to this data and may use it to improve their overall services and offerings.\n\n\n\nFunctionality cookies allow a site to remember choices you make (such as your user name, language or the region you are in) and provide more enhanced, personal features. These cookies cannot track your browsing activity on other websites. They don’t gather any information about you that could be used for advertising or remembering where you’ve been on the Internet outside our site.\nCookie Details‎Advertising and Social Media Cookies  Advertising and Social Media Cookies Third-party advertising and social media cookies are used to (1) deliver advertisements more relevant to you and your interests; (2) limit the number of times you see an advertisement; (3) help measure the effectiveness of the advertising campaign; and (4) understand people’s behavior after they view an advertisement. They are usually placed on behalf of advertising networks with the site operator’s permission. They remember that you have visited a site and quite often they will be linked to site functionality provided by the other organization. This may impact the content and messages you see on other websites you visit. If you do not allow these cookies you may not be able to use or see these sharing tools or play certain videos on our site.Cookie Details‎Back ButtonCookie List Search IconFilter IconClear checkbox label labelApply CancelConsent Leg.Interest checkbox label label checkbox label label checkbox label labelReject All Confirm My Choices"