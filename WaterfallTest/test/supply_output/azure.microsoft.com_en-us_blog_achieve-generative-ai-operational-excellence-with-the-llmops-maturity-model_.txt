"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAchieve generative AI operational excellence with the LLMOps maturity model | Microsoft Azure Blog\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nSkip to main content\n\n\n\n\n\n\n\nMicrosoft\n\n\n\nAzure\n\n\n\n\nAzure\n\n\n\n\n                            Azure\n                        \n\n\n\n\n Home \n\n\n\nExplore\n\n\nGet to know Azure\n\n\nGlobal infrastructure\n\n\nFinOps on Azure\n\n\nAzure Essentials\n\n\nCustomer stories\n\n\nAzure innovation insights\n\n\n\n \n\nProducts\n\n\nPopular\nPopular\n\n\nView all products (200+)\n\n\nAzure Virtual Machines\n\n\nAzure Virtual Desktop\n\n\nAzure SQL\n\n\nMicrosoft Copilot in Azure PREVIEW\n\n\nAzure AI Services\n\n\nAzure AI Studio\n\n\nAzure Cosmos DB\n\n\nAzure Kubernetes Service (AKS)\n\n\nAzure Arc​\n\n\nAzure Migrate\n\n\n\n\nAI + machine learning\nAI + machine learning\n\n\nAzure Machine Learning\n\n\nAzure AI Services\n\n\nMicrosoft Copilot in Azure PREVIEW\n\n\nAzure OpenAI Service\n\n\nAzure AI Studio\n\n\nAzure AI Vision\n\n\nAzure AI Search\n\n\nAzure AI Bot Service\n\n\nAzure Databricks\n\n\nAzure AI Language\n\n\n\n\nCompute\nCompute\n\n\nAzure Virtual Machines\n\n\nAzure Kubernetes Service (AKS)\n\n\nLinux virtual machines in Azure\n\n\nSQL Server on Azure Virtual Machines\n\n\nWindows Virtual Machines\n\n\nAzure Functions\n\n\nAzure Virtual Machine Scale Sets\n\n\nAzure Spot Virtual Machines\n\n\nAzure Container Apps\n\n\nAzure Compute Fleet\n\n\n\n\nContainers\nContainers\n\n\nAzure Kubernetes Service (AKS)\n\n\nAzure App Service\n\n\nAzure Functions\n\n\nAzure Container Instances​\n\n\nAzure Spring Apps\n\n\nAzure Red Hat OpenShift\n\n\nAzure Kubernetes Fleet Manager PREVIEW\n\n\nAzure Container Apps\n\n\nAzure Container Registry\n\n\nApp Configuration\n\n\n\n\nHybrid + multicloud\nHybrid + multicloud\n\n\nAzure Arc​\n\n\nAzure Stack\n\n\nMicrosoft Sentinel\n\n\nAzure SQL\n\n\nMicrosoft Defender for Cloud\n\n\nAzure ExpressRoute\n\n\nAzure DevOps\n\n\nAzure Database for PostgreSQL\n\n\nAzure IoT Edge\n\n\nAzure Monitor\n\n\n\n\nAnalytics\nAnalytics\n\n\nAzure Synapse Analytics\n\n\nAzure Databricks\n\n\nMicrosoft Purview\n\n\nAzure Data Factory\n\n\nAzure Machine Learning\n\n\nMicrosoft Fabric\n\n\nHDInsight\n\n\nAzure Data Explorer\n\n\nAzure Data Lake Storage\n\n\nAzure Operator Insights\n\n\n\n\n\n \n\nSolutions\n\n\nFeatured\nFeatured\n\n\nView all solutions (40+)\n\n\nAzure AI\n\n\nMigrate to innovate in the era of AI\n\n\nBuild and modernize intelligent apps\n\n\nCloud-scale analytics\n\n\nAzure AI Infrastructure\n\n\nAdaptive cloud\n\n\nAzure network security\n\n\n\n\nAI\nAI\n\n\nAzure AI\n\n\nResponsible AI with Azure\n\n\nAzure AI Infrastructure\n\n\nBuild and modernize intelligent apps\n\n\nKnowledge mining\n\n\nHugging Face on Azure\n\n\nAzure confidential computing\n\n\n\n\nApplication development\nApplication development\n\n\nBuild and modernize intelligent apps\n\n\nDevelopment and testing\n\n\nDevOps\n\n\nDevSecOps\n\n\nServerless computing\n\n\nApplication and Data Modernization\n\n\nLow-code application development on Azure\n\n\n\n\nCloud migration and modernization\nCloud migration and modernization\n\n\nMigration and modernization center\n\n\nMigrate to innovate in the era of AI\n\n\nBuild and modernize intelligent apps​\n\n\n.NET apps migration\n\n\nDevelopment and testing\n\n\nSQL Server migration\n\n\nWindows Server on Azure\n\n\nLinux on Azure\n\n\nSAP on the Microsoft Cloud\n\n\nOracle on Azure\n\n\n\n\nHybrid Cloud and infrastructure\nHybrid Cloud and infrastructure\n\n\nHybrid and multicloud solutions\n\n\nBackup and disaster recovery\n\n\nWindows Server on Azure\n\n\nHigh-performance computing (HPC)\n\n\nBusiness-critical applications\n\n\nQuantum computing\n\n\n5G and Space\n\n\n\n\nResources\nResources\n\n\nReference architectures\n\n\nResources for accelerating growth\n\n\nAzure Marketplace\n\n\nAzure Essentials\n\n\nBrowse the Microsoft Business Solutions Hub\n\n\n\n\n\n \n\nPricing\n\n\nHow to buy\nHow to buy\n\n\nAzure pricing\n\n\nFree Azure services\n\n\nAzure account\n\n\nFlexible purchase options\n\n\nAzure benefits and incentives\n\n\n\n\nPricing tools and resources\nPricing tools and resources\n\n\nPricing calculator\n\n\nTCO calculator\n\n\nOptimize your costs\n\n\nFinOps on Azure\n\n\n\n\n\n \n\nPartners\n\n\nFind a partner\nFind a partner\n\n\nAzure Marketplace\n\n\nFind a partner\n\n\n\n\nBecome a partner\nBecome a partner\n\n\nAzure Partner Zone\n\n\nAzure technology partners\n\n\nJoin ISV Success\n\n\n\n\n\n \n\nResources\n\n\nLearning\nLearning\n\n\nGet started with Azure\n\n\nTraining and certifications\n\n\nCustomer stories\n\n\nAnalyst reports, white papers, and e-books\n\n\nVideos\n\n\nLearn more about cloud computing\n\n\n\n\nTechnical resources\nTechnical resources\n\n\nDocumentation\n\n\nGet the Azure mobile app\n\n\nDeveloper resources\n\n\nQuickstart templates\n\n\nResources for startups\n\n\n\n\nCommunity\nCommunity\n\n\nDeveloper community\n\n\nStudents\n\n\nDeveloper stories\n\n\n\n\nWhat's new\nWhat's new\n\n\nBlog\n\n\nEvents and Webinars\n\n\n\n\n\n \nLearn\n\n\nSupport\n\n\nContact Sales\n\n\nGet started with Azure\n\n\nSign in\n\n\n\nMore\n\n\n\n\n\n\n\n \n\n\n\n All Microsoft\n\n\nGlobal\n\n\nMicrosoft 365\n\n\nTeams\n\n\nCopilot\n\n\nWindows\n\n\nSurface\n\n\nXbox\n\n\nDeals\n\n\nSmall Business\n\n\nSupport\n\n\n\n\nSoftware\nSoftware\n\n\nWindows Apps\n\n\nAI\n\n\nOutlook\n\n\nOneDrive\n\n\nMicrosoft Teams\n\n\nOneNote\n\n\nMicrosoft Edge\n\n\nSkype\n\n\n\n\nPCs & Devices  \nPCs & Devices  \n\n\nComputers\n\n\nShop Xbox\n\n\nAccessories\n\n\nVR & mixed reality\n\n\nCertified Refurbished\n\n\nTrade-in for cash\n\n\n\n\nEntertainment\nEntertainment\n\n\nXbox Game Pass Ultimate\n\n\nPC Game Pass\n\n\nXbox games\n\n\nPC and Windows games\n\n\nMovies & TV\n\n\n\n\nBusiness\nBusiness\n\n\nMicrosoft Cloud\n\n\nMicrosoft Security\n\n\nDynamics 365\n\n\nMicrosoft 365 for business\n\n\nMicrosoft Power Platform\n\n\nWindows 365\n\n\nMicrosoft Industry\n\n\nSmall Business\n\n\n\n\nDeveloper & IT  \nDeveloper & IT  \n\n\nAzure\n\n\nDeveloper Center\n\n\nDocumentation\n\n\nMicrosoft Learn\n\n\nMicrosoft Tech Community\n\n\nAzure Marketplace\n\n\nAppSource\n\n\nVisual Studio\n\n\n\n\nOther\nOther\n\n\nMicrosoft Rewards \n\n\nFree downloads & security\n\n\nEducation\n\n\nGift cards\n\n\nLicensing\n\n\nUnlocked stories\n\n\n\n\nView Sitemap\n\n\n\n\n\n\n\n\n\n\nSearch\nShow search input\n\n\n\n\n No results\n\n\n\n\nCancel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Home / Management and governance / Achieve generative AI operational excellence with the LLMOps maturity model\n\n\n\n\n\n\t\tSearch for:\t\n\n\n Submit search\n\n\n\n\n\n\n\n\n\n\nPublished Jan 30, 2024\n\n\n\t\t\t\t7 min read\t\t\t\n\n\nAchieve generative AI operational excellence with the LLMOps maturity model\n\nBy David Seda, General Manager, Azure AI\t\n \n\n\n\n\n\n\t\tShare\t\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n\n\n\n\n\t\t\t\t\tContent type\t\t\t\t\n\n\n\t\t\t\t\t\tBest practices\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tThought leadership\t\t\t\t\t\n\n\n\n\n\t\t\t\t\tTag\t\t\t\t\n\n\n\t\t\t\t\t\tLLMOps\t\t\t\t\t\n\n\n\n\n\t\t\t\t\tAudience\t\t\t\t\n\n\n\t\t\t\t\t\tBusiness decision makers\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tData professionals\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tDevelopers\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tIT decision makers\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tIT implementors\t\t\t\t\t\n\n\n\n\n\t\t\t\t\tProduct\t\t\t\t\n\n\n\t\t\t\t\t\tAzure AI\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tAzure AI Content Safety\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tAzure AI Search\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tAzure AI Studio\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tAzure Machine Learning\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tAzure OpenAI Service\t\t\t\t\t\n\n\n\n\n\n\n\n\n\t\t\tIn our LLMOps blog series, we’ve explored various dimensions of Large Language Models (LLMs) and their responsible use in AI operations. Elevating our discussion, we now introduce the LLMOps maturity model, a vital compass for business leaders.\t\t\n\n\nThis is the fourth blog in our series on LLMOps for business leaders. Read the first, second, and third articles to learn more about LLMOps on Azure AI.\nIn our LLMOps blog series, we’ve explored various dimensions of Large Language Models (LLMs) and their responsible use in AI operations. Elevating our discussion, we now introduce the LLMOps maturity model, a vital compass for business leaders. This model is not just a roadmap from foundational LLM utilization to mastery in deployment and operational management; it’s a strategic guide that underscores why understanding and implementing this model is essential for navigating the ever-evolving landscape of AI. Take, for instance, Siemens’ use of Microsoft Azure AI Studio and prompt flow to streamline LLM workflows to help support their industry leading product lifecycle management (PLM) solution Teamcenter and connect people who find problems with those who can fix them. This real-world application exemplifies how the LLMOps maturity model facilitates the transition from theoretical AI potential to practical, impactful deployment in a complex industry setting.\nExploring application maturity and operational maturity in Azure\nThe LLMOps maturity model presents a multifaceted framework that effectively captures two critical aspects of working with LLMs: the sophistication in application development and the maturity of operational processes.  \nApplication maturity: This dimension centers on the advancement of LLM techniques within an application. In the initial stages, the emphasis is placed on exploring the broad LLM capabilities, often progressing towards more intricate techniques like fine-tuning and Retrieval Augmented Generation (RAG) to meet specific needs.  \nOperational maturity: Regardless of the complexity of LLM techniques employed, operational maturity is essential for scaling applications. This includes systematic deployment, robust monitoring, and maintenance strategies. The focus here is on ensuring that the LLM applications are reliable, scalable, and maintainable, irrespective of their level of sophistication. \nThis maturity model is designed to reflect the dynamic and ever-evolving landscape of LLM technology, which requires a balance between flexibility and a methodical approach. This balance is crucial in navigating the continuous advancements and exploratory nature of the field. The model outlines various levels, each with its own rationale and strategy for progression, providing a clear roadmap for organizations to enhance their LLM capabilities. \nLLMOps maturity model \n\nLevel One—Initial: The foundation of exploration \nAt this foundational stage, organizations embark on a journey of discovery and foundational understanding. The focus is predominantly on exploring the capabilities of pre-built LLMs, such as those offered by Microsoft Azure OpenAI Service APIs or Models as a Service (MaaS) through inference APIs. This phase typically involves basic coding skills for interacting with these APIs, gaining insights into their functionalities, and experimenting with simple prompts. Characterized by manual processes and isolated experiments, this level doesn’t yet prioritize comprehensive evaluations, monitoring, or advanced deployment strategies. Instead, the primary objective is to understand the potential and limitations of LLMs through hands-on experimentation, which is crucial in understanding how these models can be applied to real-world scenarios. \nAt companies like Contoso1, developers are encouraged to experiment with a variety of models, including GPT-4 from Azure OpenAI Service and LLama 2 from Meta AI. Accessing these models through the Azure AI model catalog allows them to determine which models are most effective for their specific datasets. This stage is pivotal in setting the groundwork for more advanced applications and operational strategies in the LLMOps journey. \nLevel Two—Defined: Systematizing LLM app development \nAs organizations become more proficient with LLMs, they start adopting a systematic method in their operations. This level introduces structured development practices, focusing on prompt design and the effective use of different types of prompts, such as those found in the meta prompt templates in Azure AI Studio. At this level, developers start to understand the impact of different prompts on the outputs of LLMs and the importance of responsible AI in generated content.\nAn important tool that comes into play here is Azure AI prompt flow. It helps streamline the entire development cycle of AI applications powered by LLMs, providing a comprehensive solution that simplifies the process of prototyping, experimenting, iterating, and deploying AI applications. At this point, developers start focusing on responsibly evaluating and monitoring their LLM flows. Prompt flow offers a comprehensive evaluation experience, allowing developers to assess applications on various metrics, including accuracy and responsible AI metrics like groundedness. Additionally, LLMs are integrated with RAG techniques to pull information from organizational data, allowing for tailored LLM solutions that maintain data relevance and optimize costs.  \nFor instance, at Contoso, AI developers are now utilizing Azure AI Search to create indexes in vector databases. These indexes are then incorporated into prompts to provide more contextual, grounded and relevant responses using RAG with prompt flow. This stage represents a shift from basic exploration to a more focused experimentation, aimed at understanding the practical use of LLMs in solving specific challenges.\nLevel Three—Managed: Advanced LLM workflows and proactive monitoring  \nDuring this stage, the focus shifts to refined prompt engineering, where developers work on creating more complex prompts and integrating them effectively into applications. This involves a deeper understanding of how different prompts influence LLM behavior and outputs, leading to more tailored and effective AI solutions.  \nAt this level, developers harness prompt flow’s enhanced features, such as plugins and function callings, for creating sophisticated flows involving multiple LLMs. They can also manage various versions of prompts, code, configurations, and environments via code repositories, with the capability to track changes and rollback to previous versions. The iterative evaluation capabilities of prompt flow become essential for refining LLM flows, by conducting batch runs, employing evaluation metrics like relevance, groundedness, and similarity. This allows them to construct and compare various metaprompt variations, determining which ones yield higher quality outputs that align with their business objectives and responsible AI guidelines. \nIn addition, this stage introduces a more systematic approach to flow deployment. Organizations start implementing automated deployment pipelines, incorporating practices such as continuous integration/continuous deployment (CI/CD). This automation enhances the efficiency and reliability of deploying LLM applications, marking a move towards more mature operational practices.  \nMonitoring and maintenance also evolve during this stage. Developers actively track various metrics to ensure robust and responsible operations. These include quality metrics like groundedness and similarity, as well as operational metrics such as latency, error rate, and token consumption, alongside content safety measures.  \nAt this stage in Contoso, developers concentrate on creating diverse prompt variations in Azure AI prompt flow, refining them for enhanced accuracy and relevance. They utilize advanced metrics like Question and Answering (QnA) Groundedness and QnA Relevance during batch runs to constantly assess the quality of their LLM flows. After assessing these flows, they use the prompt flow SDK and CLI for packaging and automating deployment, integrating seamlessly with CI/CD processes. Additionally, Contoso improves its use of Azure AI Search, employing more sophisticated RAG techniques to develop more complex and efficient indexes in their vector databases. This results in LLM applications that are not only quicker in response and more contextually informed, but also more cost-effective, reducing operational expenses while enhancing performance. \nLevel Four—Optimized: Operational excellence and continuous improvement  \nAt the pinnacle of the LLMOps maturity model, organizations reach a stage where operational excellence and continuous improvement are paramount. This phase features highly sophisticated deployment processes, underscored by relentless monitoring and iterative enhancement. Advanced monitoring solutions offer deep insights into LLM applications, fostering a dynamic strategy for continuous model and process improvement. \nAt this advanced stage, Contoso’s developers engage in complex prompt engineering and model optimization. Utilizing Azure AI’s comprehensive toolkit, they build reliable and highly efficient LLM applications. They fine-tune models like GPT-4, Llama 2, and Falcon for specific requirements and set up intricate RAG patterns, enhancing query understanding and retrieval, thus making LLM outputs more logical and relevant. They continuously perform large-scale evaluations with sophisticated metrics assessing quality, cost, and latency, ensuring thorough evaluation of LLM applications. Developers can even use an LLM-powered simulator to generate synthetic data, such as conversational datasets, to evaluate and improve the accuracy and groundedness. These evaluations, conducted at various stages, embed a culture of continuous enhancement.  \nFor monitoring and maintenance, Contoso adopts comprehensive strategies incorporating predictive analytics, detailed query and response logging, and tracing. These strategies are aimed at improving prompts, RAG implementations, and fine-tuning. They implement A/B testing for updates and automated alerts to identify potential drifts, biases, and quality issues, aligning their LLM applications with current industry standards and ethical norms. \nThe deployment process at this stage is streamlined and efficient. Contoso manages the entire lifecycle of LLMOps applications, encompassing versioning and auto-approval processes based on predefined criteria. They consistently apply advanced CI/CD practices with robust rollback capabilities, ensuring seamless updates to their LLM applications. \nAt this phase, Contoso stands as a model of LLMOps maturity, showcasing not only operational excellence but also a steadfast dedication to continuous innovation and enhancement in the LLM domain.\nIdentify where you are in the journey \nEach level of the LLMOps maturity model represents a strategic step in the journey toward production-level LLM applications. The progression from basic understanding to sophisticated integration and optimization encapsulates the dynamic nature of the field. It acknowledges the need for continuous learning and adaptation, ensuring that organizations can harness the transformative power of LLMs effectively and sustainably. \nThe LLMOps maturity model offers a structured pathway for organizations to navigate the complexities of implementing and scaling LLM applications. By understanding the distinction between application sophistication and operational maturity, organizations can make more informed decisions about how to progress through the levels of the model. The introduction of Azure AI Studio that encapsulated prompt flow, model catalog, and the Azure AI Search integration into this framework underscores the importance of both cutting-edge technology and robust operational strategies in achieving success with LLMs. \nLearn more \n\nTake the 45-minute Get Started with prompt flow to develop LLM apps module on Microsoft Learn\nLeverage the solution template to put LLMOps into practice\n\n\n\n\n\n \n\n\nExplore Azure AI Studio\n\nBuild, evaluate, and deploy your AI solutions all within one space\n\n\n\nLearn more about LLMOps\n\n\n\n\n\n\n\n\n\nContoso is a fictional but representative global organization building generative AI applications. \n\n\n\n\n\n\n\n\n\n\t\t\tRelated Posts\t\t\n\n\n\n\n \n\n\n\nAnnouncements\n\n\n\t\t\t\t\tAug 15\t\t\t\t\n\n\t\t\t\t\t5 min read\t\t\t\t\n\n\n\nMicrosoft Cost Management updates—July 2024 \n\n\n\n\nBy Sameer Doultani, Principal Product Manager\t\t\t\n\n\n\n\n\n \n\n\n\nAnnouncements\n\n\n\t\t\t\t\tAug 14\t\t\t\t\n\n\t\t\t\t\t3 min read\t\t\t\t\n\n\n\nElevate your AI deployments more efficiently with new deployment and cost management solutions for Azure OpenAI Service including self-service Provisioned \n\n\n\n\nBy Zia Mansoor, Vice President, Data and AI\t\t\t\n\n\n\n\n\n \n\n\n\nAnnouncements\n\n\n\t\t\t\t\tAug 7\t\t\t\t\n\n\t\t\t\t\t3 min read\t\t\t\t\n\n\n\nAnnouncing a new OpenAI feature for developers on Azure  \n\n\n\n\nBy Steve Sweetman \n\n\n \n\n\n\n\n\n\nExploreAzure AI solutions\n\nThe future of AI starts here. Envision your next great AI app with the latest technologies. Get started with Azure.\n\nLearn more about Azure\n\n\n\n\n\nConnect with us on social\nX\nYouTube\nLinkedIn\nInstagram\n\n\n\n\n\n\n\n\n\n\n\nExplore Azure\n\n\nWhat is Azure?\n\n\nGet started with Azure\n\n\nGlobal infrastructure\n\n\nDatacenter regions\n\n\nTrust your cloud\n\n\nAzure Essentials\n\n\nCustomer stories\n\n\n\n\nProducts and pricing\n\n\nProducts\n\n\nAzure pricing\n\n\nFree Azure services\n\n\nFlexible purchase options\n\n\nFinOps on Azure\n\n\nOptimize your costs\n\n\n\n\nSolutions and support\n\n\nSolutions\n\n\nResources for accelerating growth\n\n\nSolution architectures\n\n\nSupport\n\n\nAzure demo and live Q&A\n\n\n\n\n\n\nPartners\n\n\nAzure Marketplace\n\n\nFind a partner\n\n\nJoin ISV Success\n\n\n\n\nResources\n\n\nTraining and certifications\n\n\nDocumentation\n\n\nBlog\n\n\nDeveloper resources\n\n\nStudents\n\n\nEvents and Webinars\n\n\nAnalyst reports, white papers, and e-books\n\n\nVideos\n\n\n\n\nCloud computing\n\n\nWhat is cloud computing?\n\n\nWhat is cloud migration?\n\n\nWhat is a hybrid cloud?\n\n\nWhat is AI?\n\n\nWhat is PaaS?\n\n\nWhat is IaaS?\n\n\nWhat is SaaS?\n\n\nWhat is DevOps?\n\n\n\n\n\n\nEnglish (United States)\n\n\nYour Privacy Choices Opt-Out Icon\n\n\n\n\n\nYour Privacy Choices\n\n\n\n\nYour Privacy Choices Opt-Out Icon\n\n\n\n\n\nYour Privacy Choices\n\n\n\nConsumer Health Privacy\n\n\n\n\nSitemap\n\n\nContact Microsoft\n\n\nPrivacy \n\n\nManage cookies\n\n\nTerms of use\n\n\nTrademarks\n\n\nSafety & eco\n\n\nRecycling\n\n\nAbout our ads\n\n© Microsoft 2024\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"