"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnouncing new tools in Azure AI to help you build more secure and trustworthy generative AI applications | Microsoft Azure Blog\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nSkip to main content\n\n\n\n\n\n\n\nMicrosoft\n\n\n\nAzure\n\n\n\n\nAzure\n\n\n\n\n                            Azure\n                        \n\n\n\n\n Home \n\n\n\nExplore\n\n\nGet to know Azure\n\n\nGlobal infrastructure\n\n\nFinOps on Azure\n\n\nAzure Essentials\n\n\nCustomer stories\n\n\nAzure innovation insights\n\n\n\n \n\nProducts\n\n\nPopular\nPopular\n\n\nView all products (200+)\n\n\nAzure Virtual Machines\n\n\nAzure Virtual Desktop\n\n\nAzure SQL\n\n\nMicrosoft Copilot in Azure PREVIEW\n\n\nAzure AI Services\n\n\nAzure AI Studio\n\n\nAzure Cosmos DB\n\n\nAzure Kubernetes Service (AKS)\n\n\nAzure Arc​\n\n\nAzure Migrate\n\n\n\n\nAI + machine learning\nAI + machine learning\n\n\nAzure Machine Learning\n\n\nAzure AI Services\n\n\nMicrosoft Copilot in Azure PREVIEW\n\n\nAzure OpenAI Service\n\n\nAzure AI Studio\n\n\nAzure AI Vision\n\n\nAzure AI Search\n\n\nAzure AI Bot Service\n\n\nAzure Databricks\n\n\nAzure AI Language\n\n\n\n\nCompute\nCompute\n\n\nAzure Virtual Machines\n\n\nAzure Kubernetes Service (AKS)\n\n\nLinux virtual machines in Azure\n\n\nSQL Server on Azure Virtual Machines\n\n\nWindows Virtual Machines\n\n\nAzure Functions\n\n\nAzure Virtual Machine Scale Sets\n\n\nAzure Spot Virtual Machines\n\n\nAzure Container Apps\n\n\nAzure Compute Fleet\n\n\n\n\nContainers\nContainers\n\n\nAzure Kubernetes Service (AKS)\n\n\nAzure App Service\n\n\nAzure Functions\n\n\nAzure Container Instances​\n\n\nAzure Spring Apps\n\n\nAzure Red Hat OpenShift\n\n\nAzure Kubernetes Fleet Manager PREVIEW\n\n\nAzure Container Apps\n\n\nAzure Container Registry\n\n\nApp Configuration\n\n\n\n\nHybrid + multicloud\nHybrid + multicloud\n\n\nAzure Arc​\n\n\nAzure Stack\n\n\nMicrosoft Sentinel\n\n\nAzure SQL\n\n\nMicrosoft Defender for Cloud\n\n\nAzure ExpressRoute\n\n\nAzure DevOps\n\n\nAzure Database for PostgreSQL\n\n\nAzure IoT Edge\n\n\nAzure Monitor\n\n\n\n\nAnalytics\nAnalytics\n\n\nAzure Synapse Analytics\n\n\nAzure Databricks\n\n\nMicrosoft Purview\n\n\nAzure Data Factory\n\n\nAzure Machine Learning\n\n\nMicrosoft Fabric\n\n\nHDInsight\n\n\nAzure Data Explorer\n\n\nAzure Data Lake Storage\n\n\nAzure Operator Insights\n\n\n\n\n\n \n\nSolutions\n\n\nFeatured\nFeatured\n\n\nView all solutions (40+)\n\n\nAzure AI\n\n\nMigrate to innovate in the era of AI\n\n\nBuild and modernize intelligent apps\n\n\nCloud-scale analytics\n\n\nAzure AI Infrastructure\n\n\nAdaptive cloud\n\n\nAzure network security\n\n\n\n\nAI\nAI\n\n\nAzure AI\n\n\nResponsible AI with Azure\n\n\nAzure AI Infrastructure\n\n\nBuild and modernize intelligent apps\n\n\nKnowledge mining\n\n\nHugging Face on Azure\n\n\nAzure confidential computing\n\n\n\n\nApplication development\nApplication development\n\n\nBuild and modernize intelligent apps\n\n\nDevelopment and testing\n\n\nDevOps\n\n\nDevSecOps\n\n\nServerless computing\n\n\nApplication and Data Modernization\n\n\nLow-code application development on Azure\n\n\n\n\nCloud migration and modernization\nCloud migration and modernization\n\n\nMigration and modernization center\n\n\nMigrate to innovate in the era of AI\n\n\nBuild and modernize intelligent apps​\n\n\n.NET apps migration\n\n\nDevelopment and testing\n\n\nSQL Server migration\n\n\nWindows Server on Azure\n\n\nLinux on Azure\n\n\nSAP on the Microsoft Cloud\n\n\nOracle on Azure\n\n\n\n\nHybrid Cloud and infrastructure\nHybrid Cloud and infrastructure\n\n\nHybrid and multicloud solutions\n\n\nBackup and disaster recovery\n\n\nWindows Server on Azure\n\n\nHigh-performance computing (HPC)\n\n\nBusiness-critical applications\n\n\nQuantum computing\n\n\n5G and Space\n\n\n\n\nResources\nResources\n\n\nReference architectures\n\n\nResources for accelerating growth\n\n\nAzure Marketplace\n\n\nAzure Essentials\n\n\nBrowse the Microsoft Business Solutions Hub\n\n\n\n\n\n \n\nPricing\n\n\nHow to buy\nHow to buy\n\n\nAzure pricing\n\n\nFree Azure services\n\n\nAzure account\n\n\nFlexible purchase options\n\n\nAzure benefits and incentives\n\n\n\n\nPricing tools and resources\nPricing tools and resources\n\n\nPricing calculator\n\n\nTCO calculator\n\n\nOptimize your costs\n\n\nFinOps on Azure\n\n\n\n\n\n \n\nPartners\n\n\nFind a partner\nFind a partner\n\n\nAzure Marketplace\n\n\nFind a partner\n\n\n\n\nBecome a partner\nBecome a partner\n\n\nAzure Partner Zone\n\n\nAzure technology partners\n\n\nJoin ISV Success\n\n\n\n\n\n \n\nResources\n\n\nLearning\nLearning\n\n\nGet started with Azure\n\n\nTraining and certifications\n\n\nCustomer stories\n\n\nAnalyst reports, white papers, and e-books\n\n\nVideos\n\n\nLearn more about cloud computing\n\n\n\n\nTechnical resources\nTechnical resources\n\n\nDocumentation\n\n\nGet the Azure mobile app\n\n\nDeveloper resources\n\n\nQuickstart templates\n\n\nResources for startups\n\n\n\n\nCommunity\nCommunity\n\n\nDeveloper community\n\n\nStudents\n\n\nDeveloper stories\n\n\n\n\nWhat's new\nWhat's new\n\n\nBlog\n\n\nEvents and Webinars\n\n\n\n\n\n \nLearn\n\n\nSupport\n\n\nContact Sales\n\n\nGet started with Azure\n\n\nSign in\n\n\n\nMore\n\n\n\n\n\n\n\n \n\n\n\n All Microsoft\n\n\nGlobal\n\n\nMicrosoft 365\n\n\nTeams\n\n\nCopilot\n\n\nWindows\n\n\nSurface\n\n\nXbox\n\n\nDeals\n\n\nSmall Business\n\n\nSupport\n\n\n\n\nSoftware\nSoftware\n\n\nWindows Apps\n\n\nAI\n\n\nOutlook\n\n\nOneDrive\n\n\nMicrosoft Teams\n\n\nOneNote\n\n\nMicrosoft Edge\n\n\nSkype\n\n\n\n\nPCs & Devices  \nPCs & Devices  \n\n\nComputers\n\n\nShop Xbox\n\n\nAccessories\n\n\nVR & mixed reality\n\n\nCertified Refurbished\n\n\nTrade-in for cash\n\n\n\n\nEntertainment\nEntertainment\n\n\nXbox Game Pass Ultimate\n\n\nPC Game Pass\n\n\nXbox games\n\n\nPC and Windows games\n\n\nMovies & TV\n\n\n\n\nBusiness\nBusiness\n\n\nMicrosoft Cloud\n\n\nMicrosoft Security\n\n\nDynamics 365\n\n\nMicrosoft 365 for business\n\n\nMicrosoft Power Platform\n\n\nWindows 365\n\n\nMicrosoft Industry\n\n\nSmall Business\n\n\n\n\nDeveloper & IT  \nDeveloper & IT  \n\n\nAzure\n\n\nDeveloper Center\n\n\nDocumentation\n\n\nMicrosoft Learn\n\n\nMicrosoft Tech Community\n\n\nAzure Marketplace\n\n\nAppSource\n\n\nVisual Studio\n\n\n\n\nOther\nOther\n\n\nMicrosoft Rewards \n\n\nFree downloads & security\n\n\nEducation\n\n\nGift cards\n\n\nLicensing\n\n\nUnlocked stories\n\n\n\n\nView Sitemap\n\n\n\n\n\n\n\n\n\n\nSearch\nShow search input\n\n\n\n\n No results\n\n\n\n\nCancel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Home / AI + machine learning / Announcing new tools in Azure AI to help you build more secure and trustworthy generative AI applications\n\n\n\n\n\n\t\tSearch for:\t\n\n\n Submit search\n\n\n\n\n\n\n\n\n\n\nPublished Mar 28, 2024\n\n\n\t\t\t\t6 min read\t\t\t\n\n\nAnnouncing new tools in Azure AI to help you build more secure and trustworthy generative AI applications\n\nBy Sarah Bird, Chief Product Officer of Responsible AI, Microsoft\t\n \n\n\n\n\n\n\t\tShare\t\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n\n\n\n\n\t\t\t\t\tContent type\t\t\t\t\n\n\n\t\t\t\t\t\tAnnouncements\t\t\t\t\t\n\n\n\n\n\t\t\t\t\tTag\t\t\t\t\n\n\n\t\t\t\t\t\tAI\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tGenerative AI\t\t\t\t\t\n\n\n\n\n\t\t\t\t\tAudience\t\t\t\t\n\n\n\t\t\t\t\t\tData professionals\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tDevelopers\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tIT decision makers\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tIT implementors\t\t\t\t\t\n\n\n\n\n\t\t\t\t\tProduct\t\t\t\t\n\n\n\t\t\t\t\t\tAzure AI\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tAzure AI Content Safety\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tAzure AI Studio\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tAzure OpenAI Service\t\t\t\t\t\n\n\n\n\n\n\n\n\n\t\t\tTo help customers meet  new AI quality and safety challenges, we’re announcing new tools now available or coming soon to Azure AI Studio for generative AI app developers.\t\t\n\n\nIn the rapidly evolving landscape of generative AI, business leaders are trying to strike the right balance between innovation and risk management. Prompt injection attacks have emerged as a significant challenge, where malicious actors try to manipulate an AI system into doing something outside its intended purpose, such as producing harmful content or exfiltrating confidential data. In addition to mitigating these security risks, organizations are also concerned about quality and reliability. They want to ensure that their AI systems are not generating errors or adding information that isn’t substantiated in the application’s data sources, which can erode user trust. \nTo help customers meet these AI quality and safety challenges, we’re announcing new tools now available or coming soon to Azure AI Studio for generative AI app developers: \n\nPrompt Shields to detect and block prompt injection attacks, including a new model for identifying indirect prompt attacks before they impact your model, coming soon and now available in preview in Azure AI Content Safety. \n\n\nGroundedness detection to detect “hallucinations” in model outputs, coming soon. \n\n\nSafety system messages to steer your model’s behavior toward safe, responsible outputs, coming soon.\n\n\nSafety evaluations to assess an application’s vulnerability to jailbreak attacks and to generating content risks, now available in preview.  \n\n\nRisk and safety monitoring to understand what model inputs, outputs, and end users are triggering content filters to inform mitigations, coming soon, and now available in preview in Azure OpenAI Service.\n\nWith these additions, Azure AI continues to provide our customers with innovative technologies to safeguard their applications across the generative AI lifecycle.\n\n\n\n\n\n\n\nSafeguard your LLMs against prompt injection attacks with Prompt Shields\n\nPrompt injection attacks, both direct attacks, known as jailbreaks, and indirect attacks, are emerging as significant threats to foundation model safety and security. Successful attacks that bypass an AI system’s safety mitigations can have severe consequences, such as personally identifiable information (PII) and intellectual property (IP) leakage. \n\nTo combat these threats, Microsoft has introduced Prompt Shields to detect suspicious inputs in real time and block them before they reach the foundation model. This proactive approach safeguards the integrity of large language model (LLM) systems and user interactions.\n\nPrompt Shield for Jailbreak Attacks: Jailbreak, direct prompt attacks, or user prompt injection attacks, refer to users manipulating prompts to inject harmful inputs into LLMs to distort actions and outputs. An example of a jailbreak command is a ‘DAN’ (Do Anything Now) attack, which can trick the LLM into inappropriate content generation or ignoring system-imposed restrictions. Our Prompt Shield for jailbreak attacks, released this past November as ‘jailbreak risk detection’, detects these attacks by analyzing prompts for malicious instructions and blocks their execution.\n\nPrompt Shield for Indirect Attacks: Indirect prompt injection attacks, although not as well-known as jailbreak attacks, present a unique challenge and threat. In these covert attacks, hackers aim to manipulate AI systems indirectly by altering input data, such as websites, emails, or uploaded documents. This allows hackers to trick the foundation model into performing unauthorized actions without directly tampering with the prompt or LLM. The consequences of which can lead to account takeover, defamatory or harassing content, and other malicious actions. To combat this, we’re introducing a Prompt Shield for indirect attacks, designed to detect and block these hidden attacks to support the security and integrity of your generative AI applications. \nIdentify LLM Hallucinations with Groundedness detection\n\n‘Hallucinations’ in generative AI refer to instances when a model confidently generates outputs that misalign with common sense or lack grounding data. This issue can manifest in different ways, ranging from minor inaccuracies to starkly false outputs. Identifying hallucinations is crucial for enhancing the quality and trustworthiness of generative AI systems. Today, Microsoft is announcing Groundedness detection, a new feature designed to identify text-based hallucinations. This feature detects ‘ungrounded material’ in text to support the quality of LLM outputs. \nSteer your application with an effective safety system message\nIn addition to adding safety systems like Azure AI Content Safety, prompt engineering is one of the most powerful and popular ways to improve the reliability of a generative AI system. Today, Azure AI enables users to ground foundation models on trusted data sources and build system messages that guide the optimal use of that grounding data and overall behavior (do this, not that). At Microsoft, we have found that even small changes to a system message can have a significant impact on an application’s quality and safety. To help customers build effective system messages, we’ll soon provide safety system message templates directly in the Azure AI Studio and Azure OpenAI Service playgrounds by default. Developed by Microsoft Research to mitigate harmful content generation and misuse, these templates can help developers start building high-quality applications in less time. \nEvaluate your LLM application for risks and safety\n\nHow do you know if your application and mitigations are working as intended? Today, many organizations lack the resources to stress test their generative AI applications so they can confidently progress from prototype to production. First, it can be challenging to build a high-quality test dataset that reflects a range of new and emerging risks, such as jailbreak attacks. Even with quality data, evaluations can be a complex and manual process, and development teams may find it difficult to interpret the results to inform effective mitigations. \nAzure AI Studio provides robust, automated evaluations to help organizations systematically assess and improve their generative AI applications before deploying to production. While we currently support pre-built quality evaluation metrics such as groundedness, relevance, and fluency, today we’re announcing automated evaluations for new risk and safety metrics. These safety evaluations measure an application’s susceptibility to jailbreak attempts and to producing violent, sexual, self-harm-related, and hateful and unfair content. They also provide natural language explanations for evaluation results to help inform appropriate mitigations. Developers can evaluate an application using their own test dataset or simply generate a high-quality test dataset using adversarial prompt templates developed by Microsoft Research. With this capability, Azure AI Studio can also help augment and accelerate manual red-teaming efforts by enabling red teams to generate and automate adversarial prompts at scale. \nMonitor your Azure OpenAI Service deployments for risks and safety in production\n\nMonitoring generative AI models in production is an essential part of the AI lifecycle. Today we are pleased to announce risk and safety monitoring in Azure OpenAI Service. Now, developers can visualize the volume, severity, and category of user inputs and model outputs that were blocked by their Azure OpenAI Service content filters and blocklists over time. In addition to content-level monitoring and insights, we are introducing reporting for potential abuse at the user level. Now, enterprise customers have greater visibility into trends where end-users continuously send risky or harmful requests to an Azure OpenAI Service model. If content from a user is flagged as harmful by a customer’s pre-configured content filters or blocklists, the service will use contextual signals to determine whether the user’s behavior qualifies as abuse of the AI system. With these new monitoring capabilities, organizations can better-understand trends in application and user behavior and apply those insights to adjust content filter configurations, blocklists, and overall application design. \nConfidently scale the next generation of safe, responsible AI applications\nGenerative AI can be a force multiplier for every department, company, and industry. Azure AI customers are using this technology to operate more efficiently, improve customer experience, and build new pathways for innovation and growth. At the same time, foundation models introduce new challenges for security and safety that require novel mitigations and continuous learning. \n\n\n\n\t\t\tInvest in App Innovation to Stay Ahead of the Curve\t\t\n\nLearn more \n\n\n\nAt Microsoft, whether we are working on traditional machine learning or cutting-edge AI technologies, we ground our research, policy, and engineering efforts in our AI principles. We’ve built our Azure AI portfolio to help developers embed critical responsible AI practices directly into the AI development lifecycle. In this way, Azure AI provides a consistent, scalable platform for responsible innovation for our first-party copilots and for the thousands of customers building their own game-changing solutions with Azure AI. We’re excited to continue collaborating with customers and partners on novel ways to mitigate, evaluate, and monitor risks and help every organization realize their goals with generative AI with confidence. \nLearn more about today’s announcements\n\nGet started in Azure AI Studio.\nDig deeper with technical blogs on Tech Community:\n\nPrompt Shields\nGroundedness detection\nSafety evaluations\nRisk and safety monitoring\n\n\n\n\n\n\n\n \n\n\nAzure AI Studio\n\nBuild AI solutions faster with prebuilt models or train models using your data to innovate securely and at scale.\n\n\n\nTry now\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\tRelated Posts\t\t\n\n\n\n\n \n\n\n\nAnnouncements\n\n\n\t\t\t\t\tAug 14\t\t\t\t\n\n\t\t\t\t\t3 min read\t\t\t\t\n\n\n\nElevate your AI deployments more efficiently with new deployment and cost management solutions for Azure OpenAI Service including self-service Provisioned \n\n\n\n\nBy Zia Mansoor, Vice President, Data and AI\t\t\t\n\n\n\n\n\n \n\n\n\nAnnouncements\n\n\n\t\t\t\t\tAug 7\t\t\t\t\n\n\t\t\t\t\t3 min read\t\t\t\t\n\n\n\nAnnouncing a new OpenAI feature for developers on Azure  \n\n\n\n\nBy Steve Sweetman \n\n\n\n\n\n \n\n\n\nPartnerships\n\n\n\t\t\t\t\tAug 5\t\t\t\t\n\n\t\t\t\t\t4 min read\t\t\t\t\n\n\n\nBuild AI-enabled applications with Azure AI and NVIDIA \n\n\n\n\nBy Seth Juarez \n\n\n \n\n\n\n\n\n\nExploreAzure AI solutions\n\nThe future of AI starts here. Envision your next great AI app with the latest technologies. Get started with Azure.\n\nLearn more about Azure\n\n\n\n\n\nConnect with us on social\nX\nYouTube\nLinkedIn\nInstagram\n\n\n\n\n\n\n\n\n\n\n\nExplore Azure\n\n\nWhat is Azure?\n\n\nGet started with Azure\n\n\nGlobal infrastructure\n\n\nDatacenter regions\n\n\nTrust your cloud\n\n\nAzure Essentials\n\n\nCustomer stories\n\n\n\n\nProducts and pricing\n\n\nProducts\n\n\nAzure pricing\n\n\nFree Azure services\n\n\nFlexible purchase options\n\n\nFinOps on Azure\n\n\nOptimize your costs\n\n\n\n\nSolutions and support\n\n\nSolutions\n\n\nResources for accelerating growth\n\n\nSolution architectures\n\n\nSupport\n\n\nAzure demo and live Q&A\n\n\n\n\n\n\nPartners\n\n\nAzure Marketplace\n\n\nFind a partner\n\n\nJoin ISV Success\n\n\n\n\nResources\n\n\nTraining and certifications\n\n\nDocumentation\n\n\nBlog\n\n\nDeveloper resources\n\n\nStudents\n\n\nEvents and Webinars\n\n\nAnalyst reports, white papers, and e-books\n\n\nVideos\n\n\n\n\nCloud computing\n\n\nWhat is cloud computing?\n\n\nWhat is cloud migration?\n\n\nWhat is a hybrid cloud?\n\n\nWhat is AI?\n\n\nWhat is PaaS?\n\n\nWhat is IaaS?\n\n\nWhat is SaaS?\n\n\nWhat is DevOps?\n\n\n\n\n\n\nEnglish (United States)\n\n\nYour Privacy Choices Opt-Out Icon\n\n\n\n\n\nYour Privacy Choices\n\n\n\n\nYour Privacy Choices Opt-Out Icon\n\n\n\n\n\nYour Privacy Choices\n\n\n\nConsumer Health Privacy\n\n\n\n\nSitemap\n\n\nContact Microsoft\n\n\nPrivacy \n\n\nManage cookies\n\n\nTerms of use\n\n\nTrademarks\n\n\nSafety & eco\n\n\nRecycling\n\n\nAbout our ads\n\n© Microsoft 2024\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"