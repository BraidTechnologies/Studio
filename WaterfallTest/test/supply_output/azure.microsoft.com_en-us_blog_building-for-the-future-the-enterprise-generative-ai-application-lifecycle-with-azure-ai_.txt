"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe enterprise generative AI application lifecycle with Azure AI | Microsoft Azure Blog | Microsoft Azure\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nSkip to main content\n\n\n\n\n\n\n\nMicrosoft\n\n\n\nAzure\n\n\n\n\nAzure\n\n\n\n\n                            Azure\n                        \n\n\n\n\n Home \n\n\n\nExplore\n\n\nGet to know Azure\n\n\nGlobal infrastructure\n\n\nFinOps on Azure\n\n\nAzure Essentials\n\n\nCustomer stories\n\n\nAzure innovation insights\n\n\n\n \n\nProducts\n\n\nPopular\nPopular\n\n\nView all products (200+)\n\n\nAzure Virtual Machines\n\n\nAzure Virtual Desktop\n\n\nAzure SQL\n\n\nMicrosoft Copilot in Azure PREVIEW\n\n\nAzure AI Services\n\n\nAzure AI Studio\n\n\nAzure Cosmos DB\n\n\nAzure Kubernetes Service (AKS)\n\n\nAzure Arc​\n\n\nAzure Migrate\n\n\n\n\nAI + machine learning\nAI + machine learning\n\n\nAzure Machine Learning\n\n\nAzure AI Services\n\n\nMicrosoft Copilot in Azure PREVIEW\n\n\nAzure OpenAI Service\n\n\nAzure AI Studio\n\n\nAzure AI Vision\n\n\nAzure AI Search\n\n\nAzure AI Bot Service\n\n\nAzure Databricks\n\n\nAzure AI Language\n\n\n\n\nCompute\nCompute\n\n\nAzure Virtual Machines\n\n\nAzure Kubernetes Service (AKS)\n\n\nLinux virtual machines in Azure\n\n\nSQL Server on Azure Virtual Machines\n\n\nWindows Virtual Machines\n\n\nAzure Functions\n\n\nAzure Virtual Machine Scale Sets\n\n\nAzure Spot Virtual Machines\n\n\nAzure Container Apps\n\n\nAzure Compute Fleet\n\n\n\n\nContainers\nContainers\n\n\nAzure Kubernetes Service (AKS)\n\n\nAzure App Service\n\n\nAzure Functions\n\n\nAzure Container Instances​\n\n\nAzure Spring Apps\n\n\nAzure Red Hat OpenShift\n\n\nAzure Kubernetes Fleet Manager PREVIEW\n\n\nAzure Container Apps\n\n\nAzure Container Registry\n\n\nApp Configuration\n\n\n\n\nHybrid + multicloud\nHybrid + multicloud\n\n\nAzure Arc​\n\n\nAzure Stack\n\n\nMicrosoft Sentinel\n\n\nAzure SQL\n\n\nMicrosoft Defender for Cloud\n\n\nAzure ExpressRoute\n\n\nAzure DevOps\n\n\nAzure Database for PostgreSQL\n\n\nAzure IoT Edge\n\n\nAzure Monitor\n\n\n\n\nAnalytics\nAnalytics\n\n\nAzure Synapse Analytics\n\n\nAzure Databricks\n\n\nMicrosoft Purview\n\n\nAzure Data Factory\n\n\nAzure Machine Learning\n\n\nMicrosoft Fabric\n\n\nHDInsight\n\n\nAzure Data Explorer\n\n\nAzure Data Lake Storage\n\n\nAzure Operator Insights\n\n\n\n\n\n \n\nSolutions\n\n\nFeatured\nFeatured\n\n\nView all solutions (40+)\n\n\nAzure AI\n\n\nMigrate to innovate in the era of AI\n\n\nBuild and modernize intelligent apps\n\n\nCloud-scale analytics\n\n\nAzure AI Infrastructure\n\n\nAdaptive cloud\n\n\nAzure network security\n\n\n\n\nAI\nAI\n\n\nAzure AI\n\n\nResponsible AI with Azure\n\n\nAzure AI Infrastructure\n\n\nBuild and modernize intelligent apps\n\n\nKnowledge mining\n\n\nHugging Face on Azure\n\n\nAzure confidential computing\n\n\n\n\nApplication development\nApplication development\n\n\nBuild and modernize intelligent apps\n\n\nDevelopment and testing\n\n\nDevOps\n\n\nDevSecOps\n\n\nServerless computing\n\n\nApplication and Data Modernization\n\n\nLow-code application development on Azure\n\n\n\n\nCloud migration and modernization\nCloud migration and modernization\n\n\nMigration and modernization center\n\n\nMigrate to innovate in the era of AI\n\n\nBuild and modernize intelligent apps​\n\n\n.NET apps migration\n\n\nDevelopment and testing\n\n\nSQL Server migration\n\n\nWindows Server on Azure\n\n\nLinux on Azure\n\n\nSAP on the Microsoft Cloud\n\n\nOracle on Azure\n\n\n\n\nHybrid Cloud and infrastructure\nHybrid Cloud and infrastructure\n\n\nHybrid and multicloud solutions\n\n\nBackup and disaster recovery\n\n\nWindows Server on Azure\n\n\nHigh-performance computing (HPC)\n\n\nBusiness-critical applications\n\n\nQuantum computing\n\n\n5G and Space\n\n\n\n\nResources\nResources\n\n\nReference architectures\n\n\nResources for accelerating growth\n\n\nAzure Marketplace\n\n\nAzure Essentials\n\n\nBrowse the Microsoft Business Solutions Hub\n\n\n\n\n\n \n\nPricing\n\n\nHow to buy\nHow to buy\n\n\nAzure pricing\n\n\nFree Azure services\n\n\nAzure account\n\n\nFlexible purchase options\n\n\nAzure benefits and incentives\n\n\n\n\nPricing tools and resources\nPricing tools and resources\n\n\nPricing calculator\n\n\nTCO calculator\n\n\nOptimize your costs\n\n\nFinOps on Azure\n\n\n\n\n\n \n\nPartners\n\n\nFind a partner\nFind a partner\n\n\nAzure Marketplace\n\n\nFind a partner\n\n\n\n\nBecome a partner\nBecome a partner\n\n\nAzure Partner Zone\n\n\nAzure technology partners\n\n\nJoin ISV Success\n\n\n\n\n\n \n\nResources\n\n\nLearning\nLearning\n\n\nGet started with Azure\n\n\nTraining and certifications\n\n\nCustomer stories\n\n\nAnalyst reports, white papers, and e-books\n\n\nVideos\n\n\nLearn more about cloud computing\n\n\n\n\nTechnical resources\nTechnical resources\n\n\nDocumentation\n\n\nGet the Azure mobile app\n\n\nDeveloper resources\n\n\nQuickstart templates\n\n\nResources for startups\n\n\n\n\nCommunity\nCommunity\n\n\nDeveloper community\n\n\nStudents\n\n\nDeveloper stories\n\n\n\n\nWhat's new\nWhat's new\n\n\nBlog\n\n\nEvents and Webinars\n\n\n\n\n\n \nLearn\n\n\nSupport\n\n\nContact Sales\n\n\nGet started with Azure\n\n\nSign in\n\n\n\nMore\n\n\n\n\n\n\n\n \n\n\n\n All Microsoft\n\n\nGlobal\n\n\nMicrosoft 365\n\n\nTeams\n\n\nCopilot\n\n\nWindows\n\n\nSurface\n\n\nXbox\n\n\nDeals\n\n\nSmall Business\n\n\nSupport\n\n\n\n\nSoftware\nSoftware\n\n\nWindows Apps\n\n\nAI\n\n\nOutlook\n\n\nOneDrive\n\n\nMicrosoft Teams\n\n\nOneNote\n\n\nMicrosoft Edge\n\n\nSkype\n\n\n\n\nPCs & Devices  \nPCs & Devices  \n\n\nComputers\n\n\nShop Xbox\n\n\nAccessories\n\n\nVR & mixed reality\n\n\nCertified Refurbished\n\n\nTrade-in for cash\n\n\n\n\nEntertainment\nEntertainment\n\n\nXbox Game Pass Ultimate\n\n\nPC Game Pass\n\n\nXbox games\n\n\nPC and Windows games\n\n\nMovies & TV\n\n\n\n\nBusiness\nBusiness\n\n\nMicrosoft Cloud\n\n\nMicrosoft Security\n\n\nDynamics 365\n\n\nMicrosoft 365 for business\n\n\nMicrosoft Power Platform\n\n\nWindows 365\n\n\nMicrosoft Industry\n\n\nSmall Business\n\n\n\n\nDeveloper & IT  \nDeveloper & IT  \n\n\nAzure\n\n\nDeveloper Center\n\n\nDocumentation\n\n\nMicrosoft Learn\n\n\nMicrosoft Tech Community\n\n\nAzure Marketplace\n\n\nAppSource\n\n\nVisual Studio\n\n\n\n\nOther\nOther\n\n\nMicrosoft Rewards \n\n\nFree downloads & security\n\n\nEducation\n\n\nGift cards\n\n\nLicensing\n\n\nUnlocked stories\n\n\n\n\nView Sitemap\n\n\n\n\n\n\n\n\n\n\nSearch\nShow search input\n\n\n\n\n No results\n\n\n\n\nCancel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Home / AI + machine learning / Building for the future: The enterprise generative AI application lifecycle with Azure AI\n\n\n\n\n\n\t\tSearch for:\t\n\n\n Submit search\n\n\n\n\n\n\n\n\n\n\nPublished Nov 6, 2023\n\n\n\t\t\t\t7 min read\t\t\t\n\n\nBuilding for the future: The enterprise generative AI application lifecycle with Azure AI\n\nBy Gregory Buehrer, Corporate Vice President, Chief Technology Officer of Azure Machine Learning\t\n \n\n\n\n\n\n\t\tShare\t\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n\n\n\n\n\t\t\t\t\tContent type\t\t\t\t\n\n\n\t\t\t\t\t\tBest practices\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tThought leadership\t\t\t\t\t\n\n\n\n\n\t\t\t\t\tTag\t\t\t\t\n\n\n\t\t\t\t\t\tGenerative AI\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tLLMOps\t\t\t\t\t\n\n\n\n\n\t\t\t\t\tAudience\t\t\t\t\n\n\n\t\t\t\t\t\tBusiness decision makers\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tData professionals\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tDevelopers\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tIT decision makers\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tIT implementors\t\t\t\t\t\n\n\n\n\n\t\t\t\t\tProduct\t\t\t\t\n\n\n\t\t\t\t\t\tAzure AI\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tAzure Machine Learning\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tAzure OpenAI Service\t\t\t\t\t\n\n\n\n\t\t\t\t\t\tMicrosoft Purview\t\t\t\t\t\n\n\n\n\n\n\n\n\n\t\t\tThe enterprise development process requires collaboration, diligent evaluation, risk management, and scaled deployment. By providing a robust suite of capabilities supporting these challenges, Azure AI affords a clear and efficient path to generating value in your products for your customers.\t\t\n\n\nIn our previous blog, we explored the emerging practice of large language model operations (LLMOps) and the nuances that set it apart from traditional machine learning operations (MLOps). We discussed the challenges of scaling large language model-powered applications and how Microsoft Azure AI uniquely helps organizations manage this complexity. We touched on the importance of considering the development journey as an iterative process to achieve a quality application.  \n\n\n\n\n \n\n\nMicrosoft Azure AI\n\nDrive business results and improve customer experiences \n\n\n\nExplore solutions\n\n\n\n\n\n\n\n\nIn this blog, we’ll explore these concepts in more detail. The enterprise development process requires collaboration, diligent evaluation, risk management, and scaled deployment. By providing a robust suite of capabilities supporting these challenges, Azure AI affords a clear and efficient path to generating value in your products for your customers.\nEnterprise LLM Lifecycle\n\nIdeating and exploring loop\nThe first loop typically involves a single developer searching for a model catalog for large language models (LLMs) that align with their specific business requirements. Working with a subset of data and prompts, the developer will try to understand the capabilities and limitations of each model with prototyping and evaluation. Developers usually explore altering prompts to the models, different chunking sizes and vectoring indexing methods, and basic interactions while trying to validate or refute business hypotheses. For instance, in a customer support scenario, they might input sample customer queries to see if the model generates appropriate and helpful responses. They can validate this first by typing in examples, but quickly move to bulk testing with files and automated metrics.\n\n\n\n\t\t\texplore\t\t\n\nAzure OpenAI Service \n\n\n\nBeyond Azure OpenAI Service, Azure AI offers a comprehensive model catalog, which empowers users to discover, customize, evaluate, and deploy foundation models from leading providers such as Hugging Face, Meta, and OpenAI. This helps developers find and select optimal foundation models for their specific use case. Developers can quickly test and evaluate models using their own data to see how the pre-trained model would perform for their desired scenarios.  \nBuilding and augmenting loop \nOnce a developer discovers and evaluates the core capabilities of their preferred LLM, they advance to the next loop which focuses on guiding and enhancing the LLM to better meet their specific needs. Traditionally, a base model is trained with point-in-time data. However, often the scenario requires either enterprise-local data, real-time data, or more fundamental alterations.\nFor reasoning on enterprise data, Retrieval Augmented Generation (RAG) is preferred, which injects information from internal data sources into the prompt based on the specific user request. Common sources are document search systems, structured databases, and non-SQL stores. With RAG, a developer can “ground” their solution using the capabilities of their LLMs to process and generate responses based on this injected data. This helps developers achieve customized solutions while maintaining relevance and optimizing costs. RAG also facilitates continuous data updates without the need for fine-tuning as the data comes from other sources.  \nDuring this loop, the developer may find cases where the output accuracy doesn’t meet desired thresholds. Another method to alter the outcome of an LLM is fine-tuning. Fine-tuning helps most when the nature of the system needs to be altered. Generally, the LLM will answer any prompt in a similar tone and format. But for example, if the use case requires code output, JSON, or any such modification, there may be a consistent change or restriction in the output, where fine-tuning can be employed to better align the system’s responses with the specific requirements of the task at hand. By adjusting the parameters of the LLM during fine-tuning, the developer can significantly improve the output accuracy and relevance, making the system more useful and efficient for the intended use case. \nIt is also feasible to combine prompt engineering, RAG augmentation, and a fine-tuned LLM. Since fine-tuning necessitates additional data, most users initiate with prompt engineering and modifications to data retrieval before proceeding to fine-tune the model. \nMost importantly, continuous evaluation is an essential element of this loop. During this phase, developers assess the quality and overall groundedness of their LLMs. The end goal is to facilitate safe, responsible, and data-driven insights to inform decision-making while ensuring the AI solutions are primed for production. \n\n\n\n\t\t\tlearn more\t\t\n\nAzure AI prompt flow \n\n\n\nAzure AI prompt flow is a pivotal component in this loop. Prompt flow helps teams streamline the development and evaluation of LLM applications by providing tools for systematic experimentation and a rich array of built-in templates and metrics. This ensures a structured and informed approach to LLM refinement. Developers can also effortlessly integrate with frameworks like LangChain or Semantic Kernel, tailoring their LLM flows based on their business requirements. The addition of reusable Python tools enhances data processing capabilities, while simplified and secure connections to APIs and external data sources afford flexible augmentation of the solution. Developers can also use multiple LLMs as part of their workflow, applied dynamically or conditionally to work on specific tasks and manage costs.  \nWith Azure AI, evaluating the effectiveness of different development approaches becomes straightforward. Developers can easily craft and compare the performance of prompt variants against sample data, using insightful metrics such as groundedness, fluency, and coherence. In essence, throughout this loop, prompt flow is the linchpin, bridging the gap between innovative ideas and tangible AI solutions. \nOperationalizing loop \nThe third loop captures the transition of LLMs from development to production. This loop primarily involves deployment, monitoring, incorporating content safety systems, and integrating with CI/CD (continuous integration and continuous deployment) processes. This stage of the process is often managed by production engineers who have existing processes for application deployment. Central to this stage is collaboration, facilitating a smooth handoff of assets between application developers and data scientists building on the LLMs, and production engineers tasked with deploying them.\nDeployment allows for a seamless transfer of LLMs and prompt flows to endpoints for inference without the need for a complex infrastructure setup. Monitoring helps teams track and optimize their LLM application’s safety and quality in production. Content safety systems help detect and mitigate misuse and unwanted content, both on the ingress and egress of the application. Combined, these systems fortify the application against potential risks, improving alignment with risk, governance, and compliance standards.  \nUnlike traditional machine learning models that might classify content, LLMs fundamentally generate content. This content often powers end-user-facing experiences like chatbots, with the integration often falling on developers who may not have experience managing probabilistic models. LLM-based applications often incorporate agents and plugins to enhance the capabilities of models to trigger some actions, which could also amplify the risk. These factors, combined with the inherent variability of LLM outputs, show the importance of risk management in LLMOps is critical.  \n\n\n\n\t\t\texplore\t\t\n\nAzure AI Content Safety \n\n\n\nAzure AI prompt flow ensures a smooth deployment process to managed online endpoints in Azure Machine Learning. Because prompt flows are well-defined files that adhere to published schemas, they are easily incorporated into existing productization pipelines. Upon deployment, Azure Machine Learning invokes the model data collector, which autonomously gathers production data. That way, monitoring capabilities in Azure AI can provide a granular understanding of resource utilization, ensuring optimal performance and cost-effectiveness through token usage and cost monitoring. More importantly, customers can monitor their generative AI applications for quality and safety in production, using scheduled drift detection using either built-in or customer-defined metrics. Developers can also use Azure AI Content Safety to detect and mitigate harmful content or use the built-in content safety filters provided with Azure OpenAI Service models. Together, these systems provide greater control, quality, and transparency, delivering AI solutions that are safer, more efficient, and more easily meet the organization’s compliance standards.\nAzure AI also helps to foster closer collaboration among diverse roles by facilitating the seamless sharing of assets like models, prompts, data, and experiment results using registries. Assets crafted in one workspace can be effortlessly discovered in another, ensuring a fluid handoff of LLMs and prompts. This not only enables a smoother development process but also preserves the lineage across both development and production environments. This integrated approach ensures that LLM applications are not only effective and insightful but also deeply ingrained within the business fabric, delivering unmatched value.\nManaging loop \nThe final loop in the Enterprise Lifecycle LLM process lays down a structured framework for ongoing governance, management, and security. AI governance can help organizations accelerate their AI adoption and innovation by providing clear and consistent guidelines, processes, and standards for their AI projects.\n\n\n\n\t\t\tExplore\t\t\n\nResponsible AI practices \n\n\n\nAzure AI provides built-in AI governance capabilities for privacy, security, compliance, and responsible AI, as well as extensive connectors and integrations to simplify AI governance across your data estate. For example, administrators can set policies to allow or enforce specific security configurations, such as whether your Azure Machine Learning workspace uses a private endpoint. Or, organizations can integrate Azure Machine Learning workspaces with Microsoft Purview to publish metadata on AI assets automatically to the Purview Data Map for easier lineage tracking. This helps risk and compliance professionals understand what data is used to train AI models, how base models are fine-tuned or extended, and where models are used across different production applications. This information is crucial for supporting responsible AI practices and providing evidence for compliance reports and audits.\nWhether building generative AI applications with open-source models, Azure’s managed OpenAI models, or your own pre-trained custom models, Azure AI facilitates safe, secure, and reliable AI solutions with greater ease with purpose-built, scalable infrastructure.\nExplore the harmonized journey of LLMOps at Microsoft Ignite\nAs organizations delve deeper into LLMOps to streamline processes, one truth becomes abundantly clear: the journey is multifaceted and requires a diverse range of skills. While tools and technologies like Azure AI prompt flow play a crucial role, the human element—and diverse expertise—is indispensable. It’s the harmonious collaboration of cross-functional teams that creates real magic. Together, they ensure the transformation of a promising idea into a proof of concept and then a game-changing LLM application.\nAs we approach our annual Microsoft Ignite conference this month, we will continue to post updates to our product line. Join us for more groundbreaking announcements and demonstrations and stay tuned for our next blog in this series.\n\n\n\n\n\n\n\n\n\t\t\tRelated Posts\t\t\n\n\n\n\n \n\n\n\nAnnouncements\n\n\n\t\t\t\t\tAug 15\t\t\t\t\n\n\t\t\t\t\t5 min read\t\t\t\t\n\n\n\nMicrosoft Cost Management updates—July 2024 \n\n\n\n\nBy Sameer Doultani, Principal Product Manager\t\t\t\n\n\n\n\n\n \n\n\n\nAnnouncements\n\n\n\t\t\t\t\tAug 14\t\t\t\t\n\n\t\t\t\t\t3 min read\t\t\t\t\n\n\n\nElevate your AI deployments more efficiently with new deployment and cost management solutions for Azure OpenAI Service including self-service Provisioned \n\n\n\n\nBy Zia Mansoor, Vice President, Data and AI\t\t\t\n\n\n\n\n\n \n\n\n\nAnnouncements\n\n\n\t\t\t\t\tAug 7\t\t\t\t\n\n\t\t\t\t\t3 min read\t\t\t\t\n\n\n\nAnnouncing a new OpenAI feature for developers on Azure  \n\n\n\n\nBy Steve Sweetman \n\n\n \n\n\n\n\n\n\nExploreAzure AI solutions\n\nThe future of AI starts here. Envision your next great AI app with the latest technologies. Get started with Azure.\n\nLearn more about Azure\n\n\n\n\n\nConnect with us on social\nX\nYouTube\nLinkedIn\nInstagram\n\n\n\n\n\n\n\n\n\n\n\nExplore Azure\n\n\nWhat is Azure?\n\n\nGet started with Azure\n\n\nGlobal infrastructure\n\n\nDatacenter regions\n\n\nTrust your cloud\n\n\nAzure Essentials\n\n\nCustomer stories\n\n\n\n\nProducts and pricing\n\n\nProducts\n\n\nAzure pricing\n\n\nFree Azure services\n\n\nFlexible purchase options\n\n\nFinOps on Azure\n\n\nOptimize your costs\n\n\n\n\nSolutions and support\n\n\nSolutions\n\n\nResources for accelerating growth\n\n\nSolution architectures\n\n\nSupport\n\n\nAzure demo and live Q&A\n\n\n\n\n\n\nPartners\n\n\nAzure Marketplace\n\n\nFind a partner\n\n\nJoin ISV Success\n\n\n\n\nResources\n\n\nTraining and certifications\n\n\nDocumentation\n\n\nBlog\n\n\nDeveloper resources\n\n\nStudents\n\n\nEvents and Webinars\n\n\nAnalyst reports, white papers, and e-books\n\n\nVideos\n\n\n\n\nCloud computing\n\n\nWhat is cloud computing?\n\n\nWhat is cloud migration?\n\n\nWhat is a hybrid cloud?\n\n\nWhat is AI?\n\n\nWhat is PaaS?\n\n\nWhat is IaaS?\n\n\nWhat is SaaS?\n\n\nWhat is DevOps?\n\n\n\n\n\n\nEnglish (United States)\n\n\nYour Privacy Choices Opt-Out Icon\n\n\n\n\n\nYour Privacy Choices\n\n\n\n\nYour Privacy Choices Opt-Out Icon\n\n\n\n\n\nYour Privacy Choices\n\n\n\nConsumer Health Privacy\n\n\n\n\nSitemap\n\n\nContact Microsoft\n\n\nPrivacy \n\n\nManage cookies\n\n\nTerms of use\n\n\nTrademarks\n\n\nSafety & eco\n\n\nRecycling\n\n\nAbout our ads\n\n© Microsoft 2024\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"