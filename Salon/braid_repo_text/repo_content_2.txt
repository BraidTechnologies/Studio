****************************************
BoxerEval\test output\resultsOverviewVisualization.ipynb
****************************************
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Braid Technologies Ltd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Test Results 2024052802_Baseline.xlsx into variable: Test_Results_2024052802_Baseline\n",
      "Columns in Test_Results_2024052802_Baseline:\n",
      "Index(['Column1.question', 'Column1.hit', 'Column1.summary',\n",
      "       'Column1.hitRelevance', 'Column1.followUp', 'Column1.followUpOnTopic'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded Test Results Baseline - sameEmbeddingsAsV1.xlsx into variable: Test_Results_Baseline___sameEmbeddingsAsV1\n",
      "Columns in Test_Results_Baseline___sameEmbeddingsAsV1:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.followUp',\n",
      "       'Column1.followUpOnTopic'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v1_2024-08-28_14-25-47.xlsx into variable: test_output_v1_2024_08_28_14_25_47\n",
      "Columns in test_output_v1_2024_08_28_14_25_47:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v2_businessanalyst_2024-09-03_12-17-34.xlsx into variable: test_output_v2_businessanalyst_2024_09_03_12_17_34\n",
      "Columns in test_output_v2_businessanalyst_2024_09_03_12_17_34:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v2_developer_2024-09-03_12-10-22.xlsx into variable: test_output_v2_developer_2024_09_03_12_10_22\n",
      "Columns in test_output_v2_developer_2024_09_03_12_10_22:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v2_developer_2024-09-05_11-11-44.xlsx into variable: test_output_v2_developer_2024_09_05_11_11_44\n",
      "Columns in test_output_v2_developer_2024_09_05_11_11_44:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v2_nonetype_2024-09-03_12-03-59.xlsx into variable: test_output_v2_nonetype_2024_09_03_12_03_59\n",
      "Columns in test_output_v2_nonetype_2024_09_03_12_03_59:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v2_nonetype_2024-09-05_10-56-27.xlsx into variable: test_output_v2_nonetype_2024_09_05_10_56_27\n",
      "Columns in test_output_v2_nonetype_2024_09_05_10_56_27:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v2_tester_2024-09-03_12-13-59.xlsx into variable: test_output_v2_tester_2024_09_03_12_13_59\n",
      "Columns in test_output_v2_tester_2024_09_03_12_13_59:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v2_tester_2024-09-05_11-36-37.xlsx into variable: test_output_v2_tester_2024_09_05_11_36_37\n",
      "Columns in test_output_v2_tester_2024_09_05_11_36_37:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v3_businessanalyst_2024-09-17_03-35-43.xlsx into variable: test_output_v3_businessanalyst_2024_09_17_03_35_43\n",
      "Columns in test_output_v3_businessanalyst_2024_09_17_03_35_43:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.follow_up',\n",
      "       'Column1.follow_up_on_topic'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v3_developer_2024-0.xlsx into variable: test_output_v3_developer_2024_0\n",
      "Columns in test_output_v3_developer_2024_0:\n",
      "Index(['Column1', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.follow_up',\n",
      "       'Column1.follow_up_on_topic'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v3_nonetype_2024-09.xlsx into variable: test_output_v3_nonetype_2024_09\n",
      "Columns in test_output_v3_nonetype_2024_09:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.follow_up',\n",
      "       'Column1.follow_up_on_topic'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v3_tester_2024-09-17_03-21-25.xlsx into variable: test_output_v3_tester_2024_09_17_03_21_25\n",
      "Columns in test_output_v3_tester_2024_09_17_03_21_25:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.follow_up',\n",
      "       'Column1.follow_up_on_topic'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v4_businessanalyst_2024-09-29_01-42-36.xlsx into variable: test_output_v4_businessanalyst_2024_09_29_01_42_36\n",
      "Columns in test_output_v4_businessanalyst_2024_09_29_01_42_36:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.follow_up',\n",
      "       'Column1.follow_up_on_topic', 'Column1.gemini_evaluation'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v4_developer_2024-09-28_21-45-10.xlsx into variable: test_output_v4_developer_2024_09_28_21_45_10\n",
      "Columns in test_output_v4_developer_2024_09_28_21_45_10:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.follow_up',\n",
      "       'Column1.follow_up_on_topic', 'Column1.gemini_evaluation'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v4_nonetype_2024-09-28_21-30-03.xlsx into variable: test_output_v4_nonetype_2024_09_28_21_30_03\n",
      "Columns in test_output_v4_nonetype_2024_09_28_21_30_03:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.follow_up',\n",
      "       'Column1.follow_up_on_topic', 'Column1.gemini_evaluation'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v4_tester_2024-09-29_00-32-01.xlsx into variable: test_output_v4_tester_2024_09_29_00_32_01\n",
      "Columns in test_output_v4_tester_2024_09_29_00_32_01:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.follow_up',\n",
      "       'Column1.follow_up_on_topic', 'Column1.gemini_evaluation'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v5_businessanalyst_2024-10-07_17-55-42.xlsx into variable: test_output_v5_businessanalyst_2024_10_07_17_55_42\n",
      "Columns in test_output_v5_businessanalyst_2024_10_07_17_55_42:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.follow_up',\n",
      "       'Column1.follow_up_on_topic', 'Column1.gemini_evaluation'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v5_developer_2024-10-07_17-25-23.xlsx into variable: test_output_v5_developer_2024_10_07_17_25_23\n",
      "Columns in test_output_v5_developer_2024_10_07_17_25_23:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.follow_up',\n",
      "       'Column1.follow_up_on_topic', 'Column1.gemini_evaluation'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v5_nonetype_2024-10-07_18-04-26.xlsx into variable: test_output_v5_nonetype_2024_10_07_18_04_26\n",
      "Columns in test_output_v5_nonetype_2024_10_07_18_04_26:\n",
      "Index(['Column1', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.follow_up',\n",
      "       'Column1.follow_up_on_topic', 'Column1.gemini_evaluation'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Loaded test_output_v5_tester_2024-10-07_17-35-56.xlsx into variable: test_output_v5_tester_2024_10_07_17_35_56\n",
      "Columns in test_output_v5_tester_2024_10_07_17_35_56:\n",
      "Index(['Column1.question', 'Column1.enriched_question', 'Column1.hit',\n",
      "       'Column1.summary', 'Column1.hitRelevance', 'Column1.follow_up',\n",
      "       'Column1.follow_up_on_topic', 'Column1.gemini_evaluation'],\n",
      "      dtype='object')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the files\n",
    "directory = \"D:/Braid Technologies/BraidTechnologiesRepo/WorkedExamples/BoxerTest/test output\"\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Filter to get only the Excel files (.xlsx)\n",
    "excel_files = [file for file in files if file.endswith('.xlsx')]\n",
    "\n",
    "# Function to convert filename into a valid variable name\n",
    "def create_variable_name(filename):\n",
    "    variable_name = filename.replace('.xlsx', '').replace(' ', '_').replace('-', '_').replace('.', '_')\n",
    "    return variable_name\n",
    "\n",
    "# Read each Excel file and assign it to a dynamically named variable\n",
    "for excel_file in excel_files:\n",
    "    file_path = os.path.join(directory, excel_file)\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Generate a valid variable name\n",
    "    variable_name = create_variable_name(excel_file)\n",
    "    \n",
    "    # Use globals() to dynamically assign the DataFrame to the variable name\n",
    "    globals()[variable_name] = df\n",
    "    print(f\"Loaded {excel_file} into variable: {variable_name}\")\n",
    "    \n",
    "    # Print the columns of each dataframe for inspection\n",
    "    print(f\"Columns in {variable_name}:\")\n",
    "    print(df.columns)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations Set 1: Box Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds as variables for flexibility\n",
    "threshold_baseline_to_v4 = 0.8\n",
    "threshold_v5 = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box Plot: Static Persona all versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "baseline",
         "marker": {
          "color": "rgb(102,194,165)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "baseline",
         "notched": false,
         "offsetgroup": "baseline",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.8784441145756917,
          0.8774876933819626,
          0.8746684526475066,
          0.8746424643210794,
          0.8672439394801955,
          0.8603153999309818,
          0.855133577099862,
          0.854684365530313,
          0.8545490013947185,
          0.8536750205786069,
          0.8501388581189828,
          0.8499660383782022,
          0.8470403662206168,
          0.8463422141715554,
          0.8454658353831477,
          0.8453736197417216,
          0.8451186188958659,
          0.8450729794568982,
          0.843996474043092,
          0.8417384332596856,
          0.8399934314279974,
          0.8382348105204843,
          0.8373992935457025,
          0.8361225308669625,
          0.8351752441648143,
          0.8343694018089332,
          0.8321899352349762,
          0.832155049588577,
          0.830248828676792,
          0.8295025892387569,
          0.8289186592390524,
          0.8288114265837756,
          0.8284027920639331,
          0.8273072353527722,
          0.8271236092473713,
          0.826975894551871,
          0.8265560599870281,
          0.825320371453267,
          0.8248481659124333,
          0.824346976359626,
          0.8229000166277352,
          0.8206292698708735,
          0.8198691672518295,
          0.8195897019982514,
          0.8194865396947004,
          0.8188920393542686,
          0.8167959019266425,
          0.8164857256712671,
          0.8159706347347968,
          0.8159293705435575,
          0.8157958553839585,
          0.8154986121078773,
          0.814084258399054,
          0.8117359799225621,
          0.8115161548623933,
          0.8111692492276386,
          0.8108709355131023,
          0.810498399917788,
          0.8101889348326631,
          0.8099605332098587,
          0.8092608604270364,
          0.8079074337556884,
          0.8078390308025816,
          0.8078210638903874,
          0.8077010144788173,
          0.8076098567585128,
          0.807204013767107,
          0.8067548407994568,
          0.8061181657940557,
          0.8060373413831154,
          0.8059647466331435,
          0.8049369563243841,
          0.8036939307668896,
          0.8025805035692839,
          0.8022600750793488,
          0.8012921522278786,
          0.8005338717485814,
          0.7993632539029342,
          0.7977609335991143,
          0.7977478616824621,
          0.7970567781996246,
          0.7960420128627206,
          0.7959482970504347,
          0.7948834305972643,
          0.794524347185814,
          0.7939856708447534,
          0.7937062140910492,
          0.7932719784138285,
          0.7918442800322498,
          0.7901422444482195,
          0.7889456502312663,
          0.7883422641059364,
          0.7872176322886016,
          0.7869777101688635,
          0.7856166825021259,
          0.7854434461911843,
          0.7812875857150219,
          0.7810471085440618,
          0.7763484036629806
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v1",
         "marker": {
          "color": "rgb(252,141,98)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v1",
         "notched": false,
         "offsetgroup": "v1",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1",
          "v1"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.924393906743026,
          0.9196197307846814,
          0.8825453470648145,
          0.9419836152751369,
          0.8975484931393578,
          0.9006644801836481,
          0.8977080433152496,
          0.8768427687461189,
          0.866785073743707,
          0.8800914343652871,
          0.889463879803277,
          0.8774046754452423,
          0.8853839932582857,
          0.8611237869950039,
          0.9025014929395084,
          0.8721533465732854,
          0.8893276465553455,
          0.9474367915470402,
          0.9196082914928412,
          0.9104634578659536,
          0.8813608196512471,
          0.8832289825869751,
          0.8943909102965277,
          0.8733851781088875,
          0.878329959424582,
          0.878437707412324,
          0.9036892070514992,
          0.8906516541140975,
          0.8809789373092691,
          0.7869028287789468,
          0.9122188833033122,
          0.8758124028340517,
          0.8995820133429755,
          0.8925493497314996,
          0.9076956487276172,
          0.8930047486215221,
          0.8798066217189165,
          0.8752383447498052,
          0.7869028287789468,
          0.9221819567817656,
          0.900731387387977,
          0.9049989099877668,
          0.901678749344388,
          0.8787264646280729,
          0.8688002811140939,
          0.8709995106036429,
          0.8844732560868644,
          0.9086761349035344,
          0.8970097815672291,
          0.878465725171397,
          0.8083703954979202,
          0.9083431734259648,
          0.8973444266406977,
          0.9034778476492,
          0.866285395122804,
          0.8878699520674281,
          0.8563737388393757,
          0.8823015340438092,
          0.88465944513763,
          0.7869028287789468,
          0.8854094789645809,
          0.8793141728608034,
          0.9005005328022911,
          0.8974425891351023,
          0.890067281771038,
          0.8658099442602168,
          0.8496761951073898,
          0.7869028287789468,
          0.8865766117548506,
          0.8832139456700308,
          0.8293944736856675,
          0.9003748819551849,
          0.8549134928018522,
          0.8790993214401471,
          0.8886748362035549,
          0.850524606511569,
          0.8995291091543325,
          0.8930652736969807,
          0.8730485074069402,
          0.870791079873467,
          0.7869028287789468,
          0.9088065613543568,
          0.8837147902049028,
          0.8797394457853547,
          0.8782849114748466,
          0.8793997210638661,
          0.8577444746083728,
          0.881085912634266,
          0.8352460647346155,
          0.8951948088957126,
          0.8696743779067561,
          0.8661900150435694,
          0.8725327171504833,
          0.8153449800176882,
          0.8554040653098364,
          0.8562968713770878,
          0.8490709056683587,
          0.8652669929819938,
          0.8083703954979202
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v2",
         "marker": {
          "color": "rgb(141,160,203)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v2",
         "notched": false,
         "offsetgroup": "v2",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.9243939067430264,
          0.9196197307846814,
          0.8825453470648145,
          0.9419836152751369,
          0.8975484931393578,
          0.9006644801836481,
          0.9001721544418274,
          0.8768427687461189,
          0.866785073743707,
          0.8800914343652871,
          0.889463879803277,
          0.8774046754452423,
          0.8853839932582857,
          0.8611237869950039,
          0.9025014929395084,
          0.8721533465732854,
          0.8893276465553455,
          0.9474367915470402,
          0.9196082914928412,
          0.9104634578659536,
          0.8813608196512471,
          0.8832289825869751,
          0.8943909102965277,
          0.8737754648414694,
          0.878329959424582,
          0.878437707412324,
          0.9036892070514992,
          0.8906516541140975,
          0.8809789373092691,
          0.7869028287789468,
          0.9122188833033122,
          0.8758124028340517,
          0.8995820133429755,
          0.8925493497314996,
          0.907489681483558,
          0.8930047486215221,
          0.8798066217189165,
          0.8752383447498052,
          0.7869028287789468,
          0.9221819567817656,
          0.900731387387977,
          0.9049989099877668,
          0.901678749344388,
          0.8787264646280729,
          0.8688002811140939,
          0.8709995106036429,
          0.8958046893978626,
          0.9086761349035344,
          0.8970097815672291,
          0.8862818711565011,
          0.8083703954979202,
          0.9083431734259648,
          0.8973444266406977,
          0.9034778476492,
          0.8623330133476658,
          0.8878699520674281,
          0.8563737388393757,
          0.8832868391747636,
          0.88465944513763,
          0.7869028287789468,
          0.8854094789645809,
          0.8793141728608034,
          0.9005005328022911,
          0.8974425891351023,
          0.890067281771038,
          0.8658099442602168,
          0.8496761951073898,
          0.7869028287789468,
          0.8865766117548506,
          0.8728400750173998,
          0.8293944736856675,
          0.9003748819551849,
          0.8549134928018522,
          0.8889713645737101,
          0.8886748362035549,
          0.850524606511569,
          0.8995291091543325,
          0.8930652736969807,
          0.8730485074069402,
          0.870791079873467,
          0.7869028287789468,
          0.9088065613543568,
          0.8837147902049028,
          0.8797394457853547,
          0.8782849114748466,
          0.8793997210638661,
          0.8577444746083728,
          0.881085912634266,
          0.8352460647346155,
          0.8951948088957126,
          0.8702655201361587,
          0.8661900150435694,
          0.8725327171504833,
          0.8153449800176882,
          0.8554040653098364,
          0.8562968713770878,
          0.8490709056683587,
          0.8652669929819938,
          0.8083703954979202
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v3",
         "marker": {
          "color": "rgb(231,138,195)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v3",
         "notched": false,
         "offsetgroup": "v3",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.9102863570496312,
          0.9111326313307512,
          0.8932963934535463,
          0.916287037186294,
          0.8963182789980809,
          0.9155823461989266,
          0.8804366333634528,
          0.8531395561507806,
          0.8794404378099483,
          0.911845697918194,
          0.891650221981209,
          0.8793998958141752,
          0.8963567436737593,
          0.8758339056529525,
          0.9001711385822954,
          0.8721424218133543,
          0.9241784315679225,
          0.9503984050753228,
          0.899196083760261,
          0.8729473222805881,
          0.9097360708864052,
          0.8791826793196098,
          0.8844092461003461,
          0.906051403068038,
          0.8787108485775526,
          0.8807908793545486,
          0.9072472256126204,
          0.8935409216037367,
          0.8739062348052659,
          0.8899149172803996,
          0.9050704930175772,
          0.917986871968316,
          0.8856807915827534,
          0.8889750298816943,
          0.8815775654815671,
          0.9015841067812976,
          0.8562689185154987,
          0.8788100836539721,
          0.821834469706107,
          0.9199758819533326,
          0.8730628738661588,
          0.8989870736125395,
          0.8832383397891186,
          0.8717191916649,
          0.8689511339258135,
          0.8657558862457023,
          0.8729166660338238,
          0.8750168499195771,
          0.8644314454810835,
          0.8955164057266124,
          0.8956610462740369,
          0.869623925325292,
          0.8845357012184273,
          0.874238879585829,
          0.8455064638965984,
          0.8872603065937068,
          0.8517043158830384,
          0.868910928875287,
          0.8981308721985063,
          0.8739347691944866,
          0.8917200102786358,
          0.857369829621579,
          0.8616783695004196,
          0.8691082243801631,
          0.872347983599727,
          0.8895936907611239,
          0.8831906572622278,
          0.8241676086086914,
          0.8693780270815367,
          0.8409705472570665,
          0.8498475248739437,
          0.8738315878289198,
          0.836865422200058,
          0.8491313795871752,
          0.8814053714536882,
          0.8353251641242605,
          0.8644015906793546,
          0.8661652419170786,
          0.8703993623704002,
          0.877041231277552,
          0.854653260188563,
          0.8755974266169718,
          0.8519364476849055,
          0.8489493218611897,
          0.8376595086063615,
          0.8853442104303648,
          0.8746793364511695,
          0.8357013888344408,
          0.8313767012659128,
          0.8761802927983601,
          0.8550202599149437,
          0.8698249504976189,
          0.856345651667017,
          0.8208274981947007,
          0.847567614403881,
          0.8696593450311181,
          0.8097623915928384,
          0.8685240577638,
          0.8029446049613596
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v4",
         "marker": {
          "color": "rgb(166,216,84)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v4",
         "notched": false,
         "offsetgroup": "v4",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.9097454065690208,
          0.9146952930552276,
          0.8941589155284498,
          0.916287037186294,
          0.8997835397330693,
          0.8997298548696421,
          0.8871333935790341,
          0.8573013165556782,
          0.8900350912307643,
          0.9105421821824942,
          0.8936743771219616,
          0.8748559413280973,
          0.8944453950418302,
          0.882531939367155,
          0.9050497683123672,
          0.8728668700189449,
          0.9246063188814052,
          0.9503984050753228,
          0.8919065631007775,
          0.890839257880814,
          0.9117307814851824,
          0.8791826793196098,
          0.8844092461003461,
          0.907005446339322,
          0.8730020946296939,
          0.8858990608400041,
          0.9155702794727816,
          0.8935409216037367,
          0.8806624400824667,
          0.8845030955247996,
          0.8990167445484607,
          0.9181384263037144,
          0.8856807915827534,
          0.8919791914679454,
          0.8799867775276035,
          0.906164066758436,
          0.846105972981078,
          0.8632301420589058,
          0.821834469706107,
          0.9168439843603292,
          0.8730628738661588,
          0.8961541173952502,
          0.8930383620789725,
          0.873398419894492,
          0.8680503120078186,
          0.8686086536087215,
          0.8909779895727419,
          0.8652959317079337,
          0.8644314454810835,
          0.8893894650962594,
          0.8956610462740369,
          0.869623925325292,
          0.8961282260807768,
          0.8676048856093134,
          0.8461001310998058,
          0.8872603065937068,
          0.8508780652690656,
          0.8655220585731731,
          0.8943338061561141,
          0.8678952715338496,
          0.8988973766772407,
          0.8622646466664529,
          0.8616783695004196,
          0.8774183214069123,
          0.8513876287721488,
          0.8895936907611239,
          0.8831906572622278,
          0.8210666597145564,
          0.8693780270815367,
          0.8382160214466984,
          0.8505341245916723,
          0.8751734057631104,
          0.8460107222830198,
          0.8726079394035209,
          0.8890114058330164,
          0.8299660160251069,
          0.869166415605693,
          0.8556854763683883,
          0.8763041507348912,
          0.8806153115362199,
          0.8601061732870892,
          0.8777439849842348,
          0.867812425845204,
          0.8428085509264354,
          0.8444366691045202,
          0.8831714438416778,
          0.8746793364511695,
          0.8504311665044678,
          0.8391522960946612,
          0.8482990888126966,
          0.8643824647379152,
          0.8724320843995278,
          0.8627392260254052,
          0.8198790625192233,
          0.8456025969202264,
          0.8737674294218963,
          0.8110655271040754,
          0.8600789560676712,
          0.8029446049613596
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v5",
         "marker": {
          "color": "rgb(255,217,47)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v5",
         "notched": false,
         "offsetgroup": "v5",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.6731369367196186,
          0.6323135191555299,
          0.5006659540333269,
          0.7716985956105529,
          0.5766350368531212,
          0.6663332896682035,
          0.6367316360363126,
          0.5796837212028515,
          0.5600788971319738,
          0.5975354552166916,
          0.5973072022288308,
          0.5287444433166782,
          0.6516017178514449,
          0.534736986669372,
          0.6195480880639543,
          0.645337990929014,
          0.6386517810197362,
          0.514074583983961,
          0.6815023838724285,
          0.5990940647152662,
          0.6801472106742469,
          0.5684908872406775,
          0.5752713592379886,
          0.6161912052347343,
          0.6801369401015469,
          0.5845394166769631,
          0.6543367988114225,
          0.6117959463887068,
          0.6160300278531107,
          0.6496918093041857,
          0.6719629371048373,
          0.6203056874564287,
          0.6134468627126082,
          0.5781589763970728,
          0.6105740701826523,
          0.6947086033378694,
          0.5291563195265314,
          0.5432901396564853,
          0.5179860737997545,
          0.6612861072303015,
          0.5661888095923717,
          0.6051030879690789,
          0.6402930586594894,
          0.5553412053827245,
          0.5651653651167712,
          0.608802380472875,
          0.6357586184202657,
          0.5974777919918486,
          0.662749796152806,
          0.5318721776485819,
          0.6108998408183915,
          0.5588826198839557,
          0.5962617901606643,
          0.5672801383797338,
          0.5223279169527594,
          0.6442206613763538,
          0.5551265351855341,
          0.5903162538615705,
          0.552906559133195,
          0.6186804552531608,
          0.6308996394936437,
          0.5514039965679497,
          0.5558179608474426,
          0.6582613961593514,
          0.5567287350733925,
          0.5662416833826047,
          0.5681068934105677,
          0.3935201190872517,
          0.5659531832177507,
          0.5075502790538586,
          0.47006342716934,
          0.7006802245363074,
          0.5283867200836436,
          0.4888247111847659,
          0.567965290896608,
          0.4986059847398644,
          0.6523283969648632,
          0.6352992922469146,
          0.6503658722569365,
          0.6416843997092457,
          0.4907060335795465,
          0.6441758718579682,
          0.5713241091300499,
          0.5764094654751307,
          0.5584517426067436,
          0.582698289012325,
          0.6401734158003897,
          0.5550108640888761,
          0.5072769278406136,
          0.563457141763934,
          0.6329583240946072,
          0.5768580507896294,
          0.5565887937055662,
          0.4353284213671637,
          0.5628903965614241,
          0.6477037065151873,
          0.4164287322152645,
          0.5828384288044239,
          0.37426439727290167
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "darkred",
           "size": 12
          },
          "showarrow": false,
          "text": "Threshold: 0.8",
          "x": 5,
          "xshift": 50,
          "y": 0.8,
          "yshift": 10
         },
         {
          "font": {
           "color": "darkblue",
           "size": 12
          },
          "showarrow": false,
          "text": "Threshold: 0.6",
          "x": 5,
          "xshift": 50,
          "y": 0.6,
          "yshift": -10
         }
        ],
        "bargap": 0.15,
        "boxmode": "group",
        "font": {
         "family": "Arial",
         "size": 14
        },
        "height": 650,
        "hovermode": "closest",
        "legend": {
         "title": {
          "text": "Version"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "b": 60,
         "l": 60,
         "r": 40,
         "t": 70
        },
        "plot_bgcolor": "#f7f7f7",
        "shapes": [
         {
          "line": {
           "color": "darkred",
           "dash": "dash",
           "width": 2
          },
          "opacity": 0.7,
          "type": "line",
          "x0": -0.5,
          "x1": 4.5,
          "y0": 0.8,
          "y1": 0.8
         },
         {
          "line": {
           "color": "darkblue",
           "dash": "dash",
           "width": 2
          },
          "opacity": 0.7,
          "type": "line",
          "x0": 4,
          "x1": 5.5,
          "y0": 0.6,
          "y1": 0.6
         }
        ],
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "darkblue",
          "family": "Times New Roman",
          "size": 22
         },
         "text": "Hit Relevance Distribution by Version (Static Persona)"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "baseline",
          "v1",
          "v2",
          "v3",
          "v4",
          "v5"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Version"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "showgrid": true,
         "title": {
          "text": "Hit Relevance Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define thresholds as variables for flexibility\n",
    "threshold_baseline_to_v4 = 0.8\n",
    "threshold_v5 = 0.6\n",
    "\n",
    "# Dataframes for Static Persona\n",
    "dataframes_static = {\n",
    "    \"baseline\": Test_Results_2024052802_Baseline,\n",
    "    \"v1\": test_output_v1_2024_08_28_14_25_47,\n",
    "    \"v2\": test_output_v2_nonetype_2024_09_03_12_03_59,\n",
    "    \"v3\": test_output_v3_nonetype_2024_09,\n",
    "    \"v4\": test_output_v4_nonetype_2024_09_28_21_30_03,\n",
    "    \"v5\": test_output_v5_nonetype_2024_10_07_18_04_26\n",
    "}\n",
    "\n",
    "# Combine data for easier plotting\n",
    "all_data_static = []\n",
    "for version, df in dataframes_static.items():\n",
    "    df['version'] = version  # Add a column for version\n",
    "    all_data_static.append(df[['Column1.hit', 'Column1.hitRelevance', 'version']])\n",
    "\n",
    "# Concatenate all data into a single DataFrame\n",
    "combined_df_static = pd.concat(all_data_static)\n",
    "\n",
    "# Convert hit column to binary values (1 if hit, 0 if not) based on a threshold of 0.75\n",
    "combined_df_static['hit_binary'] = combined_df_static['Column1.hitRelevance'].apply(lambda x: 1 if x >= 0.75 else 0)\n",
    "\n",
    "# Create a box plot for Static Persona including the baseline\n",
    "fig_static = px.box(combined_df_static, \n",
    "                    x='version', \n",
    "                    y='Column1.hitRelevance', \n",
    "                    points='all',  # Show all data points\n",
    "                    title='Hit Relevance Distribution by Version (Static Persona)',\n",
    "                    labels={'Column1.hitRelevance': 'Hit Relevance Score', 'version': 'Version'},\n",
    "                    color='version',  \n",
    "                    color_discrete_sequence=px.colors.qualitative.Set2)  # Use distinct color palette\n",
    "\n",
    "# Customize box plot aesthetics\n",
    "fig_static.update_traces(\n",
    "    boxmean=True, \n",
    "    jitter=0.2,\n",
    "    pointpos=-1.5,\n",
    "    marker=dict(size=6, opacity=0.8),\n",
    "    width=0.4\n",
    ")\n",
    "\n",
    "# Add horizontal lines for thresholds\n",
    "fig_static.add_shape(\n",
    "    type=\"line\", line_color=\"darkred\", line_width=2, opacity=0.7, \n",
    "    x0=-0.5, x1=4.5, y0=threshold_baseline_to_v4, y1=threshold_baseline_to_v4, \n",
    "    line_dash=\"dash\"\n",
    ")\n",
    "fig_static.add_shape(\n",
    "    type=\"line\", line_color=\"darkblue\", line_width=2, opacity=0.7, \n",
    "    x0=4, x1=5.5, y0=threshold_v5, y1=threshold_v5,\n",
    "    line_dash=\"dash\"\n",
    ")\n",
    "\n",
    "# Move the threshold text annotations to the right\n",
    "fig_static.add_annotation(\n",
    "    x=5, y=threshold_baseline_to_v4,\n",
    "    text=\"Threshold: 0.8\", showarrow=False, xshift=50, yshift=10,\n",
    "    font=dict(size=12, color=\"darkred\")\n",
    ")\n",
    "fig_static.add_annotation(\n",
    "    x=5, y=threshold_v5,\n",
    "    text=\"Threshold: 0.6\", showarrow=False, xshift=50, yshift=-10,\n",
    "    font=dict(size=12, color=\"darkblue\")\n",
    ")\n",
    "\n",
    "# Adjust layout for better spacing and visual clarity\n",
    "fig_static.update_layout(\n",
    "    xaxis_title='Version',\n",
    "    yaxis_title='Hit Relevance Score',\n",
    "    legend_title_text='Version',\n",
    "    font=dict(size=14, family='Arial'),\n",
    "    plot_bgcolor='#f7f7f7',  \n",
    "    title_font=dict(size=22, family='Times New Roman', color='darkblue'),  \n",
    "    width=1000,\n",
    "    height=650,\n",
    "    margin=dict(t=70, l=60, r=40, b=60),\n",
    "    boxmode='group', \n",
    "    showlegend=True,  \n",
    "    yaxis=dict(showgrid=True, gridcolor='lightgray'),  \n",
    "    bargap=0.15,\n",
    "    hovermode=\"closest\"  \n",
    ")\n",
    "\n",
    "# Update hover template\n",
    "fig_static.update_traces(\n",
    "    hovertemplate=\"<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}\"\n",
    ")\n",
    "\n",
    "# Display the figure\n",
    "fig_static.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box Plot: Tester Persona all versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "baseline",
         "marker": {
          "color": "rgb(102,194,165)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "baseline",
         "notched": false,
         "offsetgroup": "baseline",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.8784441145756917,
          0.8774876933819626,
          0.8746684526475066,
          0.8746424643210794,
          0.8672439394801955,
          0.8603153999309818,
          0.855133577099862,
          0.854684365530313,
          0.8545490013947185,
          0.8536750205786069,
          0.8501388581189828,
          0.8499660383782022,
          0.8470403662206168,
          0.8463422141715554,
          0.8454658353831477,
          0.8453736197417216,
          0.8451186188958659,
          0.8450729794568982,
          0.843996474043092,
          0.8417384332596856,
          0.8399934314279974,
          0.8382348105204843,
          0.8373992935457025,
          0.8361225308669625,
          0.8351752441648143,
          0.8343694018089332,
          0.8321899352349762,
          0.832155049588577,
          0.830248828676792,
          0.8295025892387569,
          0.8289186592390524,
          0.8288114265837756,
          0.8284027920639331,
          0.8273072353527722,
          0.8271236092473713,
          0.826975894551871,
          0.8265560599870281,
          0.825320371453267,
          0.8248481659124333,
          0.824346976359626,
          0.8229000166277352,
          0.8206292698708735,
          0.8198691672518295,
          0.8195897019982514,
          0.8194865396947004,
          0.8188920393542686,
          0.8167959019266425,
          0.8164857256712671,
          0.8159706347347968,
          0.8159293705435575,
          0.8157958553839585,
          0.8154986121078773,
          0.814084258399054,
          0.8117359799225621,
          0.8115161548623933,
          0.8111692492276386,
          0.8108709355131023,
          0.810498399917788,
          0.8101889348326631,
          0.8099605332098587,
          0.8092608604270364,
          0.8079074337556884,
          0.8078390308025816,
          0.8078210638903874,
          0.8077010144788173,
          0.8076098567585128,
          0.807204013767107,
          0.8067548407994568,
          0.8061181657940557,
          0.8060373413831154,
          0.8059647466331435,
          0.8049369563243841,
          0.8036939307668896,
          0.8025805035692839,
          0.8022600750793488,
          0.8012921522278786,
          0.8005338717485814,
          0.7993632539029342,
          0.7977609335991143,
          0.7977478616824621,
          0.7970567781996246,
          0.7960420128627206,
          0.7959482970504347,
          0.7948834305972643,
          0.794524347185814,
          0.7939856708447534,
          0.7937062140910492,
          0.7932719784138285,
          0.7918442800322498,
          0.7901422444482195,
          0.7889456502312663,
          0.7883422641059364,
          0.7872176322886016,
          0.7869777101688635,
          0.7856166825021259,
          0.7854434461911843,
          0.7812875857150219,
          0.7810471085440618,
          0.7763484036629806
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v2",
         "marker": {
          "color": "rgb(252,141,98)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v2",
         "notched": false,
         "offsetgroup": "v2",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.9260896548361044,
          0.8958465943886792,
          0.8835965409616544,
          0.8873837995736313,
          0.8533479846923361,
          0.9035330506872984,
          0.8713233459019327,
          0.8680085066020624,
          0.8190568611323094,
          0.8815219379965763,
          0.8345599170000927,
          0.9132679311334024,
          0.8066154482552983,
          0.8754113638252863,
          0.7869028287789468,
          0.8937630766721856,
          0.8357541911288255,
          0.8444135294118604,
          0.7869028287789468,
          0.8603974601345054,
          0.7869028287789468,
          0.8893231070197398,
          0.7869028287789468,
          0.8784992926819956,
          0.7869028287789468,
          0.8329459623017822,
          0.7869028287789468,
          0.8831018847649333,
          0.7869028287789468,
          0.8304822390967751,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.8805711473862292,
          0.7869028287789468,
          0.863031670173316,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.8083703954979202,
          0.8702575370109655,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.8432393091870631,
          0.8583835613039328,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.8083703954979202,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.8083703954979202,
          0.7869028287789468,
          0.8083703954979202,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.8083703954979202,
          0.7869028287789468,
          0.8083703954979202,
          0.7869028287789468,
          0.8083703954979202,
          0.7869028287789468
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v3",
         "marker": {
          "color": "rgb(141,160,203)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v3",
         "notched": false,
         "offsetgroup": "v3",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.8083703954979202,
          0.9015171754259578,
          0.8837635812431716,
          0.8946324709152895,
          0.8749615685205423,
          0.8609085530793594,
          0.8923783642835412,
          0.8400127777995611,
          0.8559000189173868,
          0.8610576837707733,
          0.8816710844115082,
          0.8879365385767628,
          0.8479416812151344,
          0.8660337901743131,
          0.8658823528937307,
          0.8797883047885774,
          0.8564037275268988,
          0.893291145304563,
          0.8699357659602196,
          0.8843390913864568,
          0.865274474085645,
          0.8742042946540715,
          0.894052300078144,
          0.866061568775749,
          0.8680381692617449,
          0.8763184688319102,
          0.8452840841558233,
          0.8642551674216407,
          0.9000543325509806,
          0.834566958924211,
          0.8495751864287734,
          0.857172606444935,
          0.885955392802664,
          0.883679291694515,
          0.8639565363512176,
          0.8895918588345837,
          0.8792651567865146,
          0.8588833064324073,
          0.8667847771738724,
          0.8835163885238911,
          0.8908259460290608,
          0.8778987907593877,
          0.8768674445521122,
          0.8721827309596497,
          0.8659382556285979,
          0.8570277978566414,
          0.8703736585022539,
          0.8832320962247275,
          0.8769112086779935,
          0.8613149146379736,
          0.8582612252297606,
          0.892564500517015,
          0.8644078382101941,
          0.8882612740393964,
          0.8574631475788088,
          0.8816617966667775,
          0.8680218381539563,
          0.8837603702345594,
          0.8662604177753735,
          0.8977959508719734,
          0.8763335639473581,
          0.8834053275408591,
          0.8683890274631374,
          0.8917816788812097,
          0.866012329794057,
          0.8893836466284686,
          0.8654097474120723,
          0.8871932192350038,
          0.8685926139809419,
          0.8912970771976463,
          0.8671114258538987,
          0.8877321653436078,
          0.8894235437271147,
          0.871625457533162,
          0.884415953135862,
          0.8654498883140633,
          0.8580881231454508,
          0.8737164279194867,
          0.8526935909967343,
          0.901509665570102,
          0.8938942046190123,
          0.8868835425853685,
          0.866972158098575,
          0.8845187341218077,
          0.8692471065432266,
          0.8902972146005897,
          0.850853241229639,
          0.8898047115055115,
          0.8679444453972042,
          0.8655358413538649,
          0.8572797634282897,
          0.8822278379691474,
          0.8662009219736643,
          0.8741928447012778,
          0.8674757682402574,
          0.8838565402063694,
          0.8692620309832861,
          0.8780055294175004,
          0.8497140727660184,
          0.8986917345010078,
          0.8704297858168426,
          0.8799261647674379
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v4",
         "marker": {
          "color": "rgb(231,138,195)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v4",
         "notched": false,
         "offsetgroup": "v4",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.899425678580573,
          0.8841858110842884,
          0.8946324709152895,
          0.8782529409682958,
          0.8848509948202548,
          0.8765631908790298,
          0.8694720558744535,
          0.8816710844115082,
          0.853556733131251,
          0.851390555013653,
          0.8516295850035306,
          0.8448546946284595,
          0.9149889628496224,
          0.8835936323582444,
          0.8701221601791951,
          0.8421982714748847,
          0.8507106596227634,
          0.8630587612624951,
          0.8564037275268988,
          0.8830868630872897,
          0.8959521157397163,
          0.8523304026380984,
          0.8820680897147363,
          0.873302738139707,
          0.8662067928063856,
          0.8483985653426406,
          0.861618668162659,
          0.8900700283316093,
          0.8681242705488184,
          0.8301815964287346,
          0.8781911893759358,
          0.8799118223635365,
          0.8804708824383403,
          0.8800770177556605,
          0.8658125498372031,
          0.8717858304296473,
          0.8667950988683732,
          0.8509893908541228,
          0.8707194313343154,
          0.8564858475640829,
          0.8631344371435414,
          0.8717643234307194,
          0.8593765446884328,
          0.8339525641580207,
          0.871686351236009,
          0.8809646937695196,
          0.864465999804472,
          0.8608462381511908,
          0.8749077231927151,
          0.871139547948769,
          0.8945689572110711,
          0.8708724473393297,
          0.8861350552861318,
          0.8532426815410784,
          0.8598941095982945,
          0.867567396005291,
          0.8609057670026643,
          0.8286622463562502,
          0.8780297005345394,
          0.8838005691172023,
          0.8722468594757767,
          0.8751577028106131,
          0.8600058430423959,
          0.8805785552896785,
          0.8708701548282857,
          0.8661319936330839,
          0.8672548872932427,
          0.8721837992956972,
          0.8724539762151607,
          0.8333022916990186,
          0.8846299738046205,
          0.8986499335615127,
          0.8605682992736433,
          0.873161380722288,
          0.8862103516176731,
          0.8783930326564098,
          0.8845243343928193,
          0.8592618631134071,
          0.8650531711234029,
          0.8869733166807602,
          0.8836545084123362,
          0.8583163107227766,
          0.8895492481569449,
          0.8868200736265422,
          0.8569884908993959,
          0.8639701393099244,
          0.8703775637869767,
          0.8587823329468198,
          0.8737687199223553,
          0.8460184316230777,
          0.8868657091211494,
          0.8767387618572849,
          0.8885866629771221,
          0.8645786275221989,
          0.8799682999419439,
          0.8894621218575381,
          0.8817614418139013,
          0.8682819885407279,
          0.8849975614108211,
          0.8768515264945107
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v5",
         "marker": {
          "color": "rgb(166,216,84)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v5",
         "notched": false,
         "offsetgroup": "v5",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.6547423615411883,
          0.5926958703882844,
          0.594969910319314,
          0.6160156827895168,
          0.5698871349370588,
          0.5617320256678324,
          0.6111754694470071,
          0.6351630296316265,
          0.5293620036593946,
          0.5165885848632344,
          0.6250891883376415,
          0.49050136945260353,
          0.6203614498942224,
          0.4531948769457778,
          0.6774992403523487,
          0.5846492597137487,
          0.5163347446350194,
          0.5919516919393911,
          0.6402926311497983,
          0.5635205370102799,
          0.5354044743483545,
          0.6143051704606554,
          0.5369242242159882,
          0.5367452337341134,
          0.578056803814586,
          0.5433467016775535,
          0.6301831975695363,
          0.5641906054153115,
          0.5907335452846273,
          0.6248047560151081,
          0.5660981755903569,
          0.5447378589290522,
          0.563288931130918,
          0.5748471682351924,
          0.5826424452581832,
          0.5427189123366614,
          0.5413360870891892,
          0.595766223122522,
          0.5957339778332926,
          0.5776283443287193,
          0.6032933229688233,
          0.6326433183463078,
          0.5503216950175941,
          0.6016617148871323,
          0.5544780575962043,
          0.6636248888945908,
          0.5880464619014087,
          0.6388290857277393,
          0.531036979609324,
          0.584734072567297,
          0.5338601023240597,
          0.5773632366452974,
          0.563860275460953,
          0.6406218658552324,
          0.5509740336322557,
          0.5064902771522247,
          0.5668280872435397,
          0.5332541056260819,
          0.595003980380172,
          0.6121739113380347,
          0.6440538036285128,
          0.564323388040357,
          0.5942667061121738,
          0.6414614235034671,
          0.5937492885840039,
          0.6432231385667997,
          0.611585823211942,
          0.6050815900818665,
          0.5355819303024529,
          0.538020868997667,
          0.5844923599809049,
          0.6145211319764742,
          0.5406255094606985,
          0.5920360836459677,
          0.5624074477991295,
          0.6337873312853946,
          0.5931903312840862,
          0.5922815646098171,
          0.6398459186989373,
          0.5964084460765852,
          0.5981937523759794,
          0.6656281506557784,
          0.596401168464537,
          0.6256239928849933,
          0.5764258196365921,
          0.5920360836459677,
          0.5571014837924884,
          0.5656138004916621,
          0.5641147867309964,
          0.6038237092867681,
          0.5832365100508811,
          0.5982273273453204,
          0.5981937523759794,
          0.6688786422362436,
          0.5907682871801937,
          0.5865539788915848,
          0.6398459186989373,
          0.6189789563509723,
          0.5556884954117249,
          0.6240766790855555
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "darkred",
           "size": 12
          },
          "showarrow": false,
          "text": "Threshold: 0.8",
          "x": 5,
          "xshift": 50,
          "y": 0.8,
          "yshift": 10
         },
         {
          "font": {
           "color": "darkblue",
           "size": 12
          },
          "showarrow": false,
          "text": "Threshold: 0.6",
          "x": 5,
          "xshift": 50,
          "y": 0.6,
          "yshift": -10
         }
        ],
        "bargap": 0.15,
        "boxmode": "group",
        "font": {
         "family": "Arial",
         "size": 14
        },
        "height": 650,
        "hovermode": "closest",
        "legend": {
         "title": {
          "text": "Version"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "b": 60,
         "l": 60,
         "r": 40,
         "t": 70
        },
        "plot_bgcolor": "#f7f7f7",
        "shapes": [
         {
          "line": {
           "color": "darkred",
           "dash": "dash",
           "width": 2
          },
          "opacity": 0.7,
          "type": "line",
          "x0": -0.5,
          "x1": 4,
          "y0": 0.8,
          "y1": 0.8
         },
         {
          "line": {
           "color": "darkblue",
           "dash": "dash",
           "width": 2
          },
          "opacity": 0.7,
          "type": "line",
          "x0": 3,
          "x1": 5.5,
          "y0": 0.6,
          "y1": 0.6
         }
        ],
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "darkblue",
          "family": "Times New Roman",
          "size": 22
         },
         "text": "Hit Relevance Distribution by Version (Tester Persona)"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "baseline",
          "v2",
          "v3",
          "v4",
          "v5"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Version"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "showgrid": true,
         "title": {
          "text": "Hit Relevance Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of dataframes and their version labels for comparison\n",
    "dataframes_static = {\n",
    "    \"baseline\": Test_Results_2024052802_Baseline,\n",
    "    \"v2\": test_output_v2_tester_2024_09_03_12_13_59,\n",
    "    \"v3\": test_output_v3_tester_2024_09_17_03_21_25,\n",
    "    \"v4\": test_output_v4_tester_2024_09_29_00_32_01,\n",
    "    \"v5\": test_output_v5_tester_2024_10_07_17_35_56\n",
    "}\n",
    "\n",
    "# Combine data for easier plotting\n",
    "all_data_static = []\n",
    "for version, df in dataframes_static.items():\n",
    "    df['version'] = version  # Add a column for version\n",
    "    all_data_static.append(df[['Column1.hit', 'Column1.hitRelevance', 'version']])\n",
    "\n",
    "# Concatenate all data into a single DataFrame\n",
    "combined_df_static = pd.concat(all_data_static)\n",
    "\n",
    "# Convert hit column to binary values (1 if hit, 0 if not) based on a threshold of 0.75\n",
    "combined_df_static['hit_binary'] = combined_df_static['Column1.hitRelevance'].apply(lambda x: 1 if x >= 0.75 else 0)\n",
    "\n",
    "# Create a box plot for Static Questions including the baseline\n",
    "fig_static = px.box(combined_df_static, \n",
    "                    x='version', \n",
    "                    y='Column1.hitRelevance', \n",
    "                    points='all',  # Show all data points\n",
    "                    title='Hit Relevance Distribution by Version (Tester Persona)',\n",
    "                    labels={'Column1.hitRelevance': 'Hit Relevance Score', 'version': 'Version'},\n",
    "                    color='version',  \n",
    "                    color_discrete_sequence=px.colors.qualitative.Set2)  # Use distinct color palette\n",
    "\n",
    "# Customize box plot aesthetics for bigger boxes and scatter points\n",
    "fig_static.update_traces(\n",
    "    boxmean=True,  # Show mean in each box\n",
    "    jitter=0.2,  # Reduce jitter for more space\n",
    "    pointpos=-1.5,  # Adjust point position closer to boxes\n",
    "    marker=dict(size=6, opacity=0.8),  # Increase marker size\n",
    "    width=0.4  # Increase box width\n",
    ")\n",
    "\n",
    "# Add horizontal lines for thresholds\n",
    "fig_static.add_shape(\n",
    "    type=\"line\", line_color=\"darkred\", line_width=2, opacity=0.7, \n",
    "    x0=-0.5, x1=4, y0=threshold_baseline_to_v4, y1=threshold_baseline_to_v4, \n",
    "    line_dash=\"dash\"\n",
    ")\n",
    "fig_static.add_shape(\n",
    "    type=\"line\", line_color=\"darkblue\", line_width=2, opacity=0.7, \n",
    "    x0=3, x1=5.5, y0=threshold_v5, y1=threshold_v5,  # Line starts after the v4 column\n",
    "    line_dash=\"dash\"\n",
    ")\n",
    "\n",
    "# Move the threshold text annotations to the right\n",
    "fig_static.add_annotation(\n",
    "    x=5, y=threshold_baseline_to_v4,\n",
    "    text=\"Threshold: 0.8\", showarrow=False, xshift=50, yshift=10,\n",
    "    font=dict(size=12, color=\"darkred\")\n",
    ")\n",
    "fig_static.add_annotation(\n",
    "    x=5, y=threshold_v5,\n",
    "    text=\"Threshold: 0.6\", showarrow=False, xshift=50, yshift=-10,\n",
    "    font=dict(size=12, color=\"darkblue\")\n",
    ")\n",
    "\n",
    "# Adjust layout for better spacing and visual clarity\n",
    "fig_static.update_layout(\n",
    "    xaxis_title='Version',\n",
    "    yaxis_title='Hit Relevance Score',\n",
    "    legend_title_text='Version',\n",
    "    font=dict(size=14, family='Arial'),  # Different font for readability\n",
    "    plot_bgcolor='#f7f7f7',  # Soft background for readability\n",
    "    title_font=dict(size=22, family='Times New Roman', color='darkblue'),  # Stylish title font\n",
    "    width=1000,  # Adjust width\n",
    "    height=650,  # Adjust height\n",
    "    margin=dict(t=70, l=60, r=40, b=60),\n",
    "    boxmode='group', \n",
    "    showlegend=True,  \n",
    "    yaxis=dict(showgrid=True, gridcolor='lightgray'),  # Add gridlines for clarity\n",
    "    bargap=0.15,  # Adjust gap between boxes\n",
    "    hovermode=\"closest\"  # Hovering shows closest point information\n",
    ")\n",
    "\n",
    "# Update hover template for better clarity\n",
    "fig_static.update_traces(\n",
    "    hovertemplate=\"<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}\"\n",
    ")\n",
    "\n",
    "# Display the figure\n",
    "fig_static.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box Plot: Developer Persona all versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "baseline",
         "marker": {
          "color": "rgb(102,194,165)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "baseline",
         "notched": false,
         "offsetgroup": "baseline",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.8784441145756917,
          0.8774876933819626,
          0.8746684526475066,
          0.8746424643210794,
          0.8672439394801955,
          0.8603153999309818,
          0.855133577099862,
          0.854684365530313,
          0.8545490013947185,
          0.8536750205786069,
          0.8501388581189828,
          0.8499660383782022,
          0.8470403662206168,
          0.8463422141715554,
          0.8454658353831477,
          0.8453736197417216,
          0.8451186188958659,
          0.8450729794568982,
          0.843996474043092,
          0.8417384332596856,
          0.8399934314279974,
          0.8382348105204843,
          0.8373992935457025,
          0.8361225308669625,
          0.8351752441648143,
          0.8343694018089332,
          0.8321899352349762,
          0.832155049588577,
          0.830248828676792,
          0.8295025892387569,
          0.8289186592390524,
          0.8288114265837756,
          0.8284027920639331,
          0.8273072353527722,
          0.8271236092473713,
          0.826975894551871,
          0.8265560599870281,
          0.825320371453267,
          0.8248481659124333,
          0.824346976359626,
          0.8229000166277352,
          0.8206292698708735,
          0.8198691672518295,
          0.8195897019982514,
          0.8194865396947004,
          0.8188920393542686,
          0.8167959019266425,
          0.8164857256712671,
          0.8159706347347968,
          0.8159293705435575,
          0.8157958553839585,
          0.8154986121078773,
          0.814084258399054,
          0.8117359799225621,
          0.8115161548623933,
          0.8111692492276386,
          0.8108709355131023,
          0.810498399917788,
          0.8101889348326631,
          0.8099605332098587,
          0.8092608604270364,
          0.8079074337556884,
          0.8078390308025816,
          0.8078210638903874,
          0.8077010144788173,
          0.8076098567585128,
          0.807204013767107,
          0.8067548407994568,
          0.8061181657940557,
          0.8060373413831154,
          0.8059647466331435,
          0.8049369563243841,
          0.8036939307668896,
          0.8025805035692839,
          0.8022600750793488,
          0.8012921522278786,
          0.8005338717485814,
          0.7993632539029342,
          0.7977609335991143,
          0.7977478616824621,
          0.7970567781996246,
          0.7960420128627206,
          0.7959482970504347,
          0.7948834305972643,
          0.794524347185814,
          0.7939856708447534,
          0.7937062140910492,
          0.7932719784138285,
          0.7918442800322498,
          0.7901422444482195,
          0.7889456502312663,
          0.7883422641059364,
          0.7872176322886016,
          0.7869777101688635,
          0.7856166825021259,
          0.7854434461911843,
          0.7812875857150219,
          0.7810471085440618,
          0.7763484036629806
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v2",
         "marker": {
          "color": "rgb(252,141,98)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v2",
         "notched": false,
         "offsetgroup": "v2",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.884762210789768,
          0.9255372175185402,
          0.8830329232036519,
          0.8868939205244404,
          0.8799656617494899,
          0.8838257490641401,
          0.8791118466632416,
          0.888633030629863,
          0.8689339577679515,
          0.8409274873356855,
          0.8767504925375763,
          0.8392944831300012,
          0.840288432773151,
          0.8354236330105812,
          0.7869028287789468,
          0.7869028287789468,
          0.8276331333323734,
          0.8511220281168624,
          0.8655347456999489,
          0.8559985505411742,
          0.8304667821098717,
          0.7869028287789468,
          0.7869028287789468,
          0.8460681938457998,
          0.8822233487308441,
          0.85460654032204,
          0.8707019460116849,
          0.8083703954979202,
          0.8002329691843793,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.8501232090339811,
          0.7869028287789468,
          0.8700154397996658,
          0.8311222570611649,
          0.8521720295761063,
          0.7869028287789468,
          0.8735925041588358,
          0.8083703954979202,
          0.8296160148885376,
          0.8178725886356714,
          0.8524499305394312,
          0.8203926740936641,
          0.8320366239387859,
          0.7869028287789468,
          0.8779126193979027,
          0.7869028287789468,
          0.8021703051073606,
          0.7869028287789468,
          0.8797013546473093,
          0.8083703954979202,
          0.8435304524376659,
          0.8178725886356714,
          0.8706138615015921,
          0.8229108009609454,
          0.831317130837995,
          0.7869028287789468,
          0.8700154397996658,
          0.7869028287789468,
          0.8316389768617164,
          0.7869028287789468,
          0.8735925041588358,
          0.8083703954979202,
          0.8547248148816857,
          0.8178725886356714,
          0.8524499305394312,
          0.8195337778231886,
          0.8524285623507801,
          0.7869028287789468,
          0.8779126193979027,
          0.7869028287789468,
          0.8398433105553023,
          0.7869028287789468,
          0.8794504271150948,
          0.8083703954979202,
          0.8278998306365615,
          0.8178725886356714,
          0.8706138615015921,
          0.8195337778231886,
          0.8244281571301671,
          0.7869028287789468,
          0.8700154397996658,
          0.7869028287789468,
          0.8201765125077526,
          0.7869028287789468,
          0.8736175080780997,
          0.8083703954979202,
          0.8319209908749522,
          0.8178725886356714,
          0.8524499305394312,
          0.8203926740936641,
          0.8501232090339811,
          0.7869028287789468,
          0.8779126193979027,
          0.7869028287789468,
          0.8398433105553023,
          0.7869028287789468,
          0.8794504271150948,
          0.8083703954979202
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v3",
         "marker": {
          "color": "rgb(141,160,203)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v3",
         "notched": false,
         "offsetgroup": "v3",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.8083703954979202,
          0.9152736324291726,
          0.9220781627466824,
          0.8919654041985545,
          0.8646025685043087,
          0.8684299400878649,
          0.8410708974284912,
          0.8932484912086401,
          0.8713775953387568,
          0.8753026131666618,
          0.883293010464145,
          0.907260622876584,
          0.9042310985876056,
          0.8593273449943226,
          0.917807685559686,
          0.9058252128147471,
          0.8999378878316521,
          0.8596399084204615,
          0.8862892938537512,
          0.8778862001463288,
          0.8899879172874793,
          0.8341127343120772,
          0.8806008446770845,
          0.8948522290189048,
          0.9022007209199404,
          0.894825475188518,
          0.896891218323444,
          0.8995392649638773,
          0.8845488390221227,
          0.821629911253539,
          0.8620759495068129,
          0.9091842780842432,
          0.8391656608532361,
          0.8530286731580092,
          0.8857858096153653,
          0.8435408216872798,
          0.8476780675742053,
          0.8291727401476111,
          0.8897603787665008,
          0.889588499867617,
          0.85815213170492,
          0.8891488367082941,
          0.8950908060585238,
          0.8886161825454185,
          0.8867191327635875,
          0.8886146003374512,
          0.889587321486042,
          0.8864790937132252,
          0.8848824409054965,
          0.8776778117487706,
          0.8744849010151187,
          0.8687862641361138,
          0.8722236289679591,
          0.9118992132404868,
          0.8800241603515114,
          0.8877243474188323,
          0.8774532124892932,
          0.9021872763781562,
          0.8805877117774507,
          0.8670926343124354,
          0.9112557469473244,
          0.8918657088390336,
          0.8614235671924377,
          0.8941869231689,
          0.871648437712746,
          0.8905907806316963,
          0.8896449235867104,
          0.8529272048281984,
          0.9061196473101154,
          0.8660708616953184,
          0.8743646402436148,
          0.8852254756508622,
          0.8696521390207572,
          0.8631943606808961,
          0.8887832392086623,
          0.8649853324673193,
          0.8587217142437389,
          0.8765838902641002,
          0.8787546936976759,
          0.8699711351031423,
          0.8755434650927602,
          0.862841364636884,
          0.8793772842751083,
          0.8809250827899622,
          0.8661294594104632,
          0.826462147777373,
          0.8647893941155722,
          0.8810388167943792,
          0.8705134300133269,
          0.8423343659392963,
          0.8923963688337074,
          0.8540758230430909,
          0.873027655722822,
          0.8391914855447494,
          0.872466422157343,
          0.890655241706256,
          0.868197619711733,
          0.8680196670614673,
          0.884073630161455,
          0.8663658768092102,
          0.8919416564277105
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v4",
         "marker": {
          "color": "rgb(231,138,195)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v4",
         "notched": false,
         "offsetgroup": "v4",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.9125490349735256,
          0.9170406985803092,
          0.8875982212877107,
          0.8613522262540781,
          0.872149323188163,
          0.8303637140800361,
          0.918313969608644,
          0.8700043594647302,
          0.92535528561219,
          0.8583819710497751,
          0.8999192428519139,
          0.858819883369749,
          0.8214523560132084,
          0.8106002055982614,
          0.808384891758673,
          0.8986578987944036,
          0.8634084470568473,
          0.8525247025648912,
          0.907260622876584,
          0.8949816626965765,
          0.87929871079386,
          0.8525710750967607,
          0.868392139451109,
          0.8727965657017537,
          0.8576930478307992,
          0.8626111019919999,
          0.8988737345862591,
          0.8680347375001467,
          0.8689158517535562,
          0.8780611384291408,
          0.8677586228467297,
          0.8851966152308883,
          0.906717627643286,
          0.8940908045725743,
          0.9148486679110098,
          0.8749926005977292,
          0.878880552083495,
          0.8781975541804852,
          0.8835755882376777,
          0.8957425782510202,
          0.885762491678952,
          0.8843664333476459,
          0.8945927881042208,
          0.8634093487686979,
          0.8548417013000003,
          0.8483066342935078,
          0.892257576572012,
          0.8651450565386686,
          0.8611956003588346,
          0.8875260412833762,
          0.8954760295267873,
          0.8925746774509729,
          0.8502996876444346,
          0.818756300488843,
          0.8183343139266107,
          0.8799350017855181,
          0.8153990064271667,
          0.827192133273515,
          0.8626868889682385,
          0.8667768751326128,
          0.8556137088506408,
          0.8746574453882523,
          0.8774923461575244,
          0.8903911454851037,
          0.860690197223264,
          0.8769667910547794,
          0.8703362422947982,
          0.8712658336405842,
          0.865108722348039,
          0.8595687062388213,
          0.878825694116521,
          0.8496436517836379,
          0.8883206195215161,
          0.8832981730113286,
          0.8459305817354134,
          0.8970883890016753,
          0.8608558725547802,
          0.8425493455753086,
          0.8581478847252264,
          0.8510613411169673,
          0.8602528692433901,
          0.8508760261320377,
          0.865903401046781,
          0.8636549268455518,
          0.8817146050014355,
          0.8737336955242804,
          0.8787765200107382,
          0.8751840893259993,
          0.8738807710378649,
          0.8856146243431875,
          0.8671077239455628,
          0.8798329313609885,
          0.8602289380071341,
          0.8646537586597216,
          0.8631306201667842,
          0.8734466852438502,
          0.8727960133351874,
          0.8765676198905805,
          0.8948008296396015,
          0.8612301603859128
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v5",
         "marker": {
          "color": "rgb(166,216,84)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v5",
         "notched": false,
         "offsetgroup": "v5",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.5626848281895075,
          0.5379585911759426,
          0.551143131832724,
          0.5238279786707994,
          0.5627398559313014,
          0.5735894737479884,
          0.5702665686199596,
          0.6000674100955248,
          0.556392030995828,
          0.5668812426025432,
          0.46311535403615905,
          0.5430099234621252,
          0.4720799507036731,
          0.6343678716076319,
          0.4932027539035682,
          0.5152384064071143,
          0.5340488437987333,
          0.5825052192800249,
          0.62250269184828,
          0.6241840052825935,
          0.4798247780495428,
          0.4692487452689322,
          0.5255238992445165,
          0.5337444040157748,
          0.5521718026834296,
          0.6199276586452639,
          0.6129797826495775,
          0.4945173326579632,
          0.6057761299497958,
          0.5819327288004313,
          0.544422456053703,
          0.5669384808932681,
          0.5561001472829729,
          0.595362527175347,
          0.5753078914665821,
          0.6265954644896071,
          0.47986623690501984,
          0.6022262550799531,
          0.5767135999869816,
          0.5076654469780616,
          0.6570673410039699,
          0.4967044988060334,
          0.5701683607683296,
          0.49975844268256214,
          0.5712212337473397,
          0.4913629443906314,
          0.5616694263359545,
          0.5227730512714572,
          0.5357889012458162,
          0.6941451189180716,
          0.5925004063776605,
          0.5584558280351564,
          0.6121420202806211,
          0.6285864479880248,
          0.5868831952445831,
          0.5469053927620426,
          0.5234418658356943,
          0.622444443987347,
          0.589871335309441,
          0.4895847796162715,
          0.5472130984007476,
          0.5806793864764589,
          0.5833397669588367,
          0.5036418721159758,
          0.5377070778149224,
          0.6299056343177043,
          0.601486992775078,
          0.5380527712100321,
          0.5309427397281189,
          0.5758925880647775,
          0.5441272559185285,
          0.5237898721061909,
          0.5710894332390755,
          0.6317241326451314,
          0.5672205447249299,
          0.566391972031935,
          0.5241721949874862,
          0.6160908968282496,
          0.46178273846964,
          0.5332050561052482,
          0.5578101845477924,
          0.6077017477471107,
          0.5826147620277955,
          0.5668134088658006,
          0.5509320221617643,
          0.5769870470510097,
          0.5753389842943744,
          0.5228403047921816,
          0.6076729979228671,
          0.685084738445448,
          0.5213200631938628,
          0.5604809108882302,
          0.5234418658356943,
          0.6601224635294691,
          0.5616694263359545,
          0.547334315987066,
          0.5290356177360139,
          0.6352889417787004,
          0.565444617539338,
          0.5171719849408615
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "darkred",
           "size": 12
          },
          "showarrow": false,
          "text": "Threshold: 0.8",
          "x": 5,
          "xshift": 50,
          "y": 0.8,
          "yshift": 10
         },
         {
          "font": {
           "color": "darkblue",
           "size": 12
          },
          "showarrow": false,
          "text": "Threshold: 0.6",
          "x": 5,
          "xshift": 50,
          "y": 0.6,
          "yshift": -10
         }
        ],
        "bargap": 0.15,
        "boxmode": "group",
        "font": {
         "family": "Arial",
         "size": 14
        },
        "height": 650,
        "hovermode": "closest",
        "legend": {
         "title": {
          "text": "Version"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "b": 60,
         "l": 60,
         "r": 40,
         "t": 70
        },
        "plot_bgcolor": "#f7f7f7",
        "shapes": [
         {
          "line": {
           "color": "darkred",
           "dash": "dash",
           "width": 2
          },
          "opacity": 0.7,
          "type": "line",
          "x0": -0.5,
          "x1": 4,
          "y0": 0.8,
          "y1": 0.8
         },
         {
          "line": {
           "color": "darkblue",
           "dash": "dash",
           "width": 2
          },
          "opacity": 0.7,
          "type": "line",
          "x0": 3,
          "x1": 5.5,
          "y0": 0.6,
          "y1": 0.6
         }
        ],
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "darkblue",
          "family": "Times New Roman",
          "size": 22
         },
         "text": "Hit Relevance Distribution by Version (Developer Persona)"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "baseline",
          "v2",
          "v3",
          "v4",
          "v5"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Version"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "showgrid": true,
         "title": {
          "text": "Hit Relevance Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Dataframes for Developer Persona \n",
    "dataframes_developer = {\n",
    "    \"baseline\": Test_Results_2024052802_Baseline,\n",
    "    \"v2\": test_output_v2_developer_2024_09_03_12_10_22,\n",
    "    \"v3\": test_output_v3_developer_2024_0,\n",
    "    \"v4\": test_output_v4_developer_2024_09_28_21_45_10,\n",
    "    \"v5\": test_output_v5_businessanalyst_2024_10_07_17_55_42\n",
    "}\n",
    "\n",
    "# Combine data for easier plotting\n",
    "all_data_developer = []\n",
    "for version, df in dataframes_developer.items():\n",
    "    df['version'] = version  # Add a column for version\n",
    "    all_data_developer.append(df[['Column1.hit', 'Column1.hitRelevance', 'version']])\n",
    "\n",
    "# Concatenate all data into a single DataFrame\n",
    "combined_df_developer = pd.concat(all_data_developer)\n",
    "\n",
    "# Convert hit column to binary values (1 if hit, 0 if not) based on a threshold of 0.75\n",
    "combined_df_developer['hit_binary'] = combined_df_developer['Column1.hitRelevance'].apply(lambda x: 1 if x >= 0.75 else 0)\n",
    "\n",
    "# Create a box plot for Developer Persona\n",
    "fig_developer = px.box(combined_df_developer, \n",
    "                       x='version', \n",
    "                       y='Column1.hitRelevance', \n",
    "                       points='all',\n",
    "                       title='Hit Relevance Distribution by Version (Developer Persona)',\n",
    "                       labels={'Column1.hitRelevance': 'Hit Relevance Score', 'version': 'Version'},\n",
    "                       color='version',  \n",
    "                       color_discrete_sequence=px.colors.qualitative.Set2)\n",
    "\n",
    "# Customize box plot aesthetics\n",
    "fig_developer.update_traces(\n",
    "    boxmean=True,\n",
    "    jitter=0.2,\n",
    "    pointpos=-1.5,\n",
    "    marker=dict(size=6, opacity=0.8),\n",
    "    width=0.4\n",
    ")\n",
    "\n",
    "# Add horizontal lines for thresholds\n",
    "fig_developer.add_shape(\n",
    "    type=\"line\", line_color=\"darkred\", line_width=2, opacity=0.7, \n",
    "    x0=-0.5, x1=4, y0=threshold_baseline_to_v4, y1=threshold_baseline_to_v4, \n",
    "    line_dash=\"dash\"\n",
    ")\n",
    "fig_developer.add_shape(\n",
    "    type=\"line\", line_color=\"darkblue\", line_width=2, opacity=0.7, \n",
    "    x0=3, x1=5.5, y0=threshold_v5, y1=threshold_v5,\n",
    "    line_dash=\"dash\"\n",
    ")\n",
    "\n",
    "# Move the threshold text annotations to the right\n",
    "fig_developer.add_annotation(\n",
    "    x=5, y=threshold_baseline_to_v4,\n",
    "    text=\"Threshold: 0.8\", showarrow=False, xshift=50, yshift=10,\n",
    "    font=dict(size=12, color=\"darkred\")\n",
    ")\n",
    "fig_developer.add_annotation(\n",
    "    x=5, y=threshold_v5,\n",
    "    text=\"Threshold: 0.6\", showarrow=False, xshift=50, yshift=-10,\n",
    "    font=dict(size=12, color=\"darkblue\")\n",
    ")\n",
    "\n",
    "# Adjust layout\n",
    "fig_developer.update_layout(\n",
    "    xaxis_title='Version',\n",
    "    yaxis_title='Hit Relevance Score',\n",
    "    legend_title_text='Version',\n",
    "    font=dict(size=14, family='Arial'),\n",
    "    plot_bgcolor='#f7f7f7',\n",
    "    title_font=dict(size=22, family='Times New Roman', color='darkblue'),\n",
    "    width=1000,\n",
    "    height=650,\n",
    "    margin=dict(t=70, l=60, r=40, b=60),\n",
    "    boxmode='group',\n",
    "    showlegend=True,  \n",
    "    yaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
    "    bargap=0.15,\n",
    "    hovermode=\"closest\"\n",
    ")\n",
    "\n",
    "# Update hover template\n",
    "fig_developer.update_traces(\n",
    "    hovertemplate=\"<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}\"\n",
    ")\n",
    "\n",
    "# Display the figure\n",
    "fig_developer.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box Plot: Buisness Analyst Persona all versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "baseline",
         "marker": {
          "color": "rgb(102,194,165)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "baseline",
         "notched": false,
         "offsetgroup": "baseline",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline",
          "baseline"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.8784441145756917,
          0.8774876933819626,
          0.8746684526475066,
          0.8746424643210794,
          0.8672439394801955,
          0.8603153999309818,
          0.855133577099862,
          0.854684365530313,
          0.8545490013947185,
          0.8536750205786069,
          0.8501388581189828,
          0.8499660383782022,
          0.8470403662206168,
          0.8463422141715554,
          0.8454658353831477,
          0.8453736197417216,
          0.8451186188958659,
          0.8450729794568982,
          0.843996474043092,
          0.8417384332596856,
          0.8399934314279974,
          0.8382348105204843,
          0.8373992935457025,
          0.8361225308669625,
          0.8351752441648143,
          0.8343694018089332,
          0.8321899352349762,
          0.832155049588577,
          0.830248828676792,
          0.8295025892387569,
          0.8289186592390524,
          0.8288114265837756,
          0.8284027920639331,
          0.8273072353527722,
          0.8271236092473713,
          0.826975894551871,
          0.8265560599870281,
          0.825320371453267,
          0.8248481659124333,
          0.824346976359626,
          0.8229000166277352,
          0.8206292698708735,
          0.8198691672518295,
          0.8195897019982514,
          0.8194865396947004,
          0.8188920393542686,
          0.8167959019266425,
          0.8164857256712671,
          0.8159706347347968,
          0.8159293705435575,
          0.8157958553839585,
          0.8154986121078773,
          0.814084258399054,
          0.8117359799225621,
          0.8115161548623933,
          0.8111692492276386,
          0.8108709355131023,
          0.810498399917788,
          0.8101889348326631,
          0.8099605332098587,
          0.8092608604270364,
          0.8079074337556884,
          0.8078390308025816,
          0.8078210638903874,
          0.8077010144788173,
          0.8076098567585128,
          0.807204013767107,
          0.8067548407994568,
          0.8061181657940557,
          0.8060373413831154,
          0.8059647466331435,
          0.8049369563243841,
          0.8036939307668896,
          0.8025805035692839,
          0.8022600750793488,
          0.8012921522278786,
          0.8005338717485814,
          0.7993632539029342,
          0.7977609335991143,
          0.7977478616824621,
          0.7970567781996246,
          0.7960420128627206,
          0.7959482970504347,
          0.7948834305972643,
          0.794524347185814,
          0.7939856708447534,
          0.7937062140910492,
          0.7932719784138285,
          0.7918442800322498,
          0.7901422444482195,
          0.7889456502312663,
          0.7883422641059364,
          0.7872176322886016,
          0.7869777101688635,
          0.7856166825021259,
          0.7854434461911843,
          0.7812875857150219,
          0.7810471085440618,
          0.7763484036629806
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v2",
         "marker": {
          "color": "rgb(252,141,98)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v2",
         "notched": false,
         "offsetgroup": "v2",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2",
          "v2"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.925781253398802,
          0.9002609443056855,
          0.8923076210489114,
          0.9009824042225856,
          0.8975995429338126,
          0.8964398186582996,
          0.8935559104483027,
          0.8918887561642863,
          0.7869028287789468,
          0.8982909147255994,
          0.8934098851833159,
          0.892624653364244,
          0.8885427869977558,
          0.9040159271277428,
          0.9000265481166451,
          0.8694697855639434,
          0.8863699448920073,
          0.7869028287789468,
          0.8710628351285689,
          0.8916591125458198,
          0.7869028287789468,
          0.7869028287789468,
          0.8707825197900287,
          0.9093757715592058,
          0.8906448337668644,
          0.7869028287789468,
          0.9039100474032608,
          0.8862728899488659,
          0.7869028287789468,
          0.8561247770309184,
          0.8854935210987919,
          0.8083703954979202,
          0.915025441593786,
          0.907898692918885,
          0.8760014188668405,
          0.892334230669809,
          0.7868719302070888,
          0.7869028287789468,
          0.8863341828352918,
          0.7869028287789468,
          0.8710634414323196,
          0.8922656628564806,
          0.8768367886636266,
          0.8865866297865846,
          0.8883348825145082,
          0.8802253087959571,
          0.8858399630511821,
          0.8083703954979202,
          0.8926115660595216,
          0.8914236932482871,
          0.7869028287789468,
          0.8680939611484357,
          0.7869028287789468,
          0.8879578456111935,
          0.8974754871374087,
          0.7869028287789468,
          0.8968822312779074,
          0.8929255310399842,
          0.7869028287789468,
          0.8671937593310913,
          0.7869028287789468,
          0.7869028287789468,
          0.8848897432714946,
          0.8083703954979202,
          0.8898011067416771,
          0.8876670198052422,
          0.7869028287789468,
          0.8694644280838495,
          0.8805220120799089,
          0.7869028287789468,
          0.8740941779487243,
          0.8761761520348712,
          0.8762019304139819,
          0.7869028287789468,
          0.7869028287789468,
          0.8900911835951897,
          0.7869028287789468,
          0.7869028287789468,
          0.8775940568900029,
          0.86379531251827,
          0.8855301645192643,
          0.8981586834057937,
          0.884907539838112,
          0.8849324913331528,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.7869028287789468,
          0.8966778257324771,
          0.889176407759723,
          0.7869028287789468,
          0.7869028287789468,
          0.8812311564729811,
          0.8886670657691611,
          0.8977169480039757,
          0.7869028287789468,
          0.7869028287789468,
          0.8863498316574381
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v3",
         "marker": {
          "color": "rgb(141,160,203)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v3",
         "notched": false,
         "offsetgroup": "v3",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3",
          "v3"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.8083703954979202,
          0.8922157949973222,
          0.8627125308391278,
          0.8927656084074856,
          0.8680480283887906,
          0.8752072964985901,
          0.882606349073998,
          0.8756449656794494,
          0.8917887535987512,
          0.8698714333588377,
          0.8665365655503806,
          0.8784575913704322,
          0.8781499372442343,
          0.8778038374537495,
          0.8871434618638618,
          0.8624995291125448,
          0.8714035590068662,
          0.8572886687344675,
          0.8608911867889214,
          0.8673272514800682,
          0.8651265733442882,
          0.8688606386701758,
          0.8671674454850152,
          0.8623414764615384,
          0.8589999472916422,
          0.8695840670468553,
          0.8794848508548733,
          0.8636182598567884,
          0.868438050576924,
          0.8577477943397475,
          0.9034177736070896,
          0.8771152687881361,
          0.8760996817256078,
          0.886738048304303,
          0.8502206006568602,
          0.8730891759860584,
          0.865945713662144,
          0.8654853458412803,
          0.8878529946503262,
          0.8698219506725495,
          0.8666523432710432,
          0.8753512321260981,
          0.8595540236484995,
          0.8823739243174586,
          0.8633794548817899,
          0.8676806524330092,
          0.8986746626630971,
          0.8752930084557498,
          0.8652149089637972,
          0.8717871336928219,
          0.8520950961457613,
          0.8651183968116382,
          0.8632611721269834,
          0.8688996549986941,
          0.8871666733708379,
          0.8771540832771615,
          0.8755135782145451,
          0.855304018296137,
          0.8740861607494457,
          0.8715160476703527,
          0.8580392364132345,
          0.90093500325521,
          0.8695703198407729,
          0.8691827023424603,
          0.8627288485888357,
          0.8692050114788884,
          0.832082850517313,
          0.8691950566145152,
          0.8660306223172377,
          0.8670077087307453,
          0.891131840136674,
          0.8564870278688782,
          0.8589907344074318,
          0.8636887374385043,
          0.8956752642558031,
          0.8751370901659713,
          0.8616977836874531,
          0.8571829057958268,
          0.8787222928383385,
          0.8577372744846431,
          0.8634490897211897,
          0.843634210493448,
          0.8570131420631468,
          0.8643252704702808,
          0.8715347943067006,
          0.8647883914674903,
          0.8596463453308213,
          0.8612656918987714,
          0.8614656677430144,
          0.8698455527062033,
          0.8581509187048756,
          0.862983457293862,
          0.8598030411143744,
          0.8616180665041032,
          0.8876713660394968,
          0.8764562551071113,
          0.8622165505534747,
          0.8508665105936918,
          0.8599612009153524,
          0.8879865795491658,
          0.8632537350230334,
          0.8767119771350291
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v4",
         "marker": {
          "color": "rgb(231,138,195)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v4",
         "notched": false,
         "offsetgroup": "v4",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4",
          "v4"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.8697393910899545,
          0.8910156005838029,
          0.8866139743248748,
          0.8712542972899145,
          0.8547178182262136,
          0.8809798426081538,
          0.8826171764921442,
          0.8763143550833317,
          0.8820786260461465,
          0.8770315645885366,
          0.8719744836917137,
          0.8771554147673865,
          0.8660655581544457,
          0.8779393513495969,
          0.8645237813684424,
          0.8722487047510994,
          0.8803917538145132,
          0.8657214363044599,
          0.8861883097303953,
          0.8529383027534263,
          0.8867783332114516,
          0.8776052100146059,
          0.8695506982261886,
          0.8686979370335839,
          0.8738208911988398,
          0.8806341085920368,
          0.8693046585855314,
          0.8644568365434664,
          0.8362353005141436,
          0.8697623738263205,
          0.8795061898438358,
          0.8640161809765271,
          0.8744736702078131,
          0.8588736001970815,
          0.8500439600131373,
          0.8763068031035085,
          0.8727239897573158,
          0.8754567839677414,
          0.8664180332999974,
          0.8870388343929974,
          0.8546111518269639,
          0.8826670509752038,
          0.8755384750613422,
          0.8717186470509123,
          0.9022447145246832,
          0.8719407745789967,
          0.8496301637384719,
          0.8870685665873949,
          0.890957352947751,
          0.8786800109686976,
          0.8731266772130396,
          0.8740571985272786,
          0.8711884725348232,
          0.8712235947064113,
          0.8512300377213842,
          0.8637064923801302,
          0.8715299331141968,
          0.8602343436929818,
          0.8399536505317545,
          0.8843534907059679,
          0.8937898610434534,
          0.8522376801151742,
          0.8527080555800398,
          0.8709568017803936,
          0.8680092024074321,
          0.8708864364233855,
          0.8496568100899761,
          0.8903205793213386,
          0.8606270887344426,
          0.8734531100732879,
          0.8605399912427031,
          0.8645312415737277,
          0.8964109516806297,
          0.8927689803175661,
          0.8477074602007605,
          0.8794798849294259,
          0.8935462373131613,
          0.8686149201084529,
          0.8574269261228208,
          0.8823753922434641,
          0.8595540236484995,
          0.8649193206496718,
          0.8621846556469749,
          0.8760123065105768,
          0.8875328216970341,
          0.865959202388268,
          0.8496883132724933,
          0.8710211939116201,
          0.8570131420631468,
          0.8704455816044389,
          0.8688468078365978,
          0.8787342788760055,
          0.8783062388477221,
          0.8931297067217732,
          0.8583034521431591,
          0.8713679085396201,
          0.8596463453308213,
          0.864020434400735,
          0.8576267461340911,
          0.8772074922630392
         ],
         "y0": " ",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "boxmean": true,
         "boxpoints": "all",
         "hovertemplate": "<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}",
         "jitter": 0.2,
         "legendgroup": "v5",
         "marker": {
          "color": "rgb(166,216,84)",
          "opacity": 0.8,
          "size": 6
         },
         "name": "v5",
         "notched": false,
         "offsetgroup": "v5",
         "orientation": "v",
         "pointpos": -1.5,
         "showlegend": true,
         "type": "box",
         "width": 0.4,
         "x": [
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5",
          "v5"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          0.5626848281895075,
          0.5379585911759426,
          0.551143131832724,
          0.5238279786707994,
          0.5627398559313014,
          0.5735894737479884,
          0.5702665686199596,
          0.6000674100955248,
          0.556392030995828,
          0.5668812426025432,
          0.46311535403615905,
          0.5430099234621252,
          0.4720799507036731,
          0.6343678716076319,
          0.4932027539035682,
          0.5152384064071143,
          0.5340488437987333,
          0.5825052192800249,
          0.62250269184828,
          0.6241840052825935,
          0.4798247780495428,
          0.4692487452689322,
          0.5255238992445165,
          0.5337444040157748,
          0.5521718026834296,
          0.6199276586452639,
          0.6129797826495775,
          0.4945173326579632,
          0.6057761299497958,
          0.5819327288004313,
          0.544422456053703,
          0.5669384808932681,
          0.5561001472829729,
          0.595362527175347,
          0.5753078914665821,
          0.6265954644896071,
          0.47986623690501984,
          0.6022262550799531,
          0.5767135999869816,
          0.5076654469780616,
          0.6570673410039699,
          0.4967044988060334,
          0.5701683607683296,
          0.49975844268256214,
          0.5712212337473397,
          0.4913629443906314,
          0.5616694263359545,
          0.5227730512714572,
          0.5357889012458162,
          0.6941451189180716,
          0.5925004063776605,
          0.5584558280351564,
          0.6121420202806211,
          0.6285864479880248,
          0.5868831952445831,
          0.5469053927620426,
          0.5234418658356943,
          0.622444443987347,
          0.589871335309441,
          0.4895847796162715,
          0.5472130984007476,
          0.5806793864764589,
          0.5833397669588367,
          0.5036418721159758,
          0.5377070778149224,
          0.6299056343177043,
          0.601486992775078,
          0.5380527712100321,
          0.5309427397281189,
          0.5758925880647775,
          0.5441272559185285,
          0.5237898721061909,
          0.5710894332390755,
          0.6317241326451314,
          0.5672205447249299,
          0.566391972031935,
          0.5241721949874862,
          0.6160908968282496,
          0.46178273846964,
          0.5332050561052482,
          0.5578101845477924,
          0.6077017477471107,
          0.5826147620277955,
          0.5668134088658006,
          0.5509320221617643,
          0.5769870470510097,
          0.5753389842943744,
          0.5228403047921816,
          0.6076729979228671,
          0.685084738445448,
          0.5213200631938628,
          0.5604809108882302,
          0.5234418658356943,
          0.6601224635294691,
          0.5616694263359545,
          0.547334315987066,
          0.5290356177360139,
          0.6352889417787004,
          0.565444617539338,
          0.5171719849408615
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "darkred",
           "size": 12
          },
          "showarrow": false,
          "text": "Threshold: 0.8",
          "x": 5,
          "xshift": 50,
          "y": 0.8,
          "yshift": 10
         },
         {
          "font": {
           "color": "darkblue",
           "size": 12
          },
          "showarrow": false,
          "text": "Threshold: 0.6",
          "x": 5,
          "xshift": 50,
          "y": 0.6,
          "yshift": -10
         }
        ],
        "bargap": 0.15,
        "boxmode": "group",
        "font": {
         "family": "Arial",
         "size": 14
        },
        "height": 650,
        "hovermode": "closest",
        "legend": {
         "title": {
          "text": "Version"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "b": 60,
         "l": 60,
         "r": 40,
         "t": 70
        },
        "plot_bgcolor": "#f7f7f7",
        "shapes": [
         {
          "line": {
           "color": "darkred",
           "dash": "dash",
           "width": 2
          },
          "opacity": 0.7,
          "type": "line",
          "x0": -0.5,
          "x1": 4,
          "y0": 0.8,
          "y1": 0.8
         },
         {
          "line": {
           "color": "darkblue",
           "dash": "dash",
           "width": 2
          },
          "opacity": 0.7,
          "type": "line",
          "x0": 3,
          "x1": 5.5,
          "y0": 0.6,
          "y1": 0.6
         }
        ],
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "darkblue",
          "family": "Times New Roman",
          "size": 22
         },
         "text": "Hit Relevance Distribution by Version (Business Analyst Persona)"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "baseline",
          "v2",
          "v3",
          "v4",
          "v5"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Version"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "showgrid": true,
         "title": {
          "text": "Hit Relevance Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataframes for Business Analyst Persona \n",
    "dataframes_ba = {\n",
    "    \"baseline\": Test_Results_2024052802_Baseline,\n",
    "    \"v2\": test_output_v2_businessanalyst_2024_09_03_12_17_34,\n",
    "    \"v3\": test_output_v3_businessanalyst_2024_09_17_03_35_43,\n",
    "    \"v4\": test_output_v4_businessanalyst_2024_09_29_01_42_36,\n",
    "    \"v5\": test_output_v5_businessanalyst_2024_10_07_17_55_42\n",
    "}\n",
    "\n",
    "# Combine data for easier plotting\n",
    "all_data_ba = []\n",
    "for version, df in dataframes_ba.items():\n",
    "    df['version'] = version  # Add a column for version\n",
    "    all_data_ba.append(df[['Column1.hit', 'Column1.hitRelevance', 'version']])\n",
    "\n",
    "# Concatenate all data into a single DataFrame\n",
    "combined_df_ba = pd.concat(all_data_ba)\n",
    "\n",
    "# Convert hit column to binary values (1 if hit, 0 if not) based on a threshold of 0.75\n",
    "combined_df_ba['hit_binary'] = combined_df_ba['Column1.hitRelevance'].apply(lambda x: 1 if x >= 0.75 else 0)\n",
    "\n",
    "# Create a box plot for Business Analyst Persona\n",
    "fig_ba = px.box(combined_df_ba, \n",
    "                x='version', \n",
    "                y='Column1.hitRelevance', \n",
    "                points='all', \n",
    "                title='Hit Relevance Distribution by Version (Business Analyst Persona)',\n",
    "                labels={'Column1.hitRelevance': 'Hit Relevance Score', 'version': 'Version'},\n",
    "                color='version',  \n",
    "                color_discrete_sequence=px.colors.qualitative.Set2)\n",
    "\n",
    "# Customize box plot aesthetics\n",
    "fig_ba.update_traces(\n",
    "    boxmean=True, \n",
    "    jitter=0.2, \n",
    "    pointpos=-1.5, \n",
    "    marker=dict(size=6, opacity=0.8), \n",
    "    width=0.4\n",
    ")\n",
    "\n",
    "# Add horizontal lines for thresholds\n",
    "fig_ba.add_shape(\n",
    "    type=\"line\", line_color=\"darkred\", line_width=2, opacity=0.7, \n",
    "    x0=-0.5, x1=4, y0=threshold_baseline_to_v4, y1=threshold_baseline_to_v4, \n",
    "    line_dash=\"dash\"\n",
    ")\n",
    "fig_ba.add_shape(\n",
    "    type=\"line\", line_color=\"darkblue\", line_width=2, opacity=0.7, \n",
    "    x0=3, x1=5.5, y0=threshold_v5, y1=threshold_v5,\n",
    "    line_dash=\"dash\"\n",
    ")\n",
    "\n",
    "# Move the threshold text annotations to the right\n",
    "fig_ba.add_annotation(\n",
    "    x=5, y=threshold_baseline_to_v4,\n",
    "    text=\"Threshold: 0.8\", showarrow=False, xshift=50, yshift=10,\n",
    "    font=dict(size=12, color=\"darkred\")\n",
    ")\n",
    "fig_ba.add_annotation(\n",
    "    x=5, y=threshold_v5,\n",
    "    text=\"Threshold: 0.6\", showarrow=False, xshift=50, yshift=-10,\n",
    "    font=dict(size=12, color=\"darkblue\")\n",
    ")\n",
    "\n",
    "# Adjust layout\n",
    "fig_ba.update_layout(\n",
    "    xaxis_title='Version',\n",
    "    yaxis_title='Hit Relevance Score',\n",
    "    legend_title_text='Version',\n",
    "    font=dict(size=14, family='Arial'),\n",
    "    plot_bgcolor='#f7f7f7',  \n",
    "    title_font=dict(size=22, family='Times New Roman', color='darkblue'),  \n",
    "    width=1000,\n",
    "    height=650,\n",
    "    margin=dict(t=70, l=60, r=40, b=60),\n",
    "    boxmode='group', \n",
    "    showlegend=True,  \n",
    "    yaxis=dict(showgrid=True, gridcolor='lightgray'),  \n",
    "    bargap=0.15,\n",
    "    hovermode=\"closest\"\n",
    ")\n",
    "\n",
    "# Update hover template\n",
    "fig_ba.update_traces(\n",
    "    hovertemplate=\"<b>Version</b>: %{x}<br><b>Hit Relevance</b>: %{y}<br><b>Hit Binary</b>: %{customdata}\"\n",
    ")\n",
    "\n",
    "# Display the figure\n",
    "fig_ba.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations Set 2: Grouped Bar Graphs (Gemini Evualation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_persona = {\n",
    "    \"static\": {\n",
    "        \"v4\": test_output_v4_nonetype_2024_09_28_21_30_03,\n",
    "        \"v5\": test_output_v5_nonetype_2024_10_07_18_04_26\n",
    "    },\n",
    "    \"developer\": {\n",
    "        \"v4\": test_output_v4_developer_2024_09_28_21_45_10,\n",
    "        \"v5\": test_output_v5_developer_2024_10_07_17_25_23\n",
    "    },\n",
    "    \"tester\": {\n",
    "        \"v4\": test_output_v4_tester_2024_09_29_00_32_01,\n",
    "        \"v5\": test_output_v5_tester_2024_10_07_17_35_56\n",
    "    },\n",
    "    \"business_analyst\": {\n",
    "        \"v4\": test_output_v4_businessanalyst_2024_09_29_01_42_36,\n",
    "        \"v5\": test_output_v5_businessanalyst_2024_10_07_17_55_42\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the color palette for Gemini scores (pastel colors)\n",
    "likert_colors = ['#FFB3BA', '#FFDFBA', '#BAFFC9', '#BAE1FF']  # Pastel shades for 1-4\n",
    "\n",
    "# Define score labels for the legend (with descriptions)\n",
    "score_labels = {\n",
    "    1: '1: Irrelevant or incoherent',\n",
    "    2: '2: Partially relevant but incomplete',\n",
    "    3: '3: Mostly relevant and coherent',\n",
    "    4: '4: Fully relevant and coherent'\n",
    "}\n",
    "\n",
    "# Function to create a visually enhanced grouped bar chart with mean scores for each persona\n",
    "def create_enhanced_gemini_chart(dataframes_persona, version):\n",
    "    # Prepare the layout for the visualization\n",
    "    fig = go.Figure()\n",
    "\n",
    "    personas = ['static', 'developer', 'business analyst', 'tester']  # Removed underscores\n",
    "    \n",
    "    # Iterate over each persona and plot the grouped bars\n",
    "    for i, persona in enumerate(personas):\n",
    "        df = dataframes_persona[persona.replace(' ', '_')][version]  # Replace spaces with underscores to match the data\n",
    "\n",
    "        # Calculate the mean score for each persona\n",
    "        mean_score = df['Column1.gemini_evaluation'].mean()\n",
    "        \n",
    "        # Calculate the counts for each score (1 to 4)\n",
    "        score_counts = df['Column1.gemini_evaluation'].value_counts().reindex([1, 2, 3, 4], fill_value=0).sort_index()\n",
    "\n",
    "        # Add a bar for each score (1 to 4) for this persona\n",
    "        for score, count in score_counts.items():\n",
    "            fig.add_trace(go.Bar(\n",
    "                x=[persona], y=[count], \n",
    "                name=score_labels[score],  # One legend for each score\n",
    "                marker_color=likert_colors[score-1],  # Pastel color for each score\n",
    "                hoverinfo='y+name',\n",
    "                text=f'Score: {score}, Count: {count}',\n",
    "                textposition='auto',\n",
    "                offsetgroup=score,  # Grouping the bars by score\n",
    "            ))\n",
    "        \n",
    "        # Add a text annotation for the mean score with proper spacing\n",
    "        fig.add_annotation(\n",
    "            x=persona,\n",
    "            y=max(score_counts) + 5,  # Position the annotation above the bars\n",
    "            text=f\"Mean: {mean_score:.2f}\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=14, family='Arial', color='black')\n",
    "        )\n",
    "        \n",
    "        # Add vertical dashed line separators between personas\n",
    "        fig.add_shape(type=\"line\",\n",
    "                      x0=i + 0.5, x1=i + 0.5, y0=0, y1=max(score_counts) + 10,\n",
    "                      line=dict(color=\"gray\", dash=\"dash\", width=1.5),\n",
    "                      opacity=0.5)  # Translucent separator\n",
    "\n",
    "    # Customize the layout\n",
    "    fig.update_layout(\n",
    "        barmode='group',  # Group the bars instead of stacking\n",
    "        title={\n",
    "            'text': f'Gemini Score Distribution - {version.upper()}',\n",
    "            'y':0.95,\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top',\n",
    "            'font': {'size': 24, 'family': 'Times New Roman', 'color': 'darkblue'}\n",
    "        },\n",
    "        xaxis_title=\"Personas\",\n",
    "        yaxis_title=\"Count of Responses\",\n",
    "        legend_title=\"Gemini Evaluation Scale\",\n",
    "        font=dict(size=14),\n",
    "        title_font=dict(size=20),\n",
    "        plot_bgcolor='white',\n",
    "        height=600,\n",
    "        width=1200,  # Increased width to accommodate the legend\n",
    "        margin=dict(l=50, r=50, t=50, b=50)  # Adjust margins for better spacing\n",
    "    )\n",
    "    \n",
    "    # Update legend to show only 4 entries (1 per score)\n",
    "    fig.update_traces(showlegend=False)  # Hide individual legends\n",
    "    for score, color in score_labels.items():\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=[None], y=[None],\n",
    "            marker_color=likert_colors[score-1],\n",
    "            name=score_labels[score],\n",
    "            showlegend=True\n",
    "        ))\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFB3BA"
         },
         "name": "1: Irrelevant or incoherent",
         "offsetgroup": "1",
         "showlegend": false,
         "text": "Score: 1, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "static"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFDFBA"
         },
         "name": "2: Partially relevant but incomplete",
         "offsetgroup": "2",
         "showlegend": false,
         "text": "Score: 2, Count: 1",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "static"
         ],
         "y": [
          1
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAFFC9"
         },
         "name": "3: Mostly relevant and coherent",
         "offsetgroup": "3",
         "showlegend": false,
         "text": "Score: 3, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "static"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAE1FF"
         },
         "name": "4: Fully relevant and coherent",
         "offsetgroup": "4",
         "showlegend": false,
         "text": "Score: 4, Count: 98",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "static"
         ],
         "y": [
          98
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFB3BA"
         },
         "name": "1: Irrelevant or incoherent",
         "offsetgroup": "1",
         "showlegend": false,
         "text": "Score: 1, Count: 3",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "developer"
         ],
         "y": [
          3
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFDFBA"
         },
         "name": "2: Partially relevant but incomplete",
         "offsetgroup": "2",
         "showlegend": false,
         "text": "Score: 2, Count: 2",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "developer"
         ],
         "y": [
          2
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAFFC9"
         },
         "name": "3: Mostly relevant and coherent",
         "offsetgroup": "3",
         "showlegend": false,
         "text": "Score: 3, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "developer"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAE1FF"
         },
         "name": "4: Fully relevant and coherent",
         "offsetgroup": "4",
         "showlegend": false,
         "text": "Score: 4, Count: 95",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "developer"
         ],
         "y": [
          95
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFB3BA"
         },
         "name": "1: Irrelevant or incoherent",
         "offsetgroup": "1",
         "showlegend": false,
         "text": "Score: 1, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "business analyst"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFDFBA"
         },
         "name": "2: Partially relevant but incomplete",
         "offsetgroup": "2",
         "showlegend": false,
         "text": "Score: 2, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "business analyst"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAFFC9"
         },
         "name": "3: Mostly relevant and coherent",
         "offsetgroup": "3",
         "showlegend": false,
         "text": "Score: 3, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "business analyst"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAE1FF"
         },
         "name": "4: Fully relevant and coherent",
         "offsetgroup": "4",
         "showlegend": false,
         "text": "Score: 4, Count: 100",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "business analyst"
         ],
         "y": [
          100
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFB3BA"
         },
         "name": "1: Irrelevant or incoherent",
         "offsetgroup": "1",
         "showlegend": false,
         "text": "Score: 1, Count: 16",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "tester"
         ],
         "y": [
          16
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFDFBA"
         },
         "name": "2: Partially relevant but incomplete",
         "offsetgroup": "2",
         "showlegend": false,
         "text": "Score: 2, Count: 37",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "tester"
         ],
         "y": [
          37
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAFFC9"
         },
         "name": "3: Mostly relevant and coherent",
         "offsetgroup": "3",
         "showlegend": false,
         "text": "Score: 3, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "tester"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAE1FF"
         },
         "name": "4: Fully relevant and coherent",
         "offsetgroup": "4",
         "showlegend": false,
         "text": "Score: 4, Count: 47",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "tester"
         ],
         "y": [
          47
         ]
        },
        {
         "marker": {
          "color": "#FFB3BA"
         },
         "name": "1: Irrelevant or incoherent",
         "showlegend": true,
         "type": "bar",
         "x": [
          null
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "#FFDFBA"
         },
         "name": "2: Partially relevant but incomplete",
         "showlegend": true,
         "type": "bar",
         "x": [
          null
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "#BAFFC9"
         },
         "name": "3: Mostly relevant and coherent",
         "showlegend": true,
         "type": "bar",
         "x": [
          null
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "#BAE1FF"
         },
         "name": "4: Fully relevant and coherent",
         "showlegend": true,
         "type": "bar",
         "x": [
          null
         ],
         "y": [
          null
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "black",
           "family": "Arial",
           "size": 14
          },
          "showarrow": false,
          "text": "Mean: 3.98",
          "x": "static",
          "y": 103
         },
         {
          "font": {
           "color": "black",
           "family": "Arial",
           "size": 14
          },
          "showarrow": false,
          "text": "Mean: 3.87",
          "x": "developer",
          "y": 100
         },
         {
          "font": {
           "color": "black",
           "family": "Arial",
           "size": 14
          },
          "showarrow": false,
          "text": "Mean: 4.00",
          "x": "business analyst",
          "y": 105
         },
         {
          "font": {
           "color": "black",
           "family": "Arial",
           "size": 14
          },
          "showarrow": false,
          "text": "Mean: 2.78",
          "x": "tester",
          "y": 52
         }
        ],
        "barmode": "group",
        "font": {
         "size": 14
        },
        "height": 600,
        "legend": {
         "title": {
          "text": "Gemini Evaluation Scale"
         }
        },
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 50
        },
        "plot_bgcolor": "white",
        "shapes": [
         {
          "line": {
           "color": "gray",
           "dash": "dash",
           "width": 1.5
          },
          "opacity": 0.5,
          "type": "line",
          "x0": 0.5,
          "x1": 0.5,
          "y0": 0,
          "y1": 108
         },
         {
          "line": {
           "color": "gray",
           "dash": "dash",
           "width": 1.5
          },
          "opacity": 0.5,
          "type": "line",
          "x0": 1.5,
          "x1": 1.5,
          "y0": 0,
          "y1": 105
         },
         {
          "line": {
           "color": "gray",
           "dash": "dash",
           "width": 1.5
          },
          "opacity": 0.5,
          "type": "line",
          "x0": 2.5,
          "x1": 2.5,
          "y0": 0,
          "y1": 110
         },
         {
          "line": {
           "color": "gray",
           "dash": "dash",
           "width": 1.5
          },
          "opacity": 0.5,
          "type": "line",
          "x0": 3.5,
          "x1": 3.5,
          "y0": 0,
          "y1": 57
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "darkblue",
          "family": "Times New Roman",
          "size": 20
         },
         "text": "Gemini Score Distribution - V4",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1200,
        "xaxis": {
         "title": {
          "text": "Personas"
         }
        },
        "yaxis": {
         "title": {
          "text": "Count of Responses"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the enhanced chart for v4 (you can do the same for v5 by changing the version)\n",
    "create_enhanced_gemini_chart(dataframes_persona, 'v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFB3BA"
         },
         "name": "1: Irrelevant or incoherent",
         "offsetgroup": "1",
         "showlegend": false,
         "text": "Score: 1, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "static"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFDFBA"
         },
         "name": "2: Partially relevant but incomplete",
         "offsetgroup": "2",
         "showlegend": false,
         "text": "Score: 2, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "static"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAFFC9"
         },
         "name": "3: Mostly relevant and coherent",
         "offsetgroup": "3",
         "showlegend": false,
         "text": "Score: 3, Count: 1",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "static"
         ],
         "y": [
          1
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAE1FF"
         },
         "name": "4: Fully relevant and coherent",
         "offsetgroup": "4",
         "showlegend": false,
         "text": "Score: 4, Count: 98",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "static"
         ],
         "y": [
          98
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFB3BA"
         },
         "name": "1: Irrelevant or incoherent",
         "offsetgroup": "1",
         "showlegend": false,
         "text": "Score: 1, Count: 2",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "developer"
         ],
         "y": [
          2
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFDFBA"
         },
         "name": "2: Partially relevant but incomplete",
         "offsetgroup": "2",
         "showlegend": false,
         "text": "Score: 2, Count: 15",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "developer"
         ],
         "y": [
          15
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAFFC9"
         },
         "name": "3: Mostly relevant and coherent",
         "offsetgroup": "3",
         "showlegend": false,
         "text": "Score: 3, Count: 7",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "developer"
         ],
         "y": [
          7
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAE1FF"
         },
         "name": "4: Fully relevant and coherent",
         "offsetgroup": "4",
         "showlegend": false,
         "text": "Score: 4, Count: 76",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "developer"
         ],
         "y": [
          76
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFB3BA"
         },
         "name": "1: Irrelevant or incoherent",
         "offsetgroup": "1",
         "showlegend": false,
         "text": "Score: 1, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "business analyst"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFDFBA"
         },
         "name": "2: Partially relevant but incomplete",
         "offsetgroup": "2",
         "showlegend": false,
         "text": "Score: 2, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "business analyst"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAFFC9"
         },
         "name": "3: Mostly relevant and coherent",
         "offsetgroup": "3",
         "showlegend": false,
         "text": "Score: 3, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "business analyst"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAE1FF"
         },
         "name": "4: Fully relevant and coherent",
         "offsetgroup": "4",
         "showlegend": false,
         "text": "Score: 4, Count: 100",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "business analyst"
         ],
         "y": [
          100
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFB3BA"
         },
         "name": "1: Irrelevant or incoherent",
         "offsetgroup": "1",
         "showlegend": false,
         "text": "Score: 1, Count: 2",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "tester"
         ],
         "y": [
          2
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#FFDFBA"
         },
         "name": "2: Partially relevant but incomplete",
         "offsetgroup": "2",
         "showlegend": false,
         "text": "Score: 2, Count: 0",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "tester"
         ],
         "y": [
          0
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAFFC9"
         },
         "name": "3: Mostly relevant and coherent",
         "offsetgroup": "3",
         "showlegend": false,
         "text": "Score: 3, Count: 3",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "tester"
         ],
         "y": [
          3
         ]
        },
        {
         "hoverinfo": "y+name",
         "marker": {
          "color": "#BAE1FF"
         },
         "name": "4: Fully relevant and coherent",
         "offsetgroup": "4",
         "showlegend": false,
         "text": "Score: 4, Count: 95",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "tester"
         ],
         "y": [
          95
         ]
        },
        {
         "marker": {
          "color": "#FFB3BA"
         },
         "name": "1: Irrelevant or incoherent",
         "showlegend": true,
         "type": "bar",
         "x": [
          null
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "#FFDFBA"
         },
         "name": "2: Partially relevant but incomplete",
         "showlegend": true,
         "type": "bar",
         "x": [
          null
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "#BAFFC9"
         },
         "name": "3: Mostly relevant and coherent",
         "showlegend": true,
         "type": "bar",
         "x": [
          null
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "#BAE1FF"
         },
         "name": "4: Fully relevant and coherent",
         "showlegend": true,
         "type": "bar",
         "x": [
          null
         ],
         "y": [
          null
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "black",
           "family": "Arial",
           "size": 14
          },
          "showarrow": false,
          "text": "Mean: 3.99",
          "x": "static",
          "y": 103
         },
         {
          "font": {
           "color": "black",
           "family": "Arial",
           "size": 14
          },
          "showarrow": false,
          "text": "Mean: 3.57",
          "x": "developer",
          "y": 81
         },
         {
          "font": {
           "color": "black",
           "family": "Arial",
           "size": 14
          },
          "showarrow": false,
          "text": "Mean: 4.00",
          "x": "business analyst",
          "y": 105
         },
         {
          "font": {
           "color": "black",
           "family": "Arial",
           "size": 14
          },
          "showarrow": false,
          "text": "Mean: 3.91",
          "x": "tester",
          "y": 100
         }
        ],
        "barmode": "group",
        "font": {
         "size": 14
        },
        "height": 600,
        "legend": {
         "title": {
          "text": "Gemini Evaluation Scale"
         }
        },
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 50
        },
        "plot_bgcolor": "white",
        "shapes": [
         {
          "line": {
           "color": "gray",
           "dash": "dash",
           "width": 1.5
          },
          "opacity": 0.5,
          "type": "line",
          "x0": 0.5,
          "x1": 0.5,
          "y0": 0,
          "y1": 108
         },
         {
          "line": {
           "color": "gray",
           "dash": "dash",
           "width": 1.5
          },
          "opacity": 0.5,
          "type": "line",
          "x0": 1.5,
          "x1": 1.5,
          "y0": 0,
          "y1": 86
         },
         {
          "line": {
           "color": "gray",
           "dash": "dash",
           "width": 1.5
          },
          "opacity": 0.5,
          "type": "line",
          "x0": 2.5,
          "x1": 2.5,
          "y0": 0,
          "y1": 110
         },
         {
          "line": {
           "color": "gray",
           "dash": "dash",
           "width": 1.5
          },
          "opacity": 0.5,
          "type": "line",
          "x0": 3.5,
          "x1": 3.5,
          "y0": 0,
          "y1": 105
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "darkblue",
          "family": "Times New Roman",
          "size": 20
         },
         "text": "Gemini Score Distribution - V5",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1200,
        "xaxis": {
         "title": {
          "text": "Personas"
         }
        },
        "yaxis": {
         "title": {
          "text": "Count of Responses"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the enhanced chart for v4 (you can do the same for v5 by changing the version)\n",
    "create_enhanced_gemini_chart(dataframes_persona, 'v5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
****************************************

****************************************
BoxerEval\tests\BoxerDataTest_v1.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

"""
Question Generation (Persona):
No persona-based question generation. A static list of questions is used.
    
Similarity Embedding:
Uses `text-embedding-ada-002` for embedding and cosine similarity calculations.
    
"""

# Standard Library Imports
import logging
import os
import json
import sys
from logging import Logger
from typing import List, Dict, Any
import numpy as np
from numpy.linalg import norm
import datetime

# Third-Party Packages
from openai import AzureOpenAI, OpenAIError, BadRequestError, APIConnectionError
from tenacity import retry, wait_random_exponential, stop_after_attempt, retry_if_not_exception_type

# Add the project root and scripts directory to the Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

# Local Modules
from common.ApiConfiguration import ApiConfiguration
from common.common_functions import get_embedding

# Constants
SIMILARITY_THRESHOLD = 0.8
MAX_RETRIES = 15

OPENAI_PERSONA_PROMPT =  "You are an AI assistant helping an application developer understand generative AI. You explain complex concepts in simple language, using Python examples if it helps. You limit replies to 50 words or less. If you don't know the answer, say 'I don't know'. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'."
ENRICHMENT_PROMPT = "You will be provided with a question about building applications that use generative AI technology. Write a 50 word summary of an article that would be a great answer to the question. Consider enriching the question with additional topics that the question asker might want to understand. Write the summary in the present tense, as though the article exists. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'.\n"
FOLLOW_UP_PROMPT =  "You will be provided with a summary of an article about building applications that use generative AI technology. Write a question of no more than 10 words that a reader might ask as a follow up to reading the article."

# Setup Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Function to configure the Azure OpenAI API client
def configure_openai_for_azure(config: ApiConfiguration) -> AzureOpenAI:
    """
    Configures OpenAI for Azure using the provided ApiConfiguration.

    Args:
        config (ApiConfiguration): The ApiConfiguration object containing the necessary settings.

    Returns:
        AzureOpenAI: An instance of AzureOpenAI configured with the provided settings.
    """
    return AzureOpenAI(
        azure_endpoint=config.resourceEndpoint, 
        api_key=config.apiKey.strip(),
        api_version=config.apiVersion
    )

# Class to hold test results
class TestResult:
    def __init__(self) -> None:
        """
        Initializes a new instance of the TestResult class.
        
        Sets the initial state of the test result, including the question, enriched question, 
        hit status, hit relevance, hit summary, follow-up question, and follow-up topic.
        
        Args:
            None
        
        Returns:
            None
        """
        self.question: str = ""
        self.enriched_question_summary: str = ""
        self.hit: bool = False
        self.hit_relevance: float = 0.0
        self.follow_up: str = ""
        self.follow_up_on_topic: str = ""

# Function to call the OpenAI API with retry logic
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def call_openai_chat(client: AzureOpenAI, messages: List[Dict[str, str]], config: ApiConfiguration, logger: logging.Logger) -> str:
    """
    Retries the OpenAI chat API call with exponential backoff and retry logic.

    :param client: An instance of the AzureOpenAI class.
    :type client: AzureOpenAI
    :param messages: A list of dictionaries representing the messages to be sent to the API.
    :type messages: List[Dict[str, str]]
    :param config: An instance of the ApiConfiguration class.
    :type config: ApiConfiguration
    :param logger: An instance of the logging.Logger class.
    :type logger: logging.Logger
    :return: The content of the first choice in the API response.
    :rtype: str
    :raises RuntimeError: If the finish reason in the API response is not 'stop', 'length', or an empty string.
    :raises OpenAIError: If there is an error with the OpenAI API.
    :raises APIConnectionError: If there is an error with the API connection.
    """
    try:
        response = client.chat.completions.create(
            model=config.azureDeploymentName,
            messages=messages,
            temperature=0.7,
            max_tokens=config.maxTokens,
            top_p=0.0,
            frequency_penalty=0,
            presence_penalty=0,
            timeout=config.openAiRequestTimeout,
        )
        content = response.choices[0].message.content
        finish_reason = response.choices[0].finish_reason

        if finish_reason not in {"stop", "length", ""}:
            logger.warning("Unexpected stop reason: %s", finish_reason)
            logger.warning("Content: %s", content)
            logger.warning("Consider increasing max tokens and retrying.")
            raise RuntimeError("Unexpected finish reason in API response.")

        return content

    except (OpenAIError, APIConnectionError) as e:
        logger.error(f"Error: {e}")
        raise

# Function to retrieve text embeddings using OpenAI API with retry logic
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def get_text_embedding(client: AzureOpenAI, config: ApiConfiguration, text: str, logger: Logger) -> np.ndarray:
    """
    Retrieves the text embedding for a given text using the OpenAI API.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        text (str): The text for which to retrieve the embedding.
        logger (Logger): The logger instance.

    Returns:
        np.ndarray: The text embedding as a numpy array.

    Raises:
        OpenAIError: If an error occurs while retrieving the text embedding.
    """
    try:
        embedding = get_embedding(text, client, config)
        return np.array(embedding)
    except OpenAIError as e:
        logger.error(f"Error getting text embedding: {e}")
        raise

# Function to calculate cosine similarity between two vectors
def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """
    Calculates the cosine similarity between two vectors.

    Args:
        a (np.ndarray): The first vector.
        b (np.ndarray): The second vector.

    Returns:
        float: The cosine similarity between the two vectors.

    Raises:
        ValueError: If the input vectors are not numpy arrays or convertible to numpy arrays.
        ValueError: If the input vectors do not have the same shape.
        ValueError: If either of the input vectors is a zero vector.
    """
    try:
        a, b = np.array(a), np.array(b)
    except Exception:
        raise ValueError("Input vectors must be numpy arrays or convertible to numpy arrays")

    if a.shape != b.shape:
        raise ValueError("Input vectors must have the same shape")

    dot_product = np.dot(a, b)
    a_norm, b_norm = norm(a), norm(b)

    if a_norm == 0 or b_norm == 0:
        raise ValueError("Input vectors must not be zero vectors")

    return dot_product / (a_norm * b_norm)

# Function to generate enriched questions using OpenAI API
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def generate_enriched_question(client: AzureOpenAI, config: ApiConfiguration, question: str, logger: logging.Logger) -> str:
    """
    Generates an enriched question using the OpenAI API.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        question (str): The question to be enriched.
        logger (logging.Logger): The logger instance.

    Returns:
        str: The enriched question.

    Raises:
        BadRequestError: If the API request fails.
    """
    messages = [
        {"role": "system", "content": OPENAI_PERSONA_PROMPT},
        {"role": "user", "content": ENRICHMENT_PROMPT + "Question: " + question},
    ]
    logger.info("Making API request to OpenAI...")
    logger.info("Request payload: %s", messages)

    response = call_openai_chat(client, messages, config, logger)
    logger.info("API response received: %s", response)

    return response

def process_questions(client: AzureOpenAI, config: ApiConfiguration, questions: List[str], processed_question_chunks: List[Dict[str, Any]], logger: logging.Logger) -> List[TestResult]:
    """
    Processes a list of test questions and evaluates their relevance based on their similarity to pre-processed question chunks.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        questions (List[str]): The list of test questions to be processed.
        processed_question_chunks (List[Dict[str, Any]]): The list of pre-processed question chunks.
        logger (logging.Logger): The logger instance.

    Returns:
        List[TestResult]: A list of test results, each containing the original question, its enriched version, and its relevance to the pre-processed chunks.
    """
    question_results: List[TestResult] = []
    
    for question in questions:
        question_result = TestResult()
        question_result.question = question
        question_result.enriched_question_summary = generate_enriched_question(client, config, question, logger)
        embedding = get_text_embedding(client, config, question_result.enriched_question_summary, logger)

        best_hit_relevance = 0  # To track the highest similarity score
        best_hit_summary = None  # To track the summary corresponding to the highest similarity

        for chunk in processed_question_chunks:
            if chunk and isinstance(chunk, dict) :  
                ada_embedding = chunk.get("ada_v2")
                similarity = cosine_similarity(ada_embedding, embedding)

                if similarity > SIMILARITY_THRESHOLD:
                    question_result.hit = True

                # Check if this is the best match so far
                if similarity > best_hit_relevance:
                    best_hit_relevance = similarity
                    best_hit_summary = chunk.get("summary")

        # Set the best hit relevance and summary for the question result
        question_result.hit_relevance = best_hit_relevance
        question_result.hit_summary = best_hit_summary

        question_results.append(question_result)

    logger.debug("Total tests processed: %s", len(question_results))
    return question_results


# Function to read processed chunks from the source directory
def read_processed_chunks(source_dir: str) -> List[Dict[str, Any]]:
    """
    Reads and processes JSON files from a specified source directory.

    Args:
        source_dir (str): The path to the source directory containing JSON files.

    Returns:
        List[Dict[str, Any]]: A list of dictionaries containing the processed JSON data.

    Raises:
        FileNotFoundError: If the source directory or a JSON file is not found.
        IOError: If an I/O error occurs while reading a JSON file.
    """
    processed_question_chunks: List[Dict[str, Any]] = []
    try:
        for filename in os.listdir(source_dir):
            if filename.endswith(".json"):
                file_path = os.path.join(source_dir, filename)
                with open(file_path, "r", encoding="utf-8") as f:
                    chunk = json.load(f)
                    processed_question_chunks = chunk
    except (FileNotFoundError, IOError) as e:
        logger.error(f"Error reading files: {e}")
        raise
    return processed_question_chunks

def save_results(test_destination_dir: str, question_results: List[TestResult]) -> None:
    """
    Saves the test results to a JSON file in the specified destination directory.

    Args:
        test_destination_dir (str): The path to the directory where the test results will be saved.
        question_results (List[TestResult]): A list of TestResult objects containing the test results.

    Returns:
        None
    """
    # Define the output structure with the specified columns
    output_results = [
        {
            "question": result.question,
            "enriched_question": result.enriched_question_summary, 
            "hit": result.hit,
            "summary": result.hit_summary, 
            "hitRelevance": result.hit_relevance,  
        }
        for result in question_results
    ]

    # Create a timestamp for the output file name
    current_datetime = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    output_file = os.path.join(test_destination_dir, f"test_output_v1_{current_datetime}.json")

    try:
        # Open the output file in write mode, using utf-8 encoding and create it if it doesn't exist
        with open(output_file, "w", encoding="utf-8") as f:
            # Write the output results to the file in JSON format 
            json.dump(output_results, f, indent=4)  # Save the results to the file 
        logger.info(f"Test results saved to: {output_file}")
    except IOError as e:
        logger.error(f"Error saving results: {e}")
        raise


# Main function to run tests
def run_tests(config: ApiConfiguration, test_destination_dir: str, source_dir: str, questions: List[str]) -> None:
    """
    Runs tests using the provided configuration, test destination directory, source directory, and questions.

    Args:
        config (ApiConfiguration): The configuration for the API.
        test_destination_dir (str): The directory where the test results will be saved.
        source_dir (str): The directory containing the source files.
        questions (List[str]): A list of questions to be processed.

    Returns:
        None
    """
    client = configure_openai_for_azure(config)

    if not test_destination_dir:
        logger.error("Test data folder not provided")
        raise ValueError("Test destination directory not provided")

    processed_question_chunks = read_processed_chunks(source_dir)
    question_results = process_questions(client, config, questions, processed_question_chunks, logger)
    save_results(test_destination_dir, question_results)
****************************************

****************************************
BoxerEval\tests\BoxerDataTest_v2.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

"""
Question Generation (Persona):
Introduces question generation with `gpt-3.5-turbo`, for persona-based generation.
    
Similarity Embedding:
Continues using `text-embedding-ada-002` for similarity calculations.
    
Evaluation LLM:
No evaluation LLM integrated in this version.
"""

# Standard Library Imports
import logging
import os
import json
import sys
from logging import Logger
from typing import List, Dict, Any
import numpy as np
from numpy.linalg import norm
import datetime

# Third-Party Packages
from openai import AzureOpenAI, OpenAIError, BadRequestError, APIConnectionError
from tenacity import retry, wait_random_exponential, stop_after_attempt, retry_if_not_exception_type

# Add the project root and scripts directory to the Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

# Local Modules
from common.ApiConfiguration import ApiConfiguration
from common.common_functions import get_embedding
from PersonaStrategy import DeveloperPersonaStrategy, TesterPersonaStrategy, BusinessAnalystPersonaStrategy, PersonaStrategy

# Constants
SIMILARITY_THRESHOLD = 0.8
MAX_RETRIES = 15
NUM_QUESTIONS = 100

OPENAI_PERSONA_PROMPT =  "You are an AI assistant helping an application developer understand generative AI. You explain complex concepts in simple language, using Python examples if it helps. You limit replies to 50 words or less. If you don't know the answer, say 'I don't know'. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'."
ENRICHMENT_PROMPT = "You will be provided with a question about building applications that use generative AI technology. Write a 50 word summary of an article that would be a great answer to the question. Consider enriching the question with additional topics that the question asker might want to understand. Write the summary in the present tense, as though the article exists. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'.\n"
FOLLOW_UP_PROMPT =  "You will be provided with a summary of an article about building applications that use generative AI technology. Write a question of no more than 10 words that a reader might ask as a follow up to reading the article."

# Setup Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Function to configure the Azure OpenAI API client
def configure_openai_for_azure(config: ApiConfiguration) -> AzureOpenAI:
    """
    Configures OpenAI for Azure using the provided ApiConfiguration.

    Args:
        config (ApiConfiguration): The ApiConfiguration object containing the necessary settings.

    Returns:
        AzureOpenAI: An instance of AzureOpenAI configured with the provided settings.
    """
    return AzureOpenAI(
        azure_endpoint=config.resourceEndpoint, 
        api_key=config.apiKey.strip(),
        api_version=config.apiVersion
    )

# Class to hold test results
class TestResult:
    def __init__(self) -> None:
        """
        Initializes a new instance of the TestResult class.
        
        Sets the initial state of the test result, including the question, enriched question, 
        hit status, hit relevance, hit summary, follow-up question, and follow-up topic.
        
        Args:
            None
        
        Returns:
            None
        """
        self.question: str = ""
        self.enriched_question_summary: str = ""
        self.hit: bool = False
        self.hit_relevance: float = 0.0
        self.follow_up: str = ""
        self.follow_up_on_topic: str = ""

# Function to call the OpenAI API with retry logic
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def call_openai_chat(client: AzureOpenAI, messages: List[Dict[str, str]], config: ApiConfiguration, logger: logging.Logger) -> str:
    """
    Retries the OpenAI chat API call with exponential backoff and retry logic.

    :param client: An instance of the AzureOpenAI class.
    :type client: AzureOpenAI
    :param messages: A list of dictionaries representing the messages to be sent to the API.
    :type messages: List[Dict[str, str]]
    :param config: An instance of the ApiConfiguration class.
    :type config: ApiConfiguration
    :param logger: An instance of the logging.Logger class.
    :type logger: logging.Logger
    :return: The content of the first choice in the API response.
    :rtype: str
    :raises RuntimeError: If the finish reason in the API response is not 'stop', 'length', or an empty string.
    :raises OpenAIError: If there is an error with the OpenAI API.
    :raises APIConnectionError: If there is an error with the API connection.
    """
    try:
        response = client.chat.completions.create(
            model=config.azureDeploymentName,
            messages=messages,
            temperature=0.7,
            max_tokens=config.maxTokens,
            top_p=0.0,
            frequency_penalty=0,
            presence_penalty=0,
            timeout=config.openAiRequestTimeout,
        )
        content = response.choices[0].message.content
        finish_reason = response.choices[0].finish_reason

        if finish_reason not in {"stop", "length", ""}:
            logger.warning("Unexpected stop reason: %s", finish_reason)
            logger.warning("Content: %s", content)
            logger.warning("Consider increasing max tokens and retrying.")
            raise RuntimeError("Unexpected finish reason in API response.")

        return content

    except (OpenAIError, APIConnectionError) as e:
        logger.error(f"Error: {e}")
        raise

# Function to retrieve text embeddings using OpenAI API with retry logic
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def get_text_embedding(client: AzureOpenAI, config: ApiConfiguration, text: str, logger: Logger) -> np.ndarray:
    """
    Retrieves the text embedding for a given text using the OpenAI API.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        text (str): The text for which to retrieve the embedding.
        logger (Logger): The logger instance.

    Returns:
        np.ndarray: The text embedding as a numpy array.

    Raises:
        OpenAIError: If an error occurs while retrieving the text embedding.
    """
    try:
        embedding = get_embedding(text, client, config)
        return np.array(embedding)
    except OpenAIError as e:
        logger.error(f"Error getting text embedding: {e}")
        raise

# Function to calculate cosine similarity between two vectors
def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """
    Calculates the cosine similarity between two vectors.

    Args:
        a (np.ndarray): The first vector.
        b (np.ndarray): The second vector.

    Returns:
        float: The cosine similarity between the two vectors.

    Raises:
        ValueError: If the input vectors are not numpy arrays or convertible to numpy arrays.
        ValueError: If the input vectors do not have the same shape.
        ValueError: If either of the input vectors is a zero vector.
    """
    try:
        a, b = np.array(a), np.array(b)
    except Exception:
        raise ValueError("Input vectors must be numpy arrays or convertible to numpy arrays")

    if a.shape != b.shape:
        raise ValueError("Input vectors must have the same shape")

    dot_product = np.dot(a, b)
    a_norm, b_norm = norm(a), norm(b)

    if a_norm == 0 or b_norm == 0:
        raise ValueError("Input vectors must not be zero vectors")

    return dot_product / (a_norm * b_norm)

# Function to generate enriched questions using OpenAI API
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def generate_enriched_question(client: AzureOpenAI, config: ApiConfiguration, question: str, logger: logging.Logger) -> str:
    """
    Generates an enriched question using the OpenAI API.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        question (str): The question to be enriched.
        logger (logging.Logger): The logger instance.

    Returns:
        str: The enriched question.

    Raises:
        BadRequestError: If the API request fails.
    """
    messages = [
        {"role": "system", "content": OPENAI_PERSONA_PROMPT},
        {"role": "user", "content": ENRICHMENT_PROMPT + "Question: " + question},
    ]
    logger.info("Making API request to OpenAI...")
    logger.info("Request payload: %s", messages)

    response = call_openai_chat(client, messages, config, logger)
    logger.info("API response received: %s", response)

    return response

def process_questions(client: AzureOpenAI, config: ApiConfiguration, questions: List[str], processed_question_chunks: List[Dict[str, Any]], logger: logging.Logger) -> List[TestResult]:
    """
    Processes a list of test questions and evaluates their relevance based on their similarity to pre-processed question chunks.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        questions (List[str]): The list of test questions to be processed.
        processed_question_chunks (List[Dict[str, Any]]): The list of pre-processed question chunks.
        logger (logging.Logger): The logger instance.

    Returns:
        List[TestResult]: A list of test results, each containing the original question, its enriched version, and its relevance to the pre-processed chunks.
    """
    question_results: List[TestResult] = []
    
    for question in questions:
        question_result = TestResult()
        question_result.question = question
        question_result.enriched_question_summary = generate_enriched_question(client, config, question, logger)
        embedding = get_text_embedding(client, config, question_result.enriched_question_summary, logger)

        best_hit_relevance = 0  # To track the highest similarity score
        best_hit_summary = None  # To track the summary corresponding to the highest similarity

        for chunk in processed_question_chunks:
            if chunk and isinstance(chunk, dict) :  
                ada_embedding = chunk.get("ada_v2")
                similarity = cosine_similarity(ada_embedding, embedding)

                if similarity > SIMILARITY_THRESHOLD:
                    question_result.hit = True

                # Check if this is the best match so far
                if similarity > best_hit_relevance:
                    best_hit_relevance = similarity
                    best_hit_summary = chunk.get("summary")

        # Set the best hit relevance and summary for the question result
        question_result.hit_relevance = best_hit_relevance
        question_result.hit_summary = best_hit_summary

        question_results.append(question_result)

    logger.debug("Total tests processed: %s", len(question_results))
    return question_results


# Function to read processed chunks from the source directory
def read_processed_chunks(source_dir: str) -> List[Dict[str, Any]]:
    """
    Reads and processes JSON files from a specified source directory.

    Args:
        source_dir (str): The path to the source directory containing JSON files.

    Returns:
        List[Dict[str, Any]]: A list of dictionaries containing the processed JSON data.

    Raises:
        FileNotFoundError: If the source directory or a JSON file is not found.
        IOError: If an I/O error occurs while reading a JSON file.
    """
    processed_question_chunks: List[Dict[str, Any]] = []
    try:
        for filename in os.listdir(source_dir):
            if filename.endswith(".json"):
                file_path = os.path.join(source_dir, filename)
                with open(file_path, "r", encoding="utf-8") as f:
                    chunk = json.load(f)
                    processed_question_chunks = chunk
    except (FileNotFoundError, IOError) as e:
        logger.error(f"Error reading files: {e}")
        raise
    
    if not processed_question_chunks:
        logger.error("Processed question chunks are None or empty.")
    
    return processed_question_chunks

# Function to save the results and generated questions
def save_results(test_destination_dir: str, question_results: List[TestResult], test_mode: str) -> None:
    # Define the output structure with the specified columns
    """
    Saves the test results to a JSON file in the specified destination directory.

    Args:
        test_destination_dir (str): The path to the directory where the test results will be saved.
        question_results (List[TestResult]): A list of TestResult objects containing the test results.
        test_mode (str): The test mode to be used in the output file name.

    Returns:
        None
    """
    output_data = [
        {
            "question": result.question,
            "enriched_question": result.enriched_question_summary, 
            "hit": result.hit,
            "summary": result.hit_summary, 
            "hitRelevance": result.hit_relevance,  
        }
        for result in question_results
    ]

    current_datetime = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    output_file = os.path.join(test_destination_dir, f"test_output_v2_{test_mode}_{current_datetime}.json")

    try:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(output_data, f, indent=4)
        logger.info(f"Test results saved to: {output_file}")
    except IOError as e:
        logger.error(f"Error saving results: {e}")
        raise



# Main test-running function
def run_tests(config: ApiConfiguration, test_destination_dir: str, source_dir: str, num_questions: int = 100, questions: List[str] = None, persona_strategy: PersonaStrategy = None) -> None:
    """
    Runs tests using the provided configuration, test destination directory, source directory, and questions.

    Args:
        config (ApiConfiguration): The configuration for the API.
        test_destination_dir (str): The path to the directory where the test results will be saved.
        source_dir (str): The directory containing the source files.
        num_questions (int): The number of questions to generate using the persona strategy.
        questions (List[str]): A list of questions to be processed.
        persona_strategy (PersonaStrategy): The persona strategy to use for generating questions.

    Returns:
        None
    """
    client = configure_openai_for_azure(config)

    if not test_destination_dir:
        logger.error("Test data folder not provided")
        raise ValueError("Test destination directory not provided")
    
    if persona_strategy:
        questions = persona_strategy.generate_questions(client, config, NUM_QUESTIONS, logger)

    if not questions:
        logger.error("Generated questions are None or empty. Exiting the test.")
        return
    # Determine the test mode based on the strategy
    test_mode = persona_strategy.__class__.__name__.replace('PersonaStrategy', '').lower()

    processed_question_chunks = read_processed_chunks(source_dir)
    question_results = process_questions(client, config, questions, processed_question_chunks, logger)
    save_results(test_destination_dir, question_results, test_mode)
****************************************

****************************************
BoxerEval\tests\BoxerDataTest_v3.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd
"""
Question Generation (Persona):
Upgrades to `gpt-4o` for persona-based question generation.
    
Similarity Embedding:
Retains `text-embedding-ada-002` for embedding and similarity computations.
    
Evaluation LLM:
No evaluation LLM is included.
"""

# Standard Library Imports
import logging
import os
import json
import sys
from logging import Logger
from typing import List, Dict, Any
import numpy as np
from numpy.linalg import norm
import datetime


# Third-Party Packages
from openai import AzureOpenAI, OpenAIError, BadRequestError, APIConnectionError
from tenacity import retry, wait_random_exponential, stop_after_attempt, retry_if_not_exception_type

# Add the project root and scripts directory to the Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

# Local Modules
from common.ApiConfiguration import ApiConfiguration
from common.common_functions import get_embedding
from PersonaStrategy import DeveloperPersonaStrategy, TesterPersonaStrategy, BusinessAnalystPersonaStrategy, PersonaStrategy

# Constants
SIMILARITY_THRESHOLD = 0.8
MAX_RETRIES = 15
NUM_QUESTIONS = 100

OPENAI_PERSONA_PROMPT =  "You are an AI assistant helping an application developer understand generative AI. You explain complex concepts in simple language, using Python examples if it helps. You limit replies to 50 words or less. If you don't know the answer, say 'I don't know'. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'."
ENRICHMENT_PROMPT = "You will be provided with a question about building applications that use generative AI technology. Write a 50 word summary of an article that would be a great answer to the question. Consider enriching the question with additional topics that the question asker might want to understand. Write the summary in the present tense, as though the article exists. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'.\n"
FOLLOW_UP_PROMPT =  "You will be provided with a summary of an article about building applications that use generative AI technology. Write a question of no more than 10 words that a reader might ask as a follow up to reading the article."
FOLLOW_UP_ON_TOPIC_PROMPT = "You are an AI assistant helping a team of developers understand AI. You explain complex concepts in simple language. Respond 'yes' if the follow-up question is about AI, otherwise respond 'no'."

# Setup Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Function to configure the Azure OpenAI API client
def configure_openai_for_azure(config: ApiConfiguration) -> AzureOpenAI:
    """
    Configures OpenAI for Azure using the provided ApiConfiguration.

    Args:
        config (ApiConfiguration): The ApiConfiguration object containing the necessary settings.

    Returns:
        AzureOpenAI: An instance of AzureOpenAI configured with the provided settings.
    """
    return AzureOpenAI(
        azure_endpoint=config.resourceEndpoint, 
        api_key=config.apiKey.strip(),
        api_version=config.apiVersion
    )

# Class to hold test results
class TestResult:
    def __init__(self) -> None:
        """
        Initializes a new instance of the TestResult class.
        
        Sets the initial state of the test result, including the question, enriched question, 
        hit status, hit relevance, hit summary, follow-up question, and follow-up topic.
        
        Args:
            None
        
        Returns:
            None
        """
        self.question: str = ""
        self.enriched_question_summary: str = ""
        self.hit: bool = False
        self.hit_relevance: float = 0.0
        self.follow_up: str = ""  # Adding followUp field
        self.follow_up_on_topic: str = ""  # Adding followUpOnTopic field

# Function to call the OpenAI API with retry logic
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def call_openai_chat(client: AzureOpenAI, messages: List[Dict[str, str]], config: ApiConfiguration, logger: logging.Logger) -> str:
    """
    Retries the OpenAI chat API call with exponential backoff and retry logic.

    :param client: An instance of the AzureOpenAI class.
    :type client: AzureOpenAI
    :param messages: A list of dictionaries representing the messages to be sent to the API.
    :type messages: List[Dict[str, str]]
    :param config: An instance of the ApiConfiguration class.
    :type config: ApiConfiguration
    :param logger: An instance of the logging.Logger class.
    :type logger: logging.Logger
    :return: The content of the first choice in the API response.
    :rtype: str
    :raises RuntimeError: If the finish reason in the API response is not 'stop', 'length', or an empty string.
    :raises OpenAIError: If there is an error with the OpenAI API.
    :raises APIConnectionError: If there is an error with the API connection.
    """
    try:
        response = client.chat.completions.create(
            model=config.azureDeploymentName,
            messages=messages,
            temperature=0.7,
            max_tokens=config.maxTokens,
            top_p=0.0,
            frequency_penalty=0,
            presence_penalty=0,
            timeout=config.openAiRequestTimeout,
        )
        content = response.choices[0].message.content
        finish_reason = response.choices[0].finish_reason

        if finish_reason not in {"stop", "length", ""}:
            logger.warning("Unexpected stop reason: %s", finish_reason)
            logger.warning("Content: %s", content)
            logger.warning("Consider increasing max tokens and retrying.")
            raise RuntimeError("Unexpected finish reason in API response.")

        return content

    except (OpenAIError, APIConnectionError) as e:
        logger.error(f"Error: {e}")
        raise

# Function to retrieve text embeddings using OpenAI API with retry logic
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def get_text_embedding(client: AzureOpenAI, config: ApiConfiguration, text: str, logger: Logger) -> np.ndarray:
    """
    Retrieves the text embedding for a given text using the OpenAI API.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        text (str): The text for which to retrieve the embedding.
        logger (Logger): The logger instance.

    Returns:
        np.ndarray: The text embedding as a numpy array.

    Raises:
        OpenAIError: If an error occurs while retrieving the text embedding.
    """
    try:
        embedding = get_embedding(text, client, config)
        return np.array(embedding)
    except OpenAIError as e:
        logger.error(f"Error getting text embedding: {e}")
        raise

# Function to calculate cosine similarity between two vectors
def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """
    Calculates the cosine similarity between two vectors.

    Args:
        a (np.ndarray): The first vector.
        b (np.ndarray): The second vector.

    Returns:
        float: The cosine similarity between the two vectors.

    Raises:
        ValueError: If the input vectors are not numpy arrays or convertible to numpy arrays.
        ValueError: If the input vectors do not have the same shape.
        ValueError: If either of the input vectors is a zero vector.
    """
    try:
        a, b = np.array(a), np.array(b)
    except Exception:
        raise ValueError("Input vectors must be numpy arrays or convertible to numpy arrays")

    if a.shape != b.shape:
        raise ValueError("Input vectors must have the same shape")

    dot_product = np.dot(a, b)
    a_norm, b_norm = norm(a), norm(b)

    if a_norm == 0 or b_norm == 0:
        raise ValueError("Input vectors must not be zero vectors")

    return dot_product / (a_norm * b_norm)

# Function to generate enriched questions using OpenAI API
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def generate_enriched_question(client: AzureOpenAI, config: ApiConfiguration, question: str, logger: logging.Logger) -> str:
    """
    Generates an enriched question using the OpenAI API.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        question (str): The question to be enriched.
        logger (logging.Logger): The logger instance.

    Returns:
        str: The enriched question.

    Raises:
        BadRequestError: If the API request fails.
    """
    messages = [
        {"role": "system", "content": OPENAI_PERSONA_PROMPT},
        {"role": "user", "content": ENRICHMENT_PROMPT + "Question: " + question},
    ]
    logger.info("Making API request to OpenAI...")
    logger.info("Request payload: %s", messages)

    response = call_openai_chat(client, messages, config, logger)
    logger.info("API response received: %s", response)

    return response

def generate_enriched_question(client: AzureOpenAI, config: ApiConfiguration, question: str, logger: logging.Logger) -> str:
    messages = [
        {"role": "system", "content": OPENAI_PERSONA_PROMPT},
        {"role": "user", "content": ENRICHMENT_PROMPT + "Question: " + question},
    ]
    logger.info("Making API request to OpenAI...")
    logger.info("Request payload: %s", messages)

    response = call_openai_chat(client, messages, config, logger)
    logger.info("API response received: %s", response)

    return response


def generate_follow_up_question(client: AzureOpenAI, config: ApiConfiguration, text: str, logger: logging.Logger) -> str:
    messages = [
        {"role": "system", "content": FOLLOW_UP_PROMPT},
        {"role": "user", "content": text},
    ]
    response = call_openai_chat(client, messages, config, logger)
    return response


def assess_follow_up_on_topic(client: AzureOpenAI, config: ApiConfiguration, follow_up: str, logger: logging.Logger) -> str:
    messages = [
        {"role": "system", "content": FOLLOW_UP_ON_TOPIC_PROMPT},
        {"role": "user", "content": follow_up},
    ]
    response = call_openai_chat(client, messages, config, logger)
    return response

def process_questions(client: AzureOpenAI, config: ApiConfiguration, questions: List[str], processed_question_chunks: List[Dict[str, Any]], logger: logging.Logger) -> List[TestResult]:
    """
    Processes a list of test questions and evaluates their relevance based on their similarity to pre-processed question chunks.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        questions (List[str]): The list of test questions to be processed.
        processed_question_chunks (List[Dict[str, Any]]): The list of pre-processed question chunks.
        logger (logging.Logger): The logger instance.

    Returns:
        List[TestResult]: A list of test results, each containing the original question, its enriched version, and its relevance to the pre-processed chunks.
    """
    question_results: List[TestResult] = []
    
    for question in questions:
        question_result = TestResult()
        question_result.question = question
        question_result.enriched_question_summary = generate_enriched_question(client, config, question, logger)  # Generate enriched question summary
        
        embedding = get_text_embedding(client, config, question_result.enriched_question_summary, logger)  # Get embedding for the enriched question

        best_hit_relevance = 0  # To track the highest similarity score
        best_hit_summary = None  # To track the summary corresponding to the highest similarity

        # Iterate through the processed chunks to find the best hit
        for chunk in processed_question_chunks:
            if chunk and isinstance(chunk, dict):
                ada_embedding = chunk.get("ada_v2")
                similarity = cosine_similarity(ada_embedding, embedding)

                if similarity > SIMILARITY_THRESHOLD:
                    question_result.hit = True

                # Check if this is the best match so far
                if similarity > best_hit_relevance:
                    best_hit_relevance = similarity
                    best_hit_summary = chunk.get("summary")

        # Set the best hit relevance and summary for the question result
        question_result.hit_relevance = best_hit_relevance
        question_result.hit_summary = best_hit_summary

        # Now, generate the follow-up question if a best hit summary exists
        if question_result.hit_summary:
            question_result.follow_up = generate_follow_up_question(client, config, question_result.hit_summary, logger)  # Generate follow-up question
            question_result.follow_up_on_topic = assess_follow_up_on_topic(client, config, question_result.follow_up, logger)  # Assess if follow-up question is on-topic

        question_results.append(question_result)

    logger.debug("Total tests processed: %s", len(question_results))
    return question_results

# Function to read processed chunks from the source directory
def read_processed_chunks(source_dir: str) -> List[Dict[str, Any]]:
    """
    Reads and processes JSON files from a specified source directory.

    Args:
        source_dir (str): The path to the source directory containing JSON files.

    Returns:
        List[Dict[str, Any]]: A list of dictionaries containing the processed JSON data.

    Raises:
        FileNotFoundError: If the source directory or a JSON file is not found.
        IOError: If an I/O error occurs while reading a JSON file.
    """
    processed_question_chunks: List[Dict[str, Any]] = []
    try:
        for filename in os.listdir(source_dir):
            if filename.endswith(".json"):
                file_path = os.path.join(source_dir, filename)
                with open(file_path, "r", encoding="utf-8") as f:
                    chunk = json.load(f)
                    processed_question_chunks = chunk
    except (FileNotFoundError, IOError) as e:
        logger.error(f"Error reading files: {e}")
        raise
    
    if not processed_question_chunks:
        logger.error("Processed question chunks are None or empty.")
    
    return processed_question_chunks

# Function to save the results and generated questions
def save_results(test_destination_dir: str, question_results: List[TestResult], test_mode: str) -> None:
    """
    Saves the test results to a JSON file in the specified destination directory.

    Args:
        test_destination_dir (str): The path to the directory where the test results will be saved.
        question_results (List[TestResult]): A list of TestResult objects containing the test results.
        test_mode (str): The test mode to be used in the output file name.

    Returns:
        None
    """
    output_data = [
        {
            "question": result.question,
            "enriched_question": result.enriched_question_summary, 
            "hit": result.hit,
            "summary": result.hit_summary, 
            "hitRelevance": result.hit_relevance,
            "follow_up": result.follow_up,  # Add follow_up to the output
            "follow_up_on_topic": result.follow_up_on_topic  # Add follow_up_on_topic to the output
        }
        for result in question_results
    ]

    current_datetime = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    output_file = os.path.join(test_destination_dir, f"test_output_v3_{test_mode}_{current_datetime}.json")

    try:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(output_data, f, indent=4)
        logger.info(f"Test results saved to: {output_file}")
    except IOError as e:
        logger.error(f"Error saving results: {e}")
        raise

# Main test-running function
def run_tests(config: ApiConfiguration, test_destination_dir: str, source_dir: str, num_questions: int = 100, questions: List[str] = None, persona_strategy: PersonaStrategy = None) -> None:
    """
    Runs tests using the provided configuration, test destination directory, source directory, and questions.

    Args:
        config (ApiConfiguration): The configuration for the API.
        test_destination_dir (str): The path to the directory where the test results will be saved.
        source_dir (str): The directory containing the source files.
        num_questions (int): The number of questions to generate using the persona strategy.
        questions (List[str]): A list of questions to be processed.
        persona_strategy (PersonaStrategy): The persona strategy to use for generating questions.

    Returns:
        None
    """
    client = configure_openai_for_azure(config)

    if not test_destination_dir:
        logger.error("Test data folder not provided")
        raise ValueError("Test destination directory not provided")
    
    if persona_strategy:
        questions = persona_strategy.generate_questions(client, config, NUM_QUESTIONS, logger)

    if not questions:
        logger.error("Generated questions are None or empty. Exiting the test.")
        return
    # Determine the test mode based on the strategy
    test_mode = persona_strategy.__class__.__name__.replace('PersonaStrategy', '').lower()

    processed_question_chunks = read_processed_chunks(source_dir)
    question_results = process_questions(client, config, questions, processed_question_chunks, logger)
    save_results(test_destination_dir, question_results, test_mode)
****************************************

****************************************
BoxerEval\tests\BoxerDataTest_v4.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

"""
Question Generation (Persona):
Continues with `gpt-4o` for persona-based question generation.
    
Similarity Embedding:
Still uses `text-embedding-ada-002` for similarity comparisons.
    
Evaluation LLM:
Introduces `gemini-1.5-pro` as the evaluation LLM to assess the quality of GPT-4o outputs.
"""

# Standard Library Imports
import logging
import os
import json
import sys
from logging import Logger
from typing import List, Dict, Any
import numpy as np
from numpy.linalg import norm
import datetime


# Third-Party Packages
from openai import AzureOpenAI, OpenAIError, BadRequestError, APIConnectionError
from tenacity import retry, wait_random_exponential, stop_after_attempt, retry_if_not_exception_type
from GeminiEvaluator import GeminiEvaluator

# Add the project root and scripts directory to the Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

# Local Modules
from common.ApiConfiguration import ApiConfiguration
from common.common_functions import get_embedding
from PersonaStrategy import DeveloperPersonaStrategy, TesterPersonaStrategy, BusinessAnalystPersonaStrategy, PersonaStrategy

# Constants
SIMILARITY_THRESHOLD = 0.8
MAX_RETRIES = 15
NUM_QUESTIONS = 100

OPENAI_PERSONA_PROMPT =  "You are an AI assistant helping an application developer understand generative AI. You explain complex concepts in simple language, using Python examples if it helps. You limit replies to 50 words or less. If you don't know the answer, say 'I don't know'. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'."
ENRICHMENT_PROMPT = "You will be provided with a question about building applications that use generative AI technology. Write a 50 word summary of an article that would be a great answer to the question. Consider enriching the question with additional topics that the question asker might want to understand. Write the summary in the present tense, as though the article exists. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'.\n"
FOLLOW_UP_PROMPT =  "You will be provided with a summary of an article about building applications that use generative AI technology. Write a question of no more than 10 words that a reader might ask as a follow up to reading the article."
FOLLOW_UP_ON_TOPIC_PROMPT = "You are an AI assistant helping a team of developers understand AI. You explain complex concepts in simple language. Respond 'yes' if the follow-up question is about AI, otherwise respond 'no'."

# Setup Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

gemini_evaluator = GeminiEvaluator()  #initiating an instance of the GeminiEvaluator

# Function to configure the Azure OpenAI API client
def configure_openai_for_azure(config: ApiConfiguration) -> AzureOpenAI:

    """
    Configures OpenAI for Azure using the provided ApiConfiguration.

    Args:
        config (ApiConfiguration): The ApiConfiguration object containing the necessary settings.

    Returns:
        AzureOpenAI: An instance of AzureOpenAI configured with the provided settings.
    """
    return AzureOpenAI(
        azure_endpoint=config.resourceEndpoint, 
        api_key=config.apiKey.strip(),
        api_version=config.apiVersion
    )

# Class to hold test results
class TestResult:
    def __init__(self) -> None:

        """
        Initializes a new instance of the TestResult class.

        Sets the initial state of the test result, including the question, enriched question, 
        hit status, hit relevance, hit summary, follow-up question, and follow-up topic.
        
        Args:
            None
        
        Returns:
            None
        """
        self.question: str = ""
        self.enriched_question_summary: str = ""
        self.hit: bool = False
        self.hit_relevance: float = 0.0
        self.follow_up: str = ""  # Adding followUp field
        self.follow_up_on_topic: str = ""  # Adding followUpOnTopic field
        self.gemini_evaluation: str = ""  # Field to store Gemini LLM evaluation

# Function to call the OpenAI API with retry logic
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def call_openai_chat(client: AzureOpenAI, messages: List[Dict[str, str]], config: ApiConfiguration, logger: logging.Logger) -> str:
    """
    Retries the OpenAI chat API call with exponential backoff and retry logic.

    :param client: An instance of the AzureOpenAI class.
    :type client: AzureOpenAI
    :param messages: A list of dictionaries representing the messages to be sent to the API.
    :type messages: List[Dict[str, str]]
    :param config: An instance of the ApiConfiguration class.
    :type config: ApiConfiguration
    :param logger: An instance of the logging.Logger class.
    :type logger: logging.Logger
    :return: The content of the first choice in the API response.
    :rtype: str
    :raises RuntimeError: If the finish reason in the API response is not 'stop', 'length', or an empty string.
    :raises OpenAIError: If there is an error with the OpenAI API.
    :raises APIConnectionError: If there is an error with the API connection.
    """

    try:
        response = client.chat.completions.create(
            model=config.azureDeploymentName,
            messages=messages,
            temperature=0.7,
            max_tokens=config.maxTokens,
            top_p=0.0,
            frequency_penalty=0,
            presence_penalty=0,
            timeout=config.openAiRequestTimeout,
        )
        content = response.choices[0].message.content
        finish_reason = response.choices[0].finish_reason

        if finish_reason not in {"stop", "length", ""}:
            logger.warning("Unexpected stop reason: %s", finish_reason)
            logger.warning("Content: %s", content)
            logger.warning("Consider increasing max tokens and retrying.")
            raise RuntimeError("Unexpected finish reason in API response.")

        return content

    except (OpenAIError, APIConnectionError) as e:
        logger.error(f"Error: {e}")
        raise


# Function to retrieve text embeddings using OpenAI API with retry logic
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def get_text_embedding(client: AzureOpenAI, config: ApiConfiguration, text: str, logger: Logger) -> np.ndarray:
    """
    Retrieves the text embedding for a given text using the OpenAI API.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        text (str): The text for which to retrieve the embedding.
        logger (Logger): The logger instance.

    Returns:
        np.ndarray: The text embedding as a numpy array.

    Raises:
        OpenAIError: If an error occurs while retrieving the text embedding.
    """

    try:
        embedding = get_embedding(text, client, config)
        return np.array(embedding)
    except OpenAIError as e:
        logger.error(f"Error getting text embedding: {e}")
        raise

# Function to calculate cosine similarity between two vectors
def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """
    Calculates the cosine similarity between two vectors.

    Args:
        a (np.ndarray): The first vector.
        b (np.ndarray): The second vector.

    Returns:
        float: The cosine similarity between the two vectors.

    Raises:
        ValueError: If the input vectors are not numpy arrays or convertible to numpy arrays.
        ValueError: If the input vectors do not have the same shape.
        ValueError: If either of the input vectors is a zero vector.
    """

    try:
        a, b = np.array(a), np.array(b)
    except Exception:
        raise ValueError("Input vectors must be numpy arrays or convertible to numpy arrays")

    if a.shape != b.shape:
        raise ValueError("Input vectors must have the same shape")

    dot_product = np.dot(a, b)
    a_norm, b_norm = norm(a), norm(b)

    if a_norm == 0 or b_norm == 0:
        raise ValueError("Input vectors must not be zero vectors")

    return dot_product / (a_norm * b_norm)

# Function to generate enriched questions using OpenAI API
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def generate_enriched_question(client: AzureOpenAI, config: ApiConfiguration, question: str, logger: logging.Logger) -> str:
    """
    Generates an enriched question using the OpenAI API.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        question (str): The question to be enriched.
        logger (logging.Logger): The logger instance.

    Returns:
        str: The enriched question.

    Raises:
        BadRequestError: If the API request fails.
    """
    messages = [
        {"role": "system", "content": OPENAI_PERSONA_PROMPT},
        {"role": "user", "content": ENRICHMENT_PROMPT + "Question: " + question},
    ]
    logger.info("Making API request to OpenAI...")
    logger.info("Request payload: %s", messages)

    response = call_openai_chat(client, messages, config, logger)
    logger.info("API response received: %s", response)

    return response

def generate_enriched_question(client: AzureOpenAI, config: ApiConfiguration, question: str, logger: logging.Logger) -> str:
    """
    Generates an enriched question using the OpenAI API.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        question (str): The question to be enriched.
        logger (logging.Logger): The logger instance.

    Returns:
        str: The enriched question.

    Raises:
        BadRequestError: If the API request fails.
    """
    messages = [
        {"role": "system", "content": OPENAI_PERSONA_PROMPT},
        {"role": "user", "content": ENRICHMENT_PROMPT + "Question: " + question},
    ]
    logger.info("Making API request to OpenAI...")
    logger.info("Request payload: %s", messages)

    response = call_openai_chat(client, messages, config, logger)
    logger.info("API response received: %s", response)

    return response


def generate_follow_up_question(client: AzureOpenAI, config: ApiConfiguration, text: str, logger: logging.Logger) -> str:
    """
    Generates a follow-up question using the OpenAI API.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        text (str): The text to generate a follow-up question about.
        logger (logging.Logger): The logger instance.

    Returns:
        str: The follow-up question.

    Raises:
        BadRequestError: If the API request fails.
    """
    messages = [
        {"role": "system", "content": FOLLOW_UP_PROMPT},
        {"role": "user", "content": text},
    ]
    response = call_openai_chat(client, messages, config, logger)
    return response


def assess_follow_up_on_topic(client: AzureOpenAI, config: ApiConfiguration, follow_up: str, logger: logging.Logger) -> str:
    """
    Checks if a follow-up question is about AI using the OpenAI API.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        follow_up (str): The follow-up question to assess.
        logger (logging.Logger): The logger instance.

    Returns:
        str: 'yes' if the follow-up question is about AI, 'no' otherwise.

    Raises:
        BadRequestError: If the API request fails.
    """
   
    messages = [
        {"role": "system", "content": FOLLOW_UP_ON_TOPIC_PROMPT},
        {"role": "user", "content": follow_up},
    ]
    response = call_openai_chat(client, messages, config, logger)
    return response

def process_questions(client: AzureOpenAI, config: ApiConfiguration, questions: List[str], processed_question_chunks: List[Dict[str, Any]], logger: logging.Logger) -> List[TestResult]:
    """
    Processes a list of test questions and evaluates their relevance based on their similarity to pre-processed question chunks.

    Args:
        client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        questions (List[str]): The list of test questions to be processed.
        processed_question_chunks (List[Dict[str, Any]]): The list of pre-processed question chunks.
        logger (logging.Logger): The logger instance.

    Returns:
        List[TestResult]: A list of test results, each containing the original question, its enriched version, and its relevance to the pre-processed chunks.
    """
    question_results: List[TestResult] = []
    
    for question in questions:
        question_result = TestResult()
        question_result.question = question
        question_result.enriched_question_summary = generate_enriched_question(client, config, question, logger)  # Generate enriched question summary
        
        embedding = get_text_embedding(client, config, question_result.enriched_question_summary, logger)  # Get embedding for the enriched question

        best_hit_relevance = 0  # To track the highest similarity score
        best_hit_summary = None  # To track the summary corresponding to the highest similarity

        # Iterate through the processed chunks to find the best hit
        for chunk in processed_question_chunks:
            if chunk and isinstance(chunk, dict):
                ada_embedding = chunk.get("ada_v2")
                similarity = cosine_similarity(ada_embedding, embedding)

                if similarity > SIMILARITY_THRESHOLD:
                    question_result.hit = True

                # Check if this is the best match so far
                if similarity > best_hit_relevance:
                    best_hit_relevance = similarity
                    best_hit_summary = chunk.get("summary")

        # Set the best hit relevance and summary for the question result
        question_result.hit_relevance = best_hit_relevance
        question_result.hit_summary = best_hit_summary

        # Now, generate the follow-up question if a best hit summary exists
        if question_result.hit_summary:
            question_result.follow_up = generate_follow_up_question(client, config, question_result.hit_summary, logger)  # Generate follow-up question
            question_result.follow_up_on_topic = assess_follow_up_on_topic(client, config, question_result.follow_up, logger)  # Assess if follow-up question is on-topic

        
        # Use Gemini to evaluate the Azure OpenAI enriched summary
        question_result.gemini_evaluation = gemini_evaluator.evaluate(
            question_result.question,  # This is the original question
            question_result.enriched_question_summary # This is the summary generated by Azure OpenAI
            ) 

        question_results.append(question_result)

    logger.debug("Total tests processed: %s", len(question_results))
    return question_results

# Function to read processed chunks from the source directory
def read_processed_chunks(source_dir: str) -> List[Dict[str, Any]]:
    """
    Reads and processes JSON files from a specified source directory.

    Args:
        source_dir (str): The path to the source directory containing JSON files.

    Returns:
        List[Dict[str, Any]]: A list of dictionaries containing the processed JSON data.

    Raises:
        FileNotFoundError: If the source directory or a JSON file is not found.
        IOError: If an I/O error occurs while reading a JSON file.
    """
    processed_question_chunks: List[Dict[str, Any]] = []
    try:
        for filename in os.listdir(source_dir):
            if filename.endswith(".json"):
                file_path = os.path.join(source_dir, filename)
                with open(file_path, "r", encoding="utf-8") as f:
                    chunk = json.load(f)
                    processed_question_chunks = chunk
    except (FileNotFoundError, IOError) as e:
        logger.error(f"Error reading files: {e}")
        raise
    
    if not processed_question_chunks:
        logger.error("Processed question chunks are None or empty.")
    
    return processed_question_chunks

# Function to save the results and generated questions
def save_results(test_destination_dir: str, question_results: List[TestResult], test_mode: str) -> None:
    """
    Saves the test results to a JSON file in the specified destination directory.

    Args:
        test_destination_dir (str): The path to the directory where the test results will be saved.
        question_results (List[TestResult]): A list of TestResult objects containing the test results.
        test_mode (str): The test mode to be used in the output file name.

    Returns:
        None

    Raises:
        IOError: If an I/O error occurs while writing the JSON file.
    """
    output_data = [
        {
            "question": result.question,
            "enriched_question": result.enriched_question_summary, 
            "hit": result.hit,
            "summary": result.hit_summary, 
            "hitRelevance": result.hit_relevance,
            "follow_up": result.follow_up,  # Add follow_up to the output
            "follow_up_on_topic": result.follow_up_on_topic,  # Add follow_up_on_topic to the output
            "gemini_evaluation": result.gemini_evaluation  # Add Gemini evaluation to the output
        }
        for result in question_results
    ]

    current_datetime = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    output_file = os.path.join(test_destination_dir, f"test_output_v4_{test_mode}_{current_datetime}.json")

    try:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(output_data, f, indent=4)
        logger.info(f"Test results saved to: {output_file}")
    except IOError as e:
        logger.error(f"Error saving results: {e}")
        raise

# Main test-running function
def run_tests(config: ApiConfiguration, test_destination_dir: str, source_dir: str, num_questions: int = 100, questions: List[str] = None, persona_strategy: PersonaStrategy = None) -> None:
    """
    Runs tests using the provided configuration, test destination directory, source directory, and questions.

    Args:
        config (ApiConfiguration): The configuration for the API.
        test_destination_dir (str): The path to the directory where the test results will be saved.
        source_dir (str): The directory containing the source files.
        num_questions (int): The number of questions to generate using the persona strategy.
        questions (List[str]): A list of questions to be processed.
        persona_strategy (PersonaStrategy): The persona strategy to use for generating questions.

    Returns:
        None
    """
    client = configure_openai_for_azure(config)

    if not test_destination_dir:
        logger.error("Test data folder not provided")
        raise ValueError("Test destination directory not provided")
    
    if persona_strategy:
        questions = persona_strategy.generate_questions(client, config, NUM_QUESTIONS, logger)

    if not questions:
        logger.error("Generated questions are None or empty. Exiting the test.")
        return
    # Determine the test mode based on the strategy
    test_mode = persona_strategy.__class__.__name__.replace('PersonaStrategy', '').lower()

    processed_question_chunks = read_processed_chunks(source_dir)
    question_results = process_questions(client, config, questions, processed_question_chunks, logger)
    save_results(test_destination_dir, question_results, test_mode)
****************************************

****************************************
BoxerEval\tests\BoxerDataTest_v5.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

"""
Question Generation (Persona):
Keeps using `gpt-4o` for persona-based question generation.
    
Similarity Embedding:
Upgraded to `text-embedding-3-large` for improved embedding precision and similarity calculations.
    
Evaluation LLM:
Continues with `gemini-1.5-pro` for evaluating the responses generated by GPT-4o.
"""

# Standard Library Imports
import logging
import os
import json
import sys
from logging import Logger
from typing import List, Dict, Any
import numpy as np
from numpy.linalg import norm
import datetime


# Third-Party Packages
from openai import AzureOpenAI, OpenAIError, BadRequestError, APIConnectionError
from tenacity import retry, wait_random_exponential, stop_after_attempt, retry_if_not_exception_type
from GeminiEvaluator import GeminiEvaluator

# Add the project root and scripts directory to the Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

# Local Modules
from common.ApiConfiguration import ApiConfiguration
from common.common_functions import get_embedding
from PersonaStrategy import DeveloperPersonaStrategy, TesterPersonaStrategy, BusinessAnalystPersonaStrategy, PersonaStrategy

# Constants
SIMILARITY_THRESHOLD = 0.8          # Defines the minimum similarity threshold for a question to be considered a hit
MAX_RETRIES = 15                    # Maximum number of retries for API calls
NUM_QUESTIONS = 100                 # Number of questions to be generated per test

# OpenAI prompts used for persona generation, enrichment, and follow-up question generation
OPENAI_PERSONA_PROMPT =  "You are an AI assistant helping an application developer understand generative AI. You explain complex concepts in simple language, using Python examples if it helps. You limit replies to 50 words or less. If you don't know the answer, say 'I don't know'. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'."
ENRICHMENT_PROMPT = "You will be provided with a question about building applications that use generative AI technology. Write a 50 word summary of an article that would be a great answer to the question. Consider enriching the question with additional topics that the question asker might want to understand. Write the summary in the present tense, as though the article exists. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'.\n"
FOLLOW_UP_PROMPT =  "You will be provided with a summary of an article about building applications that use generative AI technology. Write a question of no more than 10 words that a reader might ask as a follow up to reading the article."
FOLLOW_UP_ON_TOPIC_PROMPT = "You are an AI assistant helping a team of developers understand AI. You explain complex concepts in simple language. Respond 'yes' if the follow-up question is about AI, otherwise respond 'no'."

# Setup Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

gemini_evaluator = GeminiEvaluator()  ## Initialize an instance of the GeminiEvaluator for response evaluation

# Function to configure the Azure OpenAI API client
def configure_openai_for_azure(config: ApiConfiguration, task: str) -> AzureOpenAI:
    """
    Configures OpenAI for Azure using the provided ApiConfiguration.
    
    Args:
        config (ApiConfiguration): The ApiConfiguration object containing the necessary settings.
        task (str): The task for which OpenAI is being configured ("chat" or "embedding").
        
    Returns:
        AzureOpenAI: An instance of AzureOpenAI configured with the correct settings.
    """
    if task == "chat":
        return AzureOpenAI(
            azure_endpoint=config.resourceChatCompletionEndpoint,
            api_key=config.apiKey.strip(),
            api_version=config.apiVersion
        )
    elif task == "embedding":
        return AzureOpenAI(
            azure_endpoint=config.resourceEmbeddingEndpoint,
            api_key=config.apiKey.strip(),
            api_version=config.apiVersion
        )

# Class to hold test results
class TestResult:
    def __init__(self) -> None:

        """
        Initializes a new instance of the TestResult class.

        Sets the initial state of the test result, including the question, enriched question, 
        hit status, hit relevance, hit summary, follow-up question, and follow-up topic.
        
        Args:
            None
        
        Returns:
            None
        """
        self.question: str = ""                             # Original question
        self.hit_relevance: float = 0.0                     # Relevance score of the hit
        self.enriched_question_summary: str = ""            # Summary of the enriched question   
        self.hit: bool = False                              # Whether the question was considered a hit based on similarity
        self.hit_relevance: float = 0.0                     # Relevance score of the hit
        self.follow_up: str = ""                            # Adding followUp field
        self.follow_up_on_topic: str = ""                   # Adding followUpOnTopic field
        self.gemini_evaluation: str = ""                    # Field to store Gemini LLM evaluation

# Function to call the OpenAI API with retry logic
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def call_openai_chat(chat_client: AzureOpenAI, messages: List[Dict[str, str]], config: ApiConfiguration, logger: logging.Logger) -> str:
    """
    Retries the OpenAI chat API call with exponential backoff and retry logic.

    :param chat_client: An instance of the AzureOpenAI class.
    :type chat_client: AzureOpenAI
    :param messages: A list of dictionaries representing the messages to be sent to the API.
    :type messages: List[Dict[str, str]]
    :param config: An instance of the ApiConfiguration class.
    :type config: ApiConfiguration
    :param logger: An instance of the logging.Logger class.
    :type logger: logging.Logger
    :return: The content of the first choice in the API response.
    :rtype: str
    :raises RuntimeError: If the finish reason in the API response is not 'stop', 'length', or an empty string.
    :raises OpenAIError: If there is an error with the OpenAI API.
    :raises APIConnectionError: If there is an error with the API connection.
    """
    try:
        response = chat_client.chat.completions.create(
            model=config.azureDeploymentName,
            messages=messages,
            temperature=0.7,
            max_tokens=config.maxTokens,
            top_p=0.0,
            frequency_penalty=0,
            presence_penalty=0,
            timeout=config.openAiRequestTimeout,
        )
        content = response.choices[0].message.content
        finish_reason = response.choices[0].finish_reason

        if finish_reason not in {"stop", "length", ""}:
            logger.warning("Unexpected stop reason: %s", finish_reason)
            logger.warning("Content: %s", content)
            logger.warning("Consider increasing max tokens and retrying.")
            raise RuntimeError("Unexpected finish reason in API response.")

        return content

    except (OpenAIError, APIConnectionError) as e:
        logger.error(f"Error: {e}")
        raise


# Function to retrieve text embeddings using OpenAI API with retry logic
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def get_text_embedding(embedding_client: AzureOpenAI, config: ApiConfiguration, text: str, logger: Logger) -> np.ndarray:
    """
    Retrieves the text embedding for a given text using the OpenAI API.

    Args:
        embedding_client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        text (str): The text for which to retrieve the embedding.
        logger (Logger): The logger instance.

    Returns:
        np.ndarray: The text embedding as a numpy array.

    Raises:
        OpenAIError: If an error occurs while retrieving the text embedding.
    """
    try:
        embedding = get_embedding(text, embedding_client, config)
        return np.array(embedding)
    except OpenAIError as e:
        logger.error(f"Error getting text embedding: {e}")
        raise

# Function to calculate cosine similarity between two vectors
def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """
    Calculates the cosine similarity between two vectors.

    Args:
        a (np.ndarray): The first vector.
        b (np.ndarray): The second vector.

    Returns:
        float: The cosine similarity between the two vectors.

    Raises:
        ValueError: If the input vectors are not numpy arrays or convertible to numpy arrays.
        ValueError: If the input vectors do not have the same shape.
        ValueError: If either of the input vectors is a zero vector.
    """
    try:
        a, b = np.array(a), np.array(b)
    except Exception:
        raise ValueError("Input vectors must be numpy arrays or convertible to numpy arrays")

    if a.shape != b.shape:
        raise ValueError("Input vectors must have the same shape")

    dot_product = np.dot(a, b)
    a_norm, b_norm = norm(a), norm(b)

    if a_norm == 0 or b_norm == 0:
        raise ValueError("Input vectors must not be zero vectors")

    return dot_product / (a_norm * b_norm)

# Function to generate enriched questions using OpenAI API
@retry(wait=wait_random_exponential(min=5, max=15), stop=stop_after_attempt(MAX_RETRIES), retry=retry_if_not_exception_type(BadRequestError))
def generate_enriched_question(chat_client: AzureOpenAI, config: ApiConfiguration, question: str, logger: logging.Logger) -> str:
    """
    Generates an enriched question using the OpenAI API.

    Args:
        chat_client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        question (str): The question to be enriched.
        logger (logging.Logger): The logger instance.

    Returns:
        str: The enriched question.

    Raises:
        BadRequestError: If the API request fails.
    """
    messages = [
        {"role": "system", "content": OPENAI_PERSONA_PROMPT},
        {"role": "user", "content": ENRICHMENT_PROMPT + "Question: " + question},
    ]
    logger.info("Making API request to OpenAI...")
    logger.info("Request payload: %s", messages)

    response = call_openai_chat(chat_client, messages, config, logger)
    logger.info("API response received: %s", response)

    return response


def generate_follow_up_question(chat_client: AzureOpenAI, config: ApiConfiguration, text: str, logger: logging.Logger) -> str:
    """
    Generates a follow-up question using the OpenAI API.

    Args:
        chat_client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        text (str): The text to generate a follow-up question about.
        logger (logging.Logger): The logger instance.

    Returns:
        str: The follow-up question.

    Raises:
        BadRequestError: If the API request fails.
    """
    messages = [
        {"role": "system", "content": FOLLOW_UP_PROMPT},
        {"role": "user", "content": text},
    ]
    response = call_openai_chat(chat_client, messages, config, logger)
    return response


def assess_follow_up_on_topic(chat_client: AzureOpenAI, config: ApiConfiguration, follow_up: str, logger: logging.Logger) -> str:
    """
    Checks if a follow-up question is about AI using the OpenAI API.

    Args:
        chat_client (AzureOpenAI): The OpenAI client instance.
        config (ApiConfiguration): The API configuration instance.
        follow_up (str): The follow-up question to assess.
        logger (logging.Logger): The logger instance.

    Returns:
        str: 'yes' if the follow-up question is about AI, 'no' otherwise.

    Raises:
        BadRequestError: If the API request fails.
    """
    messages = [
        {"role": "system", "content": FOLLOW_UP_ON_TOPIC_PROMPT},
        {"role": "user", "content": follow_up},
    ]
    response = call_openai_chat(chat_client, messages, config, logger)
    return response

def process_questions(chat_client: AzureOpenAI, embedding_client: AzureOpenAI, config: ApiConfiguration, questions: List[str], processed_question_chunks: List[Dict[str, Any]], logger: logging.Logger) -> List[TestResult]:
    """
    Processes a list of test questions and evaluates their relevance based on their similarity to pre-processed question chunks.

    Args:
        chat_client (AzureOpenAI): The OpenAI client instance for generating enriched summaries and follow-up questions.
        embedding_client (AzureOpenAI): The OpenAI client instance for generating embeddings.
        config (ApiConfiguration): The API configuration instance.
        questions (List[str]): The list of test questions to be processed.
        processed_question_chunks (List[Dict[str, Any]]): The list of pre-processed question chunks.
        logger (logging.Logger): The logger instance.

    Returns:
        List[TestResult]: A list of test results, each containing the original question, its enriched version, its relevance to the pre-processed chunks, the follow-up question, and whether the follow-up question is on-topic.

    Raises:
        BadRequestError: If the API request fails.
    """
    # Initialize an empty list to store the results of each processed question.
    question_results: List[TestResult] = []
    
    # Loop through each question in the provided list of questions.
    for question in questions:
        # Create a new TestResult object for the current question to store its results.
        question_result = TestResult()
        question_result.question = question     # Store the original question

        question_result.enriched_question_summary = generate_enriched_question(chat_client, config, question, logger)  # Generate enriched question summary
        
        # Obtain the text embedding for the enriched question using OpenAI's embedding model.
        embedding = get_text_embedding(embedding_client, config, question_result.enriched_question_summary, logger)  # Get embedding for the enriched question

        # Initialize variables to track the highest similarity score and the corresponding summary.
        best_hit_relevance = 0      # To track the highest similarity score
        best_hit_summary = None     # To track the summary corresponding to the highest similarity

        # Iterate through the processed chunks to find the best hit
        for chunk in processed_question_chunks:
            # Ensure the chunk is valid and is a dictionary.
            if chunk and isinstance(chunk, dict):
                gpt4_embedding = chunk.get("embedding")
                similarity = cosine_similarity(gpt4_embedding, embedding)

                # If similarity exceeds the defined threshold, mark the question as a hit
                if similarity > SIMILARITY_THRESHOLD:
                    question_result.hit = True

                # Check if this is the best match so far
                if similarity > best_hit_relevance:
                    best_hit_relevance = similarity
                    best_hit_summary = chunk.get("summary") 

         # Store the highest relevance score and the associated summary in the result.
        question_result.hit_relevance = best_hit_relevance
        question_result.hit_summary = best_hit_summary

        # If a relevant summary (best hit) exists, generate a follow-up question and assess its topic relevance.
        if question_result.hit_summary:
            # Generate a follow-up question based on the best hit summary.  
            question_result.follow_up = generate_follow_up_question(chat_client, config, question_result.hit_summary, logger)

            # Check if the follow-up question is relevant to AI and mark it accordingly.  
            question_result.follow_up_on_topic = assess_follow_up_on_topic(chat_client, config, question_result.follow_up, logger)  
        
        # Use Gemini to evaluate the Azure OpenAI enriched summary
        question_result.gemini_evaluation = gemini_evaluator.evaluate(
            question_result.question,                   # This is the original question
            question_result.enriched_question_summary   # This is the summary generated by Azure OpenAI
            ) 

        # Append the result for the current question to the results list.
        question_results.append(question_result)

    # Log the total number of processed questions for debugging or tracking purposes.
    logger.debug("Total tests processed: %s", len(question_results))

    # Return the list of all test results.
    return question_results

# Function to read processed chunks from the source directory
def read_processed_chunks(source_dir: str) -> List[Dict[str, Any]]:
    """
    Reads and processes JSON files from a specified source directory.

    Args:
        source_dir (str): The path to the source directory containing JSON files.

    Returns:
        List[Dict[str, Any]]: A list of dictionaries containing the processed JSON data.

    Raises:
        FileNotFoundError: If the source directory or a JSON file is not found.
        IOError: If an I/O error occurs while reading a JSON file.
    """
    processed_question_chunks: List[Dict[str, Any]] = []            # Initialize an empty list to hold the chunks.
    try:
        # Loop through all files in the specified directory.
        for filename in os.listdir(source_dir):
            # Check if the file has a '.json' extension.
            if filename.endswith(".json"):
                file_path = os.path.join(source_dir, filename)      # Get the full path to the file.
                # Open the file and load its contents as JSON.
                with open(file_path, "r", encoding="utf-8") as f:
                    chunk = json.load(f)                        # Load JSON data into the chunk variable.
                    processed_question_chunks = chunk           # Store the JSON content in the processed chunks list.

    # Handle file not found or I/O errors that occur during file reading.                
    except (FileNotFoundError, IOError) as e:
        logger.error(f"Error reading files: {e}")
        raise
    
    # If no chunks were processed, log a warning.
    if not processed_question_chunks:
        logger.error("Processed question chunks are None or empty.")
    
    return processed_question_chunks

# Function to save the results and generated questions
def save_results(test_destination_dir: str, question_results: List[TestResult], test_mode: str) -> None:
    """
    Saves the test results to a JSON file in the specified destination directory.

    Args:
        test_destination_dir (str): The path to the directory where the test results will be saved.
        question_results (List[TestResult]): A list of TestResult objects containing the test results.
        test_mode (str): The test mode to be used in the output file name.

    Returns:
        None

    Raises:
        IOError: If an I/O error occurs while writing the JSON file.
    """
    output_data = [
        {
            "question": result.question,                                # Original question.
            "enriched_question": result.enriched_question_summary,      # Enriched question summary.
            "hit": result.hit,                                          # Whether it was a hit or not (based on similarity).
            "summary": result.hit_summary,                              # The best-matching pre-processed summary.
            "hitRelevance": result.hit_relevance,                       # Relevance score for the best hit.
            "follow_up": result.follow_up,                              # Follow-up question generated.
            "follow_up_on_topic": result.follow_up_on_topic,            # Whether the follow-up is on-topic.
            "gemini_evaluation": result.gemini_evaluation               # Evaluation result from Gemini.
        }
        for result in question_results                                  # Iterate over each TestResult and serialize it.
    ]

    # Generate a unique filename for the output based on the current timestamp and test mode.
    current_datetime = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    output_file = os.path.join(test_destination_dir, f"test_output_v5_{test_mode}_{current_datetime}.json")

    try:
        # Write the output data to the specified file as JSON.
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(output_data, f, indent=4)
        logger.info(f"Test results saved to: {output_file}")
    
    # Handle any I/O errors that might occur during writing.
    except IOError as e:
        logger.error(f"Error saving results: {e}")
        raise

# Main test-running function
def run_tests(config: ApiConfiguration, test_destination_dir: str, source_dir: str, num_questions: int = 100, questions: List[str] = None, persona_strategy: PersonaStrategy = None) -> None:
    """
    Runs tests using the provided configuration, test destination directory, source directory, and questions.

    Args:
        config (ApiConfiguration): The configuration for the API.
        test_destination_dir (str): The path to the directory where the test results will be saved.
        source_dir (str): The directory containing the source files.
        num_questions (int): The number of questions to generate using the persona strategy.
        questions (List[str]): A list of questions to be processed.
        persona_strategy (PersonaStrategy): The persona strategy to use for generating questions.

    Returns:
        None
    """
    # Initialize the OpenAI clients for both chat completions and embeddings.
    chat_client = configure_openai_for_azure(config, "chat")
    embedding_client = configure_openai_for_azure(config, "embedding")

    # Ensure that a test destination directory is provided, raise an error if not.
    if not test_destination_dir:
        logger.error("Test data folder not provided")                       # Log error message.
        raise ValueError("Test destination directory not provided")         # Raise exception
    
    if persona_strategy:
        questions = persona_strategy.generate_questions(chat_client, config, NUM_QUESTIONS, logger)

    if not questions:
        logger.error("Generated questions are None or empty. Exiting the test.")
        return
    # Determine the test mode based on the strategy
    test_mode = persona_strategy.__class__.__name__.replace('PersonaStrategy', '').lower()

    processed_question_chunks = read_processed_chunks(source_dir)
    question_results = process_questions(chat_client,embedding_client, config, questions, processed_question_chunks, logger)
    save_results(test_destination_dir, question_results, test_mode)
****************************************

****************************************
BoxerEval\tests\GeminiEvaluator.py
****************************************
"""
GeminiEvaluator Module

This module provides functionality for evaluating the quality of LLM-generated summaries using Google's Gemini model.
It assesses how well summaries capture core information from original content and address user queries.

The module includes:
- GeminiEvaluator class: Handles the evaluation process using Gemini's API
- Scoring system: 1 (poor) to 4 (excellent) rating scale
- Authentication: Uses GEMINI_API_KEY environment variable

Dependencies:
    - google.generativeai
    - os

Example:
    evaluator = GeminiEvaluator()
    score = evaluator.evaluate(original_content, summary)
"""

# Copyright (c) 2024 Braid Technologies Ltd

# Imports
import google.generativeai as genai
import os

class GeminiEvaluator:
    def __init__(self):
        """
        Initialize the GeminiEvaluator class.
        
        This class provides functions for evaluating the quality of summaries generated by a large language model (LLM). 
        The primary task is to evaluate how effectively the summary captures the core information from the original content and addresses the user's query.
        """
        # Fetch the API key from the environment variables to authenticate with Gemini LLM
        self.api_key = os.getenv("GEMINI_API_KEY")

        # Set the endpoint for the Gemini LLM
        self.endpoint = "https://generativelanguage.googleapis.com"

        # Set the API key for the Google Generative AI library (used for interacting with Gemini LLM)
        genai.api_key = self.api_key

        # Set the system instruction prompt for the evaluation
        self.system_instruction_prompt_eval = f"""Prompt: 
        You are a professional LLM evaluation judge assessing the quality of summaries generated by a large language model (LLM). 
        Your primary task is to evaluate how effectively the summary captures the core information from the original content and addresses the user's query.

        *** Instructions ***
        As a summary evaluator, follow these steps:

        - Understand the Question: Carefully read the original content to understand the key points and context.
        - Assess the Summary: Review the summary generated by the LLM, checking for its relevance, coherence, and completeness.
        - Rate the Summary: 
        1: Irrelevant or incoherent.
        2: Partially relevant but incomplete.
        3: Mostly relevant and coherent.
        4: Fully relevant and coherent.

        *** Response Format ***
        Return just the score as an integer (1, 2, 3, or 4).
        """

    def evaluate(self, original_content: str, summary: str) -> str:
        """
        Evaluates the quality of a summary based on the original content using the Gemini LLM.
        
        Args:
            original_content (str): The original text content that needs to be summarized.
            summary (str): The summary generated by the LLM that needs to be evaluated.
        
        Returns:
            str: The evaluation score as an integer value (1-4), assessing the summary's quality.
        """
        # Create a GenerativeModel object using the specified Gemini model and system instruction
        model = genai.GenerativeModel("models/gemini-1.5-pro", system_instruction=self.system_instruction_prompt_eval)
        
        # Create an evaluation prompt, providing both the original content and the summary
        evaluation_prompt = f"""
        Question: {original_content}
        Summary: {summary}
        """
         # Generate a response from the Gemini LLM using the evaluation prompt
        response = model.generate_content(evaluation_prompt)
        
        # Return the evaluation score text, which is expected to be an integer (1-4)
        return response.text
****************************************

****************************************
BoxerEval\tests\PersonaStrategy.py
****************************************
"""
This module implements the Strategy pattern for generating persona-specific questions using LLM technology.

It provides an abstract base class PersonaStrategy and concrete implementations for different user personas
(Developer, Tester, and Business Analyst). Each strategy generates relevant questions based on the
persona's perspective and interests in LLM technology.

Classes:
    PersonaStrategy (ABC): Abstract base class defining the interface for persona strategies
    DeveloperPersonaStrategy: Generates questions from a developer's perspective
    TesterPersonaStrategy: Generates questions from a tester's perspective
    BusinessAnalystPersonaStrategy: Generates questions from a business analyst's perspective

The module uses Azure OpenAI services to generate contextually relevant questions and includes
proper error handling and logging mechanisms.
"""

# Copyright (c) 2024 Braid Technologies Ltd

# Import necessary modules and libraries
from abc import ABC, abstractmethod
from typing import List
import logging
from openai import AzureOpenAI
import os
import sys

# Add the project root and scripts directory to the Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

# Import common configurations and functions
from common.ApiConfiguration import ApiConfiguration  # API configuration management
from common.common_functions import get_embedding  # Function for getting embeddings
from openai import AzureOpenAI, OpenAIError, BadRequestError, APIConnectionError  # Exception handling for OpenAI API
from BoxerDataTest_v1 import call_openai_chat  # Function to call OpenAI chat model


# Setup Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Constants for Persona Prompts
DEVELOPER_PROMPT = "You are a programmer interested in the details of writing applications that use an LLM in Python."
TESTER_PROMPT = "You are a tester who wants to know how to assess and ensure quality in an application that uses LLM technology."
BUSINESS_ANALYST_PROMPT = "You are a business analyst interested in how people can apply LLM technology to solve business problems."

# Abstract class for Persona Strategies
class PersonaStrategy(ABC):
    @abstractmethod
    def generate_questions(self, chat_client: AzureOpenAI, config: ApiConfiguration, num_questions: int, logger: logging.Logger) -> List[str]:
        """
        Abstract method to generate a list of questions based on a specific persona.

        Args:
            chat_client (AzureOpenAI): An instance of the AzureOpenAI class.
            config (ApiConfiguration): An instance of the ApiConfiguration class.
            num_questions (int): The number of questions to generate.
            logger (logging.Logger): Logger for capturing process information.

        Returns:
            List[str]: A list of questions generated based on the persona.
        """
        pass  # Abstract method to be implemented by subclasses

    def _generate_questions(self, chat_client: AzureOpenAI, config: ApiConfiguration, prompt: str, num_questions: int, logger: logging.Logger) -> List[str]:
        """
    Generates a list of questions based on a prompt.

    Args:
        chat_client (AzureOpenAI): An instance of the AzureOpenAI class.
        config (ApiConfiguration): An instance of the ApiConfiguration class.
        prompt (str): The prompt to use when generating the questions.
        num_questions (int): The number of questions to generate.
        logger (logging.Logger): An instance of the logging.Logger class.

    Returns:
        List[str]: A list of questions generated based on the prompt.
        """
        # Prepare the messages to be sent to the OpenAI chat API
        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": f"Generate {num_questions} questions about this topic."},
        ]
        # Log the prompt that will be used for generating questions
        logger.info("Generating questions with the following prompt: %s", prompt)

        # Call the OpenAI chat model and retrieve the response
        response = call_openai_chat(chat_client, messages, config, logger)

        # Split the response into individual questions and filter out empty ones
        questions = response.split('\n')
        return [q for q in questions if q.strip()]
    
# Concrete class for Developer Persona Strategy    
class DeveloperPersonaStrategy(PersonaStrategy):
    def generate_questions(self, chat_client: AzureOpenAI, config: ApiConfiguration, num_questions: int, logger: logging.Logger) -> List[str]:
        """
    Generates a list of questions based on the developer persona.

    Args:
        chat_client (AzureOpenAI): An instance of the AzureOpenAI class.
        config (ApiConfiguration): An instance of the ApiConfiguration class.
        num_questions (int): The number of questions to generate.
        logger (logging.Logger): An instance of the logging.Logger class.

    Returns:
        List[str]: A list of questions generated based on the developer persona.
        """
        return self._generate_questions(chat_client, config, DEVELOPER_PROMPT, num_questions, logger)

# Concrete class for Tester Persona Strategy
class TesterPersonaStrategy(PersonaStrategy):
    def generate_questions(self, chat_client: AzureOpenAI, config: ApiConfiguration, num_questions: int, logger: logging.Logger) -> List[str]:
        """
    Generates a list of questions based on the tester persona.

    Args:
        chat_client (AzureOpenAI): An instance of the AzureOpenAI class.
        config (ApiConfiguration): An instance of the ApiConfiguration class.
        num_questions (int): The number of questions to generate.
        logger (logging.Logger): An instance of the logging.Logger class.

    Returns:
        List[str]: A list of questions generated based on the tester persona.
        """
        return self._generate_questions(chat_client, config, TESTER_PROMPT, num_questions, logger)

# Concrete class for Business Analyst Persona Strategy
class BusinessAnalystPersonaStrategy(PersonaStrategy):
    def generate_questions(self, chat_client: AzureOpenAI, config: ApiConfiguration, num_questions: int, logger: logging.Logger) -> List[str]:
        """
    Generates a list of questions based on the business analyst persona.

    Args:
        chat_client (AzureOpenAI): An instance of the AzureOpenAI class.
        config (ApiConfiguration): An instance of the ApiConfiguration class.
        num_questions (int): The number of questions to generate.
        logger (logging.Logger): An instance of the logging.Logger class.

    Returns:
        List[str]: A list of questions generated based on the business analyst persona.
        """
        return self._generate_questions(chat_client, config, BUSINESS_ANALYST_PROMPT, num_questions, logger)
****************************************

****************************************
BoxerEval\tests\ReadMe.Salon.md
****************************************
**BoxerDataTest_v1.py**

This code is designed to process questions through similarity embedding and to generate enriched questions using the Azure OpenAI API. 

The `configure_openai_for_azure` function initializes the Azure OpenAI client. The `TestResult` class is used to hold test results, which include the original question, enriched question, hit status, and relevance.

The `call_openai_chat` and `get_text_embedding` functions call the OpenAI API with retry logic using the `tenacity` library. 

The `cosine_similarity` function calculates similarity between vectors. The `generate_enriched_question` function generates enriched questions via the OpenAI API.

The `process_questions` function handles the evaluation of each question against processed question chunks, and the `read_processed_chunks` function reads JSON files containing these chunks. 

Finally, the `save_results` function writes the results to a file, and `run_tests` orchestrates the entire process.

**BoxerDataTest_v2.py**

This Python code facilitates question generation, similarity analysis, and evaluation in the context of AI-based applications using OpenAI's Azure services.

**Classes & Functions:**
- **`configure_openai_for_azure`**: Configures OpenAI for Azure.
- **`TestResult`**: Class for storing test results.
- **`call_openai_chat`**: Calls OpenAI API with retry logic.
- **`get_text_embedding`**: Retrieves text embeddings.
- **`cosine_similarity`**: Calculates cosine similarity between vectors.
- **`generate_enriched_question`**: Generates enriched questions using OpenAI API.
- **`process_questions`**: Processes test questions.
- **`read_processed_chunks`**: Reads processed JSON files containing pre-processed question chunks.
- **`save_results`**: Saves test results to a specified directory.
- **`run_tests`**: Orchestrates the entire testing sequence.

**BoxerDataTest_v3.py**

This module facilitates persona-based question generation and evaluation using OpenAI's Azure services. It imports standard libraries and third-party packages like Tenacity for retry logic and AzureOpenAI from OpenAI. 

Key components include:
- **ApiConfiguration**: Holds API settings.
- **TestResult**: Stores results for each test question.
- **configure_openai_for_azure**: Configures the OpenAI client.
- **call_openai_chat**: Handles API calls with retries.
- **get_text_embedding**: Fetches text embeddings.
- **cosine_similarity**: Computes similarity between vectors.
- **generate_enriched_question**: Produces enriched questions.
- **generate_follow_up_question** and **assess_follow_up_on_topic**: Handle follow-up question generation and assessment.
- **process_questions**, **read_processed_chunks**, and **save_results**: Manage question processing, reading processed data, and saving results.
- **run_tests**: The main function to execute tests utilizing generated or provided questions.

**BoxerDataTest_v4.py**

This Python module handles persona-based question generation, similarity embedding, and evaluation. 

### Key Classes and Functions:

- **`configure_openai_for_azure`**: Configures and returns an AzureOpenAI client.
- **`TestResult` class**: Stores the results of the test, including question, enriched question summary, hit status, hit relevance, follow-up question, and Gemini evaluation.
- **`call_openai_chat`**: Calls the OpenAI API with retry logic to manage session consistency and fault tolerance.
- **`get_text_embedding`**: Retrieves text embedding for a given text using the OpenAI API.
- **`cosine_similarity`**: Computes cosine similarity between two vectors.
- **`generate_enriched_question`** and **`generate_follow_up_question`**: Generates enriched questions and follow-up questions using OpenAI API.
- **`assess_follow_up_on_topic`**: Determines if the follow-up question is relevant to AI.
- **`process_questions`**: Processes test questions, assesses relevance, and evaluates the enriched answers.
- **`read_processed_chunks`**: Reads and processes JSON data from a specified directory.
- **`save_results`**: Saves the processed question results to a JSON file.
- **`run_tests`**: Main test function that initiates the Azure OpenAI client, generates questions using a persona strategy, processes them, and saves the results.

### Constants and Logging:
Constants manage settings like similarity thresholds and prompts. Logging is set up for debugging and tracking the process.

**BoxerDataTest_v5.py**

The code is a suite for generating and evaluating AI-related questions using OpenAI's API, integrated with Azure.

Key Classes:
1. **TestResult**: Metadata storage for questions, follow-ups, and evaluations.
2. **ApiConfiguration**: Configures AzureOpenAI client.
3. **GeminiEvaluator**: Assess follow-up question relevance.

Important Functions:
1. **configure_openai_for_azure**: Sets up Azure OpenAI client.
2. **call_openai_chat**: Handles API calls with retries.
3. **get_text_embedding**: Fetches text embeddings.
4. **cosine_similarity**: Computes similarity between vectors.
5. **generate_enriched_question**: Creates enriched questions.
6. **generate_follow_up_question**: Generates follow-up questions.
7. **assess_follow_up_on_topic**: Validates follow-up relevance.
8. **process_questions**: Main routine for question processing and evaluation.
9. **read_processed_chunks**: Reads pre-processed question sets.
10. **save_results**: Writes results to JSON.

### Flow:
1. OpenAI clients for chat/embedding initialization.
2. Process and enrich questions based on strategies.
3. Evaluate relevance and save outputs.

**GeminiEvaluator.py**

**GeminiEvaluator Module**

**Overview:**
The GeminiEvaluator module evaluates the quality of summaries generated by large language models (LLM) using Google's Gemini model. It assesses how well summaries encapsulate core information from the original content and address user queries.

**Key Class:**
- **GeminiEvaluator Class:** This class initiates the evaluation process using Gemini's API. It authenticates using an API key and sets instructions for evaluating summaries.

**Key Function:**
- **evaluate(original_content: str, summary: str) -> str:** This function takes original content and a generated summary as inputs. It uses Gemini LLM to score the summary on a scale of 1 (poor) to 4 (excellent).

**Dependencies:**
- google.generativeai
- os

**PersonaStrategy.py**

This module uses the Strategy pattern for generating persona-specific questions using LLM (large language models) technology and Azure OpenAI services.

The PersonaStrategy abstract class defines the interface for creating persona-based question generation strategies. Concrete implementations include DeveloperPersonaStrategy, TesterPersonaStrategy, and BusinessAnalystPersonaStrategy, each generating questions from their respective perspectives.

The _generate_questions method is a helper function for generating questions using specific prompts and handles calling the OpenAI chat model. Error handling and logging mechanisms are included for robustness.

Key classes:
- PersonaStrategy (ABC)
- DeveloperPersonaStrategy
- TesterPersonaStrategy
- BusinessAnalystPersonaStrategy

**run_BoxerDataTest.py**

This module is designed to run tests for LLM-related questions using the Boxer Data Testing framework. It handles the execution of tests, supports different test implementation versions (v1/v2), and manages file operations for test inputs and outputs.

Key functions include loading and processing test questions, configuring test environments and directories, executing tests, and handling logging.

Key classes and functions:
- `run_tests` from `BoxerDataTest_v1 (or v2)`
- `ApiConfiguration` from `common.ApiConfiguration`

The script sets up logging and directories, lists predefined questions about LLMs, and executes tests while handling potential errors.

**TestRunner.py**

**TestRunner Module**

The `TestRunner` module for running automated tests on LLM-based systems supports static question testing and persona-based testing using Developer, Tester, and Business Analyst strategies. This module leverages Azure OpenAI clients for chat and embedding, configurable test output directories, logging, error handling, and directory management.

**Classes and Functions**
1. **TestRunner**: Main function to run tests based on user choice via a command-line interface, handling API configurations, directory management, and test execution.
2. **run_tests, call_openai_chat, configure_openai_for_azure**: Imported from `BoxerDataTest_v5` for executing tests.
3. **ApiConfiguration**: Manages API configurations.
4. **PersonaStrategy implementations**: DeveloperPersonaStrategy, TesterPersonaStrategy, BusinessAnalystPersonaStrategy for persona-based test execution.

### Other Relevant Points
- Logging is set up for test execution tracking.
- Ensures test output directory exists or creates it.
- Prompts users to choose testing modes and executes corresponding test strategies.
****************************************

****************************************
BoxerEval\tests\run_BoxerDataTest.py
****************************************
"""
Test runner module for the Boxer Data Testing framework.

This module orchestrates the execution of tests for LLM-related questions using the Boxer
testing framework. It provides functionality to:
- Load and process a predefined set of LLM-related test questions
- Configure test environments and directories
- Execute tests using either v1 or v2 of the BoxerDataTest implementation
- Handle test outputs and logging

The module supports different versions of the test implementation (v1/v2) and manages
file system operations for test inputs and outputs.

Usage:
    Run this module directly to execute the full test suite with the configured
    questions and settings.

Dependencies:
    - BoxerDataTest_v1 or BoxerDataTest_v2
    - common.ApiConfiguration
"""

# Copyright (c) 2024 Braid Technologies Ltd


# Standard Library Imports
import os
import sys
import logging
from typing import List, Dict, Any

# Add the project root and scripts directory to the Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

# Local Imports
from BoxerDataTest_v1 import run_tests                           # use this for v1
# from BoxerDataTest_v2 import run_tests                             # use this for v2
from common.ApiConfiguration import ApiConfiguration

# Setup Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Define the list of questions
questions: List[str] = [
    'How are LLMs different from traditional AI models?',
    'What is a Large Language Model (LLM)?',
    'What is natural language processing (NLP)?',
    'What are prompt engineering techniques and how do they work?',
    'What is the difference between supervised, unsupervised, and reinforcement learning?',
    'How can LLMs be used for chatbots?',
    'What are the considerations for using LLMs in voice assistants?',
    "What are the pricing models for popular LLM services like OpenAI's GPT?",
    "How does OpenAI's GPT-4 compare to other models like Google's BERT?",
    "How do I use Hugging Face's Transformers library?",
    'How does NLP relate to LLMs?',
    'What are the methods for implementing sentiment analysis using LLMs?',
    'What are the computational requirements for training an LLM?',
    'How do I handle bias in training data?',
    'How can LLMs assist in language translation applications?',
    'What are the techniques for chaining LLM responses for complex tasks?',
    'What is the role of LLMs in automated code generation?',
    'What is the role of the Hugging Face Model Hub in working with LLMs?',
    'How can LLMs be used for content generation, such as blog posts or articles?',
    'How can LLMs be used for data extraction from unstructured text?',
    'How do I fine-tune a pre-trained LLM on my own dataset?',
    'How do I use TensorFlow or PyTorch with LLMs?',
    'What is transfer learning and how does it apply to LLMs?',
    'How do emerging models like GPT-4.5 or GPT-5 compare to GPT-4?',
    'How much data do I need to train or fine-tune an LLM effectively?',
    'How do I implement contextual understanding in my LLM-based application?',
    'What are some common use cases for LLMs in applications?',
    'How do LLMs process and generate text?',
    'What are the steps to create a question-answering system with an LLM?',
    'What are the latest advancements in LLM technology?',
    'What are the most popular LLMs available today (eg GPT-4, BERT, T5)?',
    'How are LLMs trained?',
    'What future applications and improvements are expected for LLMs?',
    'What are the uses of LLMs in customer service?',
    'What are the common issues faced when integrating LLMs?',
    'What datasets are commonly used for training LLMs?',
    'What are the best practices for scaling LLM infrastructure?',
    'How do I gather and use user feedback to improve my LLM-based application?',
    'What are the GDPR implications of using LLMs?',
    'How do LLMs work?',
    'What are the privacy concerns when using LLMs?',
    'What are the risks of using LLMs and how can I mitigate them?',
    'What are the key components of an LLM?',
    'How do I scale an LLM-based application to handle increased traffic?',
    'What is the process for deploying an LLM-based application?',
    'What are some common performance bottlenecks when using LLMs?',
    'How have other developers solved common problems with LLMs?',
    'How do I monitor and maintain an LLM-based application in production?',
    'How can I use LLMs for specific domain applications, like medical or legal?',
    'What metrics should I use to evaluate the performance of my LLM?',
    'How do I handle API rate limits when using a hosted LLM service?',
    'What are the best courses or tutorials for learning to use LLMs?',
    'How do I evaluate the performance of different LLMs?',
    'How can LLMs benefit the education sector?',
    'What cloud services are recommended for hosting LLM-based applications?',
    'How can I use an LLM to summarize text?',
    'How can I minimize the cost of API usage for LLMs?',
    'What techniques can I use to improve the accuracy of my LLM?',
    'What are the methods to evaluate the relevance of LLM responses?',
    'What are the legal implications of using LLMs in different industries?',
    'What are the ethical considerations when using LLMs in applications?',
    'How can I optimize the performance of an LLM in production?',
    'How can I personalize LLM interactions for individual users?',
    'How is the field of LLMs expected to evolve over the next 5 years?',
    'How often should I update or retrain my LLM?',
    'How do I measure the quality of the generated text?',
    'Can I use pre-trained models or do I need to train my own from scratch?',
    'How can I use load balancing with LLMs?',
    'How are LLMs used in the healthcare industry?',
    'What security measures should I implement when using LLMs?',
    'What are the best tools for annotating and preparing training data?',
    'How can I customize the behavior of an LLM to better fit my application?',
    'How can I contribute to the development of open-source LLM projects?',
    'What online communities and forums are best for learning about LLMs?',
    'What are the copyright considerations for content generated by LLMs?',
    'How do I manage version control for my LLM models?',
    'What are some successful case studies of LLM integration?',
    'What are the applications of LLMs in finance?',
    'What strategies can I use to make LLM responses more engaging?',
    'What libraries or frameworks are available for working with LLMs in Python?',
    'How can I use Docker to deploy LLM-based applications?',
    'What factors should I consider when choosing an LLM for my application?',
    'How do I estimate the cost of using an LLM in my application?',
    'What are the signs that my LLM needs retraining?',
    'What are the cost considerations when choosing between different LLM providers?',
    'How can I ensure that my LLM is not producing biased or harmful content?',
    'How do I integrate an LLM into my Python application?',
    'How can I ensure my use of LLMs complies with industry regulations?',
    'How do I manage user data responsibly in an LLM-based application?',
    'How do LLMs apply to the entertainment and media industry?',
    'How do I protect my LLM from adversarial attacks?',
    'How do I debug issues with LLM-generated content?',
    'How can I optimize the response time of an LLM in my application?',
    'How can I ensure secure communication between my application and the LLM API?',
    'How can I reduce the latency of LLM responses?',
    'How do I determine the size of the model I need?What are the trade-offs between smaller and larger models?',
    'What caching strategies can I use to improve LLM response times?',
    'How can I track and fix inaccuracies in LLM responses?',
    'What are the best practices for managing API keys and authentication?'
    ]

# Configuration setup
config = ApiConfiguration()
test_destination_dir = "D:/Braid Technologies/BraidTechnologiesRepo/WorkedExamples/BoxerTest/test output/"
source_dir = "D:/Braid Technologies/BraidTechnologiesRepo/WorkedExamples/BoxerTest/data/"

# Ensure the test output directory exists
try:
    os.makedirs(test_destination_dir, exist_ok=True)
    logger.info(f"Test output directory ensured at: {test_destination_dir}")
except OSError as e:
    logger.error(f"Failed to create test output directory: {e}")
    raise

# Run the tests with error handling
try:
    logger.info("Starting the test process...")
    run_tests(config, test_destination_dir, source_dir, questions)
    logger.info("Test process completed successfully.")
except Exception as e:
    logger.error(f"An error occurred during testing: {e}")
    raise
****************************************

****************************************
BoxerEval\tests\TestRunner.py
****************************************
"""
TestRunner Module

This module provides functionality for running automated tests on LLM-based systems.
It supports both static question testing and persona-based testing approaches using
different strategies (Developer, Tester, and Business Analyst personas).

The module handles:
- Configuration of Azure OpenAI clients for chat and embedding
- Test execution with configurable output directories
- Multiple testing modes through a command-line interface
- Logging of test execution and results
- Error handling and directory management

Dependencies:
    - BoxerDataTest_v5
    - common.ApiConfiguration
    - PersonaStrategy
    - openai

Usage:
    Run the script directly to start the interactive test runner:
    $ python TestRunner.py
"""

# Copyright (c) 2024 Braid Technologies Ltd

import logging
import os
import sys

# Set up logging to display information about the execution of the script

# Get the current directory (tests folder)
current_dir = os.path.dirname(os.path.abspath(__file__))
# Get the parent directory (BoxerTests root)
parent_dir = os.path.dirname(current_dir)
# Add the parent directory to the Python path
sys.path.insert(0, parent_dir)

# Import necessary modules and classes for running the tests
from BoxerDataTest_v5 import run_tests, call_openai_chat, configure_openai_for_azure
from common.ApiConfiguration import ApiConfiguration
from PersonaStrategy import DeveloperPersonaStrategy, TesterPersonaStrategy, BusinessAnalystPersonaStrategy
from openai import AzureOpenAI, OpenAIError, BadRequestError, APIConnectionError

# Setup Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def TestRunner():
    """
    Runs tests using the provided configuration, test destination directory, source directory, and questions.

    This script provides a command-line interface to run tests using the BoxerDataTest_v2 module.
    Depending on the user's choice, it can run static question tests or persona-based tests.

    Parameters:
        None

    Returns:
        None
    """
    
    # Initialize the API configuration
    config = ApiConfiguration()

    # For running chat completions tests
    chat_client = configure_openai_for_azure(config, "chat")
    
    # For running embeddings tests
    embedding_client = configure_openai_for_azure(config, "embedding")

    # Define the directories for test output and data sources
    test_destination_dir = "D:/Braid Technologies/BraidTechnologiesRepo/WorkedExamples/BoxerTest/test output/"
    source_dir = "D:/Braid Technologies/BraidTechnologiesRepo/WorkedExamples/BoxerTest/data/"

    try:
        # Ensure the test output directory exists, create if it doesn't
        os.makedirs(test_destination_dir, exist_ok=True)
        logger.info(f"Test output directory ensured at: {test_destination_dir}")
    except OSError as e:
        # Log an error if the directory cannot be created
        logger.error(f"Failed to create test output directory: {e}")
        raise

    # Provide the user with options to choose the test mode
    print("Choose a test mode:")
    print("1. Static Questions")
    print("2. Developer Persona")
    print("3. Tester Persona")
    print("4. Business Analyst Persona")
    choice = input("Enter your choice: ")

    # Run tests based on the user's choice
    if choice == '1':
        questions = [
            'How are LLMs different from traditional AI models?',
            'What is a Large Language Model (LLM)?',
            'What is natural language processing (NLP)?',
            'What are prompt engineering techniques and how do they work?',
            'What is the difference between supervised, unsupervised, and reinforcement learning?',
            'How can LLMs be used for chatbots?',
            'What are the considerations for using LLMs in voice assistants?',
            "What are the pricing models for popular LLM services like OpenAI's GPT?",
            "How does OpenAI's GPT-4 compare to other models like Google's BERT?",
            "How do I use Hugging Face's Transformers library?",
            'How does NLP relate to LLMs?',
            'What are the methods for implementing sentiment analysis using LLMs?',
            'What are the computational requirements for training an LLM?',
            'How do I handle bias in training data?',
            'How can LLMs assist in language translation applications?',
            'What are the techniques for chaining LLM responses for complex tasks?',
            'What is the role of LLMs in automated code generation?',
            'What is the role of the Hugging Face Model Hub in working with LLMs?',
            'How can LLMs be used for content generation, such as blog posts or articles?',
            'How can LLMs be used for data extraction from unstructured text?',
            'How do I fine-tune a pre-trained LLM on my own dataset?',
            'How do I use TensorFlow or PyTorch with LLMs?',
            'What is transfer learning and how does it apply to LLMs?',
            'How do emerging models like GPT-4.5 or GPT-5 compare to GPT-4?',
            'How much data do I need to train or fine-tune an LLM effectively?',
            'How do I implement contextual understanding in my LLM-based application?',
            'What are some common use cases for LLMs in applications?',
            'How do LLMs process and generate text?',
            'What are the steps to create a question-answering system with an LLM?',
            'What are the latest advancements in LLM technology?',
            'What are the most popular LLMs available today (eg GPT-4, BERT, T5)?',
            'How are LLMs trained?',
            'What future applications and improvements are expected for LLMs?',
            'What are the uses of LLMs in customer service?',
            'What are the common issues faced when integrating LLMs?',
            'What datasets are commonly used for training LLMs?',
            'What are the best practices for scaling LLM infrastructure?',
            'How do I gather and use user feedback to improve my LLM-based application?',
            'What are the GDPR implications of using LLMs?',
            'How do LLMs work?',
            'What are the privacy concerns when using LLMs?',
            'What are the risks of using LLMs and how can I mitigate them?',
            'What are the key components of an LLM?',
            'How do I scale an LLM-based application to handle increased traffic?',
            'What is the process for deploying an LLM-based application?',
            'What are some common performance bottlenecks when using LLMs?',
            'How have other developers solved common problems with LLMs?',
            'How do I monitor and maintain an LLM-based application in production?',
            'How can I use LLMs for specific domain applications, like medical or legal?',
            'What metrics should I use to evaluate the performance of my LLM?',
            'How do I handle API rate limits when using a hosted LLM service?',
            'What are the best courses or tutorials for learning to use LLMs?',
            'How do I evaluate the performance of different LLMs?',
            'How can LLMs benefit the education sector?',
            'What cloud services are recommended for hosting LLM-based applications?',
            'How can I use an LLM to summarize text?',
            'How can I minimize the cost of API usage for LLMs?',
            'What techniques can I use to improve the accuracy of my LLM?',
            'What are the methods to evaluate the relevance of LLM responses?',
            'What are the legal implications of using LLMs in different industries?',
            'What are the ethical considerations when using LLMs in applications?',
            'How can I optimize the performance of an LLM in production?',
            'How can I personalize LLM interactions for individual users?',
            'How is the field of LLMs expected to evolve over the next 5 years?',
            'How often should I update or retrain my LLM?',
            'How do I measure the quality of the generated text?',
            'Can I use pre-trained models or do I need to train my own from scratch?',
            'How can I use load balancing with LLMs?',
            'How are LLMs used in the healthcare industry?',
            'What security measures should I implement when using LLMs?',
            'What are the best tools for annotating and preparing training data?',
            'How can I customize the behavior of an LLM to better fit my application?',
            'How can I contribute to the development of open-source LLM projects?',
            'What online communities and forums are best for learning about LLMs?',
            'What are the copyright considerations for content generated by LLMs?',
            'How do I manage version control for my LLM models?',
            'What are some successful case studies of LLM integration?',
            'What are the applications of LLMs in finance?',
            'What strategies can I use to make LLM responses more engaging?',
            'What libraries or frameworks are available for working with LLMs in Python?',
            'How can I use Docker to deploy LLM-based applications?',
            'What factors should I consider when choosing an LLM for my application?',
            'How do I estimate the cost of using an LLM in my application?',
            'What are the signs that my LLM needs retraining?',
            'What are the cost considerations when choosing between different LLM providers?',
            'How can I ensure that my LLM is not producing biased or harmful content?',
            'How do I integrate an LLM into my Python application?',
            'How can I ensure my use of LLMs complies with industry regulations?',
            'How do I manage user data responsibly in an LLM-based application?',
            'How do LLMs apply to the entertainment and media industry?',
            'How do I protect my LLM from adversarial attacks?',
            'How do I debug issues with LLM-generated content?',
            'How can I optimize the response time of an LLM in my application?',
            'How can I ensure secure communication between my application and the LLM API?',
            'How can I reduce the latency of LLM responses?',
            'How do I determine the size of the model I need?What are the trade-offs between smaller and larger models?',
            'What caching strategies can I use to improve LLM response times?',
            'How can I track and fix inaccuracies in LLM responses?',
            'What are the best practices for managing API keys and authentication?'
        ]
        run_tests(config, test_destination_dir, source_dir, questions=questions)
        
    elif choice == '2':
        # Developer persona-based testing
        strategy = DeveloperPersonaStrategy()
        run_tests(config, test_destination_dir, source_dir, persona_strategy=strategy)

    elif choice == '3':
        # Tester persona-based testing
        strategy = TesterPersonaStrategy()
        run_tests(config, test_destination_dir, source_dir, persona_strategy=strategy)

    elif choice == '4':
        # Business analyst persona-based testing
        strategy = BusinessAnalystPersonaStrategy()
        run_tests(config, test_destination_dir, source_dir, persona_strategy=strategy)

    else:
        # Handle invalid input
        print("Invalid choice. Exiting.")
        return


if __name__ == "__main__":
    # Run the TestRunner function if the script is executed as the main program
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    try:
        TestRunner()
    except Exception as e:
        # Log any exceptions that occur during the test execution
        logger.error(f"An error occurred during testing: {e}")
        raise
****************************************

****************************************
Cascade\dist\tsconfig.tsbuildinfo
****************************************
{"root":["../src/content.ts"],"version":"5.7.2"}
****************************************

****************************************
Cascade\src\content.ts
****************************************
/*
@module Cascade/src/content.ts

## Overview
This TypeScript module serves as a content script for a Chrome extension that performs web scraping, text summarization, and content classification. It runs in the context of web pages and communicates with both the extension's background script and an external API service.

## Key Features
- Web scraping of text content from various HTML elements (paragraphs, headers, and divs)
- Progressive text summarization with visual feedback
- Content classification into predefined categories
- Error handling for unhandled promise rejections
- Rate limiting and text length restrictions
- Message passing between extension components

## Main Components

### Global Variables
- `haveStartedScrape`: Boolean flag to prevent concurrent scraping operations
- External declarations for `artoo`, `chrome`, and `axios` APIs

### Key Functions
1. `suppressUnhandledPromiseRejection(event)`
   - Handles unhandled promise rejections
   - Resets scraping state
   - Sends error messages to the background script

2. `startScrape(key)`
   - Main scraping function that orchestrates the entire process
   - Implements progressive feedback for long-running operations
   - Manages API calls for summarization and classification
   - Handles text extraction with fallback strategies
   - Enforces text length limits (100KB)

### Message Handling
- Listens for messages from the extension's popup
- Responds to "Key" type messages to initiate scraping
- Prevents concurrent scraping operations

## API Integration
Communicates with external API endpoints:
- `/api/summarize` - Text summarization
- `/api/classify` - Content classification into categories (Business, Technology, Politics, Health, Sport)

## Error Handling
- Comprehensive error handling for API calls
- Graceful degradation when scraping fails
- User feedback for all error states
- Prevention of concurrent operations

## Dependencies
- Artoo.js for web scraping
- Axios for HTTP requests
- Chrome Extension APIs for message passing

*/
declare var artoo: any;
declare var chrome: any;
declare var axios: any;

let haveStartedScrape = false;

/**
 * Function to handle unhandled promise rejections by logging a warning message,
 * resetting a flag 'haveStartedScrape' to false, and sending error messages to the background script.
 * Also prevents the default handling of the rejection event.
 * 
 * @param event - The PromiseRejectionEvent object containing information about the unhandled promise rejection.
 */
function suppressUnhandledPromiseRejection (event: PromiseRejectionEvent) {
   console.warn(`Unhandled promise rejection: ${event.reason}`); 
 
   haveStartedScrape = false;

   chrome.runtime.sendMessage({type: "Summary", text: "Sorry, we encountered an error reading this page."}); 
   chrome.runtime.sendMessage({type: "Classification", text: "Sorry, we encountered an error reading this page."}); 

   // Prevent the default handling (such as outputting the
   // error to the console)
   event.preventDefault();
}


/**
 * Function that performs a series of actions to summarize and classify text content.
 * It periodically sends messages to the Chrome runtime for summarization and classification progress.
 * Retrieves text content from the webpage, summarizes it using an external API, and then classifies the summary.
 * Utilizes internal organization modules for scraping, summarization, and classification.
 * @param key - A string key used for internal operations.
 */
function startScrape (key: string) : void {

    let NN = 1024*100; // we only have an 8k buffer, 100k string is 12 calls to LLM then another to summarise that. 
    let haveSummary = false;
    let baseSummaryText = "Summarising ...";
    let haveClassification = false;
    let baseClassificationText = "Classifying ...";
    let allText = "";

    // This interval loop sends progress messages 
    let interval = setInterval (() => {

      if (!haveSummary || !haveClassification) {

         if (!haveSummary) {
            baseSummaryText = baseSummaryText + ".";
            chrome.runtime.sendMessage({type: "Summary", text: baseSummaryText});       
         }

         if (!haveClassification) {
            baseClassificationText = baseClassificationText + ".";
            chrome.runtime.sendMessage({type: "Classification", text: baseClassificationText});       
         }

      }
      else {
         clearInterval (interval);
      }
    }, 1000);

    // This timeout does the actual scrape  
    setTimeout (() => {

      try {
         window.addEventListener("unhandledrejection", suppressUnhandledPromiseRejection);

         // First try to get all plain text, if that doesnt work, get the headers
         // If that doesnt work, scarape all divs (like 'the guardian' website)
         var scraped = artoo.scrape('p', 'text');
         if (scraped.length === 0) {
            for (var i = 0; i < 6; i++) {
               scraped = scraped = artoo.scrape('h' + i.toString(), 'text');
            }
         }
         if (scraped.length === 0) {
            scraped = artoo.scrape('div', 'text');
         }       
      
         allText = scraped.join(' \n');

         if (allText.length > NN) 
            allText = allText.substring(0, NN);

         window.removeEventListener("unhandledrejection", suppressUnhandledPromiseRejection);         
      }
      catch {
         window.removeEventListener("unhandledrejection", suppressUnhandledPromiseRejection);          
         allText = "";
      }

      var summarizeQuery = 'https://braid-api.azurewebsites.net/api/summarize?session=' + key.toString();
      var classifyQuery = 'https://braid-api.azurewebsites.net/api/classify?session=' + key.toString();

      axios.post(summarizeQuery, {
         request: {
            text: allText
         },
         headers: {
            'Content-Type': 'application/json'
         }
      }).then ((summaryRes: any) => {
         haveSummary = true;          
         if (summaryRes.status === 200) {
            chrome.runtime.sendMessage({type: "Summary", text: summaryRes.data.summary});
            var classifications = ["Business", "Technology", "Politics", "Health", "Sport"];

            axios.post(classifyQuery, {
               request: {
                  text: summaryRes.data.summary,
                  classifications: classifications
               },
               headers: {
                  'Content-Type': 'application/json'
               }
            }).then ((classifyRes: any) => {
               haveClassification = true;          
               if (classifyRes.status === 200) {
                  chrome.runtime.sendMessage({type: "Classification", text: classifyRes.data.classification});
               } 
               else {
                  chrome.runtime.sendMessage({type: "Classification", text: "Sorry, could not fetch a classification from the Waterfall server."}); 
               }
               // whenever we finish scraping - either successfully or a fail - we allow the user to start another one
               haveStartedScrape = false;
            })
            .catch ((e : any) => {     
               haveClassification = true;  
               console.error (e);   
               chrome.runtime.sendMessage({type: "Classification", text: "Sorry, could not fetch a classification from the Waterfall server."});  
               // whenever we finish scraping - either successfully or a fail - we allow the user to start another one
               haveStartedScrape = false;

            });        
         } 
         else {
            haveSummary = true;  
            haveClassification = true;   
            chrome.runtime.sendMessage({type: "Summary", text: "Sorry, could not fetch a summary from the Waterfall server."}); 
            chrome.runtime.sendMessage({type: "Classification", text: "Sorry, could not fetch a classification from the Waterfall server."}); 
            // whenever we finish scraping - either successfully or a fail - we allow the user to start another one
            haveStartedScrape = false;

         }
      })
      .catch ((e: any) => {     
         haveSummary = true;  
         haveClassification = true;
         console.error (e);   
         chrome.runtime.sendMessage({type: "Summary", text: "Sorry, could not fetch a summary from the Waterfall server."});                 
         chrome.runtime.sendMessage({type: "Classification", text: "Sorry, could not fetch a classification from the Waterfall server."}); 
         // whenever we finish scraping - either successfully or a fail - we allow the user to start another one
         haveStartedScrape = false;

      });   

    }, 500);

}


// Listen to messages from the popup.js script 
chrome.runtime.onMessage.addListener(function (message: any) {
	
   console.log ("Got message");   

   if (message.type === "Key" && !haveStartedScrape) {
      console.log ("Starting scrape");
      haveStartedScrape = true;
      startScrape (message.text);
   }
});    

console.log ("Content script loaded");

//startScrape ("49b65194-26e1-4041-ab11-4078229f478a");
****************************************

****************************************
Cascade\src\ReadMe.Salon.md
****************************************
**content.ts**

The module `Cascade/src/content.ts` is a TypeScript script for a Chrome extension focused on web scraping, text summarization, and content classification.

**Global Variables:**
- `haveStartedScrape` prevents concurrent scraping operations.
- External integrations: `artoo`, `chrome`, `axios`.

**Key Functions:**
1. `suppressUnhandledPromiseRejection(event)`: Handles unhandled promise rejections, resets scraping state, and sends error messages.
2. `startScrape(key)`: Manages the entire scraping, summarization, and classification process, utilizing web scraping for text extraction, enforcing text length limits, and communicating with external summarize and classify APIs.

**Message Handling:**
- Listens for messages to initiate scraping.
- Prevents concurrent operations for efficiency and stability.

**Error Handling:**
- Comprehensive error handling for API and operational failures with user feedback.

**Dependencies:**
- Uses Artoo.js for web scraping, Axios for HTTP requests, and Chrome Extension APIs for communication.
****************************************

****************************************
CommonPy\src\chunk_repository_api.py
****************************************
'''API to store data in the Chunk table of the Braid Apis '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import logging
import datetime
import json
import requests
from requests.adapters import HTTPAdapter, Retry

from .request_utilities import request_timeout
from .storable_types import IStorableQuerySpec
from .chunk_repository_api_types import IStoredChunk, IStoredEmbedding, IStoredTextRendering
from .type_utilities import safe_dict_to_object, safe_cast

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)

SESSION_KEY = os.environ['SessionKey']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}

waterfall_application_name = 'Waterfall'
boxer_application_name = 'Boxer'
chunk_class_name = 'Chunk'
chunk_schema_version = '1'

class ChunkRepository:
    '''
    Class providing load, save, and existence check for files in the Braid Cosmos database.
    '''

    def __init__(self):

        self.session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[500, 502, 503, 504])
        self.session.mount('https://', HTTPAdapter(max_retries=retries))

        models_url = f'https://braid-api.azurewebsites.net/api/EnumerateModels?session={
        #models_url = f'http://localhost:7071/api/EnumerateModels?session={
            SESSION_KEY}'
        json_input = {
            'request': ''
        }

        response = self.session.post(
            models_url, json=json_input, headers=headers, timeout=request_timeout)

        if response.status_code == 200:
            data = response.json()
            self.default_model = data['defaultId']
            self.default_embedding_model = data['defaultEmbeddingId']

        else:
            raise RuntimeError('Error returned from API:' + response.text)

    def save(self, chunk: IStoredChunk) -> bool:
        '''
        Save the provided item to the database.

        Parameters:
           functional_key (str): functionalKey to use for the record
           chunk (IStoredChunk): The content to be saved.
        '''
        logger.debug('Saving: %s', chunk.id)

        utc_time = datetime.datetime.now(datetime.timezone.utc)
        utc_time_string = utc_time.strftime('%Y-%m-%d %H:%M:%S %Z')

        chunk.amended = utc_time_string

        # we need to turn embedded objects into JSON by converting to dictionaries
        chunk_as_json = IStoredChunk(chunk)
        if chunk.storedEmbedding:
            chunk_as_json.storedEmbedding = chunk.storedEmbedding.__dict__
        if chunk.storedTitle:
            chunk_as_json.storedTitle = chunk.storedTitle.__dict__
        if chunk.storedSummary:
            chunk_as_json.storedSummary = chunk.storedSummary.__dict__

        chunk_url = f'https://braid-api.azurewebsites.net/api/SaveChunk?session={
        #chunk_url = f'http://localhost:7071/api/SaveChunk?session={
            SESSION_KEY}'
        json_input = {
            'request': chunk_as_json.__dict__
        }

        response = self.session.post(
            chunk_url, json=json_input, 
            headers=headers, timeout=request_timeout)

        if response.status_code == 200:
            logger.debug('Saved: %s', chunk.id)
            return True

        logger.debug('failed save: %s', chunk.id)
        return False

    def find(self, functional_key: str) -> IStoredChunk:
        '''
        Load content from the database based on the provided context and functional key.
        If the file exists in the output location, its contents are read and returned as a string.
        If the record is not found, return None

        Parameters:
           functional_key (str): functionalKey to use for the record

        Returns:
           item (IStoredChunk): The loaded content or None
        '''

        spec: IStorableQuerySpec = IStorableQuerySpec()
        spec.id = None
        spec.functionalSearchKey = functional_key
        logger.debug('Finding: %s', functional_key)

        chunk_url = f'https://braid-api.azurewebsites.net/api/FindChunk?session={
        #chunk_url = f'http://localhost:7071/api/FindChunk?session={
            SESSION_KEY}'
        json_input = {
            'request': spec.__dict__
        }

        response = self.session.post(
            chunk_url, json=json_input, 
            headers=headers, timeout=request_timeout)

        if response.status_code == 200:

            response_json = json.loads(response.text)

            # Convert the main class and nested classes from JSON to Python classes
            summary_obj = safe_dict_to_object(response_json['storedSummary'])
            safe_summary = safe_cast(summary_obj, IStoredTextRendering)

            title_obj = safe_dict_to_object(response_json['storedTitle'])
            safe_title = safe_cast(title_obj, IStoredTextRendering)

            embedding_obj = safe_dict_to_object(
                response_json['storedEmbedding'])
            safe_embedding = safe_cast(embedding_obj, IStoredEmbedding)

            # Glue them together into one Python class
            response_json['storedEmbedding'] = safe_embedding
            response_json['storedSummary'] = safe_summary
            response_json['storedTitle'] = safe_title

            response_obj = safe_dict_to_object(response_json)
            safe_response: IStoredChunk = safe_cast(response_obj, IStoredChunk)

            logger.debug('Found: %s', functional_key)
            return safe_response

        logger.debug('Failed to find: %s', functional_key)
        return None

    def load(self, record_id: str) -> IStoredChunk:
        '''
        Load content from the database based on the provided context and key.
        If the file exists in the output location, its contents are read and returned as a string.
        If the record is not found, return None

        Parameters:
           record_id (str): key to use for the record

        Returns:
           item (IStoredChunk): The loaded content or None
        '''

        spec: IStorableQuerySpec = IStorableQuerySpec()
        spec.id = record_id
        spec.functionalSearchKey = None
        logger.debug('Finding: %s', record_id)

        chunk_url = f'https://braid-api.azurewebsites.net/api/FindChunk?session={
        #chunk_url = f'http://localhost:7071/api/GetChunk?session={
            SESSION_KEY}'
        json_input = {
            'request': spec.__dict__
        }

        response = self.session.post(
            chunk_url, json=json_input, 
            headers=headers, timeout=request_timeout)

        if response.status_code == 200:

            response_json = json.loads(response.text)

            # Convert the main class and nested classes from JSON dictionaries to Python classes
            response_obj = safe_dict_to_object(response_json)
            safe_response: IStoredChunk = safe_cast(response_obj, IStoredChunk)

            summary_obj = safe_dict_to_object(response_json['storedSummary'])
            safe_summary = safe_cast(summary_obj, IStoredTextRendering)

            embedding_obj = safe_dict_to_object(
                response_json['storedEmbedding'])
            safe_embedding = safe_cast(embedding_obj, IStoredEmbedding)

            # Glue them together into one Python class
            safe_response.storedEmbedding = safe_embedding
            safe_response.storedSummary = safe_summary

            logger.debug('Loaded: %s', record_id)
            return safe_response

        logger.debug('Failed to load: %s', record_id)
        return None

    def remove(self, record_id: str) -> bool:
        '''
        Removes a record with the specified key from database

        Parameters:
           id (str): primary key to use for the record

        Returns:
           bool: True if the record is removed, False otherwise.
        '''
        spec: IStorableQuerySpec = IStorableQuerySpec()
        spec.id = record_id
        spec.functionalSearchKey = None
        logger.debug('Removing: %s', id)

        chunk_url = f'https://braid-api.azurewebsites.net/api/FindChunk?session={
        #chunk_url = f'http://localhost:7071/api/RemoveChunk?session={
            SESSION_KEY}'
        json_input = {
            'request': spec.__dict__
        }

        response = self.session.post(
            chunk_url, json=json_input, 
            headers=headers,
            timeout=request_timeout)

        if response.status_code == 200:
            logger.debug('Removed: %s', record_id)
            return True

        logger.debug('Failed to remove: %s', record_id)
        return False

    def exists(self, functional_key: str) -> bool:
        '''
        Checks if a record with the specified key and context exists in the database

        Parameters:
           functional_key (str): functionalKey to use for the record

        Returns:
           bool: True if the record exists, False otherwise.
        '''
        spec: IStorableQuerySpec = IStorableQuerySpec()
        spec.id = None
        spec.functionalSearchKey = functional_key
        logger.debug('Checking existence of: %s', functional_key)

        chunk_url = f'https://braid-api.azurewebsites.net/api/FindChunk?session={
        #chunk_url = f'http://localhost:7071/api/FindChunk?session={
            SESSION_KEY}'
        json_input = {
            'request': spec.__dict__
        }

        response = self.session.post(
            chunk_url, json=json_input, headers=headers,
            timeout=request_timeout)

        if response.status_code == 200:
            logger.debug('Found: %s', functional_key)
            return True

        logger.debug('Failed to find: %s', functional_key)
        return False
****************************************

****************************************
CommonPy\src\chunk_repository_api_types.py
****************************************
"""
Defines several class structures for storing and querying
data related to embeddings and text renderings.

Classes:
    IStoredEmbedding: representing an embedding with a model ID
        and a list of float values.
    IStoredTextRendering: representing a text rendering with a
        model ID and text content.
    IStoredChunk: Inherits from IStorable, representing a chunk of data with
        additional attributes for functional key, parent chunk ID, original
        text, and related stored embeddings and text renderings.
    IStoredChunkQuerySpec: specifying query parameters for
        stored chunks, including a functional key.
"""
# Generated by ts2python version 0.7.5 on 2024-11-05 13:56:28.905808
# pylint: disable=invalid-name

from typing import Union, List
from .type_utilities import safe_cast
from .storable_types import IStorable


class IStoredEmbedding:
    """
    A TypedDict representing a stored embedding.

    Attributes:
       modelId (str): The identifier for the model associated with the embedding.
       embedding (List[float]): A list of float values representing the embedding.
    """
    modelId: str
    embedding: List[float]

    def __init__(self, other=None):
        if other:
            self.modelId = other.modelId
            self.embedding = other.embedding
        else:
            self.modelId = None
            self.embedding = None


class IStoredTextRendering:
    """
    A TypedDict representing a text rendering.

    Attributes:
       modelId (str): The identifier for the model associated with the text rendering.
       text (str): The content of the text rendering.
    """
    modelId: str
    text: str

    def __init__(self, other=None):
        if other:
            self.modelId = other.modelId
            self.text = other.text
        else:
            self.modelId = None
            self.text = None


def create_text_rendering(text: str, model: str) -> IStoredTextRendering:
    ''' Utility function to create a text rendering '''
    rendering: IStoredTextRendering = IStoredTextRendering()
    rendering.text = text
    rendering.modelId = model

    return rendering

def create_embedding(embedding: list[float], model: str) -> IStoredEmbedding:
    ''' Utility function to create an embedding '''
    stored_embedding: IStoredEmbedding = IStoredEmbedding()
    stored_embedding.embedding = embedding
    stored_embedding.modelId = model

    return stored_embedding


class IStoredChunk(IStorable):
    """
    Represents a stored chunk of data with various attributes.

    Attributes:
    parentChunkId (Union[str, None]): The ID of the parent chunk, if any.
    originalText (Union[str, None]): The original text content of the chunk.
    storedEmbedding (Union[IStoredEmbedding, None]): An optional stored embedding associated with the chunk.
    storedSummary (Union[IStoredTextRendering, None]): An optional stored summary text rendering.
    storedTitle (Union[IStoredTextRendering, None]): An optional stored title text rendering.
    url (Union[str, None]): web location
    relatedChunks (Union[List[str], None]): A list of IDs of related chunks, if any.
    """
    parentChunkId: Union[str, None]
    originalText: Union[str, None]
    storedEmbedding: Union[IStoredEmbedding, None]
    storedSummary: Union[IStoredTextRendering, None]
    storedTitle: Union[IStoredTextRendering, None]
    url: Union[str, None]
    relatedChunks: Union[List[str], None]

    def __init__(self, other=None):
        super().__init__(other)

        if other:
            self.parentChunkId = other.parentChunkId
            self.originalText = other.originalText
            self.storedEmbedding = safe_cast(
                other.storedEmbedding, IStoredEmbedding)
            self.storedSummary = safe_cast(
                other.storedSummary, IStoredTextRendering)
            self.storedTitle = safe_cast(
                other.storedTitle, IStoredTextRendering)
            if other.relatedChunks:
                self.relatedChunks = other.relatedChunks[:]
            else:
                self.relatedChunks = None
            self.url = other.url
        else:
            self.parentChunkId = None
            self.originalText = None
            self.storedEmbedding = None
            self.storedSummary = None
            self.storedTitle = None
            self.relatedChunks = None
            self.url = None
****************************************

****************************************
CommonPy\src\page_repository_api.py
****************************************
'''API to store data in the Page table of the Braid Apis '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import logging
import datetime
import requests
from requests.adapters import HTTPAdapter, Retry
import zlib
import base64

from .page_repository_api_types import IStoredPage

page_class_name = 'Page'
page_schema_version = '1'

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)

SESSION_KEY = os.environ['SessionKey']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}

waterfall_application_name = 'Waterfall'
boxer_application_name = 'Boxer'
chunk_class_name = 'Chunk'
chunk_schema_version = '1'


class PageRepository:
    '''
    Class providing save & load for Pages in the Braid Cosmos database.
    '''

    def __init__(self):

        self.session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[500, 502, 503, 504])
        self.session.mount('https://', HTTPAdapter(max_retries=retries))

    def save(self, page: IStoredPage) -> bool:
        '''
        Save the provided item to the database.

        Parameters:
           page (IStoredPage): The content to be saved.
        '''
        logger.debug('Saving: %s', page.id)

        utc_time = datetime.datetime.now(datetime.timezone.utc)
        utc_time_string = utc_time.strftime('%Y-%m-%d %H:%M:%S %Z')

        page.amended = utc_time_string

        page_url = f'https://braid-api.azurewebsites.net/api/SavePage?session={
        #page_url = f'http://localhost:7071/api/SavePage?session={
            SESSION_KEY}'
        json_input = {
            'request': page.__dict__
        }

        response = self.session.post(
            page_url, json=json_input, headers=headers)

        if response.status_code == 200:
            logger.debug('Saved: %s', page.id)
            return True

        logger.debug('failed save: %s', page.id)
        return False

    def load(self, record_id: str) -> str:
        '''
        Load content from the database based on the provided key.
        If the file exists in the output location, its contents are read and returned as a string.
        If the record is not found, return None

        Parameters:
           record_id (str): key to use for the record

        Returns:
           str - HTML for the page or None
        '''

        logger.debug('Finding: %s', record_id)

        page_url = f'https://braid-api.azurewebsites.net/api/GetPage?session={
        #page_url = f'http://localhost:7071/api/GetPage?session={
            SESSION_KEY}&id={record_id}'

        response = self.session.post(
            page_url, headers=headers)

        if response.status_code == 200:
            return response.text

        logger.debug('Failed to load: %s', record_id)
        return None

def compress_string(input_str: str) -> str:
    """Compress a string using deflate and encode in Base64.
    
    Parameters:
        input_str (str): The string to compress and encode.
        
    Returns:
        str: The compressed and base64-encoded string.
    """
    # Convert string to bytes using UTF-8 encoding
    data = input_str.encode('utf-8')
    # Compress the data
    compressed = zlib.compress(data)
    # Encode the compressed data in base64
    base64_encoded = base64.b64encode(compressed).decode('ascii')
    return base64_encoded

def read_file_to_string(file_path: str) -> str:
    """Read the contents of a file into a string using UTF-8 encoding.
    
    Parameters:
        file_path (str): Path to the file to read
        
    Returns:
        str: Contents of the file as a string
        
    Raises:
        FileNotFoundError: If the file doesn't exist
        IOError: If there's an error reading the file
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return file.read()
    except FileNotFoundError:
        logger.error(f"File not found: {file_path}")
        raise
    except IOError as e:
        logger.error(f"Error reading file {file_path}: {str(e)}")
        raise

def make_page_from_file(application_id: str,
                   context_id: str,
                   functional_search_key: str,
                   class_name: str,
                   schema_version: str,
                   page_id: str,
                   dir_name: str, file_name: str) -> IStoredPage:

    utc_time = datetime.datetime.now(datetime.timezone.utc)
    utc_time_string = utc_time.strftime('%Y-%m-%d %H:%M:%S %Z')

    html = read_file_to_string(os.path.join(dir_name, file_name))

    page: IStoredPage = IStoredPage()
    page.id = page_id
    page.applicationId = application_id
    page.contextId = context_id
    page.functionalSearchKey = functional_search_key
    page.userId = None
    page.created = utc_time_string
    page.amended = utc_time_string
    page.className = class_name
    page.schemaVersion = schema_version
    page.html = compress_string(html)

    return page
****************************************

****************************************
CommonPy\src\page_repository_api_types.py
****************************************
"""
Defines several class structures for storing and querying
data related to embeddings and text renderings.

Classes:
    IStoredPage: Inherits from IStorable, representing a chunk of data with
        an additional attributes for html.
"""

# Generated by ts2python version 0.7.5 on 2024-11-05 13:56:28.905808
# pylint: disable=invalid-name

from typing import Union
from .storable_types import IStorable

class IStoredPage(IStorable):
    """
    Represents a stored chunk of data with various attributes.

    Attributes:
    html (Union[str, None]): Html content of the page, if any.
    """
    html: Union[str, None]

    def __init__(self, other=None):
        super().__init__(other)

        if other:
            self.html = other.html
        else:
            self.html = None
****************************************

****************************************
CommonPy\src\ReadMe.Salon.md
****************************************
**chunk_repository_api.py**

The code defines an API for storing and managing data in the Chunk table of the Braid Apis. It includes importing necessary libraries such as `os`, `logging`, `datetime`, `json`, and `requests`.

Logging is set to the WARNING level to capture warnings and above. The `SESSION_KEY` is retrieved from the environment, and HTTP headers are defined for API requests.

The `ChunkRepository` class provides methods to interact with the Braid Cosmos database, such as `save`, `find`, `load`, `remove`, and `exists`. It uses the `requests` library for making HTTP requests, with retry logic for handling transient failures.

Important classes and functions:
- `ChunkRepository.__init__`
- `ChunkRepository.save`
- `ChunkRepository.find`
- `ChunkRepository.load`
- `ChunkRepository.remove`
- `ChunkRepository.exists`

**chunk_repository_api_types.py**

This code defines several classes and functions intended to store and manage data associated with embeddings and text renderings.

The `IStoredEmbedding` class stores an embedding with a model ID and a list of float values. It has an `__init__` method to initialize these properties.

The `IStoredTextRendering` class stores a text rendering with a model ID and text content. Similar to `IStoredEmbedding`, it includes an `__init__` method for initialization.

There are two utility functions: `create_text_rendering` creates an instance of `IStoredTextRendering`, and `create_embedding` creates an instance of `IStoredEmbedding`.

The `IStoredChunk` class inherits from `IStorable` and represents a chunk of data with various attributes, including parent chunk ID, original text, stored embedding, stored summaries and titles, a URL, and related chunk IDs, and initializes these properties in its `__init__` method.

**page_repository_api.py**

The code provides an API for storing data in the "Page" table of the Braid Apis, utilizing a `PageRepository` class.

The `PageRepository` class includes methods `save` and `load`. The `save` method saves the provided `IStoredPage` instance to the database, adding timestamps and generating the API URL dynamically. The `load` method retrieves content from the database based on a given record ID, returning the content if successful.

Utility functions `compress_string` and `read_file_to_string` are included to compress strings and read file contents respectively.

The `make_page_from_file` function generates an `IStoredPage` instance by reading HTML content from a file and applying necessary metadata.

Key classes and functions: `PageRepository`, `compress_string`, `read_file_to_string`, `make_page_from_file`.

**page_repository_api_types.py**

This code defines a class, `IStoredPage`, which inherits from `IStorable`.

### Key Points:
- **Class `IStoredPage`**: Represents a chunk of data that includes an optional HTML attribute.
- **Inheritance**: It inherits attributes and methods from the `IStorable` class.
- **Attributes**:
  - `html` (of type `Union[str, None]`): Holds HTML content of the page, if available, defaulting to `None`.
- **Constructor**: Initializes the `html` attribute from another `IStoredPage` object if provided; otherwise, sets `html` to `None`. 

### Dependencies:
- Uses `typing.Union` for type hinting.
- Imports `IStorable` from `storable_types`.

**storable_types.py**

The code defines several classes aimed at storing and querying data related to storable entities.

### Classes Defined:

#### IStorable
- A base class for storable entities with common attributes like `id`, `applicationId`, `contextId`, `functionalSearchKey`, `userId`, `created`, `amended`, `className`, and `schemaVersion`.
- The constructor allows for initializing these attributes either from an existing object or setting them to `None` by default.

#### IStorableQuerySpec
- A class for specifying query parameters for storables, including `id` and `functionalSearchKey`.
- The constructor permits initializing these attributes from another object or setting them to `None`.

#### IStorableOperationResult
- A class defining the result of a storable operation, represented by a boolean attribute `ok`.
- The constructor allows initializing the `ok` attribute from another object or setting it to `None` by default.

**type_utilities.py**

This module provides utilities to convert dictionaries into objects and safely cast values to specified types.

**Class: DictToObject**
- Converts a dictionary into an object by dynamically creating attributes for each key-value pair in the dictionary.
- `__init__` method initializes the object with the dictionary's key-value pairs as attributes.

**Function: safe_dict_to_object**
- Safely converts a dictionary to an object using the `DictToObject` class.
- Returns `None` or a specified default value if the conversion fails.

**Function: safe_cast**
- Attempts to cast a value to a specified type.
- Returns a default value if the casting fails.
****************************************

****************************************
CommonPy\src\request_utilities.py
****************************************
"""
Common functions and variables for HTTP requests
"""


request_timeout = 40
****************************************

****************************************
CommonPy\src\storable_types.py
****************************************
"""
Defines several class structures for storing and querying data.

Classes:
    IStorable: A base class with common attributes for storable entities,
        including identifiers, timestamps, and schema version.
"""
# Generated by ts2python version 0.7.5 on 2024-11-05 13:56:28.905808
# pylint: disable=invalid-name

from typing import Union

class IStorable:
    """
    A base class for storable entities with common attributes.

    Attributes:
     id (Union[str, None]): The unique identifier for the entity, which can be None.
     applicationId (str): The identifier for the application associated with the entity.
     contextId (Union[str, None]): The identifier for the context, which can be None.
     functionalSearchKey (str): A key used to identify the chunk functionally.  Can be None.
     userId (Union[str, None]): The identifier for the user, which can be None.
     created (datetime): The timestamp when the entity was created.
     amended (datetime): The timestamp when the entity was last modified.
     className (str): The name of the class.
     schemaVersion (str): The version of the schema used by the entity.
    """
    id: Union[str, None]
    applicationId: str
    contextId: Union[str, None]
    functionalSearchKey: Union[str, None]
    userId: Union[str, None]
    created: str
    amended: str
    className: str
    schemaVersion: str

    def __init__(self, other=None):
        if other:
            self.id = other.id
            self.applicationId = other.applicationId
            self.contextId = other.contextId
            self.functionalSearchKey = other.functionalSearchKey
            self.userId = other.userId
            self.created = other.created
            self.amended = other.amended
            self.className = other.className
            self.schemaVersion = other.schemaVersion
        else:
            self.id = None
            self.applicationId = None
            self.contextId = None
            self.functionalSearchKey = None
            self.userId = None
            self.created = None
            self.amended = None
            self.className = None
            self.schemaVersion = None

class IStorableQuerySpec:
    """
    A class for specifying query parameters for storables.

    Attributes:
     id (str): The primary key used to identify the chunk.
     functionalSearchKey (str) if id in None, functional key can be used.
    """
    id: str
    functionalSearchKey: str

    def __init__(self, other=None):
        if other:
            self.id = other.id
            self.functionalSearchKey = other.functionalSearchKey
        else:
            self.id = None
            self.functionalSearchKey = None


class IStorableOperationResult:
    """
    Defines the results of a storable operation - true or false.
    """

    ok: bool

    def __init__(self, other=None):
        if other:
            self.ok = other.ok
        else:
            self.ok = None
****************************************

****************************************
CommonPy\src\type_utilities.py
****************************************
"""
Utility to change a dictionary to an object - used in mapping from JSON back to object types after web requests
"""


class DictToObject:
    """
    Converts a dictionary into an object by setting attributes for each key-value pair.

    Attributes are dynamically created based on the dictionary's keys, allowing
    for easy access to the dictionary's data as object attributes.

    Parameters:
       dictionary (dict): The dictionary to be converted into an object.
    """

    def __init__(self, dictionary):
        if dictionary:
            for key, value in dictionary.items():
                setattr(self, key, value)


def safe_dict_to_object(val, default=None) -> object:
    """
    Safely converts a dictionary into an object by setting attributes for each key-value pair.

    Attributes are dynamically created based on the dictionary's keys, allowing
    for easy access to the dictionary's data as object attributes.

    Parameters:
       dictionary (dict): The dictionary to be converted into an object. If this is None, None is returned
    """

    obj = default

    try:
        if val:
           obj = DictToObject(val)
    except (ValueError, TypeError):
        return obj

    return obj


def safe_cast(val, to_type, default=None) -> object:
    """
    Safely casts a value to a specified type, returning a default value if casting fails.

    Parameters:
       val: The value to be cast.
       to_type: The type to which the value should be cast.
       default: The value to return if casting fails (default is None).

    Returns:
       The value cast to the specified type, or the default value if casting fails.
    """

    obj = default

    try:
        if val:        
           return to_type(val)
    except (ValueError, TypeError):
        return obj
****************************************

****************************************
CommonPy\test\chunk_repository_test.py
****************************************
''' Tests for the DB API '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import sys
import logging
import uuid
import datetime

from src.chunk_repository_api import ChunkRepository, IStoredChunk, IStoredEmbedding, IStoredTextRendering

test_root = os.path.dirname(__file__)
parent = os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

utc_time = datetime.datetime.now(datetime.timezone.utc)
utc_time_string = utc_time.strftime('%Y-%m-%d %H:%M:%S %Z')

embedding: IStoredEmbedding = IStoredEmbedding()
embedding.embedding = [1.0, 2.0]
embedding.modelId = 'MadeUpEmbeddingModel'

summary: IStoredTextRendering = IStoredTextRendering()
summary.text = 'Summary text'
summary.modelId = 'MadeUpModel'

title: IStoredTextRendering = IStoredTextRendering()
title.text = 'Title text'
title.modelId = 'MadeUpModel'

master_chunk: IStoredChunk = IStoredChunk()
master_chunk.id = str(uuid.uuid4())
master_chunk.applicationId = 'TestApplication'
master_chunk.contextId = 'TestContext'
master_chunk.functionalSearchKey = 'TestKey' + str(uuid.uuid4())
master_chunk.userId = None
master_chunk.created = utc_time_string
master_chunk.amended = utc_time_string
master_chunk.className = 'madeUpClass'
master_chunk.schemaVersion = '1'
master_chunk.parentChunkId = None
master_chunk.originalText = 'Original test'
master_chunk.storedEmbedding = embedding
master_chunk.storedSummary = summary
master_chunk.storedTitle = title
master_chunk.relatedChunks = [str(uuid.uuid4()), str(uuid.uuid4())]


def test_basic():
    ''' Test construction '''
    repository = ChunkRepository()
    assert repository  # If we get here without exceptions we are ok


def test_does_not_exist():
    ''' Test non-existence '''
    test_path = 'fail_test.html'

    repository = ChunkRepository()
    exists = repository.exists(test_path)

    assert not exists


def test_save():
    ''' Test save '''

    repository = ChunkRepository()
    saved = repository.save(master_chunk)

    assert saved


def test_save_exists():
    ''' Test save & then that it exists '''

    repository = ChunkRepository()
    saved = repository.save(master_chunk)

    exists = False

    if saved:
        exists = repository.exists(master_chunk.functionalSearchKey)

    assert saved
    assert exists


def test_save_find():
    ''' Test save & then that it can be loaded '''

    repository = ChunkRepository()
    saved = repository.save(master_chunk)

    loaded = False

    if saved:
        loaded = repository.find(master_chunk.functionalSearchKey)

    assert saved
    assert loaded
    assert loaded.storedEmbedding.embedding == master_chunk.storedEmbedding.embedding
    assert loaded.storedSummary.text == master_chunk.storedSummary.text
****************************************

****************************************
CommonPy\test\page_repository_test.py
****************************************
''' Tests for the DB API '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import sys
import logging
import uuid

from src.page_repository_api import (
    PageRepository, make_page_from_file)

test_root = os.path.dirname(__file__)
parent = os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

page = make_page_from_file('TestApplication', 
                           'TestContext', 
                           'TestKey' + str(uuid.uuid4()), 
                           'madeUpClass', 
                           '1', 
                           str(uuid.uuid4()),
                           test_root, 
                           'page_test.html')

def test_basic():
    ''' Test construction '''
    repository = PageRepository()
    assert repository  # If we get here without exceptions we are ok


def test_does_not_exist():
    ''' Test non-existence '''
    test_path = 'fail_test.html'

    repository = PageRepository()
    exists = repository.load(test_path)

    assert not exists


def test_save():
    ''' Test save '''

    repository = PageRepository()
    saved = repository.save(page)

    assert saved


def test_save_load():
    ''' Test save & then that it can be loaded '''

    repository = PageRepository()
    saved = repository.save(page)

    loaded = False

    if saved:
        loaded = repository.load(page.id)

    assert saved
    assert loaded
****************************************

****************************************
CommonTs\dist\tsconfig.tsbuildinfo
****************************************
{"fileNames":["../node_modules/typescript/lib/lib.es5.d.ts","../node_modules/typescript/lib/lib.es2015.d.ts","../node_modules/typescript/lib/lib.es2016.d.ts","../node_modules/typescript/lib/lib.es2017.d.ts","../node_modules/typescript/lib/lib.es2018.d.ts","../node_modules/typescript/lib/lib.es2019.d.ts","../node_modules/typescript/lib/lib.es2020.d.ts","../node_modules/typescript/lib/lib.es2021.d.ts","../node_modules/typescript/lib/lib.es2022.d.ts","../node_modules/typescript/lib/lib.dom.d.ts","../node_modules/typescript/lib/lib.es2015.core.d.ts","../node_modules/typescript/lib/lib.es2015.collection.d.ts","../node_modules/typescript/lib/lib.es2015.generator.d.ts","../node_modules/typescript/lib/lib.es2015.iterable.d.ts","../node_modules/typescript/lib/lib.es2015.promise.d.ts","../node_modules/typescript/lib/lib.es2015.proxy.d.ts","../node_modules/typescript/lib/lib.es2015.reflect.d.ts","../node_modules/typescript/lib/lib.es2015.symbol.d.ts","../node_modules/typescript/lib/lib.es2015.symbol.wellknown.d.ts","../node_modules/typescript/lib/lib.es2016.array.include.d.ts","../node_modules/typescript/lib/lib.es2016.intl.d.ts","../node_modules/typescript/lib/lib.es2017.arraybuffer.d.ts","../node_modules/typescript/lib/lib.es2017.date.d.ts","../node_modules/typescript/lib/lib.es2017.object.d.ts","../node_modules/typescript/lib/lib.es2017.sharedmemory.d.ts","../node_modules/typescript/lib/lib.es2017.string.d.ts","../node_modules/typescript/lib/lib.es2017.intl.d.ts","../node_modules/typescript/lib/lib.es2017.typedarrays.d.ts","../node_modules/typescript/lib/lib.es2018.asyncgenerator.d.ts","../node_modules/typescript/lib/lib.es2018.asynciterable.d.ts","../node_modules/typescript/lib/lib.es2018.intl.d.ts","../node_modules/typescript/lib/lib.es2018.promise.d.ts","../node_modules/typescript/lib/lib.es2018.regexp.d.ts","../node_modules/typescript/lib/lib.es2019.array.d.ts","../node_modules/typescript/lib/lib.es2019.object.d.ts","../node_modules/typescript/lib/lib.es2019.string.d.ts","../node_modules/typescript/lib/lib.es2019.symbol.d.ts","../node_modules/typescript/lib/lib.es2019.intl.d.ts","../node_modules/typescript/lib/lib.es2020.bigint.d.ts","../node_modules/typescript/lib/lib.es2020.date.d.ts","../node_modules/typescript/lib/lib.es2020.promise.d.ts","../node_modules/typescript/lib/lib.es2020.sharedmemory.d.ts","../node_modules/typescript/lib/lib.es2020.string.d.ts","../node_modules/typescript/lib/lib.es2020.symbol.wellknown.d.ts","../node_modules/typescript/lib/lib.es2020.intl.d.ts","../node_modules/typescript/lib/lib.es2020.number.d.ts","../node_modules/typescript/lib/lib.es2021.promise.d.ts","../node_modules/typescript/lib/lib.es2021.string.d.ts","../node_modules/typescript/lib/lib.es2021.weakref.d.ts","../node_modules/typescript/lib/lib.es2021.intl.d.ts","../node_modules/typescript/lib/lib.es2022.array.d.ts","../node_modules/typescript/lib/lib.es2022.error.d.ts","../node_modules/typescript/lib/lib.es2022.intl.d.ts","../node_modules/typescript/lib/lib.es2022.object.d.ts","../node_modules/typescript/lib/lib.es2022.string.d.ts","../node_modules/typescript/lib/lib.es2022.regexp.d.ts","../node_modules/typescript/lib/lib.decorators.d.ts","../node_modules/typescript/lib/lib.decorators.legacy.d.ts","../node_modules/axios/index.d.ts","../src/ienvironment.ts","../src/api.ts","../src/istorable.ts","../src/storablerepositoryapi.ts","../src/activityrepositoryapi.ts","../src/logging.ts","../src/errors.ts","../src/asserts.ts","../src/chunkapi.types.ts","../src/chunkrepositoryapi.types.ts","../src/chunkrepositoryapi.ts","../src/classifyapi.types.ts","../node_modules/@types/pako/index.d.ts","../src/compress.ts","../src/ipromptpersona.ts","../src/embedapi.types.ts","../src/enrichedchunk.ts","../src/imodeldriver.ts","../src/enrichedquery.ts","../src/enumeratemodelsapi.types.ts","../src/environment.ts","../src/findenrichedchunkapi.ts","../src/findthemeapi.types.ts","../src/fluid.ts","../node_modules/axios-retry/dist/cjs/index.d.ts","../src/fluidapi.ts","../node_modules/@fluidframework/core-interfaces/lib/disposable.d.ts","../node_modules/@fluidframework/core-interfaces/lib/error.d.ts","../node_modules/@fluidframework/core-interfaces/lib/events.d.ts","../node_modules/@fluidframework/core-interfaces/lib/erasedtype.d.ts","../node_modules/@fluidframework/core-interfaces/lib/fluidrouter.d.ts","../node_modules/@fluidframework/core-interfaces/lib/handles.d.ts","../node_modules/@fluidframework/core-interfaces/lib/fluidloadable.d.ts","../node_modules/@fluidframework/core-interfaces/lib/logger.d.ts","../node_modules/@fluidframework/core-interfaces/lib/provider.d.ts","../node_modules/@fluidframework/core-interfaces/lib/config.d.ts","../node_modules/@fluidframework/core-interfaces/lib/messages.d.ts","../node_modules/@fluidframework/core-interfaces/lib/events/listeners.d.ts","../node_modules/@fluidframework/core-interfaces/lib/events/emitter.d.ts","../node_modules/@fluidframework/core-interfaces/lib/events/index.d.ts","../node_modules/@fluidframework/core-interfaces/lib/index.d.ts","../node_modules/@fluidframework/core-interfaces/lib/public.d.ts","../node_modules/@fluidframework/driver-definitions/lib/urlresolver.d.ts","../node_modules/@fluidframework/driver-definitions/lib/drivererror.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/users.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/clients.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/config.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/consensus.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/date.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/protocol.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/scopes.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/tokens.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/sockets.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/storage.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/summary.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/index.d.ts","../node_modules/@fluidframework/driver-definitions/lib/storage.d.ts","../node_modules/@fluidframework/driver-definitions/lib/git/resources.d.ts","../node_modules/@fluidframework/driver-definitions/lib/git/index.d.ts","../node_modules/@fluidframework/driver-definitions/lib/index.d.ts","../node_modules/@fluidframework/driver-definitions/lib/public.d.ts","../node_modules/@fluidframework/container-definitions/lib/audience.d.ts","../node_modules/@fluidframework/container-definitions/lib/fluidpackage.d.ts","../node_modules/@fluidframework/container-definitions/lib/browserpackage.d.ts","../node_modules/@fluidframework/driver-definitions/internal.d.ts","../node_modules/@fluidframework/container-definitions/lib/deltas.d.ts","../node_modules/@fluidframework/container-definitions/lib/error.d.ts","../node_modules/@fluidframework/container-definitions/lib/runtime.d.ts","../node_modules/@fluidframework/container-definitions/lib/fluidmodule.d.ts","../node_modules/@fluidframework/container-definitions/lib/loader.d.ts","../node_modules/@fluidframework/core-interfaces/internal.d.ts","../node_modules/@fluidframework/container-definitions/lib/index.d.ts","../node_modules/@fluidframework/container-definitions/lib/public.d.ts","../node_modules/@fluidframework/container-definitions/internal.d.ts","../node_modules/@fluidframework/shared-object-base/lib/serializer.d.ts","../node_modules/@fluid-internal/client-utils/lib/bufferbrowser.d.ts","../node_modules/@fluid-internal/client-utils/lib/hashfilebrowser.d.ts","../node_modules/@fluid-internal/client-utils/lib/performanceisomorphic.d.ts","../node_modules/@fluid-internal/client-utils/lib/base64encodingbrowser.d.ts","../node_modules/@fluid-internal/client-utils/lib/buffershared.d.ts","../node_modules/@types/events_pkg/index.d.ts","../node_modules/@fluid-internal/client-utils/lib/eventemitter.d.cts","../node_modules/@fluid-internal/client-utils/lib/trace.d.ts","../node_modules/@fluid-internal/client-utils/lib/typedeventemitter.d.ts","../node_modules/@fluid-internal/client-utils/lib/events/emitter.d.ts","../node_modules/@fluid-internal/client-utils/lib/events/index.d.ts","../node_modules/@fluid-internal/client-utils/lib/indexbrowser.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/attribution.d.ts","../node_modules/@fluidframework/core-utils/lib/assert.d.ts","../node_modules/@fluidframework/core-utils/lib/compare.d.ts","../node_modules/@fluidframework/core-utils/lib/delay.d.ts","../node_modules/@fluidframework/core-utils/lib/heap.d.ts","../node_modules/@fluidframework/core-utils/lib/lazy.d.ts","../node_modules/@fluidframework/core-utils/lib/promisecache.d.ts","../node_modules/@fluidframework/core-utils/lib/promises.d.ts","../node_modules/@fluidframework/core-utils/lib/timer.d.ts","../node_modules/@fluidframework/core-utils/lib/unreachable.d.ts","../node_modules/@fluidframework/core-utils/lib/typesguards.d.ts","../node_modules/@fluidframework/core-utils/lib/oob.d.ts","../node_modules/@fluidframework/core-utils/lib/index.d.ts","../node_modules/@fluidframework/core-utils/internal.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/telemetrytypes.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/logger.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/config.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/fluiderrorbase.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/errorlogging.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/error.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/eventemitterwitherrorhandling.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/events.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/mocklogger.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/thresholdcounter.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/sampledtelemetryhelper.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/utils.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/telemetryeventbatcher.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/index.d.ts","../node_modules/@fluidframework/telemetry-utils/internal.d.ts","../node_modules/@fluidframework/id-compressor/lib/types/identifiers.d.ts","../node_modules/@fluidframework/id-compressor/lib/types/persisted-types/0.0.1.d.ts","../node_modules/@fluidframework/id-compressor/lib/types/persisted-types/index.d.ts","../node_modules/@fluidframework/id-compressor/lib/types/idcompressor.d.ts","../node_modules/@fluidframework/id-compressor/lib/types/index.d.ts","../node_modules/@fluidframework/id-compressor/lib/identifiers.d.ts","../node_modules/@fluidframework/id-compressor/lib/persistanceutilities.d.ts","../node_modules/@fluidframework/id-compressor/lib/sessions.d.ts","../node_modules/@fluidframework/id-compressor/lib/idcompressor.d.ts","../node_modules/@fluidframework/id-compressor/lib/utilities.d.ts","../node_modules/@fluidframework/id-compressor/lib/index.d.ts","../node_modules/@fluidframework/id-compressor/lib/public.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/datastorefactory.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/datastoreregistry.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/garbagecollectiondefinitions.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/protocol.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/summary.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/datastorecontext.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/index.d.ts","../node_modules/@fluidframework/runtime-definitions/internal.d.ts","../node_modules/@fluidframework/datastore-definitions/lib/datastoreruntime.d.ts","../node_modules/@fluidframework/datastore-definitions/lib/storage.d.ts","../node_modules/@fluidframework/datastore-definitions/lib/channel.d.ts","../node_modules/@fluidframework/datastore-definitions/lib/jsonable.d.ts","../node_modules/@fluidframework/datastore-definitions/lib/serializable.d.ts","../node_modules/@fluidframework/datastore-definitions/lib/index.d.ts","../node_modules/@fluidframework/datastore-definitions/internal.d.ts","../node_modules/@fluidframework/shared-object-base/lib/types.d.ts","../node_modules/@fluidframework/shared-object-base/lib/sharedobject.d.ts","../node_modules/@fluidframework/shared-object-base/lib/summaryserializer.d.ts","../node_modules/@fluidframework/shared-object-base/lib/utils.d.ts","../node_modules/@fluidframework/shared-object-base/lib/valuetype.d.ts","../node_modules/@fluidframework/shared-object-base/lib/index.d.ts","../node_modules/@fluidframework/shared-object-base/lib/public.d.ts","../node_modules/@fluidframework/shared-object-base/internal.d.ts","../node_modules/@fluidframework/fluid-static/lib/types.d.ts","../node_modules/@fluidframework/fluid-static/lib/fluidcontainer.d.ts","../node_modules/@fluidframework/fluid-static/lib/rootdataobject.d.ts","../node_modules/@fluidframework/fluid-static/lib/serviceaudience.d.ts","../node_modules/@fluidframework/fluid-static/lib/index.d.ts","../node_modules/@fluidframework/fluid-static/lib/public.d.ts","../node_modules/@fluidframework/driver-utils/lib/buildsnapshottree.d.ts","../node_modules/@fluidframework/driver-utils/lib/blob.d.ts","../node_modules/@fluidframework/driver-utils/lib/documentstorageserviceproxy.d.ts","../node_modules/@fluidframework/driver-utils/lib/error.d.ts","../node_modules/@fluidframework/driver-utils/lib/insecureurlresolver.d.ts","../node_modules/@fluidframework/driver-utils/lib/messagerecognition.d.ts","../node_modules/@fluidframework/driver-utils/lib/network.d.ts","../node_modules/@fluidframework/driver-utils/lib/networkutils.d.ts","../node_modules/@fluidframework/driver-utils/lib/parallelrequests.d.ts","../node_modules/@fluidframework/driver-utils/lib/prefetchdocumentstorageservice.d.ts","../node_modules/@fluidframework/driver-utils/lib/ratelimiter.d.ts","../node_modules/@fluidframework/driver-utils/lib/readandparse.d.ts","../node_modules/@fluidframework/driver-utils/lib/runwithretry.d.ts","../node_modules/@fluidframework/driver-utils/lib/summaryforcreatenew.d.ts","../node_modules/@fluidframework/driver-utils/lib/treeconversions.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/compression/compressiontypes.d.ts","../node_modules/@fluidframework/driver-utils/lib/documentservicefactoryproxy.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/compression/documentservicefactorycompressionadapter.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/compression/summaryblob/documentstorageservicesummaryblobcompressionadapter.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/compression/summaryblob/index.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/compression/index.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/predefinedadapters.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/index.d.ts","../node_modules/@fluidframework/driver-utils/lib/storageutils.d.ts","../node_modules/@fluidframework/driver-utils/lib/protocol/githelper.d.ts","../node_modules/@fluidframework/driver-utils/lib/protocol/index.d.ts","../node_modules/@fluidframework/driver-utils/lib/index.d.ts","../node_modules/@fluidframework/driver-utils/lib/public.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/routerliciousresolvedurl.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/tokens.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/defaulttokenprovider.d.ts","../node_modules/@fluidframework/driver-utils/internal.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/errorutils.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/users.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/clients.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/config.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/consensus.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/date.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/protocol.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/scopes.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/tokens.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/sockets.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/storage.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/summary.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/index.d.ts","../node_modules/@fluidframework/server-services-client/dist/auth.d.ts","../node_modules/@fluidframework/server-services-client/dist/array.d.ts","../node_modules/@fluidframework/server-services-client/dist/constants.d.ts","../node_modules/@fluidframework/server-services-client/dist/error.d.ts","../node_modules/@fluidframework/server-services-client/dist/generatenames.d.ts","../node_modules/@fluidframework/gitresources/dist/resources.d.ts","../node_modules/@fluidframework/gitresources/dist/services.d.ts","../node_modules/@fluidframework/gitresources/dist/index.d.ts","../node_modules/@fluidframework/server-services-client/dist/storagecontracts.d.ts","../node_modules/@fluidframework/server-services-client/dist/storage.d.ts","../node_modules/@fluidframework/server-services-client/dist/gitmanager.d.ts","../node_modules/@fluidframework/server-services-client/dist/heap.d.ts","../node_modules/@fluidframework/server-services-client/dist/restwrapper.d.ts","../node_modules/@fluidframework/server-services-client/dist/historian.d.ts","../node_modules/@fluidframework/server-services-client/dist/interfaces.d.ts","../node_modules/@fluidframework/server-services-client/dist/promisetimeout.d.ts","../node_modules/@fluidframework/server-services-client/dist/restlessclient.d.ts","../node_modules/@fluidframework/server-services-client/dist/rollinghash.d.ts","../node_modules/@fluidframework/server-services-client/dist/scopes.d.ts","../node_modules/@fluidframework/protocol-base/dist/githelper.d.ts","../node_modules/@fluidframework/common-utils/dist/assert.d.ts","../node_modules/@fluidframework/common-utils/dist/base64encoding.d.ts","../node_modules/@fluidframework/common-utils/dist/buffershared.d.ts","../node_modules/@fluidframework/common-utils/dist/delay.d.ts","../node_modules/@fluidframework/common-definitions/dist/disposable.d.ts","../node_modules/@fluidframework/common-definitions/dist/events.d.ts","../node_modules/@fluidframework/common-definitions/dist/logger.d.ts","../node_modules/@fluidframework/common-definitions/dist/index.d.ts","../node_modules/@fluidframework/common-utils/dist/disposal.d.ts","../node_modules/@types/events/index.d.ts","../node_modules/@fluidframework/common-utils/dist/typedeventemitter.d.ts","../node_modules/@fluidframework/common-utils/dist/eventforwarder.d.ts","../node_modules/@fluidframework/common-utils/dist/heap.d.ts","../node_modules/@fluidframework/common-utils/dist/buffernode.d.ts","../node_modules/@fluidframework/common-utils/dist/hashfilenode.d.ts","../node_modules/@fluidframework/common-utils/dist/performanceisomorphic.d.ts","../node_modules/@fluidframework/common-utils/dist/indexnode.d.ts","../node_modules/@fluidframework/common-utils/dist/lazy.d.ts","../node_modules/@fluidframework/common-utils/dist/logger.d.ts","../node_modules/@fluidframework/common-utils/dist/promisecache.d.ts","../node_modules/@fluidframework/common-utils/dist/promises.d.ts","../node_modules/@fluidframework/common-utils/dist/rangetracker.d.ts","../node_modules/@fluidframework/common-utils/dist/ratelimiter.d.ts","../node_modules/@fluidframework/common-utils/dist/safeparser.d.ts","../node_modules/@fluidframework/common-utils/dist/timer.d.ts","../node_modules/@fluidframework/common-utils/dist/trace.d.ts","../node_modules/@fluidframework/common-utils/dist/unreachable.d.ts","../node_modules/@fluidframework/common-utils/dist/index.d.ts","../node_modules/@fluidframework/protocol-base/dist/quorum.d.ts","../node_modules/@fluidframework/protocol-base/dist/protocol.d.ts","../node_modules/@fluidframework/protocol-base/dist/index.d.ts","../node_modules/@fluidframework/server-services-client/dist/scribehelper.d.ts","../node_modules/@fluidframework/server-services-client/dist/storageutils.d.ts","../node_modules/@fluidframework/server-services-client/dist/summarytreeuploadmanager.d.ts","../node_modules/@fluidframework/server-services-client/dist/timeoutcontext.d.ts","../node_modules/@fluidframework/server-services-client/dist/utils.d.ts","../node_modules/@fluidframework/server-services-client/dist/wholesummaryuploadmanager.d.ts","../node_modules/@fluidframework/server-services-client/dist/index.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/policies.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/documentservicefactory.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/index.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/public.d.ts","../node_modules/@fluidframework/azure-client/lib/interfaces.d.ts","../node_modules/@fluidframework/azure-client/lib/azureclient.d.ts","../node_modules/@fluidframework/azure-client/lib/index.d.ts","../node_modules/@fluidframework/azure-client/lib/public.d.ts","../src/ienvironmentfactory.ts","../src/fluidtokenprovider.ts","../src/imodel.ts","../node_modules/gpt4-tokenizer/dist/index.d.ts","../src/model.oai.ts","../src/ipromptpersonafactory.ts","../src/modeldrivers.oai.ts","../src/imodelfactory.ts","../src/loginapi.ts","../src/looseobject.ts","../src/pagerepositoryapi.types.ts","../src/pagerepositoryapi.ts","../src/querymodelapi.ts","../src/sessionapi.ts","../src/studioapi.types.ts","../src/summariseapi.types.ts","../src/testforsummarisefailapi.types.ts","../src/themeapi.ts","../node_modules/@types/bintrees/index.d.ts","../node_modules/@types/json-schema/index.d.ts","../node_modules/@types/node/compatibility/disposable.d.ts","../node_modules/@types/node/compatibility/indexable.d.ts","../node_modules/@types/node/compatibility/iterators.d.ts","../node_modules/@types/node/compatibility/index.d.ts","../node_modules/@types/node/globals.typedarray.d.ts","../node_modules/@types/node/buffer.buffer.d.ts","../node_modules/buffer/index.d.ts","../node_modules/undici-types/header.d.ts","../node_modules/undici-types/readable.d.ts","../node_modules/undici-types/file.d.ts","../node_modules/undici-types/fetch.d.ts","../node_modules/undici-types/formdata.d.ts","../node_modules/undici-types/connector.d.ts","../node_modules/undici-types/client.d.ts","../node_modules/undici-types/errors.d.ts","../node_modules/undici-types/dispatcher.d.ts","../node_modules/undici-types/global-dispatcher.d.ts","../node_modules/undici-types/global-origin.d.ts","../node_modules/undici-types/pool-stats.d.ts","../node_modules/undici-types/pool.d.ts","../node_modules/undici-types/handlers.d.ts","../node_modules/undici-types/balanced-pool.d.ts","../node_modules/undici-types/agent.d.ts","../node_modules/undici-types/mock-interceptor.d.ts","../node_modules/undici-types/mock-agent.d.ts","../node_modules/undici-types/mock-client.d.ts","../node_modules/undici-types/mock-pool.d.ts","../node_modules/undici-types/mock-errors.d.ts","../node_modules/undici-types/proxy-agent.d.ts","../node_modules/undici-types/env-http-proxy-agent.d.ts","../node_modules/undici-types/retry-handler.d.ts","../node_modules/undici-types/retry-agent.d.ts","../node_modules/undici-types/api.d.ts","../node_modules/undici-types/interceptors.d.ts","../node_modules/undici-types/util.d.ts","../node_modules/undici-types/cookies.d.ts","../node_modules/undici-types/patch.d.ts","../node_modules/undici-types/websocket.d.ts","../node_modules/undici-types/eventsource.d.ts","../node_modules/undici-types/filereader.d.ts","../node_modules/undici-types/diagnostics-channel.d.ts","../node_modules/undici-types/content-type.d.ts","../node_modules/undici-types/cache.d.ts","../node_modules/undici-types/index.d.ts","../node_modules/@types/node/globals.d.ts","../node_modules/@types/node/assert.d.ts","../node_modules/@types/node/assert/strict.d.ts","../node_modules/@types/node/async_hooks.d.ts","../node_modules/@types/node/buffer.d.ts","../node_modules/@types/node/child_process.d.ts","../node_modules/@types/node/cluster.d.ts","../node_modules/@types/node/console.d.ts","../node_modules/@types/node/constants.d.ts","../node_modules/@types/node/crypto.d.ts","../node_modules/@types/node/dgram.d.ts","../node_modules/@types/node/diagnostics_channel.d.ts","../node_modules/@types/node/dns.d.ts","../node_modules/@types/node/dns/promises.d.ts","../node_modules/@types/node/domain.d.ts","../node_modules/@types/node/dom-events.d.ts","../node_modules/@types/node/events.d.ts","../node_modules/@types/node/fs.d.ts","../node_modules/@types/node/fs/promises.d.ts","../node_modules/@types/node/http.d.ts","../node_modules/@types/node/http2.d.ts","../node_modules/@types/node/https.d.ts","../node_modules/@types/node/inspector.d.ts","../node_modules/@types/node/module.d.ts","../node_modules/@types/node/net.d.ts","../node_modules/@types/node/os.d.ts","../node_modules/@types/node/path.d.ts","../node_modules/@types/node/perf_hooks.d.ts","../node_modules/@types/node/process.d.ts","../node_modules/@types/node/punycode.d.ts","../node_modules/@types/node/querystring.d.ts","../node_modules/@types/node/readline.d.ts","../node_modules/@types/node/readline/promises.d.ts","../node_modules/@types/node/repl.d.ts","../node_modules/@types/node/sea.d.ts","../node_modules/@types/node/sqlite.d.ts","../node_modules/@types/node/stream.d.ts","../node_modules/@types/node/stream/promises.d.ts","../node_modules/@types/node/stream/consumers.d.ts","../node_modules/@types/node/stream/web.d.ts","../node_modules/@types/node/string_decoder.d.ts","../node_modules/@types/node/test.d.ts","../node_modules/@types/node/timers.d.ts","../node_modules/@types/node/timers/promises.d.ts","../node_modules/@types/node/tls.d.ts","../node_modules/@types/node/trace_events.d.ts","../node_modules/@types/node/tty.d.ts","../node_modules/@types/node/url.d.ts","../node_modules/@types/node/util.d.ts","../node_modules/@types/node/v8.d.ts","../node_modules/@types/node/vm.d.ts","../node_modules/@types/node/wasi.d.ts","../node_modules/@types/node/worker_threads.d.ts","../node_modules/@types/node/zlib.d.ts","../node_modules/@types/node/index.d.ts","../node_modules/@types/ungap__structured-clone/index.d.ts"],"fileIdsList":[[353,396],[140,353,396],[130,353,396],[144,353,396],[135,353,396],[135,136,137,138,139,141,142,143,145,353,396],[101,102,141,353,396],[216,324,353,396],[101,102,120,124,216,323,324,325,353,396],[101,102,120,216,244,323,353,396],[326,353,396],[286,287,288,353,396],[289,353,396],[289,292,353,396,408],[295,353,396],[282,283,284,285,290,292,293,294,297,298,299,300,301,302,303,304,305,306,307,308,353,396],[295,296,297,353,396],[289,353,396,408],[131,353,396],[101,102,120,353,396],[122,353,396],[101,102,120,124,353,396],[101,102,353,396],[101,102,122,127,353,396],[121,122,123,125,126,127,128,129,130,353,396],[101,102,120,121,122,124,125,126,127,128,353,396],[101,102,120,121,124,125,126,129,353,396],[100,353,396],[97,353,396],[97,98,353,396],[91,353,396],[89,90,353,396],[86,87,88,89,90,91,92,93,94,95,96,99,353,396],[159,353,396],[148,149,150,151,152,153,154,155,156,157,158,353,396],[201,353,396],[101,102,124,195,196,197,353,396],[101,102,120,124,130,132,187,195,198,353,396],[196,197,198,199,200,353,396],[101,102,199,353,396],[119,353,396],[102,353,396],[117,353,396],[102,103,115,116,118,353,396],[104,353,396],[105,353,396],[104,105,106,107,108,109,110,111,112,113,114,353,396],[105,106,109,111,353,396],[108,353,396],[101,102,103,115,353,396],[243,353,396],[101,102,120,124,232,233,353,396],[232,234,236,353,396],[120,124,219,237,353,396],[235,353,396],[237,238,353,396],[124,237,353,396],[124,353,396],[120,124,353,396],[124,175,353,396],[217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,239,240,242,353,396],[101,102,124,353,396],[101,102,124,175,353,396],[175,353,396],[124,219,353,396],[241,353,396],[101,102,132,133,209,211,353,396],[211,212,213,214,353,396],[215,353,396],[133,211,353,396],[120,133,211,353,396],[101,102,195,209,210,353,396],[267,268,353,396],[267,353,396],[101,102,175,180,182,183,353,396],[180,353,396],[180,184,185,353,396],[181,353,396],[186,353,396],[180,181,353,396],[176,178,353,396],[176,178,179,353,396],[176,353,396],[177,353,396],[261,269,353,396],[281,310,311,353,396],[261,310,353,396],[261,309,353,396],[250,353,396],[251,353,396],[250,251,252,253,254,255,256,257,258,259,260,353,396],[251,252,255,257,353,396],[254,353,396],[246,353,396],[101,102,120,124,246,319,320,353,396],[124,175,248,353,396],[245,246,247,249,320,321,353,396],[322,353,396],[194,353,396],[120,353,396],[101,102,120,124,130,132,133,187,188,189,190,191,192,353,396],[193,353,396],[188,353,396],[147,188,189,190,191,192,193,353,396],[101,102,120,124,175,190,353,396],[261,353,396],[261,269,270,271,353,396],[269,270,271,274,353,396],[262,263,264,265,266,270,271,272,273,274,275,276,277,278,279,280,313,314,315,316,317,318,353,396],[59,84,353,396],[261,269,312,353,396],[261,269,270,353,396],[270,353,396],[261,270,271,353,396],[270,271,353,396],[208,353,396],[134,203,204,205,206,207,353,396],[101,102,130,353,396],[101,102,124,130,133,134,146,175,195,202,203,353,396],[130,134,353,396],[101,102,124,195,202,353,396],[101,102,134,195,353,396],[174,353,396],[101,102,160,161,162,353,396],[101,102,124,130,161,164,165,353,396],[101,102,130,161,164,353,396],[101,102,146,353,396],[146,161,353,396],[101,102,161,353,396],[161,162,163,164,165,166,167,168,169,170,171,172,173,353,396],[161,353,396],[353,393,396],[353,395,396],[396],[353,396,401,431],[353,396,397,402,408,409,416,428,439],[353,396,397,398,408,416],[348,349,350,353,396],[353,396,399,440],[353,396,400,401,409,417],[353,396,401,428,436],[353,396,402,404,408,416],[353,395,396,403],[353,396,404,405],[353,396,408],[353,396,406,408],[353,395,396,408],[353,396,408,409,410,428,439],[353,396,408,409,410,423,428,431],[353,391,396,444],[353,391,396,404,408,411,416,428,439],[353,396,408,409,411,412,416,428,436,439],[353,396,411,413,428,436,439],[351,352,353,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445],[353,396,408,414],[353,396,415,439,444],[353,396,404,408,416,428],[353,396,417],[353,396,418],[353,395,396,419],[353,393,394,395,396,397,398,399,400,401,402,403,404,405,406,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445],[353,396,421],[353,396,422],[353,396,408,423,424],[353,396,423,425,440,442],[353,396,408,428,429,430,431],[353,396,428,430],[353,396,428,429],[353,396,431],[353,396,432],[353,393,396,428],[353,396,408,434,435],[353,396,434,435],[353,396,401,416,428,436],[353,396,437],[353,396,416,438],[353,396,411,422,439],[353,396,401,440],[353,396,428,441],[353,396,415,442],[353,396,443],[353,396,401,408,410,419,428,439,442,444],[353,396,428,445],[353,363,367,396,439],[353,363,396,428,439],[353,358,396],[353,360,363,396,436,439],[353,396,416,436],[353,396,446],[353,358,396,446],[353,360,363,396,416,439],[353,355,356,359,362,396,408,428,439],[353,363,370,396],[353,355,361,396],[353,363,384,385,396],[353,359,363,396,431,439,446],[353,384,396,446],[353,357,358,396,446],[353,363,396],[353,357,358,359,360,361,362,363,364,365,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,385,386,387,388,389,390,396],[353,363,378,396],[353,363,370,371,396],[353,361,363,371,372,396],[353,362,396],[353,355,358,363,396],[353,363,367,371,372,396],[353,367,396],[353,361,363,366,396,439],[353,355,360,363,370,396],[353,396,428],[353,358,363,384,396,444,446],[60,61,62,63,353,396],[59,60,84,353,396],[66,353,396],[62,353,396],[72,353,396],[74,353,396],[76,77,353,396],[76,353,396],[60,353,396],[65,353,396],[59,60,61,76,84,353,396],[59,60,61,83,84,353,396],[60,66,83,85,327,328,353,396],[60,80,353,396],[77,330,332,334,353,396],[74,77,353,396],[59,60,61,84,353,396],[66,330,331,353,396],[59,74,77,84,333,353,396],[60,61,62,63,73,353,396],[59,60,61,78,84,353,396],[59,62,84,353,396]],"fileInfos":[{"version":"e41c290ef7dd7dab3493e6cbe5909e0148edf4a8dad0271be08edec368a0f7b9","affectsGlobalScope":true,"impliedFormat":1},{"version":"45b7ab580deca34ae9729e97c13cfd999df04416a79116c3bfb483804f85ded4","impliedFormat":1},{"version":"3facaf05f0c5fc569c5649dd359892c98a85557e3e0c847964caeb67076f4d75","impliedFormat":1},{"version":"e44bb8bbac7f10ecc786703fe0a6a4b952189f908707980ba8f3c8975a760962","impliedFormat":1},{"version":"5e1c4c362065a6b95ff952c0eab010f04dcd2c3494e813b493ecfd4fcb9fc0d8","impliedFormat":1},{"version":"68d73b4a11549f9c0b7d352d10e91e5dca8faa3322bfb77b661839c42b1ddec7","impliedFormat":1},{"version":"5efce4fc3c29ea84e8928f97adec086e3dc876365e0982cc8479a07954a3efd4","impliedFormat":1},{"version":"feecb1be483ed332fad555aff858affd90a48ab19ba7272ee084704eb7167569","impliedFormat":1},{"version":"ee7bad0c15b58988daa84371e0b89d313b762ab83cb5b31b8a2d1162e8eb41c2","impliedFormat":1},{"version":"4fd3f3422b2d2a3dfd5cdd0f387b3a8ec45f006c6ea896a4cb41264c2100bb2c","affectsGlobalScope":true,"impliedFormat":1},{"version":"c57796738e7f83dbc4b8e65132f11a377649c00dd3eee333f672b8f0a6bea671","affectsGlobalScope":true,"impliedFormat":1},{"version":"dc2df20b1bcdc8c2d34af4926e2c3ab15ffe1160a63e58b7e09833f616efff44","affectsGlobalScope":true,"impliedFormat":1},{"version":"515d0b7b9bea2e31ea4ec968e9edd2c39d3eebf4a2d5cbd04e88639819ae3b71","affectsGlobalScope":true,"impliedFormat":1},{"version":"62bb211266ee48b2d0edf0d8d1b191f0c24fc379a82bd4c1692a082c540bc6b1","affectsGlobalScope":true,"impliedFormat":1},{"version":"0dc1e7ceda9b8b9b455c3a2d67b0412feab00bd2f66656cd8850e8831b08b537","affectsGlobalScope":true,"impliedFormat":1},{"version":"ce691fb9e5c64efb9547083e4a34091bcbe5bdb41027e310ebba8f7d96a98671","affectsGlobalScope":true,"impliedFormat":1},{"version":"8d697a2a929a5fcb38b7a65594020fcef05ec1630804a33748829c5ff53640d0","affectsGlobalScope":true,"impliedFormat":1},{"version":"4ff2a353abf8a80ee399af572debb8faab2d33ad38c4b4474cff7f26e7653b8d","affectsGlobalScope":true,"impliedFormat":1},{"version":"936e80ad36a2ee83fc3caf008e7c4c5afe45b3cf3d5c24408f039c1d47bdc1df","affectsGlobalScope":true,"impliedFormat":1},{"version":"d15bea3d62cbbdb9797079416b8ac375ae99162a7fba5de2c6c505446486ac0a","affectsGlobalScope":true,"impliedFormat":1},{"version":"68d18b664c9d32a7336a70235958b8997ebc1c3b8505f4f1ae2b7e7753b87618","affectsGlobalScope":true,"impliedFormat":1},{"version":"eb3d66c8327153d8fa7dd03f9c58d351107fe824c79e9b56b462935176cdf12a","affectsGlobalScope":true,"impliedFormat":1},{"version":"38f0219c9e23c915ef9790ab1d680440d95419ad264816fa15009a8851e79119","affectsGlobalScope":true,"impliedFormat":1},{"version":"69ab18c3b76cd9b1be3d188eaf8bba06112ebbe2f47f6c322b5105a6fbc45a2e","affectsGlobalScope":true,"impliedFormat":1},{"version":"fef8cfad2e2dc5f5b3d97a6f4f2e92848eb1b88e897bb7318cef0e2820bceaab","affectsGlobalScope":true,"impliedFormat":1},{"version":"2f11ff796926e0832f9ae148008138ad583bd181899ab7dd768a2666700b1893","affectsGlobalScope":true,"impliedFormat":1},{"version":"4de680d5bb41c17f7f68e0419412ca23c98d5749dcaaea1896172f06435891fc","affectsGlobalScope":true,"impliedFormat":1},{"version":"954296b30da6d508a104a3a0b5d96b76495c709785c1d11610908e63481ee667","affectsGlobalScope":true,"impliedFormat":1},{"version":"ac9538681b19688c8eae65811b329d3744af679e0bdfa5d842d0e32524c73e1c","affectsGlobalScope":true,"impliedFormat":1},{"version":"0a969edff4bd52585473d24995c5ef223f6652d6ef46193309b3921d65dd4376","affectsGlobalScope":true,"impliedFormat":1},{"version":"9e9fbd7030c440b33d021da145d3232984c8bb7916f277e8ffd3dc2e3eae2bdb","affectsGlobalScope":true,"impliedFormat":1},{"version":"811ec78f7fefcabbda4bfa93b3eb67d9ae166ef95f9bff989d964061cbf81a0c","affectsGlobalScope":true,"impliedFormat":1},{"version":"717937616a17072082152a2ef351cb51f98802fb4b2fdabd32399843875974ca","affectsGlobalScope":true,"impliedFormat":1},{"version":"d7e7d9b7b50e5f22c915b525acc5a49a7a6584cf8f62d0569e557c5cfc4b2ac2","affectsGlobalScope":true,"impliedFormat":1},{"version":"71c37f4c9543f31dfced6c7840e068c5a5aacb7b89111a4364b1d5276b852557","affectsGlobalScope":true,"impliedFormat":1},{"version":"576711e016cf4f1804676043e6a0a5414252560eb57de9faceee34d79798c850","affectsGlobalScope":true,"impliedFormat":1},{"version":"89c1b1281ba7b8a96efc676b11b264de7a8374c5ea1e6617f11880a13fc56dc6","affectsGlobalScope":true,"impliedFormat":1},{"version":"74f7fa2d027d5b33eb0471c8e82a6c87216223181ec31247c357a3e8e2fddc5b","affectsGlobalScope":true,"impliedFormat":1},{"version":"f1e2a172204962276504466a6393426d2ca9c54894b1ad0a6c9dad867a65f876","affectsGlobalScope":true,"impliedFormat":1},{"version":"063600664504610fe3e99b717a1223f8b1900087fab0b4cad1496a114744f8df","affectsGlobalScope":true,"impliedFormat":1},{"version":"934019d7e3c81950f9a8426d093458b65d5aff2c7c1511233c0fd5b941e608ab","affectsGlobalScope":true,"impliedFormat":1},{"version":"52ada8e0b6e0482b728070b7639ee42e83a9b1c22d205992756fe020fd9f4a47","affectsGlobalScope":true,"impliedFormat":1},{"version":"3bdefe1bfd4d6dee0e26f928f93ccc128f1b64d5d501ff4a8cf3c6371200e5e6","affectsGlobalScope":true,"impliedFormat":1},{"version":"59fb2c069260b4ba00b5643b907ef5d5341b167e7d1dbf58dfd895658bda2867","affectsGlobalScope":true,"impliedFormat":1},{"version":"639e512c0dfc3fad96a84caad71b8834d66329a1f28dc95e3946c9b58176c73a","affectsGlobalScope":true,"impliedFormat":1},{"version":"368af93f74c9c932edd84c58883e736c9e3d53cec1fe24c0b0ff451f529ceab1","affectsGlobalScope":true,"impliedFormat":1},{"version":"af3dd424cf267428f30ccfc376f47a2c0114546b55c44d8c0f1d57d841e28d74","affectsGlobalScope":true,"impliedFormat":1},{"version":"995c005ab91a498455ea8dfb63aa9f83fa2ea793c3d8aa344be4a1678d06d399","affectsGlobalScope":true,"impliedFormat":1},{"version":"959d36cddf5e7d572a65045b876f2956c973a586da58e5d26cde519184fd9b8a","affectsGlobalScope":true,"impliedFormat":1},{"version":"965f36eae237dd74e6cca203a43e9ca801ce38824ead814728a2807b1910117d","affectsGlobalScope":true,"impliedFormat":1},{"version":"3925a6c820dcb1a06506c90b1577db1fdbf7705d65b62b99dce4be75c637e26b","affectsGlobalScope":true,"impliedFormat":1},{"version":"0a3d63ef2b853447ec4f749d3f368ce642264246e02911fcb1590d8c161b8005","affectsGlobalScope":true,"impliedFormat":1},{"version":"b5ce7a470bc3628408429040c4e3a53a27755022a32fd05e2cb694e7015386c7","affectsGlobalScope":true,"impliedFormat":1},{"version":"8444af78980e3b20b49324f4a16ba35024fef3ee069a0eb67616ea6ca821c47a","affectsGlobalScope":true,"impliedFormat":1},{"version":"3287d9d085fbd618c3971944b65b4be57859f5415f495b33a6adc994edd2f004","affectsGlobalScope":true,"impliedFormat":1},{"version":"b4b67b1a91182421f5df999988c690f14d813b9850b40acd06ed44691f6727ad","affectsGlobalScope":true,"impliedFormat":1},{"version":"8e7f8264d0fb4c5339605a15daadb037bf238c10b654bb3eee14208f860a32ea","affectsGlobalScope":true,"impliedFormat":1},{"version":"782dec38049b92d4e85c1585fbea5474a219c6984a35b004963b00beb1aab538","affectsGlobalScope":true,"impliedFormat":1},{"version":"dc602ef9638db2163c461ec64133fe76f890f6e03b69b1c96f5c5e59592025e8","impliedFormat":99},{"version":"abc1adb9d8309cf8621e47df438b875e019be7cc461864fa2a0011ed2876f778","signature":"6fd6b3ac72ab962c88755c945c78e1332ced6a1c881dd94e794f0970fbaf74b1"},{"version":"3151c4209b0b04241bdbb9a2bd781feeaec6c56054756bea2a2ce843583feaaa","signature":"520c382abb839023db1cf06fd36059fc0eb0bee6b77eff5295ad3a7e626f131a"},{"version":"fa6d3dcd39ee34a7d7650e68f0996cc9a3d49ad4f260a385cee7257735854a27","signature":"58d51138b3bd18a838caf47910a7c69c122632c801a4cfc112221ee342d74401"},{"version":"073ce94919c3894f3495e8eefc7ec3b1fde7d51e69961bce6fcefa3747fcadf0","signature":"7d65510dda44e14a4c7732f013679a5356d3467d7aff912ab7f571190c4587a5"},{"version":"ef56fba494ea51cb67782f74305495fdbbfd1bcebfa31725a0cab562ffef09de","signature":"0eb973e8741a7fedfafe3eb5912e7b888e05b4c31abc623b7b404fd509ad319c"},{"version":"a69618c7f19ae55dd06768539907dd6cc91f97c9558d236a0681c935b3e9757c","signature":"ce3ee7c38113b9eec26cefa3d2c0082a3f7059fecb6c03c0561f2559efc9b25e"},{"version":"89bc17e638f3676226ec6ba1df1e55b9e9c666188230a717e3427e9ef494cbf3","signature":"7902eff502d90669760e8394e84ca31f8668a230612b84d57b570508b0b20317"},{"version":"ed5e43a3f9dd9f74269ab525824ae20346833a5df5d6e49179b55213ec1e860c","signature":"191d9b688a81f839d254e43dfa6ace3417b8cb49106726ebab65caad4cb12110"},{"version":"6c82c54879c106a2f3c791c0003b190b01f0ac5e82a27bee29b0a456e27978bb","signature":"e297fb6cc7e1961b86fb20fe31bd80e315f264f451117544438e7f57d0d9c1c5"},{"version":"139a9a775ad536832498163672d0a23ed23492f7c38803c79ad6e5c99a2e3215","signature":"5b935de7afab76779ea90f34ad7bbf49d3eb1e5862bdf4c8ef2db44fdbb190fd"},{"version":"82ca7c9100a670b4199c61883c615e80cff307aefd0025ebb62c93b5486b6362","signature":"ce149651956603568d4722cdd3808c9606769aa2d0d0ca2d6d46d336e458b0bc"},{"version":"19bfa166f0546c3cb2a609327322ca1e21fe7b72cb59bc1006e554b537720ef5","signature":"f3d7e2dd07ebb346a803a89a1ca0312523e10b0812ef2188a18231f2ff001bbc"},{"version":"c634df3e1b52761b2a219edcc61d0a7f748cdc54b93d73bcb817619452a6388a","impliedFormat":1},{"version":"6af064316f0af4e818a4a3b01551a3c4f5bb1eec4dfe3bd1f0ac10be3d2204c2","signature":"68c461dd20402dd9777e274c53580934288bd156efe720f9e16daa758d8ab209"},{"version":"7763872fae30dd2648107586f39ad00f25cd9ec1d002c539386bd5d0807440cc","signature":"d8c2ff72b2b017fc74cde058dfa6033bf65e9d629e9927a73ead060793746d0b"},{"version":"20d0bf7b3f57064bf0a94d805edeff836e6f626a2c5281c8dd64af2cd807badf","signature":"98af9fe7e9483b88aa3416347bdb11cf2f97543510324722cad69537d0eb6bf7"},{"version":"fcd0df303f42e3c82018471405e5533a2c2b03acec116eac11298ff499a0f9ea","signature":"0b1ca3d9e6a96edaec95d15f5d876136e2749e61000ba2d2b2d3289df2b7c1e0"},{"version":"c6a49203b2b31bf8cf632033909c7c56a8c5ccad5dd1c13f745b5bc881fa9e92","signature":"66b4d417da64a3559948b5ec8f464f753263cfdff610f329dc7d3123e49def1f"},{"version":"496766eac1dbdd48125cf72a46fe4cd156c7b24d287f4e6e74246c5c24abd8ce","signature":"16adf39eda49226118992f127d34ff99420ce0817382393ec4610bbec7aabf3f"},{"version":"c8e8e5d89d7a7d92026bdbd0ac6b5eccf5f160c465f0655814de3e97c63efa6b","signature":"be7016047764195716416775862917d688280bd1a7d4bc0c074fa79c194c56d8"},{"version":"064b76972f012a0a5956ecab037c7fa0e5784cf29d93fa7a8a7d055416247aab","signature":"513a1db5b029450a22085c3a9d2e90ce7e52d2e66c4ecf42d37c0c7a64db30ad"},{"version":"65a861e1a5a27ca0f0a21367751140204207d6e75af5ba79cc0bca51b416be8b","signature":"c9ecb878c17c2e4b474f9d5ba26d1f90e331fbce6147f2ed8aff25409ac521ec"},{"version":"195aae1ea9a94f0bdc20fb68961e2722d3c465d66d70914373a8ac2c5adbd31e","signature":"0604850767ce8611891c3b3186a5ac682142d206986e5af1ccf5d57f1e9e2ad1"},{"version":"d580522b6a7e4d2e970941e7d841828cd1c3d0816b96e21a2568f3645c62bde9","signature":"5221f3123aff7653087e40f18d8fd6910caa725d50abcfc2c78f703e21f8bf3c"},{"version":"0e61da58d136e579473ea50552c918f8724a924541b7dd5e922e5acb4146a13d","impliedFormat":1},{"version":"842658f282d17185b0a85e3177dd46221fdfd5c6d9cd3a2bf5b954e0724d84d8","signature":"b6fd921ab532355c40a32eaadd22c1c47baa6bdc97a99fe06855d0a74360007f"},{"version":"76222708e1fd35e13ea7930d141c76811842af42e8200abd3617cdcc800fca9b","impliedFormat":99},{"version":"b82040a39ffdb225a97fc1a934af30ce65364a1acbeb1900ed06dc305c08419a","impliedFormat":99},{"version":"acf8e4812e25c86d55725f365c6fd004c099c125351799002077c749d7c32cb5","impliedFormat":99},{"version":"a4da212ce63d1e8c9937eddc3fa94196a40eec042b0b4a130f18ba909ee10f58","impliedFormat":99},{"version":"d1d878a1661002034e2dc6a7d40baa2e3d1aec74643c341f7469d604cc245192","impliedFormat":99},{"version":"b83f2e8e8c6b7f2c761015bd22fa66d0933af1a5396dd706090d1992ab76b508","impliedFormat":99},{"version":"5d8bc3018458dffe489343207f008e55c693b1d3d734fd1cd1ba13e3540800a4","impliedFormat":99},{"version":"8c3dc920164192ff835183ea33579ff913cc3f2829682d0250a2180838fa1df3","impliedFormat":99},{"version":"a64edb16eacf69e9473e5b829d850ac4b526daf673e92a84628c8c492fe06d68","impliedFormat":99},{"version":"06c8622d8f31b530058177e1ba6e97e3896c369be4b5f0d19e870512787e9e78","impliedFormat":99},{"version":"905bca74f61f72b7eb9d4d7c5b9020b018e1e125c2b7123f8c62e84921c26198","impliedFormat":99},{"version":"376ff482d80bbb582be419c5d85120e2294c856e0d2c1700b035b104add94efd","impliedFormat":99},{"version":"3190a83f44dd89ff7f816b6591355786073a3abb552ba5fbc91ae024a54eb496","impliedFormat":99},{"version":"6149950fb375ce2a28651fb44c33ce8510a65d18ccfb04624688a21ccdf00995","impliedFormat":99},{"version":"98a072a60dc4d5d36b4da374b15cdd14028fca46ff067c74f73b2c7200245db4","impliedFormat":99},{"version":"fe9abbfbc1a2b1ae9ef74f67dface75a0d78ebca758ccc201f8acb099e4ea302","impliedFormat":99},{"version":"d278b1734e9f958b9b9f0705896b3d76c9c73cc74987ea30471b5db8d3eb3f53","impliedFormat":99},{"version":"f3f1896a7411aa9f3e8fa652f55d07e736333f5d2a93c798aa12b10cfe9bda43","impliedFormat":99},{"version":"f338a331fc98b7a1f203f27b72934b22157bab6e23102f005b09786dcf383668","impliedFormat":99},{"version":"af742d95ad117e7e7f97d36c1df19ef68299ee41dc9da1671e7573874b333804","impliedFormat":99},{"version":"ce990e4091223d3a0b7732e962a4f714382e1329271066e3eca2c9853e941c30","impliedFormat":99},{"version":"60ed184ec95dc22fc01808907ab2387098f79fd019dfb8a54b3a2220430bcaff","impliedFormat":99},{"version":"648ec08f15d9e5b13fd7a29b03cbcd4c21ba7bfe47674d3e7ef4c45f93b81016","impliedFormat":99},{"version":"61aee4092283c67d02e54111c10bc566bc48e470888f3a6719cc1491bd153032","impliedFormat":99},{"version":"848413d9d679929c63161fb1f28f6df6dc6d2de057cb6e63ca0091ad84f1abf4","impliedFormat":99},{"version":"ec0860d3af71ec05e7b64a66e00ef3d93a3b7e3a47a5aabb3b5287366c932b7e","impliedFormat":99},{"version":"9973f2bb033798c44f6723124957466b58a050a47f3327fe5eef48a3a81635e7","impliedFormat":99},{"version":"ad0dd8d0f68236cb000f06f8d9d8e0282918d5f9208b0ae23fc33c8c2a39c3d3","impliedFormat":99},{"version":"c30644883e1fd1e643a8500b97ce49d8ef95f61cb9971fb6978f4f3ff63b0322","impliedFormat":99},{"version":"35406f025a591674e32f4144b8c3fd48645042bdcefa5ec987c5114e8c1159a2","impliedFormat":99},{"version":"f252ef09603db5db7d4701c84a45ab4a00395d41f41f33e16eb01b8d4c648edd","impliedFormat":99},{"version":"f83fa2051c8c4c23bb4e4fbb8d8dffe498ea23536ed7eaa3d2c6a57e88d39bb2","impliedFormat":99},{"version":"69367ea67e9d60d2777ad8fcde58467c7e1cd9c07e5cbc49284a92d0398e130f","impliedFormat":99},{"version":"cd79409534ca0e391e7c4d1df0901069a1a21374141cf49f651439fc1d544b79","impliedFormat":99},{"version":"3ce35452520daee30c080aa24077564c83a709c612e5756fe2c85236a6c866aa","impliedFormat":99},{"version":"9c823c1ad764769d7499ee748e67deacf76302c7663054a5f1866decd0f1115e","impliedFormat":99},{"version":"4fc5afde3c92f7237627284d009ac9bc15e6c10d9efa741cd2320c6b3453515b","impliedFormat":99},{"version":"6a07ba30908ad95dc690755101072babf5dbeffee8f65f2f29ff3ac67ee14034","impliedFormat":99},{"version":"021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","impliedFormat":99},{"version":"28c3c304dfab7028725b6c183fae6ab63cd616a142bb0e88abeb084e0fd11b2a","impliedFormat":99},{"version":"2cb3ba6b919393c69e0acf8683f6b5dfc831a421fe29c768a263d52961f32384","impliedFormat":99},{"version":"6037f40d5ddecc221ce1ec233d6872ee98f478be706321abe7ee954ee5ca2d5a","impliedFormat":99},{"version":"1a3620b673cbda5514238aacf42657fca59232dd8a1e76fd0b530c4092900973","impliedFormat":99},{"version":"f9c2491f24300401901b44c2a3c0dcb23c23327f293ffa2042535aac41d6ac8b","impliedFormat":99},{"version":"021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","impliedFormat":99},{"version":"8bdc4c6d2d24a7bbc7e224be54e6fc11082162e6fdcb982a75fd565d48fb1b0c","impliedFormat":99},{"version":"5e1ad0763d3a3b5276301157c8a2d6d246469162a1f777274ac772259614f1d4","impliedFormat":99},{"version":"021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","impliedFormat":99},{"version":"be86f4b43f294650b702fa56ec74b80abc8996fe9aa827753de8d1cf557b605d","impliedFormat":99},{"version":"2af11fa3c25ff650be8197090801e9a657b76eafe4dfc89e916f71d7eb122b2d","impliedFormat":99},{"version":"85869f1e603b27f51671459a4f98f540f472a2452c337214a023483c4f0ba717","impliedFormat":99},{"version":"858f82bb3501bc4e3ec08c4d9f8035768a62549d4de42804600e9eb63a475e36","impliedFormat":99},{"version":"b6e4b2df38794096aba6944a0941accf45da9b97d2da719dd8a95d883b0fc7b1","impliedFormat":99},{"version":"023683fdc80a7f5c8dc1426427f328373aa309bf28be20bb7ff9b5fe1a3010c3","impliedFormat":99},{"version":"93d28b4eb12c68fccc1f2fc04a4ef83ea3b2a03b18055d3bf29cab267aa7042e","impliedFormat":1},{"version":"81dc23d5f6728d5bfc366a79aa017d83c0c180989cceb4faa570555038436200","impliedFormat":1},{"version":"5fa5ca164fea16db2c611d502b3f5c82c1f02417507de0c4debeaf924f771a7a","impliedFormat":99},{"version":"09ba4f33b0f77d1d78b10d3acdb6d0e5cdfd50613cf1882e6b7ae6bac6cb366e","impliedFormat":99},{"version":"4b1b6c49096a68c461f721ada7092cb0b2ea5af3487fb4baf7b3fc8b9ddfd72a","impliedFormat":99},{"version":"35dbd536df4bd1fc9e1c9cea51b754c7939d3246e5d7b758e8107318bf612e5b","impliedFormat":99},{"version":"ffbd9bca2be5714390a6616745f532a57e6b7fdc9b8501848a04a1e7c305a7ea","impliedFormat":99},{"version":"3df4f4977a0ff52ad829b6cc94ad374c0c0acb935e55abe87063f2b59016f0ee","impliedFormat":99},{"version":"76363ee0ff4a535c4610ffb2218d3cecd84f480f6be08a4a95a0fdc2f4887e1a","impliedFormat":99},{"version":"c024d9facf96dc8b416a033b160f30fffea900700f3f2bd238b1a31b67449769","impliedFormat":99},{"version":"7a2e7c19fbfd3ca11cd3fb90edf4fc3adf379bd31da785bef41f34a5c97d18c0","impliedFormat":99},{"version":"f4f9db86be98abda0930205133aa386c24ca11f277cfc0d0f1b0fa2de23c6bae","impliedFormat":99},{"version":"11004bbba9c301e4c60e006ada6adb81b0dc14c648b0c1e01f19439d1f776719","impliedFormat":99},{"version":"afdc6e7f37a50777eb39afec605955227e931a658ef1fa521faed16973e1deed","impliedFormat":99},{"version":"afaad0bb62b562a94dcc058825ea7ebf186521024c516f7b0c98bd08a35b1336","impliedFormat":99},{"version":"b50b9c126725991530c65ef84701450c0e3cca4d7c9d9caeb6a3806b69c0c6c4","impliedFormat":99},{"version":"568ea0e68446d5ba3c9f511a3a89d2c2c3eb2ec9d71f9c38a692fbb3915339ee","impliedFormat":99},{"version":"8265e7d6b8b26a3883124f895202fb4b5b65549e1bd6fac4478b1c0914dec628","impliedFormat":99},{"version":"d13af6c285e514d9a6d136128c277caaf18654a4244f57de4f2a62c8e620782a","impliedFormat":99},{"version":"10c73797d5742c71db4b536a8ded2319754b0fce698625210ac650e285e2a38e","impliedFormat":99},{"version":"021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","impliedFormat":99},{"version":"e35123612375690f4775f422f76fc191015f2c11247689af818691e0e7cf186a","impliedFormat":99},{"version":"d879775003b6feb704931bda5f4d8767a7c4385487180795e49e39fdedb80bae","impliedFormat":99},{"version":"b39c4be45e541c41e74a6e1e98bce5f87c81ee0e349a4f443264ac6db68093cf","impliedFormat":99},{"version":"cd352dca0687583413c65c64fd7d4145c9dbe51206f2c5ada38a6114f3aeff84","impliedFormat":99},{"version":"ec70a684935852408686d32ee9d351c154a5fd95b3274f887685172b65ba721d","impliedFormat":99},{"version":"c1022eecdc3f6aae6e93e452a68f46dc7ad45924c9eb47c2a92540fc24520f1f","impliedFormat":99},{"version":"94e838908103710c131fe491b0ac30143fd6224d86ec526a6d43220b658857e8","impliedFormat":99},{"version":"f3b721c00165d7fce0ff106c2bf3b4ecf9ca0eebc83db98998a7e8f8a1ccd1db","impliedFormat":99},{"version":"4cffdeb4fe0cdaed0dff5efbbf1c76b09479f97bb3b70c542174abcf9f4f0c3d","impliedFormat":99},{"version":"f1409ca7c84b6bb8e4470b6fdaca0701a5a260d8a229d123720333be6edc1bfb","impliedFormat":99},{"version":"2dad866a6b54b13820fd5d46709ed7b2f11af19414048a1f0ed9c8bb7fdf8afe","impliedFormat":99},{"version":"3661088f65668cf69edfb1fd5fd7f3563d8a224cd2c35e0b198240622d205865","impliedFormat":99},{"version":"b8e65d8c2faf5a2b96c51bc92dc75bf0a359528dcc0c6f970f5d5c0f834882a9","impliedFormat":99},{"version":"7aa143ea57c75b21ba2eec71acb162b4378ba74909778c0410e35e94cac6ed41","impliedFormat":99},{"version":"021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","impliedFormat":99},{"version":"03d1384a8eb825f29933e631db99bd1685ee058cc2764d6c8a60db1d02598407","impliedFormat":99},{"version":"abff08bca8d9c32926713b2f941dddc5309a7fc8f24f741d03b3044f8549888a","impliedFormat":99},{"version":"d1bf6ff2b40bb2ca030836a8a0f255d4ac0d5027b777a254ec85f0cc1faddf0e","impliedFormat":99},{"version":"f63bb0b18912e54251237b83754cb5630a8866eedd93ef2e366584b4ab7e62fa","impliedFormat":99},{"version":"2ec363e2c7fe514d6db7da8a8a6177e5aeefbb619d96650dd242e890aeca2645","impliedFormat":99},{"version":"d53323b449ff5dd1273219251cf9f4e640747f1ae322d1af861cd8bf536e0c7d","impliedFormat":99},{"version":"c8d7aca18f8446d801908ab8025dd241aef7ad6cd83843663b6271e07acfec24","impliedFormat":99},{"version":"7f52f6bbb7e0bee51f540fd37af9c33c420ebc536539adf376a5905f04edf7e0","impliedFormat":99},{"version":"625001813cf43ab48deddbcab9cf61453ccf6738fbfec0952e38707e42822e3c","impliedFormat":99},{"version":"ae8073201d5105ed350ae644a0a1951ced542daa51a4fdc75794a37e44d93da2","impliedFormat":99},{"version":"da713bcf397e56564f24a6173f6c4e001f8302051929ba729dd8eb040ed88a82","impliedFormat":99},{"version":"78781534bd73651a42c096bd8764e099506278b61b93099936b7d27b4db9d51f","impliedFormat":99},{"version":"63570617a6e436ee3cc7e6145bb2116f83807bb76e15afaf2189d9cd19219fb9","impliedFormat":99},{"version":"4fe38776dc95dec6af4d924850d428ac1b0d36a12773f747cdae5cc4c8808296","impliedFormat":99},{"version":"576af7f1374ffe097f26a45785e50fc385755e3abf400871df12908b26c43dfb","impliedFormat":99},{"version":"667faa1825f96b88b7857877d174032a524e89aadee6656ec2d4d1cf82380f31","impliedFormat":99},{"version":"755d095832368c6d9089b9c612cd0d4d7b653225f303b12c77f79f086c3e6132","impliedFormat":99},{"version":"890c6fdf5390cde4221af694f983ea7f8fbfc9ace318af44ca91653b1a9ffd14","impliedFormat":99},{"version":"8e91f935865167fbf71b399969c1c87b90a45357d312a448e953030b1e089b39","impliedFormat":99},{"version":"021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","impliedFormat":99},{"version":"433c26f78f3ff2c7adace5737716ac2285c3a05594b011f5a4b4dba41a427360","impliedFormat":99},{"version":"7da1ca657f036a4da52da123265514f1079bc60f7dfde82ea85aa28f27c63a40","impliedFormat":99},{"version":"bf53e39fdecd468850414af07462355d091d4c1a6b4533830a7094d30370d2a2","impliedFormat":99},{"version":"24c63dd5d622f149c208c30e72e04dda61db9c47c49c00cb5197c0964d2823fa","impliedFormat":99},{"version":"7785fa1bf42df640a28e1a5ca7a3f2c4a2b2f72926749e5ea37c6f60ff4ac0cf","impliedFormat":99},{"version":"759fbc8ddc4fc784f7b9141e2eef7180659c196911d71295d2e8448cb94bc831","impliedFormat":99},{"version":"09ee43ae7a402f4c062ecdd56652b08adf1a4f58f7fd54b95061aef64d6eb18b","impliedFormat":99},{"version":"d95ec2c1f87180efd1985f1a23051f8f058ffe051ebfe0b4b71f74caff96f7c0","impliedFormat":99},{"version":"6b7b2aa6b0d588f6eaf48db8998721222ac97a80c47feea3c98011634d0fb62c","impliedFormat":99},{"version":"5fde1d474cb425206c2bee4a5daad3ea5f3a076ed8321c1978bcfa0c70120c4b","impliedFormat":99},{"version":"be684eccf9e47a66098aeaf58e3fa0042e3759b43768fedfade3cd6232326861","impliedFormat":99},{"version":"1ec7cf5145caf91c45a00e641b766cf2657cc48c09220652660737235f7bdf97","impliedFormat":99},{"version":"e28f754ca99523d5cc4fd71d28ca62706588511eaeabebe4b0de51abce4b3bea","impliedFormat":99},{"version":"f594ccc1a1fdabf6ab0b875343e827c2a359ad45a5c141c0b5eaf1ea61ffaefa","impliedFormat":99},{"version":"021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","impliedFormat":99},{"version":"94722c0ce2c348208e958b939ff9b898b7bc0607f3c149a146e25447fc98ac80","impliedFormat":99},{"version":"c1549fd16f2765b4735589fa07bcc12664fd1ddb077ec392f5a2341210fc300d","impliedFormat":99},{"version":"de463e4e94423b5a3fe6dd5ecdbb956e3d8059dbc7d596cdda5e35cea1f7735c","impliedFormat":99},{"version":"1c83b27d92088815dcdabb94a0aacb5003cfc817afe0102baa4d37d776b99b6d","impliedFormat":99},{"version":"58c1d7604faeacf5b0581183077e65ec53bd82e49d09d35506f7073ca0efd129","impliedFormat":99},{"version":"a19d3b4dc1fd282420c2eb391a16671de2448cee11e2792659ef9ab32e1a68e1","impliedFormat":99},{"version":"19c8c28ff48cdc8d9f3dad0d59f66205508a35f436be4ad41478d7f3ca142dba","impliedFormat":99},{"version":"a9b7e861a9d12ed0d2d32072b530920f6c2cdd1678b887dfca918b284bc0e39b","impliedFormat":99},{"version":"eba603682ab2e7f819bc6562d46d45720b89e70f0e5bba78d3226f423fc9c6c7","impliedFormat":99},{"version":"a7f07680a8aa67c61dc19ed9a9058be4a1e2b2b11b8bdec1d1057466d08ac1a9","impliedFormat":99},{"version":"e66955b0b42e7f1f20dc42076569e42eb2c1da7e06468bdfab0a387408881b82","impliedFormat":99},{"version":"b4069f9aed4198c69b20a8daade43c0c7c5b4a49c06bf2ebe9584cd8aa025f94","impliedFormat":99},{"version":"3833e686d7df5b4fb1c3fbd8b62bc8986c5a1ba2f63a7f50b92ff9c443aefd15","impliedFormat":99},{"version":"efd5bede1fde7e0c6ebb1e83d5ccb9d3d6a17e60f132c71f4168678935c58c4b","impliedFormat":99},{"version":"311e82e0ff986d6401764585f96776ef9a9e2acd0e087e722a5849a731f14682","impliedFormat":99},{"version":"20b71d238301ca7204568d3d66bd86aed63d091cb16493cd2d072a329eea6f46","impliedFormat":99},{"version":"a6b9638bfa99955f5aabc8557fb882fe42879e15a38db0a13a0cb3f535d7f547","impliedFormat":99},{"version":"ae6a13337a9d1e4d2652d702a05bffadfff726e2713ee4388eb6f26b8330b804","impliedFormat":99},{"version":"caf4ff1b378b920addc5dfc24e4f1c16d68a4f06f00e012732f05eaa9ad2d25f","impliedFormat":99},{"version":"cfb245c719e0ea0bbcd640d9b65f94e12706b63f0fc950d860770ed46d83264e","impliedFormat":99},{"version":"7a47653ca382f75c9ffb4497e8c54e0b7ca8f4dcfc7b168c7fd2250eab893da2","impliedFormat":99},{"version":"0e97456057e413a64f5a103df512abbeebfffa5c69445c5df0471cb89cbf699c","impliedFormat":99},{"version":"46cd205be3218999d1ec27620895a3ebd2b70000fd11cc29f32f1ff0620e7794","impliedFormat":99},{"version":"4055718568409184cbb834346d74c6be4b981d399cc52163a60443d0f57d491a","impliedFormat":99},{"version":"dec7349c2cddaa1793c1179db1bee327a8a138e1def11c2d9cc5461704420ff9","impliedFormat":99},{"version":"53cdcfb57c6c06401e7656a6bf6a6f31e1f5f975f9d8dff4abcec4ef331ce9f2","impliedFormat":99},{"version":"21a13cda8bb793012582d06c260c6e81a5574417fa2ad280531f9f9eb0de80c0","impliedFormat":99},{"version":"7fe63905dd2115a25ede4f6da6a835560edd44a953509037a686a3af1dbb027c","impliedFormat":99},{"version":"c4235c8d390dc610c1afb57371df39705735318bf47497bcda92fc292f3a819c","impliedFormat":99},{"version":"8143252207f3e662603fb191a62cfc33e6910b09ff2ecc99a9e6258eae867a8c","impliedFormat":99},{"version":"6790f423c74646a936e15c7040c674ffeef6c5fda2c690b25607fd25b206b6db","impliedFormat":99},{"version":"f2181c6ddc831bfdc69e7b08c57340fcdc3c4def65cec00fbe7367c20e2e3cbe","impliedFormat":99},{"version":"54f200358938db4592ef064cc70575b5b93782b2a1e9a4f3ddb725cb8585c2a2","impliedFormat":99},{"version":"97c213aa8753e0a40f74c465dacdfa6f0481ef79fc852ec417fed051819e5080","impliedFormat":99},{"version":"4f6da11b3a981f0f61a3285ee7328fa9fd278cd5d894311eb3d32d3fb851f73c","impliedFormat":99},{"version":"4c3fe1c1ec258e4a2e00b36be83d69434cbccbe0df278b750ffbb285c019d991","impliedFormat":99},{"version":"2f0e2bd23bb1ec390a24282ace30b7957ce8fe52a208d753ea9b5fbb07be7cb3","impliedFormat":99},{"version":"021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","impliedFormat":99},{"version":"8ed23cedf0da030d9eaf0a2264b410a519b6368823c28e84c42370bc53a6df91","impliedFormat":99},{"version":"f338a331fc98b7a1f203f27b72934b22157bab6e23102f005b09786dcf383668","impliedFormat":1},{"version":"7336bc25cc72933b720c3bef0cb3087991aa27844c83376fc3fe36a824d7a8ed","impliedFormat":1},{"version":"cb45b2d61ca2a978551d75614ffb129a4386b4b3b59dc7d05d5c721f6da97684","impliedFormat":1},{"version":"1070df8aa24c5dd2823080a2882e5d09fb86fcbfc0104ccba13326121233de3f","impliedFormat":1},{"version":"2f1b2648a9ddeb7af4f497573aa751c99adf6ab11f40b554527f0f65fa5e39a8","impliedFormat":1},{"version":"8bb104774ea2cd12848b1ecae4c2933f76b876ec4dc21160235f47a25ce9701e","impliedFormat":1},{"version":"5aa6397b22f8a04f8e5d97b2c08bb7038ca611363da1fe8e1174aa7114022248","impliedFormat":1},{"version":"c12cfe54ae9534e67fcef5c56efa1af3433b3dab19277866219e150a53db7aa6","impliedFormat":1},{"version":"63c4a0b4eb97c1f17198ffac8e868c2ade94bed702a93f364fb0de5459244a37","impliedFormat":1},{"version":"17797f8fd9ef3af7442b58158ce901230538678ff4f776d1bec3396ea9a7db61","impliedFormat":1},{"version":"b223ca15aac3a161f9f7eb5f7df3c98da26c84ce16866374d7919d196728f054","impliedFormat":1},{"version":"e197b79669e5e7a62be85bb55a2c4b0a3935c9c21031f16b4801f9c1424fc7de","impliedFormat":1},{"version":"5c359ff6b9f27ed265bb87736679ba5eb9ef83d356e72f57f207b7b1faaa2be1","impliedFormat":1},{"version":"244159bc6d99d3f66d2e4233c45fb688f4eb5d753183df4f539bf8f32c8f1330","impliedFormat":1},{"version":"964cf42a495adc2cc2037613f43522be40fc82012446fbfa4a0c4e3cef2bb97e","impliedFormat":1},{"version":"b482831de35852ffa394a8070061c4894b171857018d052a9d24d8684a8e99bd","impliedFormat":1},{"version":"df5ad3e5f00364b3f1beb243a4ce7538b0cead886bfc7c9ef7a6b4084d120bff","impliedFormat":1},{"version":"7b029c55b78626c3d13bccb4b77dd75047b73d84a7272405a770c3bab61bff15","impliedFormat":1},{"version":"c7c0b008caa3b7840ac9c52ee5ece3a36b65047ee12210dd2ea5276147a3a2ec","impliedFormat":1},{"version":"8d69c50f39132a4e9290f41cec755fa8bfa559362fb126f599409bdb6d8a3c7f","impliedFormat":1},{"version":"ef7263161d377d39bd03f1d6b0b888db7641067a331f92e0b522108e88be9321","impliedFormat":1},{"version":"a6af53ae0a4603cf6255dbd8bb4209edfad8e952bfa762684033782a28f68272","impliedFormat":1},{"version":"cbaac46ec418641fcb50afd7d0c8bf9462b6f7ca83af24d1317659a721175e2a","impliedFormat":1},{"version":"467c234ece0262e142939e2740ce970a71e7dca4adeeed872f0797fd4c3b34ac","impliedFormat":1},{"version":"508d1d9d7b04b090a99cd0ccf53b7e1e45ec2f96577b34e60fb9847c3d612efb","impliedFormat":1},{"version":"c6991234729127037d9d3653d89f1c8097caf2e22bf07bd603df5bc324b1c2ee","impliedFormat":1},{"version":"e1c249a691a5debf16ec5d8127c4b34f2bc12621d626a332cfec3d2592a317f7","impliedFormat":1},{"version":"6dba67434473193e6248d4db56aa0a23eed8791e861c863b36a4c347c5c9a307","impliedFormat":1},{"version":"6dcb16b880a06d2dd2912d2ce33c6f5bb09f4e7fa0f94090595caabeeb5454c6","impliedFormat":1},{"version":"a146e3f554d4f4eeb8fadf905892103cec35a60690c5d0437f65d1a5c85ecac7","impliedFormat":1},{"version":"65415fad6e906843d03b4f9ffecc427c7264a7b99824d95600f3ba24b0e8c511","impliedFormat":1},{"version":"ad12999de217ddbea616ff753af3f34217e717ffa9c67b62ca777e35ab3c5874","impliedFormat":1},{"version":"461f9060dd1fe58a9b79f5fa482fcf82580c47f58418fa3147ae2dd71dede99a","impliedFormat":1},{"version":"feb85f66b299d0c7379909f145010da50f187b4a87c9d3959d04fbdba4efe2a5","impliedFormat":1},{"version":"6b0004f4263d883c0428f6bcb6c777a50ea1b898ecb0ad624bf4f2a459d8cf80","impliedFormat":1},{"version":"32548c99315cdcd18f2d35d4874e86d3a65ab2b5106a6f01282a36a458c90b0e","impliedFormat":1},{"version":"58ca0005765de377f6af7e4f16e8f6e57a058ea2b7a732f7912807e0ea382ebb","impliedFormat":1},{"version":"2a6bd474eb954e8c55f890054787bbddd9b2798d298e743ed21758df69b5a303","impliedFormat":1},{"version":"abf6816f679f726d08e6732d433c94482efcd2a047bfbd7269d4ee8e56bbea13","impliedFormat":1},{"version":"3db678f64a08de6ed4971ae67dc59f70cbd810c67e15bc907f71ce71e5f61646","impliedFormat":1},{"version":"95578005d28f8532878f92217ac977b95dd3f61f45a4db882969e90dca98c28f","impliedFormat":1},{"version":"93d28b4eb12c68fccc1f2fc04a4ef83ea3b2a03b18055d3bf29cab267aa7042e","impliedFormat":1},{"version":"d8f1ffaf53542b1c5889927060616a3b36495881ece29b8e38b0b17a5bba1e63","impliedFormat":1},{"version":"d40f28fbc898cd4a152834c3838d26acb6447387958413a3e1a1bacc98e9b03b","impliedFormat":1},{"version":"3cf26bbbaa0f35f79bc74cc80347663689014af5637e09c07f88ceca8f50a4fc","impliedFormat":1},{"version":"c846f48f4361e54596493f0e00e6061aa7deeec84fbdcf74c302e1e83035ce6a","impliedFormat":1},{"version":"c603d9797601ceef13a55f78658c8fa2c4713bc9b7fdee6849115b9c414972ab","impliedFormat":1},{"version":"c09cc09af6c63564aaf8882cd1ad4522400930bbb3fcb2bdcc99d23c5f8d247b","impliedFormat":1},{"version":"3946f68bd37bad2765ea915e4aa750d30909a7bdc3012c030e1dafacced4b0a1","impliedFormat":1},{"version":"29b688cdaf703dfe8727069bcc384c5dbe6658e975152d42a873c8f40d324088","impliedFormat":1},{"version":"f973eeeb6c6f24a698824ea8b3a104632c82ef985143753d8ed4041ba948fdaa","impliedFormat":1},{"version":"94cc2d7bc4e0bb60472a4d1339d06072cd06965a58c335b609336c01795a2de9","impliedFormat":1},{"version":"001050d2385c4dd19b7043ef1b410dc22e1ac015e3e8dc2f312e16d1ad47a13c","impliedFormat":1},{"version":"c43867a3c095c21039c931980683d74c112f383b45b6a5b8a162564adb10643c","impliedFormat":1},{"version":"d380a790875c51668a846e69ef594be09715731f18b8e24bf6191ccc5dc96db4","impliedFormat":1},{"version":"68c6bfbcc44ace7fe4bbcc55810460b7356235624dc15ce7116e312eb8266c1f","impliedFormat":1},{"version":"0fd5c7cbde56982de70a99695bc4bfd7c6b30d9f3eab4bbd7770cc6442517914","impliedFormat":1},{"version":"43d3a46ed3aafbce9d061a5bd9acc5bea3b492b9a198092d7c52df51eb4a0865","impliedFormat":1},{"version":"259aa02b58eebacdc00fb938f402c7228b2f540809a3e4b6cd302defcee4b92a","impliedFormat":1},{"version":"29accd4fc02fc3278fe31791bb6d42612ca54b1f1541116f78a404941e79cf7b","impliedFormat":1},{"version":"027a206c5d144c662f6fb51da30a7e50f7dcb7fabc4dc174034c0f0f0858c32d","impliedFormat":1},{"version":"53869260ad4b0471e55efd292ed86dd522b99f5f1da0a0430709accda8781634","impliedFormat":1},{"version":"539c78bde44b8b6a595df8e4ddd3a9c5a4952a66aeaaca822515b312ac7ae3d5","impliedFormat":1},{"version":"1fe8f0c13354c3939901e103ab22444de77b9e4aa6337e6fdaf2e4c3276fff45","impliedFormat":1},{"version":"2b86ecc37fe743c9cdd7b0f602dde4e82df61e65f8b967ed6d76d4eea337d81d","impliedFormat":1},{"version":"4030b77e9ae60454573a3719eb115cbf2011e77f3ce3cfb6e3fc5472d760cdf8","impliedFormat":1},{"version":"d54de56aae4ea724dd68867575ec03773571d1da9021d2a3faf1230ea7f5a833","impliedFormat":1},{"version":"144e4a91dc7f7037ed34641eadb23bd804d97e2003f6127d396cadd6fe036dd9","impliedFormat":1},{"version":"0eaa5c5acab4c493c1b6205679fd55a3040f1e64d3104f658c1e34f3de0d9c02","impliedFormat":1},{"version":"4a1fc61a141cd286d75516879952d8de019e5e8f89ba91dda0ffb20259c7650a","impliedFormat":1},{"version":"e58401ac759eca62a971022e1c2d4b19c5cc142b3118c402c1de855dcb38d221","impliedFormat":99},{"version":"526afd4a3d0b0553efcae2d3afd994b803ad2eca6df72d5a871dbfe36909bcdf","impliedFormat":99},{"version":"4ad360917a549b72b951cdd935b7c692ec6393606573366a1c0af3194881246c","impliedFormat":99},{"version":"58d79e2ace4d50f42ecddafd1662f94ec0b8aae0f386a29358d9f25282a3789c","impliedFormat":99},{"version":"477de575189bc1f66bb778cf94b5f97db92e5dd55d76815649aa618e18d7f17e","impliedFormat":99},{"version":"8a4de9ed3e190e97a429956d8c315cf3d671770632df4b16cd1bfb64af43f9ec","impliedFormat":99},{"version":"91f0bef0fa97508e4aa610cba632816aea98a2372be7c603a3ec66311c523346","impliedFormat":99},{"version":"0724b126a8fa0aad75d3c921e2d810e6b1f6c1fd657f31db2634af19361bc9aa","impliedFormat":99},{"version":"cc8644818aef417ff5a8dc6b4e3714a52f9fca942b962bca64975873d28e27b6","signature":"211b3729f5d53dc1ae9438a1259462e3ffbe18559840d03202389b5b9bc8f05b"},{"version":"20acd7ef78c8b89ea34f8f90a46ecae7f280f30d7240f59d2d9c5ab1c7b2c4bb","signature":"98396d6c7b713ce83dc725da48f052da0774179ae72394790be9044599e45fc0"},{"version":"e448470f0003444191b0a6eea8471959bf37c52f552248ae1588764cfc62d2af","signature":"f912b6858ffdf3d1b472aa6f1e86f732def82eae199b6be293bd96b07572fee3"},{"version":"14f5893b90b84ec02fad9860e9d3ae7d84a8914fad3241d9c5dddf285b225fd7","impliedFormat":1},{"version":"9b7818d17b2cc9e053b7c808ebe1ef3e4da2a62763cfb115c4f29811bb3bb709","signature":"0f6c04cf473b670db1a519d2558fbd767f03fcd0a44a6b9f8d49d1b28f0fa26f"},{"version":"3f38769eb2013b946660ee3d7716bb7c0d7e30d91f8f142d917457754617b0ec","signature":"913a7e3d56b9fc3302dbd411d52c6b68b771ba9bfaa57bd8c8aebe811a0f6de2"},{"version":"fabc5ff5586c7c7352b6aad52e7114dccef1ff9a89be998a3eb67b041a4aae1d","signature":"73f355f92eae7416ae0199acab0826902aff00adb8fde07fc67b6c0c4cb0c4a1"},{"version":"61980d4dc9abae55160593deade0816710922b91f7bfbc6ceacd867f03e75ed2","signature":"508a43f63ad35f4e5286ee159f3e60216de62bbee414ea7e30c46eaf553394f7"},{"version":"451deb2aefd37fee1599d2ddbe1bfdb53275f82812795cb0b0e95b7a1265d1a9","signature":"37c7f02de6cef06512bcca0b9fd53b846f875be78461a14d201ce9bfe527cf9d"},{"version":"fcc1ccb3cf7f6431d1cebe41313989030bb1c62abe82331a507a26d62977577c","signature":"631a6d2443af5033e504d829062a6bea14ad86e723c2796210892fca889661d6"},{"version":"1489fd982948c580df8e2b1e013001820bf6b4c6f968b93ca12160e1b8a89d6c","signature":"f8012cbb6534562eeb36fc4ec956d12e307bb68fc0df74f0d568d841b4752827"},{"version":"186cf0c8651fd6172fe0b5d817972d0458b10bf2f22c6e12c8aac8c8ff23f758","signature":"bb76308a2ead74ae19763e205bc418b29d7181923ea4330b4b470cb14d1765e7"},{"version":"79935a4454e91fd0e74799645ddc0c388eac97fb601a209cf441fa41ed83086e","signature":"391428d66877aba3715f6f4db8ac2dd1ad52f1e26f09a24349eaa466ef4be629"},{"version":"6f9c84b6cc24a7bc245861cb700cecf1a751be725058391fc499f1e846d86a54","signature":"72af8499fca304d9b289d42464c6d9e258b38ead0b89e954801430c478d86f9e"},{"version":"79a549a8f558236dd3c8f3626740ac246764adf9ccd71770b7c165eafb050900","signature":"754e86d1b23d6d1cf65c3eed09af4a969189dd4a0219c19caad54ae857523624"},{"version":"edadb38204d9b450eaa399f171ddb6615189f2c16650e2d276a588d92bd103fd","signature":"09ac86f4b6777c0468b650f636c9fbd278c7eab430d27610e958d063165dc9c7"},{"version":"31e8ef42ca69b7ba5ecf0e619eba9eb07292dc4f5a15ae664cc50c5f0982dccc","signature":"d39f64ea67698f4dc89194ff3682744065a1ce72f9ff2bd8bb0629fb2e38f6ad"},{"version":"299ac08b22bbd848b91f476e7e6206b7bf02cf7c922d017f7c6d2b6167b16405","signature":"50cecb57d248e63cd1d36e25f3e96cacc165cac4f2544e2bff9ed13049aaea72"},{"version":"85e015a0a95b81409629a30294d1bbe928219c1add01066eb6729b16e2cc2d94","impliedFormat":1},{"version":"f3d8c757e148ad968f0d98697987db363070abada5f503da3c06aefd9d4248c1","impliedFormat":1},{"version":"70521b6ab0dcba37539e5303104f29b721bfb2940b2776da4cc818c07e1fefc1","affectsGlobalScope":true,"impliedFormat":1},{"version":"030e350db2525514580ed054f712ffb22d273e6bc7eddc1bb7eda1e0ba5d395e","affectsGlobalScope":true,"impliedFormat":1},{"version":"d153a11543fd884b596587ccd97aebbeed950b26933ee000f94009f1ab142848","affectsGlobalScope":true,"impliedFormat":1},{"version":"21d819c173c0cf7cc3ce57c3276e77fd9a8a01d35a06ad87158781515c9a438a","impliedFormat":1},{"version":"a79e62f1e20467e11a904399b8b18b18c0c6eea6b50c1168bf215356d5bebfaf","affectsGlobalScope":true,"impliedFormat":1},{"version":"0fd06258805d26c72f5997e07a23155d322d5f05387adb3744a791fe6a0b042d","affectsGlobalScope":true,"impliedFormat":1},{"version":"4967529644e391115ca5592184d4b63980569adf60ee685f968fd59ab1557188","impliedFormat":1},{"version":"5929864ce17fba74232584d90cb721a89b7ad277220627cc97054ba15a98ea8f","impliedFormat":1},{"version":"24bd580b5743dc56402c440dc7f9a4f5d592ad7a419f25414d37a7bfe11e342b","impliedFormat":1},{"version":"25c8056edf4314820382a5fdb4bb7816999acdcb929c8f75e3f39473b87e85bc","impliedFormat":1},{"version":"c464d66b20788266e5353b48dc4aa6bc0dc4a707276df1e7152ab0c9ae21fad8","impliedFormat":1},{"version":"78d0d27c130d35c60b5e5566c9f1e5be77caf39804636bc1a40133919a949f21","impliedFormat":1},{"version":"c6fd2c5a395f2432786c9cb8deb870b9b0e8ff7e22c029954fabdd692bff6195","impliedFormat":1},{"version":"1d6e127068ea8e104a912e42fc0a110e2aa5a66a356a917a163e8cf9a65e4a75","impliedFormat":1},{"version":"5ded6427296cdf3b9542de4471d2aa8d3983671d4cac0f4bf9c637208d1ced43","impliedFormat":1},{"version":"6bdc71028db658243775263e93a7db2fd2abfce3ca569c3cca5aee6ed5eb186d","impliedFormat":1},{"version":"cadc8aced301244057c4e7e73fbcae534b0f5b12a37b150d80e5a45aa4bebcbd","impliedFormat":1},{"version":"385aab901643aa54e1c36f5ef3107913b10d1b5bb8cbcd933d4263b80a0d7f20","impliedFormat":1},{"version":"9670d44354bab9d9982eca21945686b5c24a3f893db73c0dae0fd74217a4c219","impliedFormat":1},{"version":"0b8a9268adaf4da35e7fa830c8981cfa22adbbe5b3f6f5ab91f6658899e657a7","impliedFormat":1},{"version":"11396ed8a44c02ab9798b7dca436009f866e8dae3c9c25e8c1fbc396880bf1bb","impliedFormat":1},{"version":"ba7bc87d01492633cb5a0e5da8a4a42a1c86270e7b3d2dea5d156828a84e4882","impliedFormat":1},{"version":"4893a895ea92c85345017a04ed427cbd6a1710453338df26881a6019432febdd","impliedFormat":1},{"version":"c21dc52e277bcfc75fac0436ccb75c204f9e1b3fa5e12729670910639f27343e","impliedFormat":1},{"version":"13f6f39e12b1518c6650bbb220c8985999020fe0f21d818e28f512b7771d00f9","impliedFormat":1},{"version":"9b5369969f6e7175740bf51223112ff209f94ba43ecd3bb09eefff9fd675624a","impliedFormat":1},{"version":"4fe9e626e7164748e8769bbf74b538e09607f07ed17c2f20af8d680ee49fc1da","impliedFormat":1},{"version":"24515859bc0b836719105bb6cc3d68255042a9f02a6022b3187948b204946bd2","impliedFormat":1},{"version":"ea0148f897b45a76544ae179784c95af1bd6721b8610af9ffa467a518a086a43","impliedFormat":1},{"version":"24c6a117721e606c9984335f71711877293a9651e44f59f3d21c1ea0856f9cc9","impliedFormat":1},{"version":"dd3273ead9fbde62a72949c97dbec2247ea08e0c6952e701a483d74ef92d6a17","impliedFormat":1},{"version":"405822be75ad3e4d162e07439bac80c6bcc6dbae1929e179cf467ec0b9ee4e2e","impliedFormat":1},{"version":"0db18c6e78ea846316c012478888f33c11ffadab9efd1cc8bcc12daded7a60b6","impliedFormat":1},{"version":"e61be3f894b41b7baa1fbd6a66893f2579bfad01d208b4ff61daef21493ef0a8","impliedFormat":1},{"version":"bd0532fd6556073727d28da0edfd1736417a3f9f394877b6d5ef6ad88fba1d1a","impliedFormat":1},{"version":"89167d696a849fce5ca508032aabfe901c0868f833a8625d5a9c6e861ef935d2","impliedFormat":1},{"version":"615ba88d0128ed16bf83ef8ccbb6aff05c3ee2db1cc0f89ab50a4939bfc1943f","impliedFormat":1},{"version":"a4d551dbf8746780194d550c88f26cf937caf8d56f102969a110cfaed4b06656","impliedFormat":1},{"version":"8bd86b8e8f6a6aa6c49b71e14c4ffe1211a0e97c80f08d2c8cc98838006e4b88","impliedFormat":1},{"version":"317e63deeb21ac07f3992f5b50cdca8338f10acd4fbb7257ebf56735bf52ab00","impliedFormat":1},{"version":"4732aec92b20fb28c5fe9ad99521fb59974289ed1e45aecb282616202184064f","impliedFormat":1},{"version":"2e85db9e6fd73cfa3d7f28e0ab6b55417ea18931423bd47b409a96e4a169e8e6","impliedFormat":1},{"version":"c46e079fe54c76f95c67fb89081b3e399da2c7d109e7dca8e4b58d83e332e605","impliedFormat":1},{"version":"bf67d53d168abc1298888693338cb82854bdb2e69ef83f8a0092093c2d562107","impliedFormat":1},{"version":"81184fe8e67d78ac4e5374650f0892d547d665d77da2b2f544b5d84729c4a15d","affectsGlobalScope":true,"impliedFormat":1},{"version":"f52e8dacc97d71dcc96af29e49584353f9c54cb916d132e3e768d8b8129c928d","impliedFormat":1},{"version":"7394959e5a741b185456e1ef5d64599c36c60a323207450991e7a42e08911419","impliedFormat":1},{"version":"76103716ba397bbb61f9fa9c9090dca59f39f9047cb1352b2179c5d8e7f4e8d0","impliedFormat":1},{"version":"53eac70430b30089a3a1959d8306b0f9cfaf0de75224b68ef25243e0b5ad1ca3","affectsGlobalScope":true,"impliedFormat":1},{"version":"4314c7a11517e221f7296b46547dbc4df047115b182f544d072bdccffa57fc72","impliedFormat":1},{"version":"115971d64632ea4742b5b115fb64ed04bcaae2c3c342f13d9ba7e3f9ee39c4e7","impliedFormat":1},{"version":"c2510f124c0293ab80b1777c44d80f812b75612f297b9857406468c0f4dafe29","affectsGlobalScope":true,"impliedFormat":1},{"version":"a40826e8476694e90da94aa008283a7de50d1dafd37beada623863f1901cb7fb","impliedFormat":1},{"version":"86956cc2eb9dd371d6fab493d326a574afedebf76eef3fa7833b8e0d9b52d6f1","affectsGlobalScope":true,"impliedFormat":1},{"version":"24642567d3729bcc545bacb65ee7c0db423400c7f1ef757cab25d05650064f98","impliedFormat":1},{"version":"e6f5a38687bebe43a4cef426b69d34373ef68be9a6b1538ec0a371e69f309354","impliedFormat":1},{"version":"a6bf63d17324010ca1fbf0389cab83f93389bb0b9a01dc8a346d092f65b3605f","impliedFormat":1},{"version":"e009777bef4b023a999b2e5b9a136ff2cde37dc3f77c744a02840f05b18be8ff","impliedFormat":1},{"version":"1e0d1f8b0adfa0b0330e028c7941b5a98c08b600efe7f14d2d2a00854fb2f393","impliedFormat":1},{"version":"ee1ee365d88c4c6c0c0a5a5701d66ebc27ccd0bcfcfaa482c6e2e7fe7b98edf7","affectsGlobalScope":true,"impliedFormat":1},{"version":"875928df2f3e9a3aed4019539a15d04ff6140a06df6cd1b2feb836d22a81eaca","affectsGlobalScope":true,"impliedFormat":1},{"version":"e9ad08a376ac84948fcca0013d6f1d4ae4f9522e26b91f87945b97c99d7cc30b","impliedFormat":1},{"version":"eaf9ee1d90a35d56264f0bf39842282c58b9219e112ac7d0c1bce98c6c5da672","impliedFormat":1},{"version":"c15c4427ae7fd1dcd7f312a8a447ac93581b0d4664ddf151ecd07de4bf2bb9d7","impliedFormat":1},{"version":"5135bdd72cc05a8192bd2e92f0914d7fc43ee077d1293dc622a049b7035a0afb","impliedFormat":1},{"version":"4f80de3a11c0d2f1329a72e92c7416b2f7eab14f67e92cac63bb4e8d01c6edc8","impliedFormat":1},{"version":"6d386bc0d7f3afa1d401afc3e00ed6b09205a354a9795196caed937494a713e6","impliedFormat":1},{"version":"75c3400359d59fae5aed4c4a59fcd8a9760cf451e25dc2174cb5e08b9d4803e2","affectsGlobalScope":true,"impliedFormat":1},{"version":"94c4187083503a74f4544503b5a30e2bd7af0032dc739b0c9a7ce87f8bddc7b9","impliedFormat":1},{"version":"b1b6ee0d012aeebe11d776a155d8979730440082797695fc8e2a5c326285678f","impliedFormat":1},{"version":"45875bcae57270aeb3ebc73a5e3fb4c7b9d91d6b045f107c1d8513c28ece71c0","impliedFormat":1},{"version":"3eb62baae4df08c9173e6903d3ca45942ccec8c3659b0565684a75f3292cffbb","affectsGlobalScope":true,"impliedFormat":1},{"version":"a85683ef86875f4ad4c6b7301bbcc63fb379a8d80d3d3fd735ee57f48ef8a47e","affectsGlobalScope":true,"impliedFormat":1},{"version":"3f16a7e4deafa527ed9995a772bb380eb7d3c2c0fd4ae178c5263ed18394db2c","impliedFormat":1},{"version":"c6b4e0a02545304935ecbf7de7a8e056a31bb50939b5b321c9d50a405b5a0bba","impliedFormat":1},{"version":"fab29e6d649aa074a6b91e3bdf2bff484934a46067f6ee97a30fcd9762ae2213","impliedFormat":1},{"version":"8145e07aad6da5f23f2fcd8c8e4c5c13fb26ee986a79d03b0829b8fce152d8b2","impliedFormat":1},{"version":"e1120271ebbc9952fdc7b2dd3e145560e52e06956345e6fdf91d70ca4886464f","impliedFormat":1},{"version":"15c5e91b5f08be34a78e3d976179bf5b7a9cc28dc0ef1ffebffeb3c7812a2dca","impliedFormat":1},{"version":"a8f06c2382a30b7cb89ad2dfc48fc3b2b490f3dafcd839dadc008e4e5d57031d","impliedFormat":1},{"version":"553870e516f8c772b89f3820576152ebc70181d7994d96917bb943e37da7f8a7","impliedFormat":1},{"version":"37ba7b45141a45ce6e80e66f2a96c8a5ab1bcef0fc2d0f56bb58df96ec67e972","impliedFormat":1},{"version":"93452d394fdd1dc551ec62f5042366f011a00d342d36d50793b3529bfc9bd633","impliedFormat":1},{"version":"745c4240220559bd340c8aeb6e3c5270a709d3565e934dc22a69c304703956bc","affectsGlobalScope":true,"impliedFormat":1},{"version":"2754d8221d77c7b382096651925eb476f1066b3348da4b73fe71ced7801edada","impliedFormat":1},{"version":"9212c6e9d80cb45441a3614e95afd7235a55a18584c2ed32d6c1aca5a0c53d93","affectsGlobalScope":true,"impliedFormat":1},{"version":"bef91efa0baea5d0e0f0f27b574a8bc100ce62a6d7e70220a0d58af6acab5e89","affectsGlobalScope":true,"impliedFormat":1},{"version":"282fd2a1268a25345b830497b4b7bf5037a5e04f6a9c44c840cb605e19fea841","impliedFormat":1},{"version":"5360a27d3ebca11b224d7d3e38e3e2c63f8290cb1fcf6c3610401898f8e68bc3","impliedFormat":1},{"version":"66ba1b2c3e3a3644a1011cd530fb444a96b1b2dfe2f5e837a002d41a1a799e60","impliedFormat":1},{"version":"7e514f5b852fdbc166b539fdd1f4e9114f29911592a5eb10a94bb3a13ccac3c4","impliedFormat":1},{"version":"7d6ff413e198d25639f9f01f16673e7df4e4bd2875a42455afd4ecc02ef156da","affectsGlobalScope":true,"impliedFormat":1},{"version":"6bd91a2a356600dee28eb0438082d0799a18a974a6537c4410a796bab749813c","affectsGlobalScope":true,"impliedFormat":1},{"version":"f689c4237b70ae6be5f0e4180e8833f34ace40529d1acc0676ab8fb8f70457d7","impliedFormat":1},{"version":"ae25afbbf1ed5df63a177d67b9048bf7481067f1b8dc9c39212e59db94fc9fc6","impliedFormat":1},{"version":"ac5ed35e649cdd8143131964336ab9076937fa91802ec760b3ea63b59175c10a","impliedFormat":1},{"version":"52a8e7e8a1454b6d1b5ad428efae3870ffc56f2c02d923467f2940c454aa9aec","affectsGlobalScope":true,"impliedFormat":1},{"version":"78dc0513cc4f1642906b74dda42146bcbd9df7401717d6e89ea6d72d12ecb539","impliedFormat":1},{"version":"ad90122e1cb599b3bc06a11710eb5489101be678f2920f2322b0ac3e195af78d","impliedFormat":1},{"version":"4c9dd88817e91f98e93c3445102dd3671748c8c523a5b3ba01c5b65af0db07e2","impliedFormat":1}],"root":[[60,71],[73,83],85,[328,330],[332,345]],"options":{"composite":true,"declaration":true,"declarationMap":true,"esModuleInterop":true,"module":1,"noImplicitAny":true,"outDir":"./","rootDir":"..","sourceMap":true,"strict":true,"target":2},"referencedMap":[[138,1],[135,1],[139,1],[141,2],[144,3],[145,4],[136,5],[146,6],[137,1],[142,1],[143,7],[325,8],[326,9],[324,10],[327,11],[286,1],[287,1],[289,12],[288,1],[282,1],[283,1],[295,1],[284,1],[285,1],[290,13],[293,14],[296,15],[294,1],[309,16],[298,17],[299,1],[300,13],[297,1],[301,1],[302,1],[303,1],[304,1],[305,1],[306,1],[307,1],[292,18],[308,1],[133,19],[121,20],[123,21],[125,22],[126,23],[128,24],[122,1],[131,25],[129,26],[132,19],[127,27],[130,28],[95,1],[86,1],[89,1],[87,28],[88,1],[98,29],[99,30],[97,1],[92,31],[90,1],[91,32],[100,33],[93,1],[96,1],[94,1],[101,28],[160,34],[148,1],[149,1],[150,1],[151,1],[159,35],[152,1],[158,1],[153,1],[154,1],[155,1],[157,1],[156,1],[202,36],[198,37],[196,38],[201,39],[199,1],[200,40],[197,1],[124,41],[103,42],[118,43],[117,1],[119,44],[105,45],[106,1],[107,46],[108,1],[115,47],[109,1],[110,1],[112,48],[113,49],[114,1],[111,45],[104,1],[120,41],[116,50],[102,23],[248,51],[232,1],[234,52],[237,53],[235,54],[236,55],[239,56],[238,57],[218,58],[217,58],[233,22],[219,59],[220,60],[243,61],[221,62],[222,58],[223,63],[224,64],[225,63],[226,65],[241,58],[242,66],[244,51],[227,1],[228,58],[229,64],[240,58],[230,59],[231,59],[212,67],[215,68],[216,69],[213,70],[214,71],[211,72],[269,73],[267,1],[268,74],[184,75],[181,76],[186,77],[182,78],[187,79],[183,80],[179,81],[176,1],[180,82],[177,83],[178,84],[185,80],[281,85],[312,86],[311,87],[310,88],[251,89],[252,1],[253,90],[254,1],[261,91],[255,1],[256,1],[258,92],[259,93],[260,1],[257,89],[250,1],[247,94],[321,95],[249,96],[322,97],[320,1],[323,98],[245,58],[246,58],[195,99],[147,100],[193,101],[188,102],[189,103],[190,1],[194,104],[191,58],[192,105],[263,1],[262,106],[264,1],[265,1],[266,1],[272,107],[273,1],[275,108],[319,109],[276,1],[277,1],[278,110],[274,110],[279,106],[280,1],[313,111],[271,112],[270,106],[314,113],[315,114],[316,1],[317,110],[318,115],[210,116],[208,117],[209,116],[134,118],[204,119],[205,120],[203,121],[206,122],[207,1],[175,123],[163,124],[166,125],[165,126],[167,127],[168,128],[164,129],[174,130],[162,129],[169,129],[171,129],[173,131],[161,23],[170,131],[172,131],[346,1],[291,1],[140,1],[347,1],[393,132],[394,132],[395,133],[353,134],[396,135],[397,136],[398,137],[348,1],[351,138],[349,1],[350,1],[399,139],[400,140],[401,141],[402,142],[403,143],[404,144],[405,144],[407,145],[406,146],[408,147],[409,148],[410,149],[392,150],[352,1],[411,151],[412,152],[413,153],[446,154],[414,155],[415,156],[416,157],[417,158],[418,159],[419,160],[420,161],[421,162],[422,163],[423,164],[424,164],[425,165],[426,1],[427,1],[428,166],[430,167],[429,168],[431,169],[432,170],[433,171],[434,172],[435,173],[436,174],[437,175],[438,176],[439,177],[440,178],[441,179],[442,180],[443,181],[444,182],[445,183],[72,1],[447,1],[84,110],[59,1],[354,1],[331,1],[57,1],[58,1],[10,1],[12,1],[11,1],[2,1],[13,1],[14,1],[15,1],[16,1],[17,1],[18,1],[19,1],[20,1],[3,1],[21,1],[22,1],[4,1],[23,1],[27,1],[24,1],[25,1],[26,1],[28,1],[29,1],[30,1],[5,1],[31,1],[32,1],[33,1],[34,1],[6,1],[38,1],[35,1],[36,1],[37,1],[39,1],[7,1],[40,1],[45,1],[46,1],[41,1],[42,1],[43,1],[44,1],[8,1],[50,1],[47,1],[48,1],[49,1],[51,1],[9,1],[52,1],[53,1],[54,1],[56,1],[55,1],[1,1],[370,184],[380,185],[369,184],[390,186],[361,187],[360,188],[389,189],[383,190],[388,191],[363,192],[377,193],[362,194],[386,195],[358,196],[357,189],[387,197],[359,198],[364,199],[365,1],[368,199],[355,1],[391,200],[381,201],[372,202],[373,203],[375,204],[371,205],[374,206],[384,189],[366,207],[367,208],[376,209],[356,210],[379,201],[378,199],[382,1],[385,211],[64,212],[61,213],[67,214],[68,1],[70,212],[69,215],[71,1],[73,216],[75,217],[76,1],[78,218],[79,219],[80,220],[66,221],[81,222],[82,1],[83,1],[85,223],[329,224],[60,1],[328,225],[330,1],[77,217],[335,226],[74,1],[333,227],[62,1],[65,1],[336,228],[337,1],[332,229],[334,230],[339,231],[338,215],[340,232],[341,228],[63,233],[342,1],[343,217],[344,1],[345,1]],"latestChangedDtsFile":"./src/ThemeApi.d.ts","version":"5.7.2"}
****************************************

****************************************
CommonTs\src\ActivityRepositoryApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * @module ActivityRepositoryApi
 * 
 * This module provides an API wrapper for managing activity records in a repository.
 * It extends the base Api class and implements IStorableRepostoryApiWrapper interface
 * to provide CRUD operations for activity records.
 * 
 * The module handles:
 * - Loading individual activity records
 * - Finding activities by search key
 * - Saving new or updated activities
 * - Removing activities
 * - Retrieving recent activities with query specifications
 * 
 * All operations require proper authentication via session key and communicate
 * with the appropriate environment-specific API endpoints.
 */

import { Api } from './Api';
import { IStorable, IStorableMultiQuerySpec} from "./IStorable";
import { IEnvironment } from "./IEnvironment";
import { StorableRepostoryApi, IStorableRepostoryApiWrapper } from './StorableRepositoryApi';

/**
 * Represents an API for activities.
 * 
 * @param {EEnvironment} environment_ - The environment to use for saving activities.
 * @param {string} sessionKey_ - The session key for authentication.
 * 
 * @method save - Saves a record to the Activity API.
 * @method remove - removes a record
 * @method load - load an Activity given the key 
 * @method recent - return a list of recent activities
 */
export class ActivityRepostoryApi extends Api implements IStorableRepostoryApiWrapper {

   private storableApi: StorableRepostoryApi;
   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);

      this.storableApi = new StorableRepostoryApi();
   }  

   /**
    * Asynchronously loads a record from the activity repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
    */
   async load (recordId: string) : Promise<IStorable | undefined> {

      let apiUrl = this.environment.getActivityApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.load (recordId, apiUrl);  
   }

   /**
    * Asynchronously finds a record from the activity repository API.
    * 
    * @param functionalSearchKey - The ID of the record to be removed.
    * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
    */
   async find (functionalSearchKey: string) : Promise<IStorable | undefined> {

      let apiUrl = this.environment.findActivityApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.load (functionalSearchKey, apiUrl);  
   }

   /**
    * Asynchronously saves a record to the activity repository API.
    * 
    * @param record - The record to be saved, must implement the IStorable interface.
    * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
    */
   async save (record: IStorable) : Promise<boolean> {

      let apiUrl = this.environment.saveActivityApi() + "?session=" + this.sessionKey.toString();
      
      return this.storableApi.save (record, apiUrl);
   }

   /**
    * Asynchronously removes a record from the activity repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @returns A Promise that resolves to true if the record is successfully removed, false otherwise.
    */
   async remove (recordId: string) : Promise<boolean> {

      let apiUrl = this.environment.removeActivityApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.remove (recordId, apiUrl);  
   }

   /**
    * Asynchronously retrieves recent records from the activity repository API based on the provided query specifications.
    * 
    * @param querySpec - The query specifications including the limit and storeClassName to filter the records.
    * @returns A Promise that resolves to an array of IStorable objects representing the recent records, or an empty array if an error occurs.
    */
   async recent (querySpec: IStorableMultiQuerySpec) : Promise<Array<IStorable>> {

      let apiUrl = this.environment.getActivitiesApi() + "?session=" + this.sessionKey.toString();

      return this.storableApi.recent (querySpec, apiUrl);  
   }
}
****************************************

****************************************
CommonTs\src\Api.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * @module Api
 * 
 * This module provides a base class for interacting with an API.
 * It includes common properties and methods for all API classes.
 */

import axios from 'axios';

import { IEnvironment } from "./IEnvironment";

/**
 * Represents an API class that interacts with the specified environment using the provided session key. 
 * This is a super class of each actual (useful) API. In itself it isn't very useful, it just holds common data. 
 * @param {IEnvironment} environemnt_ - The environment interface to interact with.
 * @param {string} sessionKey_ - The session key for authentication.
 */
export class Api {
   private _environment: IEnvironment;
   private _sessionKey: string;

   public constructor(environemnt_: IEnvironment, sessionKey_: string) {
      this._environment = environemnt_;
      this._sessionKey = sessionKey_;
   }  

   public get environment() : IEnvironment  {
      return this._environment;
   }
   public get sessionKey() : string  {
      return this._sessionKey;
   }   
}
****************************************

****************************************
CommonTs\src\Asserts.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * Provides type-safe assertion utilities for runtime checks.
 * 
 * This module contains a collection of assertion functions that help verify
 * runtime conditions and provide TypeScript type narrowing. Each function
 * throws an AssertionFailedError when the condition is not met.
 * 
 * @module Asserts
 */

import { AssertionFailedError} from './Errors';

export const throwIfUndefined: <T, >(x: T | undefined) => asserts x is T = x => {
   if (typeof x === "undefined") throw new AssertionFailedError ("Object is undefined.");
}

export const throwIfNull: <T, >(x: T | null) => asserts x is T = x => {
   if (x === null) throw new AssertionFailedError ("Object is null.");
}

export const throwIfFalse: (x: boolean) => asserts x is true = x => {
   if (!x) throw new AssertionFailedError ("Value is false.");
}
****************************************

****************************************
CommonTs\src\ChunkApi.Types.ts
****************************************
/**
 * @module ChunkApi.Types
 * @description Type definitions for the Chunk API, which handles text chunking operations.
 * This module provides interfaces for chunk request and response objects used in text
 * segmentation operations. It supports configurable chunk sizes and overlap between
 * chunks for optimal text processing.
 */

// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Chunk API

/**
 * Interface for chunk reqiest API.
 * @property {string} text - The text content of the chunk.
 * @property {number | undefined} chunkSize - The size of the chunk in tokens, if specified.
 * @property {number | undefined} overlapWords - The size of the overlap between chunks, in words (=2 * tokens) if specified.
 */
export interface IChunkRequest{

   text: string;
   chunkSize?: number | undefined;
   overlapWords?: number | undefined;
}

/**
 * Return type of chunk reqiest API.
 * @property {Array<string>} chunks - Array of text chunks
 */
export interface IChunkResponse {

   chunks: Array<string>;
}
****************************************

****************************************
CommonTs\src\ChunkApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from ChunkApi.Types.yaml with typeconv
  version: '1'
  x-id: ChunkApi.Types.yaml
  x-comment: >-
    Generated from src\ChunkApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IChunkRequest:
      properties:
        text:
          title: IChunkRequest.text
          type: string
        chunkSize:
          title: IChunkRequest.chunkSize
          type: number
        overlapWords:
          title: IChunkRequest.overlapWords
          type: number
      required:
        - text
      additionalProperties: false
      title: IChunkRequest
      description: >-
        Interface for chunk reqiest API.

        @property {string} text - The text content of the chunk.

        @property {number | undefined} chunkSize - The size of the chunk in
        tokens, if specified.

        @property {number | undefined} overlapWords - The size of the overlap
        between chunks, in words (=2 * tokens) if specified.
      type: object
    IChunkResponse:
      properties:
        chunks:
          items:
            type: string
          title: IChunkResponse.chunks
          type: array
      required:
        - chunks
      additionalProperties: false
      title: IChunkResponse
      description: |-
        Return type of chunk reqiest API.
        @property {Array<string>} chunks - Array of text chunks
      type: object
****************************************

****************************************
CommonTs\src\ChunkRepositoryApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * @module ChunkRepositoryApi
 * 
 * This module provides an API wrapper for managing text chunking operations.
 * It extends the base Api class and implements IStorableRepostoryApiWrapper interface
 * to provide CRUD operations for text chunking.
 * 
 * The module handles:
 * - Loading individual text chunks
 * - Finding text chunks by search key
 * - Saving new or updated text chunks
 * - Removing text chunks
 * - Retrieving recent text chunks with query specifications
 * 
 * All operations require proper authentication via session key and communicate
 * with the appropriate environment-specific API endpoints.
 */

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IStorable, IStorableMultiQuerySpec} from "./IStorable";
import { StorableRepostoryApi, IStorableRepostoryApiWrapper} from './StorableRepositoryApi';

/**
 * Represents an API for the Chunk repository
 * 
 * @param {EEnvironment} environment_ - The environment to use for saving Chunks.
 * @param {string} sessionKey_ - The session key for authentication.
 * 
 * @method save - Saves a record to the Chunk API.
 * @method remove - removes a record
 * @method load - load an Chunk given the key 
 */
export class ChunkRepostoryApi extends Api implements IStorableRepostoryApiWrapper {
   
   private storableApi: StorableRepostoryApi;

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);

      this.storableApi = new StorableRepostoryApi();      
   }  

   /**
    * Asynchronously loads a record from the Chunk repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
    */
    async load (recordId: string) : Promise<IStorable | undefined> {

         let apiUrl = this.environment.getChunkApi() + "?session=" + this.sessionKey.toString();
         return this.storableApi.load (recordId, apiUrl);  
      }

   /**
    * Asynchronously finds a record from the Chunk repository API.
    * 
    * @param functionalSearchKey - The ID of the record to be removed.
    * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
    */
    async find (functionalSearchKey: string) : Promise<IStorable | undefined> {

      let apiUrl = this.environment.findChunkApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.find (functionalSearchKey, apiUrl);  
   }

   /**
    * Asynchronously saves a record to the chunk repository API.
    * 
    * @param record - The record to be saved, must implement the IStoredChunk interface.
    * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
    */
   async save (record: IStorable) : Promise<boolean> {

      let apiUrl = this.environment.saveChunkApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.save (record, apiUrl);             
   }  

   /**
    * Asynchronously removes a record from the Chunk repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @returns A Promise that resolves to true if the record is successfully removed, false otherwise.
    */
   async remove (recordId: string) : Promise<boolean> {

      let apiUrl = this.environment.removeChunkApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.remove (recordId, apiUrl);  
   }

   /**
    * Asynchronously retrieves recent records from the activity repository API based on the provided query specifications.
    * 
    * @param querySpec - The query specifications including the limit and storeClassName to filter the records.
    * @returns A Promise that resolves to an array of IStorable objects representing the recent records, or an empty array if an error occurs.
    */
   async recent (querySpec: IStorableMultiQuerySpec) : Promise<Array<IStorable>> {

      let apiUrl = this.environment.getChunksApi() + "?session=" + this.sessionKey.toString();

      return this.storableApi.recent (querySpec, apiUrl);  
   }   
}
****************************************

****************************************
CommonTs\src\ChunkRepositoryApi.Types.ts
****************************************
/**
 * @module ChunkRepositoryApi.Types
 * @description Defines the core data types and interfaces for the ChunkRepository API.
 * This module contains type definitions for chunks, embeddings, and text renderings used
 * throughout the chunk storage system. It includes interfaces for storing and managing
 * text fragments with their associated metadata, embeddings, and relationships.
 * 
 * Key components:
 * - IStoredEmbedding: For storing vector embeddings with their model ID
 * - IStoredTextRendering: For storing text generations with their model ID
 * - IStoredChunk: The main chunk interface that combines text, embeddings, and metadata
 */

// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the ChunkRepository API

import { IStorable} from "./IStorable";

export const storedChunkClassName = "Chunk";

/**
 * Represents an interface for storing embeddings with a model ID and an array of numbers representing the embedding.
 */
export interface IStoredEmbedding {

   modelId: string;
   embedding: Array<number>;
};

/**
 * Defines the structure of a stored text rendering object.
 */
export interface IStoredTextRendering {

   modelId: string;
   text: string;
};

/**
 * Interface representing a chunk of data.
 * 
 * Core data for a chunk:
 * - parentChunkId: Primary key to parent document
 * - originalText: Original text; 0 if undefined, it has been thrown away (as maybe it can be reconstructed)
 * - url: string | undefined;                 // url to external resource, can be null  
 * - storedEmbedding: Embedding of the original text
 * - storedSummary: Summary of the original text - generated with application-specific prompt 
 * - storedTitle: A generated of the original text - generated with application-specific prompt
 * - related: Array of IDs to related chunks
 */
export interface IStoredChunk extends IStorable {

   parentChunkId: string | undefined;       // primary key to parent document
   originalText: string | undefined;        // original text - if undefined, it has been thrown way (as maybe it can be reconstructed)
   url: string | undefined;                 // url to external resource, can be null  
   storedEmbedding: IStoredEmbedding | undefined;   // Embedding of the original text
   storedSummary: IStoredTextRendering | undefined; // Summary of the original text - generated with application specific prompt
   storedTitle: IStoredTextRendering | undefined;   // Title for the original text - generated with application specific prompt   
   relatedChunks: Array <string> | undefined;       // An optional array of related chunks - often the full set that was pulled from a parent document
}
****************************************

****************************************
CommonTs\src\ChunkRepositoryApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from ChunkRepositoryApi.Types.yaml with typeconv
  version: '1'
  x-id: ChunkRepositoryApi.Types.yaml
  x-comment: >-
    Generated from src\ChunkRepositoryApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IStoredEmbedding:
      properties:
        modelId:
          title: IStoredEmbedding.modelId
          type: string
        embedding:
          items:
            type: number
          title: IStoredEmbedding.embedding
          type: array
      required:
        - modelId
        - embedding
      additionalProperties: false
      title: IStoredEmbedding
      description: >-
        Represents an interface for storing embeddings with a model ID and an
        array of numbers representing the embedding.
      type: object
    IStoredTextRendering:
      properties:
        modelId:
          title: IStoredTextRendering.modelId
          type: string
        text:
          title: IStoredTextRendering.text
          type: string
      required:
        - modelId
        - text
      additionalProperties: false
      title: IStoredTextRendering
      description: Defines the structure of a stored text rendering object.
      type: object
    IStoredChunk:
      properties:
        parentChunkId:
          title: IStoredChunk.parentChunkId
          type: string
        originalText:
          title: IStoredChunk.originalText
          type: string
        url:
          title: IStoredChunk.url
          type: string
        storedEmbedding:
          $ref: '#/components/schemas/IStoredEmbedding'
          title: IStoredChunk.storedEmbedding
        storedSummary:
          $ref: '#/components/schemas/IStoredTextRendering'
          title: IStoredChunk.storedSummary
        storedTitle:
          $ref: '#/components/schemas/IStoredTextRendering'
          title: IStoredChunk.storedTitle
        relatedChunks:
          items:
            type: string
          title: IStoredChunk.relatedChunks
          type: array
      required:
        - parentChunkId
        - originalText
        - url
        - storedEmbedding
        - storedSummary
        - storedTitle
        - relatedChunks
      additionalProperties: false
      title: IStoredChunk
      description: "Interface representing a chunk of data.\r\n\r\nCore data for a chunk:\r\n- parentChunkId: Primary key to parent document\r\n- originalText: Original text; 0 if undefined, it has been thrown away (as maybe it can be reconstructed)\r\n- url: string | undefined;                 // url to external resource, can be null  \r\n- storedEmbedding: Embedding of the original text\r\n- storedSummary: Summary of the original text - generated with application-specific prompt \r\n- storedTitle: A generated of the original text - generated with application-specific prompt\r\n- related: Array of IDs to related chunks"
      type: object
****************************************

****************************************
CommonTs\src\ClassifyApi.Types.ts
****************************************
/**
 * @fileoverview Type definitions for the Classification API
 * Contains interfaces for classification requests and responses used in the text classification system.
 * These types ensure type safety when making classification API calls and handling responses.
 * 
 * @module ClassifyApi.Types
 */

// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Chunk API

/**
 * Represents a classification request object with text and classifications.
 */
export interface IClassifyRequest{

   text: string;
   classifications: Array<string>;
}

/**
 * Interface for the classification response object.
 */
export interface IClassifyResponse {

   classification: string;
}
****************************************

****************************************
CommonTs\src\ClassifyApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from ClassifyApi.Types.yaml with typeconv
  version: '1'
  x-id: ClassifyApi.Types.yaml
  x-comment: >-
    Generated from src\ClassifyApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IClassifyRequest:
      properties:
        text:
          title: IClassifyRequest.text
          type: string
        classifications:
          items:
            type: string
          title: IClassifyRequest.classifications
          type: array
      required:
        - text
        - classifications
      additionalProperties: false
      title: IClassifyRequest
      description: >-
        Represents a classification request object with text and
        classifications.
      type: object
    IClassifyResponse:
      properties:
        classification:
          title: IClassifyResponse.classification
          type: string
      required:
        - classification
      additionalProperties: false
      title: IClassifyResponse
      description: Interface for the classification response object.
      type: object
****************************************

****************************************
CommonTs\src\Compress.ts
****************************************
/**
 * @module Compress
 * 
 * This module provides functions for compressing and decompressing strings using the deflate algorithm.
 * It supports both Node.js and browser environments.
 */
// Copyright (c) 2024 Braid Technologies Ltd
import * as pako from 'pako';


/**
 * Compresses a string using deflate algorithm
 * @param input The string to compress
 * @returns Base64 encoded compressed string
 */
export function compressString(input: string): string {
   // Convert string to Uint8Array
   const data = new TextEncoder().encode(input);
   // Compress the data
   const compressed = pako.deflate(data);

   // Universal base64 encoding
   if (typeof window === 'undefined') {
      // Node.js environment
      return Buffer.from(compressed).toString('base64');
   } else {
      // Browser environment
      return btoa(String.fromCharCode.apply(null, Array.from(compressed)));
   }
}

/**
 * Decompresses a string that was compressed using compressString
 * @param input Base64 encoded compressed string
 * @returns Original decompressed string
 */
export function decompressString(input: string): string {
   try {
      // Universal base64 decoding
      let compressedData: Uint8Array;
      if (typeof window === 'undefined') {
         // Node.js environment
         compressedData = Buffer.from(input, 'base64');
      } else {
         // Browser environment
         compressedData = new Uint8Array(
            atob(input).split('').map(char => char.charCodeAt(0))
         );
      }

      // Decompress the data
      const decompressed = pako.inflate(compressedData);
      // Convert back to string
      return new TextDecoder().decode(decompressed);
   } catch (error) {
      throw new Error('Failed to decompress string: Invalid input');
   }
}
****************************************

****************************************
CommonTs\src\EmbedApi.Types.ts
****************************************
/**
 * @fileoverview Type definitions for the Embed API, which handles text embedding operations.
 * This module contains interfaces for embedding requests and responses, defining the 
 * contract between clients and the embedding service.
 * 
 * @module EmbedApi.Types
 */

// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Embed API

import { EPromptPersona } from "./IPromptPersona";

/**
 * Interface for the embedding request object.
 */
export interface IEmbedRequest{

   persona: EPromptPersona;
   text: string;
}

/**
 * Interface for the embedding response object.
 */
export interface IEmbedResponse {

   embedding: Array<number>;
}
****************************************

****************************************
CommonTs\src\EmbedApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from EmbedApi.Types.yaml with typeconv
  version: '1'
  x-id: EmbedApi.Types.yaml
  x-comment: >-
    Generated from src\EmbedApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IEmbedRequest:
      properties:
        text:
          title: IEmbedRequest.text
          type: string
      required:
        - text
      additionalProperties: false
      title: IEmbedRequest
      description: Interface for the embedding request object.
      type: object
    IEmbedResponse:
      properties:
        embedding:
          items:
            type: number
          title: IEmbedResponse.embedding
          type: array
      required:
        - embedding
      additionalProperties: false
      title: IEmbedResponse
      description: Interface for the embedding response object.
      type: object
****************************************

****************************************
CommonTs\src\EnrichedChunk.ts
****************************************
/**
 * @fileoverview Defines the core data structures and interfaces for the Chunk API.
 * This module contains type definitions and interfaces for enriched chunks, which are
 * fundamental units of content that can be stored, queried, and retrieved based on
 * semantic similarity. It includes specifications for both client-side summaries and
 * server-side storage formats, as well as query parameters for retrieving relevant chunks.
 * 
 * Key components:
 * - EChunkRepository: Enumeration of available chunk storage repositories
 * - IEnrichedChunk: Complete chunk representation with embeddings
 * - IEnrichedChunkSummary: simple chunk representation
 * - IChunkQuerySpec: Base query parameters for chunk retrieval
 * 
 * @module EnrichedChunk
 */

// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Chunk API

// We have an ID to distinguish different Chunk repostories. 
export enum EChunkRepository {

   kBoxer = "Boxer",
   kWaterfall = "Waterfall"
};

// Default is we only consider >= 50% relevant to present to the user (GPT4 seems to generate low scores ...)
export const kDefaultSimilarityThreshold = 0.5;

/**
 * Represents a Chunk enriched with specific properties.
 * This is a summary class that can be passed between client & server. 
 * @property {string} url - The URL associated with the chunk.
 * @property {string} text - The textual content of the chunk.
 * @property {string} summary - The summary content of the chunk.
 */
export interface IEnrichedChunkSummary {

   url: string;
   text: string;
   summary: string;
}

/**
 * Represents a Chunk enriched with specific properties.
  * This is a server side class only - its for storage. 
 * @property {string} id - The unique identifier of the chunk.
 * @property {Array<number>} embedding - An array of numbers representing the embedding of the chunk.
 */
export interface IEnrichedChunk extends IEnrichedChunkSummary {

   id: string;
   embedding: number[];
}

/**
 * Represents a relevant chunk with its associated relevance score.
 */
export interface IRelevantEnrichedChunk {

   chunk: IEnrichedChunkSummary;
   relevance: number;
}

/**
 * Defines the structure of a chunk query specification object.
 * 
 * @property {EChunkRepository} repositoryId - The ID of the repository to query.
 * @property {number} maxCount - The maximum number of results to retrieve.
 * @property {number} similarityThreshold - The threshold for similarity comparison.
 */
export interface IChunkQuerySpec {

   repositoryId: EChunkRepository;
   maxCount: number;
   similarityThreshold: number;
}

/**
 * Extends the IChunkQuerySpec interface to include a 'url' property of type string.
 */
export interface IChunkQueryRelevantToUrlSpec extends IChunkQuerySpec {

   url: string;
}

/**
 * Extends the IChunkQuerySpec interface to include a 'summary' property of type string.
 */
export interface IChunkQueryRelevantToSummarySpec extends IChunkQuerySpec {

   summary: string;
}
****************************************

****************************************
CommonTs\src\EnrichedQuery.ts
****************************************
/**
 * @module EnrichedQuery
 * 
 * This module defines the core interfaces and enums for the Query API, which handles
 * enriched conversations with AI assistants. It includes:
 * 
 * - Conversation roles and elements
 * - Standard system prompts for different AI interactions
 * - Query and response interfaces for enriched conversations
 * - Structures for question generation and responses
 * 
 * The interfaces defined here are used throughout the application to maintain
 * type safety when working with AI-enriched conversations and queries.
 */

// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Query API

import { EChunkRepository, IRelevantEnrichedChunk} from "./EnrichedChunk";
import { IModelConversationElement } from "./IModelDriver";


/**
 * Defines the structure of an enriched query object.
 * Contains information about the repository, persona prompt, question prompt,
 * enrichment document prompt, and conversation history.
 */
export interface IEnrichedQuery {

   repositoryId : EChunkRepository;
   similarityThreshold: number;
   maxCount: number;
   history: Array<IModelConversationElement>;
   question: string;
   wordTarget: number;
}

/**
 * Defines the structure of an enriched response object.
 * Contains an answer field of type string and a chunks field as an array of Relevant Enriched Chunk objects.
 */
export interface IEnrichedResponse {

   answer: string;
   chunks: Array<IRelevantEnrichedChunk>;
}

/**
 * Interface for generating questions query.
 * Contains a summary which after reading a developer might have a question
 * and a word target for the question
 */
export interface IGenerateQuestionQuery {

   summary: string;
   wordTarget: number;
}

/**
 * Defines the structure of a response object for question generation.
 * Contains a property 'question' of type string representing the generated question.
 */
export interface IQuestionGenerationResponse {

   question: string;
}
****************************************

****************************************
CommonTs\src\EnumerateModelsApi.Types.ts
****************************************
/**
 * Type definitions for the EnumerateModels and EnumerateRepositories APIs
 * 
 * This module contains the interface definitions for requests and responses
 * used in model enumeration and repository listing operations. It defines:
 * - EnumerateModels API interfaces for listing available AI models
 * - EnumerateRepositories API interfaces for listing available chunk repositories
 * 
 * @module EnumerateModelsApi.Types
 */

// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the EnumerateModels API

import {EChunkRepository} from './EnrichedChunk';

/**
 * Interface for the EnumerateModels request object.
 */
export interface IEnumerateModelsRequest{

}

/**
 * Interface for the EnumerateModels response object.
 */
export interface IEnumerateModelsResponse {

   defaultId: string;
   defaultEmbeddingId: string;   
   largeId: string;
   largeEmbeddingId: string;
   smallId: string;
   smallEmbeddingId: string;   
}

/**
 * Interface for the EnumerateRepositories request object.
 */
export interface IEnumerateRepositoriesRequest{

}

/**
 * Interface for the EnumerateModels response object.
 */
export interface IEnumerateReposotoriesResponse {

   repositoryIds: Array<EChunkRepository>
}
****************************************

****************************************
CommonTs\src\EnumerateModelsApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from EnumerateModelsApi.Types.yaml with typeconv
  version: '1'
  x-id: EnumerateModelsApi.Types.yaml
  x-comment: >-
    Generated from src\EnumerateModelsApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IEnumerateModelsRequest:
      additionalProperties: false
      title: IEnumerateModelsRequest
      description: Interface for the EnumerateModels request object.
      type: object
    IEnumerateModelsResponse:
      properties:
        defaultId:
          title: IEnumerateModelsResponse.defaultId
          type: string
        defaultEmbeddingId:
          title: IEnumerateModelsResponse.defaultEmbeddingId
          type: string
        largeId:
          title: IEnumerateModelsResponse.largeId
          type: string
        largeEmbeddingId:
          title: IEnumerateModelsResponse.largeEmbeddingId
          type: string
        smallId:
          title: IEnumerateModelsResponse.smallId
          type: string
        smallEmbeddingId:
          title: IEnumerateModelsResponse.smallEmbeddingId
          type: string
      required:
        - defaultId
        - defaultEmbeddingId
        - largeId
        - largeEmbeddingId
        - smallId
        - smallEmbeddingId
      additionalProperties: false
      title: IEnumerateModelsResponse
      description: Interface for the EnumerateModels response object.
      type: object
    IEnumerateRepositoriesRequest:
      additionalProperties: false
      title: IEnumerateRepositoriesRequest
      description: Interface for the EnumerateRepositories request object.
      type: object
    IEnumerateReposotoriesResponse:
      properties:
        repositoryIds:
          items: {}
          title: IEnumerateReposotoriesResponse.repositoryIds
          type: array
      required:
        - repositoryIds
      additionalProperties: false
      title: IEnumerateReposotoriesResponse
      description: Interface for the EnumerateModels response object.
      type: object
****************************************

****************************************
CommonTs\src\Environment.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * @module Environment
 * 
 * This module provides a base class for interacting with an environment.
 */

import {EEnvironment, IEnvironment} from './IEnvironment';

/**
 * Class representing the Development Environment with methods to retrieve various API endpoints.
 * @class DevelopmentEnvironment
 */
export class DevelopmentEnvironment implements IEnvironment {

   name: string = EEnvironment.kLocal;

   checkSessionApi () : string {
      return "http://localhost:7071/api/CheckSession"; 
   }
   summariseApi () : string {
      return "http://localhost:7071/api/Summarize"; 

   }
   findThemeApi(): string {
      return "http://localhost:7071/api/FindTheme";
   }
   classifyApi () : string {
      return "http://localhost:7071/api/Classify"; 
   }
   chunkApi () : string {
      return "http://localhost:7071/api/Chunk"; 
   }
   embedApi () : string {
      return "http://localhost:7071/api/Embed"; 
   }
   testForSummariseFail(): string {
      return "http://localhost:7071/api/TestForSummariseFail";
   }
   saveActivityApi(): string {
      return "http://localhost:7071/api/SaveActivity"
   }
   removeActivityApi(): string {
      return "http://localhost:7071/api/RemoveActivity"
   }   
   getActivitiesApi(): string {
      return "http://localhost:7071/api/GetActivities"      
   }   
   getActivityApi(): string {
      return "http://localhost:7071/api/GetActivity"      
   }  
   findActivityApi(): string {
      return "http://localhost:7071/api/FindActivity"      
   }     
   loginWithLinkedInApi(): string {
      return "http://localhost:7071/api/LoginWithLinkedIn"; 
   }
   authFromLinkedInApi(): string {
      return "http://localhost:7071/api/ProcessAuthFromLinkedIn"; 
   }   
   boxerHome(): string {
      return "http://localhost:1337/boxer.html";
   }
   findRelevantEnrichedChunksFromUrl (): string {
      return "http://localhost:7071/api/FindRelevantEnrichedChunksFromUrl";
   }
   findRelevantEnrichedChunksFromSummary(): string{
      return "http://localhost:7071/api/FindRelevantEnrichedChunksFromSummary";
   }
   findEnrichedChunkFromUrl(): string {
      return "http://localhost:7071/api/FindEnrichedChunkFromUrl";      
   }
   queryModelWithEnrichment(): string {
      return "http://localhost:7071/api/QueryModelWithEnrichment";        
   }
   generateQuestion(): string{
      return "http://localhost:7071/api/GenerateQuestion";       
   }      
   generateFluidTokenApi(): string {
      return "http://localhost:7071/api/GenerateFluidToken";        
   } 
   fluidApi(): string {
      return  "http://localhost:7070";
   }
   fluidTenantId(): string {
      return "b9576484-5c2e-4613-bfdf-039948cdd521";
   }     
   studioForTeamsBoxer(): string {
      return "http://localhost:7071/api/StudioForTeams-Boxer";
   }   
   saveChunkApi() : string {
      return "http://localhost:7071/api/SaveChunk";
   }   
   removeChunkApi(): string{
      return "http://localhost:7071/api/RemoveChunk";
   }   
   getChunkApi(): string{
      return "http://localhost:7071/api/GetChunk";
   }    
   findChunkApi(): string {
      return "http://localhost:7071/api/FindChunk";
   }   
   getChunksApi(): string {
      return "http://localhost:7071/api/GetChunks";
   }         
   savePageApi() : string {
      return "http://localhost:7071/api/SavePage";
   }   
   getPageApi(): string {
      return "http://localhost:7071/api/GetPage";
   }   
   hostProtocolAndName(): string {
      return "http://localhost:7071";
   }
}

/**
 * Class representing the Staging Environment with methods to retrieve various API endpoints.
 * @class StagingEnvironment
 */
export class StagingEnvironment implements IEnvironment {

   name: string = EEnvironment.kStaging;

   checkSessionApi () : string {
      return "https://braid-api.azurewebsites.net/api/CheckSession";
   }
   summariseApi () : string {
      return "https://braid-api.azurewebsites.net/api/Summarize"; 
   }
   findThemeApi(): string {
      return "https://braid-api.azurewebsites.net/api/FindTheme";
   }
   classifyApi () : string {
      return "https://braid-api.azurewebsites.net/api/Classify"; 
   }
   chunkApi () : string {
      return "https://braid-api.azurewebsites.net/api/Chunk"; 
   }
   embedApi () : string {
      return "https://braid-api.azurewebsites.net/api/Embed"; 
   }   
   testForSummariseFail(): string {
      return "https://braid-api.azurewebsites.net/api/TestForSummariseFail";
   }   
   saveActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/SaveActivity";
   }  
   removeActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/RemoveActivity";
   }   
   getActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetActivity"      
   }     
   findActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/FindActivity"      
   }    
   getActivitiesApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetActivities";      
   }  
   loginWithLinkedInApi(): string {
      return "https://braid-api.azurewebsites.net/api/LoginWithLinkedIn"; 
   }
   authFromLinkedInApi(): string {
      return "https://braid-api.azurewebsites.net/api/ProcessAuthFromLinkedIn"; 
   }
   boxerHome(): string {
      return "https://braidapps.io/boxer.html";
   }   
   findRelevantEnrichedChunksFromUrl (): string {
      return "https://braid-api.azurewebsites.net/api/FindRelevantEnrichedChunksFromUrl";
   }
   findRelevantEnrichedChunksFromSummary(): string{
      return "https://braid-api.azurewebsites.net/api/FindRelevantEnrichedChunksFromSummary";
   }   
   findEnrichedChunkFromUrl(): string {
      return "https://braid-api.azurewebsites.net/api/FindEnrichedChunkFromUrl";      
   }   
   queryModelWithEnrichment(): string {
      return "https://braid-api.azurewebsites.net/api/QueryModelWithEnrichment";        
   }   
   generateQuestion(): string{
      return "https://braid-api.azurewebsites.net/api/GenerateQuestion";       
   }     
   generateFluidTokenApi(): string {
      return "https://braid-api.azurewebsites.net/api/GenerateFluidToken";        
   }    
   fluidApi(): string {
      return  "https://eu.fluidrelay.azure.com";
   }
   fluidTenantId(): string {
      return "b9576484-5c2e-4613-bfdf-039948cdd521";
   }    
   studioForTeamsBoxer(): string {
      return "https://braid-api.azurewebsites.net/api/StudioForTeams-Boxer";
   }
   saveChunkApi() : string{
      return "https://braid-api.azurewebsites.net/api/SaveChunk";
   }   
   removeChunkApi(): string{
      return "https://braid-api.azurewebsites.net/api/RemoveChunk";
   }   
   getChunkApi(): string{
      return "https://braid-api.azurewebsites.net/api/GetChunk";   
   }
   findChunkApi(): string{
      return "https://braid-api.azurewebsites.net/api/FindChunk";   
   }   
   getChunksApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetChunks";
   }         
   savePageApi() : string {
      return "https://braid-api.azurewebsites.net/api/SavePage";
   }   
   getPageApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetPage";
   }   
   hostProtocolAndName(): string {
      return "https://braid-api.azurewebsites.net";
   }
}

/**
 * Class representing a Production Environment with methods to retrieve various API endpoints.
 * @class ProductionEnvironment
 */
export class ProductionEnvironment implements IEnvironment {

   name: string = EEnvironment.kProduction;
   
   checkSessionApi () : string {
      return "https://braid-api.azurewebsites.net/api/CheckSession";
   }
   summariseApi () : string {
      return "https://braid-api.azurewebsites.net/api/Summarize"; 

   }
   findThemeApi(): string {
      return "https://braid-api.azurewebsites.net/api/FindTheme";
   }
   classifyApi () : string {
      return "https://braid-api.azurewebsites.net/api/Classify"; 
   }
   chunkApi () : string {
      return "https://braid-api.azurewebsites.net/api/Chunk"; 
   }   
   embedApi () : string {
      return "https://braid-api.azurewebsites.net/api/Embed"; 
   }    
   testForSummariseFail(): string {
      return "https://braid-api.azurewebsites.net/api/TestForSummariseFail";
   }      
   saveActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/SaveActivity"
   }    
   removeActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/RemoveActivity"
   }    
   getActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetActivity"      
   }     
   findActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/FindActivity"      
   }       
   getActivitiesApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetActivities"      
   }       
   loginWithLinkedInApi(): string {
      return "https://braid-api.azurewebsites.net/api/LoginWithLinkedIn"; 
   }
   authFromLinkedInApi(): string {
      return "https://braid-api.azurewebsites.net/api/ProcessAuthFromLinkedIn"; 
   }    
   boxerHome(): string {
      return "https://braidapps.io/boxer.html";
   }  
   findRelevantEnrichedChunksFromUrl (): string {
      return "https://braid-api.azurewebsites.net/api/FindRelevantEnrichedChunksFromUrl";
   }
   findRelevantEnrichedChunksFromSummary(): string {
      return "https:/braid-api.azurewebsites.net/api/FindRelevantEnrichedChunksFromSummary";   
   }
   findEnrichedChunkFromUrl(): string {
      return "https://braid-api.azurewebsites.net/api/FindEnrichedChunkFromUrl";      
   }    
   queryModelWithEnrichment(): string {
      return "https://braid-api.azurewebsites.net/api/QueryModelWithEnrichment";        
   } 
   generateQuestion(): string{
      return "https://braid-api.azurewebsites.net/api/GenerateQuestion";       
   }   
   generateFluidTokenApi(): string {
      return "https://braid-api.azurewebsites.net/api/GenerateFluidToken";        
   }
   fluidApi(): string {
      return  "https://eu.fluidrelay.azure.com";
   }
   fluidTenantId(): string {
      return "b9576484-5c2e-4613-bfdf-039948cdd521";
   }  
   studioForTeamsBoxer(): string {
      return "https://braid-api.azurewebsites.net/api/StudioForTeams-Boxer";
   }      
   saveChunkApi() : string{
      return "https://braid-api.azurewebsites.net/api/SaveChunk";
   }   
   removeChunkApi(): string{
      return "https://braid-api.azurewebsites.net/api/RemoveChunk";
   }   
   getChunkApi(): string{
      return "https://braid-api.azurewebsites.net/api/GetChunk";   
   }   
   findChunkApi(): string{
      return "https://braid-api.azurewebsites.net/api/FindChunk";   
   }      
   getChunksApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetChunks";
   }        
   savePageApi() : string {
      return "https://braid-api.azurewebsites.net/api/SavePage";
   }   
   getPageApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetPage";
   }   
   hostProtocolAndName(): string {
      return "https://braid-api.azurewebsites.net";
   }
}
****************************************

****************************************
CommonTs\src\Errors.ts
****************************************
/**
 * Custom error classes for the Braid application.
 * 
 * This module provides a collection of specialized error classes that extend the base Error class.
 * Each error type is designed to handle specific categories of errors that may occur within the
 * application, such as invalid parameters, connection issues, or environment-related problems.
 * 
 * All error classes include:
 * - Proper prototype chain restoration for TypeScript
 * - Automatic error logging through logCoreError or logApiError
 * - Standardized error naming for stack traces
 * 
 * @module Errors
 */

import { logApiError, logCoreError } from "./Logging";

/**
 * Represents an error thrown when an invalid parameter is encountered.
 * @param {string} message - The error message describing the invalid parameter.
 */
export class InvalidParameterError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidParameterError.name; // stack traces display correctly now

      logCoreError ("InvalidParameterError:" + (message ? message : ""), JSON.stringify (this));
   }
}

/**
 * Represents an error that occurs when an invalid operation is attempted.
 * @extends Error
 * @constructor
 * @param {string} [message] - The error message.
 */
export class InvalidOperationError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidOperationError.name; // stack traces display correctly now

      logCoreError ("InvalidOperationError:" + (message ? message : ""), JSON.stringify (this));      
   }
}


/**
 * Represents an error indicating an invalid state.
 * @param message - Optional. A message to describe the error.
 */
export class InvalidStateError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidStateError.name; // stack traces display correctly now

      logCoreError ("InvalidStateError:" + (message ? message : ""), JSON.stringify (this));      
   }
}

/**
 * Represents a custom error class for connection-related errors.
 * @class ConnectionError
 * @extends Error
 * @constructor
 * @param {string} [message] - The error message.
 */
export class ConnectionError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = ConnectionError.name; // stack traces display correctly now

      logApiError ("ConnectionError:" + (message ? message : ""), JSON.stringify (this));      
   }
}

/**
 * Represents an error related to the environment.
 * @param {string} [message] - The error message.
 */
export class EnvironmentError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = EnvironmentError.name; // stack traces display correctly now

      logCoreError ("EnvironmentError:" + (message ? message : ""), JSON.stringify (this));       
   }
}

/**
 * Represents an error that occurs when an assertion fails.
 * @param message - Optional. A message to describe the error.
 */
export class AssertionFailedError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = AssertionFailedError.name; // stack traces display correctly now

      logCoreError ("AssertionFailedError:" + (message ? message : ""), JSON.stringify (this));       
   }
}

/*
 
export class InvalidUnitError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidUnitError.name; // stack traces display correctly now
   }
}

export class InvalidFormatError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidFormatError.name; // stack traces display correctly now
   }
}

export class InvalidServerResponseError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidServerResponseError.name; // stack traces display correctly now
   }
}

*/
****************************************

****************************************
CommonTs\src\FindEnrichedChunkApi.ts
****************************************
/**
 * @module   FindEnrichedChunkApi
 * @description Provides an API for finding and retrieving enriched chunks.
 * 
 * This module contains the FindEnrichedChunkApi class which handles various API calls
 * related to finding enriched chunks based on URLs and summaries. It provides methods
 * for retrieving both individual chunk summaries and arrays of relevant chunks.
 * 
 * The API supports:
 * - Finding single enriched chunk summaries by URL
 * - Finding relevant enriched chunks by URL
 * - Finding relevant enriched chunks by summary
 */

// Copyright (c) 2024 Braid Technologies Ltd


import axios from 'axios';

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IChunkQueryRelevantToSummarySpec, IChunkQueryRelevantToUrlSpec, IEnrichedChunkSummary, IRelevantEnrichedChunk } from './EnrichedChunk';


/**
 * Class representing an API for finding enriched chunks.
 */
export class FindEnrichedChunkApi extends Api {

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */   
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);
   }  


   /**
    * Asynchronously finds an enriched chunk summary based on the provided URL query.
    * 
    * @param urlQuery - The URL query specifying the URL to search for the enriched chunk.
    * @returns An IEnrichedChunkSummary objects representing the found enriched chunk summary, or undefined.
    */
   async findChunkFromUrl (urlQuery: IChunkQueryRelevantToUrlSpec) : Promise<IEnrichedChunkSummary | undefined> {

      let apiUrl = this.environment.findEnrichedChunkFromUrl() + "?session=" + this.sessionKey.toString();
      var response: any;
      let empty = undefined;

      try {
         response = await axios.post(apiUrl, {
            data: urlQuery
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return empty;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return empty;      
      }          
   }

   /**
    * Asynchronously finds relevant enriched chunks based on the provided URL query.
    * 
    * @param urlQuery - The URL query specifying the URL to search for relevant enriched chunks.
    * @returns A Promise that resolves to an array of IRelevantEnrichedChunk objects representing the found relevant enriched chunks.
    */
   async findRelevantChunksFromUrl (urlQuery: IChunkQueryRelevantToUrlSpec) : Promise<Array<IRelevantEnrichedChunk>> {

      let apiUrl = this.environment.findRelevantEnrichedChunksFromUrl() + "?session=" + this.sessionKey.toString();
      var response: any;
      let empty = new Array<IRelevantEnrichedChunk> ();

      try {
         response = await axios.post(apiUrl, {
            data: urlQuery
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return empty;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return empty;      
      }          
   }

   /**
    * Asynchronously finds relevant enriched chunks based on the provided summary query.
    * 
    * @param urlQuery - The summary query specifying the summary to search for relevant enriched chunks.
    * @returns A Promise that resolves to an array of IRelevantEnrichedChunk objects representing the found relevant enriched chunks.
    */
   async findRelevantChunksFromSummary (urlQuery: IChunkQueryRelevantToSummarySpec) : Promise<Array<IRelevantEnrichedChunk>> {

      let apiUrl = this.environment.findRelevantEnrichedChunksFromSummary() + "?session=" + this.sessionKey.toString();
      var response: any;
      let empty = new Array<IRelevantEnrichedChunk> ();      

      try {
         response = await axios.post(apiUrl, {
            data: urlQuery
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return empty;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return empty;    
      }          
   }
}
****************************************

****************************************
CommonTs\src\FindThemeApi.Types.ts
****************************************
/**
 * Types and interfaces for the FindTheme API.
 * 
 * This module contains the type definitions for the request and response
 * objects used in the FindTheme API, which is responsible for analyzing
 * text content and identifying its primary theme.
 * 
 * @module FindThemeApi.Types
 */

// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the FindTheme API

/**
 * Interface for the find theme request object.
 */
export interface IFindThemeRequest{

   text: string;
   length: number;
}

/**
 * Interface for the find theme response object.
 */
export interface IFindThemeResponse {

   theme: string;
}
****************************************

****************************************
CommonTs\src\FindThemeApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from FindThemeApi.Types.yaml with typeconv
  version: '1'
  x-id: FindThemeApi.Types.yaml
  x-comment: >-
    Generated from src\FindThemeApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IFindThemeRequest:
      properties:
        text:
          title: IFindThemeRequest.text
          type: string
        length:
          title: IFindThemeRequest.length
          type: number
      required:
        - text
        - length
      additionalProperties: false
      title: IFindThemeRequest
      description: Interface for the find theme request object.
      type: object
    IFindThemeResponse:
      properties:
        theme:
          title: IFindThemeResponse.theme
          type: string
      required:
        - theme
      additionalProperties: false
      title: IFindThemeResponse
      description: Interface for the find theme response object.
      type: object
****************************************

****************************************
CommonTs\src\Fluid.ts
****************************************
/**
 * @module Fluid
 * @description Defines the core interfaces for Fluid Framework token authentication.
 * Contains type definitions for user authentication, token requests, and token responses
 * used in the Fluid Framework integration.
 * 
 * These interfaces facilitate the token-based authentication flow between the client
 * application and the Fluid service, supporting both local development and production
 * environments.
 */

// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Fluid Token API

/**
 * Represents a Fluid user.
 * @interface
 * @property {boolean} local - if true, we are running locally - use local tentantID
 * @property {string} userId - The ID of the user making the request.
 * @property {string} userName - The name of the user making the request.
 
 */
export interface IFluidUser {

   local: boolean;
   userId: string;
   userName: string; 
}

/**
 * Represents a request for a Fluid token.
 * @interface
 * @property {string} documentId - ID of the shared document.
 */
export interface IFluidTokenRequest extends IFluidUser {

   documentId: string;   
}

/**
 * Represents a response to a request for a Fluid token.
 * @interface
 * @property {string} token - the token 
 */
export interface IFluidTokenResponse {

   token: string;   
}
****************************************

****************************************
CommonTs\src\FluidApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * @module FluidApi
 * @description Provides an API wrapper for generating Fluid Framework tokens.
 * This module contains the FluidApi class, which handles the generation of Fluid
 * Framework tokens using the provided environment and session key.
 * 
 * The class supports:
 * - Generating a Fluid token using a request object containing documentId, userId, and userName.
 * - Handling errors and retries for token generation.
 */

import axios, {AxiosInstance, AxiosStatic} from 'axios';
import axiosRetry from 'axios-retry';

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IFluidTokenRequest } from './Fluid';

export class FluidApi extends Api {

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);
   }  

   /**
    * Asynchronously generates a token using the provided query parameters.
    * 
    * @param query - The request object containing documentId, userId, and userName.
    * @returns A Promise that resolves to a string if successful, otherwise undefined.
    */
   async generateToken (query: IFluidTokenRequest ) : Promise<string | undefined> {

      let apiUrl = this.environment.generateFluidTokenApi() + "?session=" + this.sessionKey;
      var response: any;
      let empty = undefined;

      try {
         // Up to 5 retries - it is a big fail if we cannot get a token for Fluid
         axiosRetry(axios as AxiosStatic | AxiosInstance, {
            retries: 5,
            retryDelay: axiosRetry.exponentialDelay,
            retryCondition: (error) => {
               return error?.response?.status === 429 || axiosRetry.isNetworkOrIdempotentRequestError(error);
            }
         });

         response = await axios.post(apiUrl, {
            data: query
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return empty;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return empty;      
      }          
   }
}
****************************************

****************************************
CommonTs\src\FluidTokenProvider.ts
****************************************
/**
 * @module FluidTokenProvider
 * @description Provides token management and connection configuration for Azure Fluid Relay services.
 * 
 * This module implements the necessary components to establish and manage connections
 * to Azure Fluid Relay, including:
 * - Token generation and management via FluidTokenProvider
 * - Connection configuration via FluidConnectionConfig
 * - Client properties setup via FluidClientProps
 * 
 * The implementation supports both local and remote environments, with configurable
 * authentication through session keys and user contexts.
 */

// Copyright (c) 2024 Braid Technologies Ltd
// Implementation of the Fluid connection API

import { AzureRemoteConnectionConfig, AzureClientProps, ITokenProvider, ITokenResponse } from "@fluidframework/azure-client";

import { IEnvironment, EEnvironment } from "./IEnvironment";
import { FluidApi } from "./FluidApi";
import { IFluidUser, IFluidTokenRequest } from "./Fluid";
import { ConnectionError } from "./Errors";
import { getDefaultFluidEnvironment, getEnvironment } from "./IEnvironmentFactory";

/**
 * Token Provider implementation for connecting to an Azure Function endpoint for
 * Azure Fluid Relay token resolution.
 */
export class FluidTokenProvider implements ITokenProvider {
   
   private _api: FluidApi;
   private _user: IFluidUser;

   /**
    * Creates a new instance using configuration parameters.
    * @param environment The environment settings to be used.
    * @param sessionKey The session key for authentication 
    * @param user - User object
    */
   constructor(environment: IEnvironment, sessionKey: string, user: IFluidUser) {

      this._api = new FluidApi(environment, sessionKey);
      this._user = user;
   }

   public async fetchOrdererToken(tenantId: string, documentId?: string): Promise<ITokenResponse> {
      return {
         jwt: await this.getToken(tenantId, documentId),
      };
   }

   public async fetchStorageToken(tenantId: string, documentId: string): Promise<ITokenResponse> {
      return {
         jwt: await this.getToken(tenantId, documentId),
      };
   }

   private async getToken(tenantId: string, documentId: string | undefined): Promise<string> {

      let local = false;
      if (tenantId === "local")
         local = true;

      let request : IFluidTokenRequest = {
         local: local,
         userId: this._user.userId,
         userName: this._user.userName,
         documentId: documentId? documentId : ""
      }
      
      const response = await this._api.generateToken(request);
      if (!response)
         throw new ConnectionError("Unable to generate Fluid Token");
      return response;
   }
}

export class FluidConnectionConfig implements AzureRemoteConnectionConfig {

   tokenProvider: ITokenProvider; 
   endpoint: string;
   type: any;
   tenantId: string;
   documentId: string = "";

   /**
    * Creates a new instance using configuration parameters.
    * @param sessionKey The session key for authentication 
    * @param tokenRequest - Details to request a token
    * @param forceProduction - boolean, if true then connect to production else default
    */
   constructor(sessionKey: string, tokenRequest: IFluidTokenRequest, forceProduction: boolean) {

      let environment = getDefaultFluidEnvironment();
      if (forceProduction)
         environment = getEnvironment (EEnvironment.kProduction);

      if (environment.name === EEnvironment.kLocal)
         this.type = "local";
      else
         this.type = "remote";

      this.tenantId = environment.fluidTenantId();
      this.endpoint = environment.fluidApi();   
      if (tokenRequest.documentId)   
         this.documentId = tokenRequest.documentId;
      this.tokenProvider = new FluidTokenProvider (environment, sessionKey, tokenRequest);
   }
};

export class FluidClientProps implements AzureClientProps {
   connection: FluidConnectionConfig;

   /**
    * Creates a new instance using configuration parameters.
    * @param sessionKey The session key for authentication 
    * @param tokenRequest - Details to request a token
    * @param forceProduction - boolean, if true then connect to production else default
    */   
   constructor(sessionKey: string, tokenRequest: IFluidTokenRequest, forceProduction: boolean) {
      this.connection = new FluidConnectionConfig(sessionKey, tokenRequest, forceProduction);
   }
};
****************************************

****************************************
CommonTs\src\IEnvironment.ts
****************************************
/**
 * @module IEnvironment
 * @description Defines the environment configuration interface and types for the Braid application.
 * 
 * This module defines the environment configuration interface (IEnvironment) used across
 * the application to handle different deployment environments (Local, Staging, Production).
 * It provides type definitions for environment-specific API endpoints and service URLs.
 * 
 * The interface includes methods for:
 * - Authentication and session management
 * - Content operations (summarization, classification, embedding)
 * - Activity tracking and management
 * - Chunk and page operations
 * - Integration endpoints (LinkedIn, Fluid, Teams)
 */

// Copyright (c) 2024 Braid Technologies Ltd

export const BRAID_ENVIRONMENT_KEY = "BRAID_ENVIRONMENT"

export enum EEnvironment {

   kLocal = "Local", 
   kStaging = "Staging", 
   kProduction = "Production"   
};

export interface IEnvironment {

   name : string;
   hostProtocolAndName(): string;
   checkSessionApi () : string;
   summariseApi () : string;
   findThemeApi(): string;
   chunkApi () : string;   
   classifyApi () : string;
   embedApi() : string;
   testForSummariseFail(): string;
   saveActivityApi(): string;
   removeActivityApi(): string;
   getActivityApi(): string;   
   findActivityApi(): string;      
   getActivitiesApi(): string;
   boxerHome(): string;
   loginWithLinkedInApi(): string;
   authFromLinkedInApi(): string;
   findRelevantEnrichedChunksFromUrl(): string;
   findRelevantEnrichedChunksFromSummary(): string;   
   findEnrichedChunkFromUrl(): string;   
   queryModelWithEnrichment(): string;
   generateQuestion(): string;   
   generateFluidTokenApi(): string;
   fluidApi(): string;
   fluidTenantId(): string;
   studioForTeamsBoxer() : string;
   saveChunkApi() : string;
   removeChunkApi(): string;
   getChunkApi(): string;
   findChunkApi(): string;   
   getChunksApi(): string;   
   savePageApi() : string;   
   getPageApi(): string;   
}
****************************************

****************************************
CommonTs\src\IEnvironmentFactory.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * @module IEnvironmentFactory
 * 
 * Factory module for creating environment instances that define application behavior
 * across different deployment contexts (Development, Staging, Production).
 * 
 * This module provides factory functions to create appropriate environment instances
 * based on the current execution context (browser vs Node.js) and configuration.
 * It supports automatic environment detection and explicit environment selection
 * through the getEnvironment function.
 * 
 * The module handles three main scenarios:
 * - Default environment detection
 * - Fluid-specific environment configuration
 * - Login-specific environment configuration
 */

// Internal imports
import {EEnvironment, IEnvironment} from './IEnvironment';
import {DevelopmentEnvironment, StagingEnvironment, ProductionEnvironment} from './Environment';

declare var process : any;


/**
 * Returns the default environment based on the current execution context.
 * If running in a browser and on localhost, returns a DevelopmentEnvironment instance.
 * If the process environment variable BRAID_ENVIRONMENT is set to 'Local', returns a DevelopmentEnvironment instance.
 * Otherwise, returns a ProductionEnvironment instance.
 * @returns An instance of IEnvironment representing the default environment.
 */
export function getDefaultEnvironment () : IEnvironment  {

   // Use Development if we are running in Node.js
   if (typeof process !== 'undefined') {
      if (process.env.BRAID_ENVIRONMENT === EEnvironment.kLocal) {
         return new DevelopmentEnvironment();
      }
   }

   return new ProductionEnvironment();   
}

export function getDefaultFluidEnvironment () : IEnvironment  {

   let environment = getDefaultEnvironment();

   // If we are in Browser, and in localhost, use development
   if (typeof window !== 'undefined') {
      if (window.location.hostname === 'localhost') {
         environment = getEnvironment (EEnvironment.kLocal);
      }
   }
   return environment;
}

export function getDefaultLoginEnvironment () : IEnvironment  {

   let environment = getDefaultEnvironment();

   // If we are in Browser, and in localhost, use development
   if (typeof window !== 'undefined') {
      if (window.location.hostname === 'localhost') {
         environment = getEnvironment (EEnvironment.kLocal);
      }
   }
   return environment;
}

/**
 * Returns an instance of IEnvironment based on the provided EEnvironment type.
 * 
 * @param environmentString - The EEnvironment type to determine the environment.
 * @returns An instance of IEnvironment corresponding to the specified EEnvironment type.
 */
export function getEnvironment (environmentString: EEnvironment) : IEnvironment  {

   switch (environmentString) {
      case EEnvironment.kLocal:
         return new DevelopmentEnvironment();   

      case EEnvironment.kStaging:
         return new StagingEnvironment();   

      case EEnvironment.kProduction:
      default:
         return new ProductionEnvironment();
   }
}
****************************************

****************************************
CommonTs\src\IModel.ts
****************************************
/**
 * @module IModel
 * @description Defines the core model interfaces and enums used for AI model management.
 * Contains the model size enumeration and the base interface for model implementations,
 * including deployment configuration and text processing capabilities.
 */

// Copyright (c) 2024 Braid Technologies Ltd

/**
 * Enum representing different sizes of a model.
 * 
 * @enum {string}
 */
export enum EModel {

   kSmall = "Small", 
   kLarge = "Large"  
};

/**
 * Represents an interface for a model with deployment information.
 * @interface
 */
export interface IModel {

   implementsModel: EModel
   deploymentName : string;
   embeddingDeploymentName: string;
   defaultChunkSize : number;
   maximumChunkSize : number;
   embeddingChunkSize : number;
   fitsInDefaultChunk(text: string): boolean;
   fitsInMaximumChunk(text: string): boolean;
   fitsInEmbeddingChunk(text: string): boolean;
   chunkText (text: string, chunkSize: number | undefined, overlapWords: number | undefined): Array<string>;
   estimateTokens (text: string): number;
}
****************************************

****************************************
CommonTs\src\IModelDriver.ts
****************************************
/**
 * @module IModelDriver
 * 
 * This module defines the core interfaces and enums for model-driven conversations.
 * It provides the fundamental types used to structure conversations between users
 * and AI models, including role definitions and conversation formats.
 * 
 * The module includes:
 * - EModelConversationRole: Enum for different conversation participant roles
 * - IModelConversationElement: Interface for individual conversation messages
 * - IModelConversationPrompt: Interface for complete conversation contexts
 */

// Copyright (c) 2024 Braid Technologies Ltd

import { EPromptPersona } from './IPromptPersona';
/**
 * Enum representing the roles in a conversation with a model.
 * 
 * @enum {string} EModelConversationRole
 * @property {string} kSystem - System message role
 * @property {string} kAssistant - Assistant message role
 * @property {string} kUser - User message role
 */
export enum EModelConversationRole {

   kSystem = "system",
   kAssistant = "assistant",
   kUser = "user"
};


/**
 * Defines the structure of a conversation element.
 */
export interface IModelConversationElement {
   role: EModelConversationRole,
   content: string
}

/**
 * Defines the structure of a conversation prompt used for model interactions.
 * This interface encapsulates both the conversation history and the current prompt.
 * 
 * @interface IModelConversationPrompt
 * @property {Array<IModelConversationElement>} history - Array of previous conversation elements 
 *           including system messages, user inputs, and assistant responses
 * @property {string} prompt - The current prompt or query to be processed by the model
 */
export interface IModelConversationPrompt {
   history: Array<IModelConversationElement>;
   prompt: string;
}

/**
 * Interface for drivers that provide text embedding capabilities.
 * Text embeddings are vector representations of text that capture semantic meaning,
 * allowing for operations like semantic search and similarity comparisons.
 * 
 * @interface IEmbeddingModelDriver
 */
export interface IEmbeddingModelDriver {
   /**
    * Gets the type identifier of the model being driven.
    * 
    * @returns {string} A string identifier representing the type of the underlying model
    */
   getDrivenModelType(): string;
   
   
    /**
     * Converts text into a vector embedding representation.
     * 
     * @param {string} text - The input text to be embedded
     * @returns {Promise<Array<number>>} A promise that resolves to an array of numbers 
     *         representing the text embedding vector
     */
    embed(text: string): Promise<Array<number>>;
}

export interface IChatModelDriverParams {
   wordTarget?: number | undefined;
   promptParam1?: string | undefined;
}

/**
 * Interface for drivers that provide chat model capabilities.
 * 
 * @interface IChatModelDriver
 */
export interface IChatModelDriver {

      /**
    * Gets the type identifier of the model being driven.
    * 
    * @returns {string} A string identifier representing the type of the underlying model
    */
   getDrivenModelType(): string;

   /**
    * Generates a response to a given conversation prompt.
    * 
    * @param {EPromptPersona} persona - The persona to use for the response
    * @param {IModelConversationPrompt} prompt - The conversation prompt to be processed
    * @param {IChatModelDriverParams} params - The parameters for the prompt (optional)
    * @returns {Promise<IModelConversationElement>} A promise that resolves to the generated response
    */
   generateResponse(persona: EPromptPersona, 
      prompt: IModelConversationPrompt, 
      params?: IChatModelDriverParams): Promise<IModelConversationElement>;
}
****************************************

****************************************
CommonTs\src\IModelFactory.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module IModelFactory
 * @description Factory module for creating AI model instances.
 * 
 * This module provides factory functions to create appropriate model instances
 * based on the requested model type. It supports:
 * - Default model creation through getDefaultModel()
 * - Specific model creation through getModel() based on EModel type
 * 
 * The factory ensures consistent model instantiation across the application
 * while abstracting the concrete model implementation details.
 */

// Internal imports
import {EModel, IModel} from './IModel';
import { IEmbeddingModelDriver, IChatModelDriver } from './IModelDriver';
import {GPT4} from './Model.OAI';
import { OpenAIEmbeddingModelDriver, OpenAIChatModelDriver } from './ModelDrivers.OAI';

/**
 * Returns the default model which is an instance of GPT4oMini.
 * @returns {IModel} The default model.
 */
export function getDefaultModel () : IModel  {

   return new GPT4();   
}

/**
 * Returns an instance of IModel based on the provided EModel type.
 * 
 * @param model - The EModel type to determine the model.
 * @returns An instance of IModel corresponding to the specified EModel type.
 */
export function getModel (model: EModel) : IModel  {

   switch (model) {
      default:
         return new GPT4();
   }
}


/**
 * Returns an instance of IEmbeddingModelDriver for the default embedding model.
 * @returns {IEmbeddingModelDriver} The default embedding model driver.
 */

export function getDefaultEmbeddingModelDriver () : IEmbeddingModelDriver  {

   return new OpenAIEmbeddingModelDriver();   
}

/**
 * Returns an instance of IEmbeddingModelDriver based on the provided EModel type.
 * @param model - The EModel type to determine the model.
 * @returns {IEmbeddingModelDriver} An instance of IEmbeddingModelDriver corresponding to the specified EModel type.
 */
export function getEmbeddingModelDriver (model: EModel) : IEmbeddingModelDriver  {

   switch (model) {
      default:
         return new OpenAIEmbeddingModelDriver();
   }
}

export function getDefaultChatModelDriver () : IChatModelDriver  {

   return new OpenAIChatModelDriver();   
}

/**
 * Returns an instance of IChatModelDriver based on the provided EModel type.
 * @param model - The EModel type to determine the model.
 * @returns {IChatModelDriver} An instance of IChatModelDriver corresponding to the specified EModel type.
 */
export function getChatModelDriver (model: EModel) : IChatModelDriver  {

   switch (model) {
      default:
         return new OpenAIChatModelDriver();
   }
}
****************************************

****************************************
CommonTs\src\IPromptPersona.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module IPromptPersona
 * @description Defines interfaces and enums for managing different prompt personas.
 * 
 * This module provides the core types for configuring different AI prompt personas,
 * each specialized for specific summarization tasks. It includes:
 * - EPromptPersona enum for different persona types (Article, Code, Survey)
 * - IPromptPersona interface defining the structure of a prompt persona
 * 
 * Each persona contains configuration for system-level and item-level prompting,
 * allowing for specialized behavior across different summarization contexts.
 */


export enum EPromptPersona {

   kDefault = "Default",
   kArticleSummariser = "ArticleSummariser", 
   kCodeSummariser = "CodeSummariser",
   kSurveySummariser = "SurveySummariser",
   kTestForSummariseFail = "TestForSummariseFail",
   kClassifier = "Classifier",
   kThemeFinder = "ThemeFinder",
   kDeveloperAssistant = "DeveloperAssistant", 
   kDeveloperImaginedAnswerGenerator = "DeveloperImaginedAnswerGenerator",
   kDeveloperQuestionGenerator = "DeveloperQuestionGenerator"
};

export interface IPromptPersona {

   name : string;
   systemPrompt: string;
   itemPrompt: string;
}
****************************************

****************************************
CommonTs\src\IPromptPersonaFactory.ts
****************************************
/**
 * @module IPromptPersonaFactory
 * 
 * This module provides functionality to generate specialized AI prompt personas
 * for different types of content summarization (articles, code, surveys).
 * Each persona includes a system prompt and an item prompt tailored to the
 * specific summarization task.
 * 
 * The module exports:
 * - Predefined persona templates for Article, Code, and Survey summarization
 * - getSummariser function to generate configured prompt personas with
 *   customized word count targets
 */

// Copyright (c) 2024 Braid Technologies Ltd


import { IChatModelDriverParams } from "./IModelDriver";
import { EPromptPersona, IPromptPersona } from "./IPromptPersona";

const DefaultPersona: IPromptPersona = {

   name: EPromptPersona.kDefault,
   systemPrompt: "",
   itemPrompt: ""
};

const DeveloperAssistantPersona: IPromptPersona = {

   name: EPromptPersona.kDeveloperAssistant,
   systemPrompt: "",
   itemPrompt: ""
}

const ArticleSummariserPersona: IPromptPersona = {

   name: EPromptPersona.kArticleSummariser,
   systemPrompt: "",
   itemPrompt: ""   
}

const CodeSummariserPersona: IPromptPersona = {

   name: EPromptPersona.kCodeSummariser,
   systemPrompt: "",
   itemPrompt: ""
};

const SurveySummariserPersona: IPromptPersona = {

   name: EPromptPersona.kSurveySummariser,
   systemPrompt: "",
   itemPrompt: ""
};

const TestForSummariseFailPersona: IPromptPersona = {

   name: EPromptPersona.kTestForSummariseFail,
   systemPrompt: "",
   itemPrompt: ""
};

const ClassifierPersona: IPromptPersona = {

   name: EPromptPersona.kClassifier,
   systemPrompt: "",
   itemPrompt: ""
};

const ThemeFinderPersona: IPromptPersona = {

   name: EPromptPersona.kThemeFinder,
   systemPrompt: "",
   itemPrompt: ""
};

const DeveloperQuestionGeneratorPersona: IPromptPersona = {

   name: EPromptPersona.kDeveloperQuestionGenerator,
   systemPrompt: "",
   itemPrompt: ""
};

const DeveloperImaginedAnswerGeneratorPersona: IPromptPersona = {

   name: EPromptPersona.kDeveloperImaginedAnswerGenerator,
   systemPrompt: "",
   itemPrompt: ""
};

export function getChatPersona (persona: EPromptPersona, userPrompt: string, params: IChatModelDriverParams) : IPromptPersona {

   let wordString = "50";
   if (params && params.wordTarget) {
      wordString = params.wordTarget.toString();
   }
   let promptParam1 = "";
   if (params && params.promptParam1) {
      promptParam1 = params.promptParam1;
   }

   switch (persona) {
      
      case EPromptPersona.kSurveySummariser:
         const surveyTemplate = SurveySummariserPersona;
         surveyTemplate.systemPrompt = "You are an AI asistant that summarises survey responses in "
         + wordString  +
         " words or less, to explain it to the management team that issues the survey. Please summarise the following survey result in "
         + wordString + " words. Make each distinct point a separate paragraph. Be as positive as reasonably possible.";

         surveyTemplate.itemPrompt = userPrompt;
         return surveyTemplate;

      case EPromptPersona.kCodeSummariser:
         const codeTemplate = CodeSummariserPersona;
         codeTemplate.systemPrompt = "You are an AI asistant that summarises code in "
         + wordString  +
         " words or less, to help explain the code it to new developers. Please summarise the following code in "
         + wordString + " words. Make each distinct point a separate paragraph. List the important classes or functions in the module";

         codeTemplate.itemPrompt = userPrompt;
         return codeTemplate;

      case EPromptPersona.kTestForSummariseFail:
         const testForSummariseFailTemplate = TestForSummariseFailPersona;
         testForSummariseFailTemplate.systemPrompt = "You are an AI asistant that reviews the work of a summariser. The summariser occasionally cannot find the main body of the text to summarise. The summariser may apologise for this, or may say there is not enough relevant information to summarise, or may state the text contains only web page navigation, all of which are failed summaries."
         + " Please review the following summary and reply 'No' if the summariser has not been able to create a good summary of a body of text, otherwise reply 'Yes'.";

         testForSummariseFailTemplate.itemPrompt = userPrompt;
         return testForSummariseFailTemplate;   

      case EPromptPersona.kClassifier:
         const classifierTemplate = ClassifierPersona;
         classifierTemplate.systemPrompt =  "You are an asistant that can classify text into one of the following subjects: "
         + promptParam1 + "."
         + "Try to classify the subject of the following text. The classification is a single word from the list "
         + promptParam1
         + ". If you cannot classify it well, answer 'Unknown'."         
         classifierTemplate.itemPrompt = userPrompt;
         return classifierTemplate;

      case EPromptPersona.kThemeFinder:
         const themeFinderTemplate = ThemeFinderPersona;
         themeFinderTemplate.systemPrompt = "You are an AI asistant that finds a common theme from a number of paragraphs of text in "
         + wordString  + " words or less. Please find the most common theme in the following text in "
         + wordString + " words. Do not start your reply with the phrase 'The most common theme in the text is'. Translate to English if necessary. "
         themeFinderTemplate.itemPrompt = userPrompt;
         return themeFinderTemplate;

      case EPromptPersona.kDeveloperQuestionGenerator:
         const developerQuestionGeneratorTemplate = DeveloperQuestionGeneratorPersona;
         developerQuestionGeneratorTemplate.systemPrompt = "You are an AI asistant that generates a question after a developer has read an article about AI. The question is a single sentence of no more than 10 words. The question is one that the developer might ask as a follow up to reading the article.";
         developerQuestionGeneratorTemplate.itemPrompt = userPrompt;
         return developerQuestionGeneratorTemplate;

      case EPromptPersona.kDeveloperAssistant:
         const developerAssistantTemplate = DeveloperAssistantPersona;
         developerAssistantTemplate.systemPrompt = "You are an AI assistant helping an application developer understand generative AI. You explain complex concepts in simple language, using Python examples if it helps. You limit replies to "
         + wordString + " words or less. If you don't know the answer, say 'I don't know'. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'.";
         developerAssistantTemplate.itemPrompt = userPrompt;
         return developerAssistantTemplate;

      case EPromptPersona.kDeveloperImaginedAnswerGenerator:
         const developerImaginedAnswerGeneratorTemplate = DeveloperImaginedAnswerGeneratorPersona;
         developerImaginedAnswerGeneratorTemplate.systemPrompt = "You are an AI assistant helping an application developer understand generative AI. You explain complex concepts in simple language, using Python examples if it helps. You will be provided with a question about building applications that use generative AI technology. Write a "
         + wordString + " word summary of an article that would be a great answer to the question. Enrich the summary with additional topics that the question asker might want to understand. Write the summary in the present tense, as though the article exists. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'.\n";
         developerImaginedAnswerGeneratorTemplate.itemPrompt = userPrompt;
         return developerImaginedAnswerGeneratorTemplate;

      case EPromptPersona.kArticleSummariser:
         const articleTemplate = ArticleSummariserPersona;          
         articleTemplate.systemPrompt = "You are an AI asistant that summarises text in "
         + wordString  +
         " words or less. You ignore text that look like to be web page navigation, javascript, or other items that are not the main body of the text. Please summarise the following text in "
         + wordString  + " words. Translate to English if necessary. Make each distinct point a separate paragraph.";
         articleTemplate.itemPrompt = userPrompt;
         return ArticleSummariserPersona;

      default:
         const defaultTemplate = DefaultPersona;          
         defaultTemplate.systemPrompt = "You are an AI asistant that provides assistance to developers building AI with Python. You provide concise answers of 50 words or less."
         defaultTemplate.itemPrompt = userPrompt;
         return DefaultPersona;         
   }
}
****************************************

****************************************
CommonTs\src\IStorable.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module IStorable
 * @description Defines core interfaces and types for persistent storage functionality.
 * 
 * This module provides the foundational types for object persistence across the application,
 * including:
 * - IStorable interface for objects that can be stored in the database
 * - EStorableApplicationIds enum for identifying different applications
 * - Query specification interfaces for database operations
 * 
 * The module enables consistent storage patterns across different applications while
 * maintaining flexibility through application-specific extensions of the base interfaces.
 */

/**
 * Enum representing application names
 * 
 * @enum {string}
 */
export enum EStorableApplicationIds {

   kBoxer = "Boxer", 
   kWaterfall = "Waterfall"  
};

/**
 * Represents an interface for objects that can be stored.
 * 
 * Contains properties:
 * - id: string - the primary key of the stored object
 * - applicationId: string - identifies the application - one of the Enums above. 
 * - contextId: string - identifies the context, e.g., a conversation in Boxer
 * - userId: string | undefined - identifies the user; undefined if no direct user
 * - functionalSearchKey: string | undefined - used if the app needs to searcg by an attribute other than primary key
 * - created: Date - timestamp of creation
 * - amended: Date - timestamp of amendment
 * - className: string - class name; further fields are class-specific
 * - schemaVersion: string - allows versioning on the schema* 
 */
export interface IStorable {
                       
   id : string | undefined;  // id of the object that is stored - primary key. Can be undefined before the object is stored. 
   applicationId: string;    // Name of the application that generated and uses the chunk
   contextId: string | undefined;  // id to identify context - such as a conversation in Boxer. Undefined if application has no multi-tenanting. 
   functionalSearchKey: string | undefined; // Used if the app needs to searcg by an attribute other than primary key
   userId: string | undefined;     // id to identify the user. Undefined if there is no direct user. 
   created: string;      // creation timestamp as ISO date string
   amended: string;      // amend timestamp as ISO date string  
   className: string;  // className - all further fields are specific to the class
   schemaVersion: string;  // Allow versioning on the schema       
}

/**
 * Defines the structure of a query specification for searching for multiple records.
 * Includes the limit of records to return and the class name of the records to be stored / retrieved.
 */
export interface IStorableMultiQuerySpec {

   limit : number;          // limit of records to return
   className: string;       // what sort of records to return
}

/**
 * Defines the structure of a query specification for searching for a single record.
 * Includes the id (primary key) of the record. 
 */
export interface IStorableQuerySpec {

   id : string | undefined;  // id of the object that is stored - primary key.  
   functionalSearchKey: string | undefined; // If the id is unefined, this is used for the search
}

/**
 * Defines the structure of a query specification for searching for a single record.
 * Includes the id (primary key) of the record. 
 */
export interface IStorableOperationResult {

   ok :boolean;  // True if operation succeeeded
}
****************************************

****************************************
CommonTs\src\Logging.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Logging
 * @description Provides logging functionality for different parts of the application.
 * 
 * This module contains utility functions for logging errors and information across
 * different domains of the application, including:
 * - Core system errors
 * - Database errors 
 * - API errors and information
 * 
 * Each logging function follows a consistent pattern of accepting a description
 * and details parameter, formatting them appropriately for the logging context.
 * The module helps maintain consistent logging practices across the application
 * while differentiating between error domains for easier debugging.
 */

/**
 * Logs a core error with the provided description and details.
 * 
 * @param description - A brief description of the core error.
 * @param details - Additional details related to the core error.
 * @returns void
 */
export function logCoreError (description: string, details: any) : void {

   console.error ("Core error:" + description + "Details:" + details.toString());
}

/**
 * Logs a database error with the provided description and details.
 * 
 * @param description - A brief description of the error.
 * @param details - Additional details about the error.
 * @returns void
 */
export function logDbError (description: string, details: any) : void {

   console.error ("Database error:" + description + "Details:" + details.toString());
}

/**
 * Logs an API error with the provided description and details.
 * 
 * @param description A brief description of the API error.
 * @param details Additional details related to the API error.
 * @returns void
 */
export function logApiError (description: string, details: any) : void {

   console.error ("Api error:" + description + "Details:" + details.toString());
}

/**
 * Logs API information.
 * 
 * @param description - A brief description of the API information.
 * @param details - Additional details about the API information.
 * @returns void
 */
export function logApiInfo (description: string, details: any) : void {

   console.log ("Api Info:" + description + "Details:" + details.toString());
}
****************************************

****************************************
CommonTs\src\LoginApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module LoginApi
 * @description Provides an API for handling login operations.
 * 
 * This module contains the LoginApi class, which handles the login process
 * using LinkedIn API. It provides methods for:
 * - Logging in using LinkedIn API
 * - Handling errors and retries for login operations
 */

import axios from 'axios';

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";

/**
 * Represents a class for handling login operations.
 * @constructor
 * @param environment_ - The environment settings for the login operations.
 * @param sessionKey_ - The session key for the current login session.
 * @returns A Promise that resolves to a string indicating the login status.
 */
export class LoginApi extends Api {

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);
   }  

   /**
    * Asynchronously logs in using LinkedIn API.
    * 
    * @returns A Promise that resolves to a string indicating the status after attempting to log in.
    */
   async login () : Promise<string> {

      let apiUrl = this.environment.loginWithLinkedInApi() + "?session=" + this.sessionKey.toString();
      var response: any;

      try {
         response = await axios.post(apiUrl, {
         });

         if (response.status === 200) {
            return "Redirecting...";
         }
         else {
            console.error ("Error, status: " + response.status);               
            return "";
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return "";       
      }          
   }
   
}
****************************************

****************************************
CommonTs\src\LooseObject.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * @module LooseObject
 * @description Defines a type for a loose object that can contain any key-value pairs.
 * 
 * This module provides a type alias for an object that allows for dynamic key-value
 * assignments, useful for creating flexible data structures without specifying
 * a fixed schema.
 */
export interface LooseObject {
   [key: string]: any
}
****************************************

****************************************
CommonTs\src\Model.OAI.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Model
 * @description Provides a class for managing AI models and their deployment settings.
 * 
 * This module contains the GPT4 class, which implements the IModel interface.
 * It provides methods for:
 * - Checking if a text fits within the context window size with buffer
 * - Chunking text into smaller pieces with optional overlap
 * - Estimating the number of tokens in a given text
 */

import { InvalidParameterError } from './Errors';
import { EModel, IModel } from './IModel';
import GPT4Tokenizer from 'gpt4-tokenizer';

const tokenizer = new GPT4Tokenizer({ type: 'gpt3' });


/**
 * GPTM class implementing IModel interface.
 * Represents a model with specific deployment settings and context window sizes.
 */
export class GPT4 implements IModel {

   deploymentName: string;
   embeddingDeploymentName: string;
   defaultChunkSize: number;
   maximumChunkSize: number;
   embeddingChunkSize: number;
   defaultChunkSizeWithBuffer: number;
   maximumChunkSizeWithBuffer: number;
   embeddingChunkSizeWithBuffer: number;

   implementsModel: EModel = EModel.kLarge;

   public constructor() {
      this.deploymentName = "GPT4o";
      this.embeddingDeploymentName = "Embed-3";
      this.defaultChunkSize = 8192;
      this.maximumChunkSize = 65536;
      this.embeddingChunkSize = 8191;
      this.defaultChunkSizeWithBuffer = (8192 - 256)
      this.embeddingChunkSizeWithBuffer = (8191 - 256)
      this.maximumChunkSizeWithBuffer = (65536 - 256)      
   }

   /**
    * Checks if the given text fits within the context window size with buffer.
    * 
    * @param text The text to check if it fits within the context window size with buffer.
    * @returns True if the text fits within the context window size with buffer, false otherwise.
    */
   fitsInDefaultChunk(text: string): boolean {

      let estimatedTokens = tokenizer.estimateTokenCount(text);

      if (estimatedTokens < this.defaultChunkSizeWithBuffer)
         return true;
      return false;
   }

   /**
    * Checks if the given text fits within the maximum context window size with buffer.
    * 
    * @param text The text to check if it fits within the context window size with buffer.
    * @returns True if the text fits within the context window size with buffer, false otherwise.
    */
   fitsInMaximumChunk(text: string): boolean {

         let estimatedTokens = tokenizer.estimateTokenCount(text);
   
         if (estimatedTokens < this.maximumChunkSizeWithBuffer)
            return true;
         return false;
      }

   /**
    * Checks if the given text fits within the embedding context window size with buffer.
    * 
    * @param text The text to check if it fits within the context window size with buffer.
    * @returns True if the text fits within the context window size with buffer, false otherwise.
    */
   fitsInEmbeddingChunk(text: string): boolean {

      let estimatedTokens = tokenizer.estimateTokenCount(text);

      if (estimatedTokens < this.embeddingChunkSizeWithBuffer)
         return true;
      return false;
   }      
   
   /**
    * Splits the input text into chunks based on the specified overlap of words.
    * 
    * @param text The text to be chunked.
    * @param overlapWords The number of overlapping words between consecutive chunks. If undefined, we chunk with no obverlap. 
    * @returns An array of strings representing the chunked text.
    */
   chunkText(text: string, chunkSize: number | undefined, overlapWords: number | undefined): Array<string> {

      let effectiveChunkSize = chunkSize
         ? Math.min(this.defaultChunkSizeWithBuffer, chunkSize)
         : this.defaultChunkSizeWithBuffer;

      if (overlapWords) {

         if (overlapWords > effectiveChunkSize)
            throw new InvalidParameterError ("Overlap window size cannot be bigger than chunk size")

         // If the users requests overlapping chunks, we divide the text into pieces the size of the overlap, then glue them back
         // together until we fill a buffer. 
         let chunked = tokenizer.chunkText(text, Math.floor(overlapWords * 2));
         let chunks = new Array<string>();

         let workingBufferText = "";
         let workingBufferTokens = 0;
         let lastChunkText = "";
         let lastChunkTokens = 0;

         for (let i = 0; i < chunked.length; i++) {

            let thisChunkText = chunked[i].text;
            let thisChunkTokens = tokenizer.estimateTokenCount(thisChunkText);

            if (workingBufferTokens + thisChunkTokens < effectiveChunkSize) {
               // If we are within buffer size, we just accumulate
               workingBufferText = workingBufferText + thisChunkText;
               workingBufferTokens = workingBufferTokens + thisChunkTokens;
            }
            else {
               // If we are outside buffer, we save the current chunk and build the start of the next one
               chunks.push(workingBufferText);

               workingBufferText = lastChunkText + thisChunkText
               workingBufferTokens = lastChunkTokens + thisChunkTokens;
            }

            // If we have reached the last chunk, we have to save it. 
            if (i === chunked.length - 1) {
               chunks.push(workingBufferText);
            }

            lastChunkTokens = thisChunkTokens;
            lastChunkText = thisChunkText;
         }
         return chunks;
      }
      else {
         let chunked = tokenizer.chunkText(text, effectiveChunkSize);

         let chunks = new Array<string>();

         for (let i = 0; i < chunked.length; i++) {
            chunks.push(chunked[i].text);
         }
         return chunks;
      }
   }

   /**
    * Estimates the number of tokens in the provided text using the tokenizer.
    * 
    * @param text The text for which to estimate the number of tokens.
    * @returns The estimated number of tokens in the text.
    */
   estimateTokens(text: string): number {

      return tokenizer.estimateTokenCount(text);
   }
}
****************************************

****************************************
CommonTs\src\ModelDrivers.OAI.ts
****************************************
/**
 * @module IModelDrivers.OAI
 * 
 * This module provides OpenAI-specific implementations for embedding model drivers.
 * It includes functionality to calculate text embeddings using Azure OpenAI services.
 * 
 * Key components:
 * - OpenAIEmbeddingModelDriver: Implementation of IEmbeddingModelDriver for OpenAI
 * - calculateEmbedding: Utility function to compute embeddings via Azure OpenAI API
 * 
 */

// Copyright (c) 2024 Braid Technologies Ltd

import axios from 'axios';
import axiosRetry from 'axios-retry';

// Internal imports
import { IEmbeddingModelDriver, IChatModelDriver, IModelConversationElement, IModelConversationPrompt, EModelConversationRole, IChatModelDriverParams} from './IModelDriver';
import { EPromptPersona } from './IPromptPersona';
import { getChatPersona } from "./IPromptPersonaFactory";

interface OpenAIChatElement {
   role: string;
   content: string;
}

let modelType = "OpenAI";

/**
 * Class representing an OpenAI embedding model driver.
 * Implements the IEmbeddingModelDriver interface.
 * 
 * @method embed
 * @param {string} text - The text to be embedded.
 * @returns {Promise<Array<number>>} A promise that resolves to an array of numbers representing the embedding.
 * @throws {Error} Throws an error if the method is not implemented.
 */
export class OpenAIEmbeddingModelDriver implements IEmbeddingModelDriver {

   getDrivenModelType(): string {
      return modelType;
   }

   embed(text: string): Promise<Array<number>> {
      return calculateEmbedding(text);
   }
}


/**
 * Asynchronously calculates the embedding for the given text using the Azure AI service.
 * 
 * @param text The text for which the embedding needs to be calculated.
 * @returns A Promise that resolves to an array of numbers representing the calculated embedding.
 */
export async function calculateEmbedding(text: string): Promise<Array<number>> {

   // Up to 5 retries if we hit rate limit
   axiosRetry(axios, {
      retries: 5,
      retryDelay: axiosRetry.exponentialDelay,
      retryCondition: (error) => {
         return error?.response?.status === 429 || axiosRetry.isNetworkOrIdempotentRequestError(error);
      }
   });

   try {
      const response = await axios.post('https://studiomodels.openai.azure.com/openai/deployments/StudioEmbeddingLarge/embeddings?api-version=2024-06-01', {
         input: text,
      },
         {
            headers: {
               'Content-Type': 'application/json',
               'api-key': process.env.AzureAiKey
            }
         }
      );

      const embedding = response.data.data[0].embedding as Array<number>;

      return (embedding);

   }
   catch (error) {
      console.error(error);
      throw error;
   }
}

/**
 * Class representing a driver for OpenAI chat models.
 * Implements the IChatModelDriver interface to provide methods for
 * retrieving the model type and generating responses to conversation prompts.
 */
export class OpenAIChatModelDriver implements IChatModelDriver {


   getDrivenModelType(): string {
      return modelType;
   }

   generateResponse(persona: EPromptPersona, prompt: IModelConversationPrompt, 
      params: IChatModelDriverParams): Promise<IModelConversationElement> {

      return chat(persona, prompt, params);
   }
}

/**
 * Asynchronously generates a chat response using the Azure OpenAI service.
 * 
 * @param persona The type of persona (ArticleSummariser, CodeSummariser, or SurveySummariser) to use for the response
 * @param prompt The conversation prompt containing the system and user messages
 * @param params The parameters for the prompt
 * @returns A Promise that resolves to a model conversation element containing the LLM response
 */

async function chat(persona: EPromptPersona, prompt: IModelConversationPrompt, 
   params: IChatModelDriverParams): Promise<IModelConversationElement> {

   // Up to 5 retries if we hit rate limit
   axiosRetry(axios, {
      retries: 5,
      retryDelay: axiosRetry.exponentialDelay,
      retryCondition: (error) => {
         return error?.response?.status === 429 || axiosRetry.isNetworkOrIdempotentRequestError(error);
      }
   });

   const summariser = getChatPersona(persona, prompt.prompt, params);

   const systemPrompt = summariser.systemPrompt;
   const userPrompt = summariser.itemPrompt;

   let messages: Array<OpenAIChatElement> = [];

   messages.push({
      role: 'system',
      content: systemPrompt
   });

   for (const message of prompt.history) {
      messages.push({
         role: message.role,
         content: message.content
      });
   }

   messages.push({
      role: 'user',
      content: userPrompt
   });

   try {
      const response = await axios.post('https://studiomodels.openai.azure.com/openai/deployments/StudioLarge/chat/completions?api-version=2024-06-01', {
         messages: messages
      },
      {
         headers: {
            'Content-Type': 'application/json',
            'api-key': process.env.AzureAiKey
         }
      });

      return {role: EModelConversationRole.kAssistant, 
         content: response.data.choices[0].message.content};
   }
   catch (error) {
      console.error(error);
      throw error;
   }

}
****************************************

****************************************
CommonTs\src\PageRepositoryApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module PageRepositoryApi
 * @description Provides an API for managing page storage and retrieval.
 * 
 * This module contains the PageRepositoryApi class which handles storage operations
 * for pages in the application. It provides methods for:
 * - Saving pages to persistent storage
 * - Compressing page content for efficient storage
 * 
 * The module extends the base Api class and implements IStorablePageRepositoryApiWrapper
 * to provide consistent storage patterns while handling page-specific requirements
 * like content compression.
 */

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IStorable} from "./IStorable";
import { StorableRepostoryApi, IStorablePageRepostoryApiWrapper} from './StorableRepositoryApi';
import { compressString, decompressString } from './Compress';
/**
 * Represents an API for the Page repository
 * 
 * @param {EEnvironment} environment_ - The environment to use for saving Pages.
 * @param {string} sessionKey_ - The session key for authentication.
 * 
 * @method save - Saves a record to the Page API.
 * Does not provide a 'load' as Pages are loaded directly into the browser
 */
export class PageRepostoryApi extends Api implements IStorablePageRepostoryApiWrapper {
   
   private storableApi: StorableRepostoryApi;

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);

      this.storableApi = new StorableRepostoryApi();      
   }  

   /**
    * Asynchronously saves a record to the page repository API.
    * 
    * @param record - The record to be saved, must implement the IStoredPage interface.
    * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
    */
   async save (record: IStorable) : Promise<boolean> {

      let apiUrl = this.environment.savePageApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.save (record, apiUrl);             
   }  

   /**
    * Compresses a string using deflate algorithm
    * @param input The string to compress
    * @returns Base64 encoded compressed string
    */
   public compressString(input: string): string {
      return compressString(input);
   }

   /**
    * Decompresses a string that was compressed using compressString
    * @param input Base64 encoded compressed string
    * @returns Original decompressed string
    */
   public decompressString(input: string): string {
      return decompressString(input);
   }

}
****************************************

****************************************
CommonTs\src\PageRepositoryApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the PageRepository API
/**
 * @module PageRepositoryApi.Types
 * @description Defines the data types and interfaces used by the PageRepository API.
 * 
 * This module contains the interfaces that define the structure of:
 * - Stored pages and their HTML content
 * - Request and response types for page storage operations
 * 
 * These types support the PageRepositoryApi module in providing type-safe
 * page storage and retrieval operations.
 */

import { IStorable, IStorableQuerySpec} from "./IStorable";

/**
 * Interface representing a web page Chunk.
 * 
 * Core data for a Page:
 * - html: HTML content
 */
export interface IStoredPage extends IStorable {

   html: string;       // HTML content
}

// We have an explicit type for the input so code generators can identify it to generate test code
export interface IStoredPageRequest extends IStorableQuerySpec {

}

// We have an explicit type for the output so code generators can identify it to generate test code
export interface IStoredPageResponse extends IStoredPage {

}
****************************************

****************************************
CommonTs\src\PageRepositoryApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from PageRepositoryApi.Types.yaml with typeconv
  version: '1'
  x-id: PageRepositoryApi.Types.yaml
  x-comment: >-
    Generated from src\PageRepositoryApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
components:
  schemas:
    IStoredPage:
      properties:
        html:
          title: IStoredPage.html
          type: string
      required:
        - html
      additionalProperties: false
      title: IStoredPage
      description: "Interface representing a web page Chunk.\r\n\r\nCore data for a Page:\r\n- html: HTML content"
      type: object
    IStoredPageRequest:
      additionalProperties: false
      title: IStoredPageRequest
      type: object
    IStoredPageResponse:
      properties:
        html:
          title: IStoredPage.html
          type: string
      required:
        - html
      additionalProperties: false
      title: IStoredPageResponse, IStoredPage
      description: "Interface representing a web page Chunk.\r\n\r\nCore data for a Page:\r\n- html: HTML content"
      type: object
    StoredPageApi:
      title: StoredPageApi
    paths:
      /functions:
        get:
          operationId: get_page
          summary: Returns a page. 
          description: Returns a page. 
          parameters:
            - request: request
              in: query
              description: A spec for a Page
              schema:
                type: IStoredPageRequest
              required: true
          responses:
            '200':
              description: A Page
              content:
                application/json:
                  schema:
                    type: IStoredPageResponse    
            '400':
              description: An error 
              content:
                application/json:
                  schema:
                    type: string
****************************************

****************************************
CommonTs\src\QueryModelApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module QueryModelApi
 * @description Provides an API for querying models with enrichment and generating questions.
 * 
 * This module contains the QueryModelApi class, which handles the interaction with the specified environment
 * to query models with enrichment and generate questions. It provides methods for:
 * - Querying models with enrichment
 * - Generating questions
 */

import axios from 'axios';

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IEnrichedQuery, IEnrichedResponse, IGenerateQuestionQuery, IQuestionGenerationResponse } from './EnrichedQuery';

/**
 * Represents a QueryModelApi class that interacts with the specified environment to query models with enrichment and generate questions.
 * @constructor
 * @param environment_ - The environment to interact with.
 * @param sessionKey_ - The session key for authentication.
 */
export class QueryModelApi extends Api {

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);
   }  

   /**
    * Asynchronously queries the model with enrichment data.
    * 
    * @param query - The enriched query data to be sent.
    * @returns A promise that resolves to the enriched response data, or undefined if an error occurs.
    */
   async queryModelWithEnrichment (query: IEnrichedQuery) : Promise<IEnrichedResponse | undefined> {

      let apiUrl = this.environment.queryModelWithEnrichment() + "?session=" + this.sessionKey.toString();
      var response: any;
      let empty = undefined;

      try {
         response = await axios.post(apiUrl, {
            data: query
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return empty;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return empty;      
      }          
   }

   /**
    * Asynchronously generates a question based on the provided query data.
    * 
    * @param query - The data containing persona prompt, question generation prompt, and summary.
    * @returns A promise that resolves to the generated question response, or undefined if an error occurs.
    */
   async generateQuestion (query: IGenerateQuestionQuery) : Promise<IQuestionGenerationResponse | undefined> {

      let apiUrl = this.environment.generateQuestion() + "?session=" + this.sessionKey.toString();
      var response: any;
      let empty = undefined;

      try {
         response = await axios.post(apiUrl, {
            data: query
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return empty;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return empty;      
      }          
   }   
}
****************************************

****************************************
CommonTs\src\ReadMe.Salon.md
****************************************
**ActivityRepositoryApi.ts**

The `ActivityRepositoryApi` module provides a wrapper for managing activity records using CRUD operations. It extends the `Api` class and implements the `IStorableRepositoryApiWrapper` interface.

The main functions include:
- `load(recordId: string)`: Loads an activity record by its ID.
- `find(functionalSearchKey: string)`: Finds an activity by a search key.
- `save(record: IStorable)`: Saves a new or updated activity record.
- `remove(recordId: string)`: Removes an activity record by its ID.
- `recent(querySpec: IStorableMultiQuerySpec)`: Retrieves recent activity records based on query specifications.

Authentication via session key is required for all operations, which communicate with environment-specific API endpoints.

**Api.ts**

This module defines a base class named `Api` that facilitates interaction with various APIs.

The `Api` class requires an environment interface (`IEnvironment`) and a session key for authentication. These are passed as parameters to its constructor and stored as private properties `_environment` and `_sessionKey`.

The class provides public getter methods, `environment` and `sessionKey`, to access these properties.

The module imports the `axios` library for making HTTP requests, though there are no methods implemented in this base class utilizing `axios`.

The `Api` class is designed to be a superclass, meaning more specific API classes will extend it to implement their own unique functionality.

**Asserts.ts**

This module named `Asserts` provides type-safe assertion utilities to ensure runtime checks with type narrowing in TypeScript.

### Key Functions:

- **throwIfUndefined**: Throws an `AssertionFailedError` if the input `x` is `undefined`, ensuring `x` is of type `T`.
- **throwIfNull**: Throws an `AssertionFailedError` if the input `x` is `null`, ensuring `x` is of type `T`.
- **throwIfFalse**: Throws an `AssertionFailedError` if the input `x` is `false`, ensuring `x` is `true`.

### Important Classes:

- **AssertionFailedError**: Imported from `./Errors`, this class is used to throw errors when assertions fail.

**ChunkApi.Types.ts**

The module `ChunkApi.Types` provides type definitions for a Chunk API that handles text chunking operations.

The `IChunkRequest` interface defines the structure for API requests, including properties for `text` (mandatory string), `chunkSize` (optional number, size of each chunk in tokens), and `overlapWords` (optional number, size of overlap between chunks in words).

The `IChunkResponse` interface defines the structure for API responses, containing a `chunks` property, which is an array of strings representing the segmented text chunks.

These interfaces ensure consistent formatting of request and response data for text segmentation operations.

**ChunkRepositoryApi.ts**

The `ChunkRepositoryApi` module is an API wrapper for managing text chunking, extending the base `Api` class and implementing the `IStorableRepostoryApiWrapper` interface. This module allows CRUD operations (Create, Read, Update, Delete) for text chunks.

Key classes and methods:
- `ChunkRepostoryApi`: Main class for the API with methods for operations.
- `constructor(environment_, sessionKey_)`: Initializes the API with environment settings and an authentication session key.
- `load(recordId)`: Loads a record by ID from the repository.
- `find(functionalSearchKey)`: Finds a record using a search key.
- `save(record)`: Saves a new or updated record.
- `remove(recordId)`: Removes a record by ID.
- `recent(querySpec)`: Retrieves recent records based on query specifications.

All operations communicate with environment-specific API endpoints and require authentication through the session key.

**ChunkRepositoryApi.Types.ts**

This module defines core data types and interfaces for the ChunkRepository API. These definitions are used for handling chunks, embeddings, and text renderings throughout the chunk storage system.

The `IStoredEmbedding` interface stores vector embeddings associated with a model ID.

The `IStoredTextRendering` interface defines the structure for storing generated text along with its related model ID.

The `IStoredChunk` interface represents data chunks, including metadata, embeddings, summaries, and relationships with other chunks. It includes fields for parent chunk ID, original text, URL to external resources, stored embeddings, summaries, titles, and IDs of related chunks.

The `storedChunkClassName` constant is defined as "Chunk".

**ClassifyApi.Types.ts**

The code provides type definitions for a Classification API used in a text classification system.

The `IClassifyRequest` interface defines the structure of a classification request, which includes `text` (a string) and an array of possible `classifications`.

The `IClassifyResponse` interface defines the structure of a classification response, which contains a single `classification` string.

These interfaces ensure type safety when making API calls and handling responses.

**Compress.ts**

The module "Compress" provides functions to compress and decompress strings using the deflate algorithm. It is compatible with both Node.js and browser environments.

Key functions include `compressString` and `decompressString`.

`compressString` converts the input string to a `Uint8Array`, compresses it using pako's `deflate` method and then base64 encodes the compressed data. Base64 encoding differs slightly for Node.js and browsers.

`decompressString` reverses this process. It base64 decodes the input and then inflates the resulting `Uint8Array` using pako’s `inflate` method, finally converting it back to a string. It throws an error if decompression fails.

**EmbedApi.Types.ts**

This module, `EmbedApi.Types`, defines the data structures for the Embed API which is responsible for handling text embedding operations. 

The `IEmbedRequest` interface describes the structure of an embedding request object containing `persona` of type `EPromptPersona` and `text` which is a string.

The `IEmbedResponse` interface outlines the structure of an embedding response object including `embedding`, which is an array of numbers representing the embedding vector.

These interfaces define the contract between clients and the embedding service ensuring consistent data exchange formats.

The `EPromptPersona` type is imported from `./IPromptPersona` and is used within the `IEmbedRequest` interface.

**EnrichedChunk.ts**

This module defines the core data structures and interfaces for the Chunk API, which deals with enriched chunks of content that can be stored, queried, and retrieved based on semantic similarity. It caters to both client-side summaries and server-side storage formats.

Important components include the `EChunkRepository` enum which lists available chunk storage repositories, while `IEnrichedChunk` and `IEnrichedChunkSummary` interfaces define the structures for both server-side and client-side chunks. The `IChunkQuerySpec` and its extensions (`IChunkQueryRelevantToUrlSpec`, `IChunkQueryRelevantToSummarySpec`) specify the parameters for querying these chunks.

The default similarity threshold for presenting chunks to users is set at 0.5.

**EnrichedQuery.ts**

The `EnrichedQuery` module defines core interfaces and enums for managing enriched conversations with AI assistants.

The `IEnrichedQuery` interface structures an enriched query object, including repository identification, similarity threshold, maximum result count, conversation history, the posed question, and word count target.

The `IEnrichedResponse` interface structures an enriched response object, including an answer string and an array of relevant enriched chunk objects (`IRelevantEnrichedChunk`).

The `IGenerateQuestionQuery` interface defines the structure for a question generation query, including a summary text and a word target for the resulting question.

The `IQuestionGenerationResponse` interface structures the response for question generation, consisting only of a generated question string. 

Key Interfaces: `IEnrichedQuery`, `IEnrichedResponse`, `IGenerateQuestionQuery`, `IQuestionGenerationResponse`.

**EnumerateModelsApi.Types.ts**

This module defines TypeScript interfaces for the EnumerateModels and EnumerateRepositories APIs, which are used in AI model enumeration and repository listing operations.

The `IEnumerateModelsRequest` interface represents the structure of the request for listing available AI models.

The `IEnumerateModelsResponse` interface defines the structure of the response, including ID fields for different sizes and embeddings of models.

The `IEnumerateRepositoriesRequest` interface represents the structure of the request for listing available chunk repositories.

The `IEnumerateRepositoriesResponse` interface defines the structure of the response, which includes an array of chunk repository IDs (`EChunkRepository`).

**Environment.ts**

This code provides a base for different environment configurations (Development, Staging, Production) by defining various API endpoints specific to each environment.

The `DevelopmentEnvironment` class represents the development settings. It defines several methods, such as `checkSessionApi()`, `summariseApi()`, `findThemeApi()`, and others, returning local endpoints (e.g., `http://localhost:7071/api/CheckSession`).

The `StagingEnvironment` class represents the staging environment settings. It similarly defines the same set of methods as the development class but points to staging URLs (e.g., `https://braid-api.azurewebsites.net/api/CheckSession`).

The `ProductionEnvironment` class represents the production environment settings. It contains the same methods as the other classes but uses production URLs (e.g., `https://braid-api.azurewebsites.net/api/CheckSession`). 

Important classes: `DevelopmentEnvironment`, `StagingEnvironment`, `ProductionEnvironment`. Important functions: `checkSessionApi()`, `summariseApi()`, `findThemeApi()`, `classifyApi()`, `chunkApi()`, `embedApi()`, `testForSummariseFail()`, `saveActivityApi()`, `removeActivityApi()`, `getActivityApi()`, `findActivityApi()`, `getActivitiesApi()`, `loginWithLinkedInApi()`, `authFromLinkedInApi()`, `boxerHome()`, `findRelevantEnrichedChunksFromUrl()`, and `generateFluidTokenApi()`.

**Errors.ts**

This module defines custom error classes that extend the native JavaScript `Error` class, tailored for the Braid application. Each custom error class such as `InvalidParameterError`, `InvalidOperationError`, `InvalidStateError`, `ConnectionError`, `EnvironmentError`, and `AssertionFailedError` includes features like restoring the prototype chain for TypeScript support, standard error naming for improved stack trace readability, and automatic logging.

Logging functions `logApiError` and `logCoreError` are used within the constructors to log error messages, enhancing error traceability.

Classes:
- InvalidParameterError
- InvalidOperationError
- InvalidStateError
- ConnectionError
- EnvironmentError
- AssertionFailedError

**FindEnrichedChunkApi.ts**

The `FindEnrichedChunkApi` module provides an API for locating and retrieving enriched data chunks. 

It includes the `FindEnrichedChunkApi` class, which extends from the `Api` class. The class is initialized with environment and session key parameters for authentication.

Key methods include `findChunkFromUrl`, which fetches an enriched chunk summary for a given URL query, `findRelevantChunksFromUrl`, which retrieves a list of relevant enriched chunks based on URL, and `findRelevantChunksFromSummary`, which finds relevant chunks based on a summary query.

The methods make asynchronous POST requests using the `axios` library to the defined API endpoints, handling errors and logging them as necessary.

**FindThemeApi.Types.ts**

This module, `FindThemeApi.Types`, contains type definitions for the FindTheme API. The API is designed to analyze text content and identify its primary theme.

The interface `IFindThemeRequest` defines the structure of request objects, detailing that they should include a `text` property (the text to be analyzed) and a `length` property (the length of the text).

The interface `IFindThemeResponse` describes the structure of response objects. These responses contain a `theme` property, indicating the primary theme derived from the supplied text. 

These interfaces ensure that requests and responses adhere to expected formats for efficient communication with the FindTheme API.

**Fluid.ts**

The code defines core interfaces for the Fluid Framework token authentication module.

**Key interfaces:**
1. **IFluidUser:** Represents a Fluid user with properties indicating if the user is operating locally (local), the userId, and userName.
2. **IFluidTokenRequest:** Combines the user information from IFluidUser with a documentId that specifies the ID of the shared document.
3. **IFluidTokenResponse:** Returns a token in response to a Fluid token request.

These interfaces facilitate the authentication process between client applications and the Fluid service, accommodating both development and production environments.

**FluidApi.ts**

The provided code defines a TypeScript module named `FluidApi`, which is used to generate Fluid Framework tokens.

The **`FluidApi`** class extends a base class `Api` and includes error handling and retry logic using `axios` and `axios-retry`. The class is initialized with an environment configuration and a session key.

The `generateToken` method takes a query parameter containing `documentId`, `userId`, and `userName`. It attempts to post this data to an API endpoint, retrying up to 5 times in case of network errors or HTTP 429 status responses. If successful, it returns the generated token; otherwise, it logs an error and returns undefined.

Important classes and functions:
- **FluidApi**
- **generateToken**

**FluidTokenProvider.ts**

The module **FluidTokenProvider** is designed for managing token generation and connection configuration for Azure Fluid Relay services.

- The **FluidTokenProvider** class handles the token generation for both orderer and storage connections. It interacts with the **FluidApi** class to generate tokens based on user credentials and environment settings.
  
- The **FluidConnectionConfig** class configures connection details such as the token provider, endpoint, tenant ID, and connection type. It can operate in both local and remote environments by adjusting its settings accordingly.
  
- The **FluidClientProps** class sets up client properties using the connection configuration specified in **FluidConnectionConfig**.

This module manages authentication through session keys and user contexts, and adjusts configurations based on the environment settings.

**IEnvironment.ts**

The `IEnvironment` module defines an interface for managing different deployment environments (Local, Staging, Production) in the Braid application. It outlines the environment-specific configurations and API endpoints required throughout the application. 

The key elements include:
- Enum `EEnvironment` lists the types of environments.
- Constant `BRAID_ENVIRONMENT_KEY` holds the environment key.
- Interface `IEnvironment` details properties and methods for handling environment settings.

The `IEnvironment` interface includes methods for various operations:
- Authentication and session management (`checkSessionApi`, `loginWithLinkedInApi`, `authFromLinkedInApi`).
- Content operations such as summarization, classification, and embedding (`summariseApi`, `classifyApi`, `embedApi`).
- Activity tracking (`saveActivityApi`, `removeActivityApi`, `getActivityApi`, `findActivityApi`, `getActivitiesApi`).
- Chunk and page operations (`chunkApi`, `saveChunkApi`, `removeChunkApi`, `getChunkApi`, `findChunkApi`, `getChunksApi`, `savePageApi`, `getPageApi`).
- Integration with other services like LinkedIn and Fluid (`generateFluidTokenApi`, `fluidApi`, `fluidTenantId`, `studioForTeamsBoxer`).

Overall, the module ensures appropriate environment configurations and streamline API interactions for the Braid application across various deployment setups.

**IEnvironmentFactory.ts**

This module, **IEnvironmentFactory**, is designed to create environment instances for different deployment contexts: Development, Staging, and Production.

The `getDefaultEnvironment` function determines and returns the default environment instance by checking the execution context and the `BRAID_ENVIRONMENT` process variable, returning a `DevelopmentEnvironment` for local settings or a `ProductionEnvironment` otherwise.

The `getDefaultFluidEnvironment` and `getDefaultLoginEnvironment` functions decide the environment similarly but prioritize the browser's localhost to set `DevelopmentEnvironment`.

The `getEnvironment` function creates and returns specific environment instances based on the provided `EEnvironment` type.

Important classes/functions:
- `getDefaultEnvironment`
- `getDefaultFluidEnvironment`
- `getDefaultLoginEnvironment`
- `getEnvironment`
- `DevelopmentEnvironment`
- `StagingEnvironment`
- `ProductionEnvironment`

**IModel.ts**

The code defines core elements for AI model management.

It contains an enumeration `EModel` with two possible values, "Small" and "Large", representing model sizes.

An interface `IModel` is defined to standardize AI model deployments. The interface includes properties for deployment names, chunk sizes, and several text processing methods. These methods check if a given text fits within specific chunk sizes and provide a way to chunk text and estimate the number of tokens in the text.

The module facilitates the organization and handling of model variants and their text processing capabilities in AI model management systems.

**IModelDriver.ts**

The `IModelDriver` module defines core interfaces and enums for facilitating model-driven conversations between users and AI models. 

It introduces `EModelConversationRole`, an enum for differentiating roles such as system, assistant, and user.

`IModelConversationElement` is an interface representing individual messages with properties for role and content.

`IModelConversationPrompt` is an interface for structuring complete conversation contexts, including conversation history and the current prompt.

`IEmbeddingModelDriver` defines methods for text embedding, including `getDrivenModelType()` and `embed()`.

`IChatModelDriver` includes methods for chat model interactions, such as `generateResponse()` which generates a model response based on a given prompt and persona. 

Key classes/interfaces/functions: `EModelConversationRole`, `IModelConversationElement`, `IModelConversationPrompt`, `IEmbeddingModelDriver`, `IChatModelDriver`, and `generateResponse()`.

**IModelFactory.ts**

This module, `IModelFactory`, is responsible for creating AI model instances. It provides functions for default model creation and specific model creation based on the requested `EModel` type. This abstraction ensures consistent instantiation and hides implementation details.

Key functions in the module include:
- `getDefaultModel()`: Returns the default model instance, `GPT4`.
- `getModel(model: EModel)`: Returns an AI model instance based on the provided `EModel` type.
- `getDefaultEmbeddingModelDriver()`: Returns the default embedding model driver, `OpenAIEmbeddingModelDriver`.
- `getEmbeddingModelDriver(model: EModel)`: Returns an embedding model driver based on the `EModel` type.
- `getDefaultChatModelDriver()`: Returns the default chat model driver, `OpenAIChatModelDriver`.
- `getChatModelDriver(model: EModel)`: Returns a chat model driver based on the `EModel` type.

**IPromptPersona.ts**

**Module Description**  
The `IPromptPersona` module defines interfaces and enums for managing different AI prompt personas tailored for specific summarization tasks.

**Key Classes and Functions**  
- **EPromptPersona**: An enumeration listing different persona types, including `ArticleSummariser`, `CodeSummariser`, `SurveySummariser`, among others. Each value represents a specific AI prompt persona designed for specialized summarization tasks.
- **IPromptPersona**: An interface that outlines the structure of a prompt persona. It includes:
  - `name`: A string representing the persona's name.
  - `systemPrompt`: A string defining the system-level prompt configuration.
  - `itemPrompt`: A string specifying the item-level prompt configuration.

**IPromptPersonaFactory.ts**

The `IPromptPersonaFactory` module creates specialized AI prompt personas for different content summarization tasks.

Predefined persona templates include those for summarizing articles, code, and surveys. Each persona is defined with a `systemPrompt` and an `itemPrompt`.

The `getChatPersona` function generates customized prompt personas based on the specified persona type, userPrompt, and additional parameters. The word count target can be adjusted through the function's parameters.

Notable functions and classes: 
- `getChatPersona`: Generates the appropriate prompt persona based on input parameters.
- Persona templates: `DefaultPersona`, `DeveloperAssistantPersona`, `ArticleSummariserPersona`, `CodeSummariserPersona`, `SurveySummariserPersona`, `TestForSummariseFailPersona`, `ClassifierPersona`, `ThemeFinderPersona`, `DeveloperQuestionGeneratorPersona`, `DeveloperImaginedAnswerGeneratorPersona`.

**IStorable.ts**

This module, `IStorable`, establishes core interfaces and types for persistent storage within an application. It aims to provide consistent storage patterns while allowing flexibility for application-specific extensions.

**Important Classes/Functions:**

1. **EStorableApplicationIds**: An enumeration representing application identifiers such as "Boxer" and "Waterfall".

2. **IStorable**: An interface outlining the structure of objects that can be stored, including properties like `id`, `applicationId`, `contextId`, `userId`, `created`, `amended`, `className`, and `schemaVersion`.

3. **IStorableMultiQuerySpec**: Defines the structure for querying multiple records, including properties `limit` and `className`.

4. **IStorableQuerySpec**: Defines the structure for querying a single record by `id` or `functionalSearchKey`.

5. **IStorableOperationResult**: An interface defining the result of storage operations, indicating success with the `ok` property.

**Logging.ts**

This module provides logging functionality to handle different parts of an application, including core system errors, database errors, and API errors and information.

Major functions include:
- `logCoreError(description: string, details: any): void` for logging core system errors.
- `logDbError(description: string, details: any): void` for logging database errors.
- `logApiError(description: string, details: any): void` for logging API errors.
- `logApiInfo(description: string, details: any): void` for logging API-related information.

Each logging function accepts a description and details parameter to format and output consistent log messages for easier debugging and maintenance across the application.

**LoginApi.ts**

The `LoginApi` module provides functionality for handling login operations using the LinkedIn API.

The main class, `LoginApi`, extends the `Api` class and requires environment settings (`IEnvironment`) and a session key for instantiation.

The constructor initializes a `LoginApi` instance with the given environment and session key.

The asynchronous `login` method constructs a URL using the provided session key, makes a POST request to the LinkedIn API, and handles the response. If successful, it returns a "Redirecting..." status; otherwise, it logs the error and returns an empty string.

Important classes or functions:
- `LoginApi` class
- `login` method

**LooseObject.ts**

This module defines a TypeScript interface called `LooseObject`.

The `LooseObject` interface allows for any key-value pairs, where keys are strings and values can be of any type. 

This is useful for creating flexible data structures without predefined schemas, making it a versatile choice when working with dynamic data.

The main component of this module is the `LooseObject` interface.

**Model.OAI.ts**

The provided module, `Model`, is designed to manage AI models and their deployment settings, focusing on the GPT4 implementation of the IModel interface.

The `GPT4` class encapsulates various properties such as deployment names and chunk sizes, both with and without buffers. It has methods to check if a text fits into default, maximum, or embedding chunk sizes, determining if the number of tokens in a text is within specific limits.

The `chunkText` method splits input text into smaller chunks based on optional overlap parameters, facilitating manageable text pieces for processing.

The `estimateTokens` method estimates the number of tokens in the provided text using a tokenizer.

**ModelDrivers.OAI.ts**

This module, `IModelDrivers.OAI`, provides implementations specific to OpenAI for embedding model drivers, with functionality for calculating text embeddings using Azure OpenAI services.

Key components include:
- **OpenAIEmbeddingModelDriver**: This class implements the `IEmbeddingModelDriver` interface and the `embed` method, which computes text embeddings using the `calculateEmbedding` function.
- **calculateEmbedding**: This is an asynchronous utility function that uses Azure OpenAI services to compute embeddings for given text, with up to 5 retries for handling rate limits.

Additionally, the module provides the `OpenAIChatModelDriver` class implementing the `IChatModelDriver` interface to facilitate OpenAI chat model interactions via the `chat` function. This function generates chat responses for specified personas by communicating with Azure OpenAI and includes retry logic for robustness.

**PageRepositoryApi.ts**

The `PageRepositoryApi` module provides an API for managing the storage and retrieval of pages within an application. It contains the class `PageRepositoryApi`.

The `PageRepositoryApi` class extends from the `Api` class and implements the `IStorablePageRepositoryApiWrapper` interface, ensuring consistent storage patterns and handling specific requirements such as content compression.

Key methods include `save`, which saves a page record to a persistent storage system using the `StorableRepostoryApi` class, and `compressString`/`decompressString`, which handle compression and decompression of page content using a deflate algorithm. The constructor initializes the instance with the provided environment and session key for authentication.

Important classes and functions:
- `Api`
- `PageRepositoryApi`
- `IStorablePageRepositoryApiWrapper`
- `StorableRepostoryApi`
- `compressString`
- `decompressString`

**PageRepositoryApi.Types.ts**

This module `PageRepositoryApi.Types` defines data types and interfaces for the PageRepository API. It includes the structure for stored pages and their HTML content, as well as request and response types for page storage operations. These interfaces ensure type-safe operations in the PageRepositoryApi module.

**Important Interfaces:**
1. `IStoredPage`: Represents a stored web page, including its HTML content.
2. `IStoredPageRequest`: Specifies the structure for page storage request operations.
3. `IStoredPageResponse`: Defines the structure for the response obtained after a page storage operation.

These types support the API's functionality by providing clear, consistent data structures.

**QueryModelApi.ts**

The module `QueryModelApi` provides an API for querying models with enrichment and generating questions. 

The `QueryModelApi` class extends the `Api` class. It requires an environment and a session key for authentication during initialization. 

The method `queryModelWithEnrichment` allows you to send an enriched query to the model and returns a promise that resolves to the enriched response data. It handles HTTP POST requests and returns undefined in case of errors.

The method `generateQuestion` sends a query containing persona prompt, question generation prompt, and summary to the model to generate questions. It also handles HTTP POST requests and returns a promise that resolves to the generated question response or undefined for errors.

**SessionApi.ts**

**SessionApi Class:**
The `SessionApi` class extends the base `Api` class to manage user sessions and authentication. It implements methods for validating session keys and handling session authentication states. 

**Constructor:**
The constructor initializes an instance of `SessionApi` with environment settings and a session key required for authentication.

**checkSessionKey Method:**
The `checkSessionKey` method is an asynchronous function that verifies the validity of a session key by sending a POST request to a session API endpoint. It returns a promise that resolves to a string indicating the session key's validity. 

**Modules and Imports:**
The code imports `axios` for HTTP requests, and imports `Api` and `IEnvironment` for class dependencies.

**StorableRepositoryApi.ts**

The module `StorableRepositoryApi` provides a framework for handling repository operations for objects implementing the `IStorable` interface.

`IStorablePageRepostoryApiWrapper` is an interface that provides a `save` method for saving storable records. 

`IStorableRepostoryApiWrapper` extends `IStorablePageRepostoryApiWrapper` with additional methods like `remove`, `load`, `find`, and `recent` to manage storable records.

`StorableRepostoryApi` class offers methods (`save`, `remove`, `load`, `find`, and `recent`) to interact with a repository via HTTP requests using Axios. These methods handle saving, removing, loading, and fetching recent records by making API calls.

**StudioApi.Types.ts**

This module, `StudioApi.Types`, defines the data types and interfaces used by the Studio API, ensuring type-safe interactions with its endpoints.

The `IStudioBoxerRequest` interface defines the structure for requests made to the Studio Boxer, requiring a `question` string.

The `IStudioBoxerResponseEnrichment` interface outlines the structure for the enrichment data in responses, including an `id`, `summary`, and optional `title`, `url`, and `iconUrl`.

**SummariseApi.Types.ts**

This module, named `SummariseApi.Types`, defines the data types and interfaces used within the Summarise API, ensuring type-safe text summarisation operations.

The `ISummariseRequest` interface outlines the structure for summarisation requests, which includes properties such as `persona` (an enum of type `EPromptPersona`), `text` (the text to be summarized), and an optional `lengthInWords` parameter to specify the desired length of the summary.

The `ISummariseResponse` interface defines the structure for summarisation responses, containing a single property `summary` that holds the summarized text.

These definitions support the core functionality of the SummariseApi module.

**TestForSummariseFailApi.Types.ts**

This module belongs to the `TestForSummariseFailApi` and handles the data types and interfaces required for summary validation.

The interface `ITestForSummariseFailRequest` defines the structure of a summarise request, including mandatory `text` and an optional `lengthInWords`.

The `ETestForSummariseFail` is an enumeration that lists possible validation results: `kSummaryFailed` and `kSummarySucceeded`.

The `ITestForSummariseFailResponse` interface defines the structure of a summarise response, which includes the validation result of type `ETestForSummariseFail`.

These types ensure type-safe validation of summaries within the `TestForSummariseFailApi` module.

**ThemeApi.ts**

The given code is part of the `ThemeApi` module developed by Braid Technologies Ltd. It provides type definitions and interfaces for detecting and analyzing themes in textual content.

The `IFindThemeRequest` interface specifies the structure of a request for theme detection. It includes two properties: `text`, which is the content to be analyzed, and `length`, which likely represents the length of the text or a relevant parameter for the theme-finding algorithm.

These type definitions ensure that the theme-related operations are type-safe, making the code more robust and easier to maintain.
****************************************

****************************************
CommonTs\src\SessionApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
import axios from 'axios';
/**
 * @module SessionApi
 * @description Provides an API for managing user sessions and authentication.
 * 
 * This module contains the SessionApi class which handles session validation
 * and authentication operations. It provides methods for:
 * - Checking session key validity
 * - Managing session authentication state
 * 
 * The module extends the base Api class to provide consistent authentication
 * patterns while handling session-specific requirements.
 */

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";


export class SessionApi extends Api {

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);
   }  

   /**
    * Asynchronously checks the validity of a session key by sending a POST request to the session API endpoint.
    * 
    * @returns A Promise that resolves to a boolean value indicating the validity of the session key.
    */
   async checkSessionKey () : Promise<string> {

      let apiUrl = this.environment.checkSessionApi() + "?session=" + this.sessionKey.toString();
      var response: any;

      try {
         response = await axios.post(apiUrl, {
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return "";
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return "";       
      }          
   }
   
}
****************************************

****************************************
CommonTs\src\StorableRepositoryApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
import axios from 'axios';
/**
 * @module StorableRepositoryApi
 * @description Provides base classes and interfaces for storable object repositories.
 * 
 * This module contains the StorableRepositoryApi class and related interfaces which handle
 * generic storage operations for objects implementing the IStorable interface. It provides:
 * - Base repository API implementation for saving, loading, and querying storable objects
 * - Interface definitions for repository wrappers with different capabilities
 * - Common patterns for interacting with storage APIs
 * 
 * The module serves as a foundation for specific repository implementations like
 * PageRepositoryApi while ensuring consistent storage patterns across the application.
 */

import { IStorable, IStorableMultiQuerySpec as IStorablesQuerySpec, IStorableQuerySpec} from "./IStorable";

/**
 * Represents a wrapper for interacting with a repository of storable objects.
 * Provides methods to save storable records.
 */
export interface IStorablePageRepostoryApiWrapper {
   
   save (record: IStorable) : Promise<boolean>;  
};

/**
 * Represents a wrapper for interacting with a repository of storable objects.
 * Provides methods to save, remove, and load storable records.
 */
export interface IStorableRepostoryApiWrapper extends IStorablePageRepostoryApiWrapper{
   
   remove (recordId: string) : Promise<boolean>;
   load (recordId: string) : Promise<IStorable | undefined>;
   find (functionalSearchKey: string) : Promise<IStorable | undefined>;  
   recent (querySpec: IStorablesQuerySpec, url: string) : Promise<Array<IStorable>>;
};

/**
 * Represents an API for Storables.
 * 
 * @param {EEnvironment} environment_ - The environment to use for saving Storables.
 * @param {string} sessionKey_ - The session key for authentication.
 * 
 * @method save - Saves a record to the Storables API.
 * @method remove - removes a record
 * @method recent - return a list of recent Storables
 */
export class StorableRepostoryApi {

   /**
    * Initializes a new instance of the class 
    */
   public constructor() {
   }  

   /**
    * Asynchronously saves a record to the Storables repository API.
    * 
    * @param record - The record to be saved, must implement the IStorable interface.
    * @param url - fully factored URL to the API to call
    * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
    */
   async save (record: IStorable, url: string) : Promise<boolean> {

      var response: any;

      try {
         response = await axios.post(url, {request: record});

         if (response && response.status === 200) {
            return true;
         }
         else {
            console.error ("Error, status: " + response?.status);               
            return false;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return false;       
      }          
   }

   /**
    * Asynchronously removes a record from the Storables repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @param url - fully factored URL to the API to call
    * @returns A Promise that resolves to true if the record is successfully removed, false otherwise.
    */
   async remove (recordId: string, url: string) : Promise<boolean> {

      let query: IStorableQuerySpec = {
         id: recordId,
         functionalSearchKey: undefined         
      }
      
      var response: any;

      try {
         response = await axios.post(url, {request: query});

         if (response && response.status === 200) {
            return true;
         }
         else {
            console.error ("Error, status: " + response?.status);               
            return false;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return false;       
      }          
   }

   /**
    * Asynchronously loads a record from the Storable repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @param url - fully factored URL to the API to call
    * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
    */
   async load (recordId: string, url: string) : Promise<IStorable | undefined> {

      let query: IStorableQuerySpec = {
         id: recordId,
         functionalSearchKey: undefined
      }
      var response: any;

      try {
         response = await axios.post(url, {request: query});

         if (response && response.status === 200) {       
            return (response.data as IStorable);
         }
         else {
            console.error ("Error, status: " + response?.status);               
            return undefined;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return undefined;       
      } 
   }

   /**
    * Asynchronously finds a record from the Storable repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @param url - fully factored URL to the API to call
    * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
    */
   async find (functionalSearchKey: string, url: string) : Promise<IStorable | undefined> {

      let query: IStorableQuerySpec = {
         id: undefined,
         functionalSearchKey: functionalSearchKey
      }
      var response: any;

      try {
         response = await axios.post(url, {request: query});

         if (response.status === 200) {          
            return (response.data as IStorable);
         }
         else {
            console.error ("Error, status: " + response.status);               
            return undefined;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return undefined;       
      } 
   }

   /**
    * Asynchronously retrieves recent records from the Storables repository API based on the provided query specifications.
    * 
    * @param querySpec - The query specifications including the limit and storeClassName to filter the records.
    * @param url - fully factored URL to the API to call
    * @returns A Promise that resolves to an array of IStorable objects representing the recent records, or an empty array if an error occurs.
    */
   async recent (querySpec: IStorablesQuerySpec, url: string) : Promise<Array<IStorable>> {

      var response: any;

      try {
         response = await axios.post(url, {request: querySpec});

         if (response.status === 200) {

            let responseRecords = response.data;
            let storedRecords = new Array<IStorable>()

            for (let i = 0; i < responseRecords.length; i++) {
               storedRecords.push (responseRecords[i]);
            }

            return storedRecords;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return new Array<IStorable>();
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return new Array<IStorable>();       
      }          
   }   
}
****************************************

****************************************
CommonTs\src\StudioApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Studio API
/**
 * @module StudioApi.Types
 * @description Defines the data types and interfaces used by the Studio API.
 * 
 * This module contains the interfaces that define the structure of:
 * - Studio boxer requests and responses
 * - Enrichment data structures for studio responses
 * 
 * These types support the StudioApi module in providing type-safe
 * interactions with the Studio API endpoints.
 */

/**
 * Interface for the StudioBoxer request object.
 */
export interface IStudioBoxerRequest {

   question: string;
}

/**
 * Interface for the IStudioBoxerResponseEnrichment response object.
 */
export interface IStudioBoxerResponseEnrichment {

   id: string,
   summary: string;    
   title: string | undefined;
   url: string | undefined;  
   iconUrl: string | undefined;
}
****************************************

****************************************
CommonTs\src\StudioApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from StudioApi.Types.yaml with typeconv
  version: '1'
  x-id: StudioApi.Types.yaml
  x-comment: >-
    Generated from src\StudioApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IStudioBoxerRequest:
      properties:
        question:
          title: IStudioBoxerRequest.question
          type: string
      required:
        - question
      additionalProperties: false
      title: IStudioBoxerRequest
      description: Interface for the StudioBoxer request object.
      type: object
    IStudioBoxerResponseEnrichment:
      properties:
        id:
          title: IStudioBoxerResponseEnrichment.id
          type: string
        summary:
          title: IStudioBoxerResponseEnrichment.summary
          type: string
        title:
          title: IStudioBoxerResponseEnrichment.title
          type: string
        url:
          title: IStudioBoxerResponseEnrichment.url
          type: string
        iconUrl:
          title: IStudioBoxerResponseEnrichment.iconUrl
          type: string
      required:
        - id
        - summary
        - title
        - url
        - iconUrl
      additionalProperties: false
      title: IStudioBoxerResponseEnrichment
      description: Interface for the IStudioBoxerResponseEnrichment response object.
      type: object
****************************************

****************************************
CommonTs\src\SummariseApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Summarise API
/**
 * @module SummariseApi.Types
 * @description Defines the data types and interfaces used by the Summarise API.
 * 
 * This module contains the interfaces that define the structure of:
 * - Summarisation requests and responses
 * - Configuration options for summary generation
 * 
 * These types support the SummariseApi module in providing type-safe
 * text summarisation operations.
 */

import { EPromptPersona } from "./IPromptPersona";
/**
 * Defines the structure of a summarise request object.
 */
export interface ISummariseRequest{
   
   persona: EPromptPersona;
   text: string;
   lengthInWords?: number | undefined;
}

/**
 * Defines the structure of a summarise response object.
 */
export interface ISummariseResponse {

   summary: string;
}
****************************************

****************************************
CommonTs\src\SummariseApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from SummariseApi.Types.yaml with typeconv
  version: '1'
  x-id: SummariseApi.Types.yaml
  x-comment: >-
    Generated from src\SummariseApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    ISummariseRequest:
      properties:
        text:
          title: ISummariseRequest.text
          type: string
        lengthInWords:
          title: ISummariseRequest.lengthInWords
          type: number
      required:
        - text
      additionalProperties: false
      title: ISummariseRequest
      description: Defines the structure of a summarise request object.
      type: object
    ISummariseResponse:
      properties:
        summary:
          title: ISummariseResponse.summary
          type: string
      required:
        - summary
      additionalProperties: false
      title: ISummariseResponse
      description: Defines the structure of a summarise response object.
      type: object
****************************************

****************************************
CommonTs\src\TestForSummariseFailApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the SuppressSummariseFail API
/**
 * @module TestForSummariseFailApi.Types
 * @description Defines the data types and interfaces used by the TestForSummariseFail API.
 * 
 * This module contains the interfaces that define the structure of:
 * - Test requests for summary validation
 * - Response types indicating summary validation status
 * - Enumeration of possible validation results
 * 
 * These types support the TestForSummariseFailApi module in providing type-safe
 * validation of generated summaries.
 */

/**
 * Defines the structure of a summarise request object.
 */
export interface ITestForSummariseFailRequest{

   text: string;
   lengthInWords?: number | undefined;
}

export enum ETestForSummariseFail {
   kSummaryFailed = "SummaryFailed",
   kSummarySucceeded = "SummarySucceeded"
}

/**
 * Defines the structure of a summarise response object.
 */
export interface ITestForSummariseFailResponse {

   isValidSummary: ETestForSummariseFail;
}
****************************************

****************************************
CommonTs\src\ThemeApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the FindTheme API
/**
 * @module ThemeApi
 * @description Provides interfaces and types for theme detection and analysis.
 * 
 * This module contains the interfaces that define the structure of:
 * - Theme detection requests and responses
 * - Criteria for finding themes in text
 * 
 * These types support theme-related operations by providing type-safe
 * structures for analyzing and identifying thematic elements in content.
 */

/**
 * Interface for specifying the criteria to find a theme.
 * @interface
 */
export interface IFindThemeRequest{

   text: string;
   length : number;
}
****************************************

****************************************
CommonTs\dist\src\ActivityRepositoryApi.d.ts
****************************************
/**
 * @module ActivityRepositoryApi
 *
 * This module provides an API wrapper for managing activity records in a repository.
 * It extends the base Api class and implements IStorableRepostoryApiWrapper interface
 * to provide CRUD operations for activity records.
 *
 * The module handles:
 * - Loading individual activity records
 * - Finding activities by search key
 * - Saving new or updated activities
 * - Removing activities
 * - Retrieving recent activities with query specifications
 *
 * All operations require proper authentication via session key and communicate
 * with the appropriate environment-specific API endpoints.
 */
import { Api } from './Api';
import { IStorable, IStorableMultiQuerySpec } from "./IStorable";
import { IEnvironment } from "./IEnvironment";
import { IStorableRepostoryApiWrapper } from './StorableRepositoryApi';
/**
 * Represents an API for activities.
 *
 * @param {EEnvironment} environment_ - The environment to use for saving activities.
 * @param {string} sessionKey_ - The session key for authentication.
 *
 * @method save - Saves a record to the Activity API.
 * @method remove - removes a record
 * @method load - load an Activity given the key
 * @method recent - return a list of recent activities
 */
export declare class ActivityRepostoryApi extends Api implements IStorableRepostoryApiWrapper {
    private storableApi;
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously loads a record from the activity repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
     */
    load(recordId: string): Promise<IStorable | undefined>;
    /**
     * Asynchronously finds a record from the activity repository API.
     *
     * @param functionalSearchKey - The ID of the record to be removed.
     * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
     */
    find(functionalSearchKey: string): Promise<IStorable | undefined>;
    /**
     * Asynchronously saves a record to the activity repository API.
     *
     * @param record - The record to be saved, must implement the IStorable interface.
     * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
     */
    save(record: IStorable): Promise<boolean>;
    /**
     * Asynchronously removes a record from the activity repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @returns A Promise that resolves to true if the record is successfully removed, false otherwise.
     */
    remove(recordId: string): Promise<boolean>;
    /**
     * Asynchronously retrieves recent records from the activity repository API based on the provided query specifications.
     *
     * @param querySpec - The query specifications including the limit and storeClassName to filter the records.
     * @returns A Promise that resolves to an array of IStorable objects representing the recent records, or an empty array if an error occurs.
     */
    recent(querySpec: IStorableMultiQuerySpec): Promise<Array<IStorable>>;
}
//# sourceMappingURL=ActivityRepositoryApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Api.d.ts
****************************************
import { IEnvironment } from "./IEnvironment";
/**
 * Represents an API class that interacts with the specified environment using the provided session key.
 * This is a super class of each actual (useful) API. In itself it isn't very useful, it just holds common data.
 * @param {IEnvironment} environemnt_ - The environment interface to interact with.
 * @param {string} sessionKey_ - The session key for authentication.
 */
export declare class Api {
    private _environment;
    private _sessionKey;
    constructor(environemnt_: IEnvironment, sessionKey_: string);
    get environment(): IEnvironment;
    get sessionKey(): string;
}
//# sourceMappingURL=Api.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Asserts.d.ts
****************************************
export declare const throwIfUndefined: <T>(x: T | undefined) => asserts x is T;
export declare const throwIfNull: <T>(x: T | null) => asserts x is T;
export declare const throwIfFalse: (x: boolean) => asserts x is true;
//# sourceMappingURL=Asserts.d.ts.map
****************************************

****************************************
CommonTs\dist\src\ChunkApi.Types.d.ts
****************************************
/**
 * @module ChunkApi.Types
 * @description Type definitions for the Chunk API, which handles text chunking operations.
 * This module provides interfaces for chunk request and response objects used in text
 * segmentation operations. It supports configurable chunk sizes and overlap between
 * chunks for optimal text processing.
 */
/**
 * Interface for chunk reqiest API.
 * @property {string} text - The text content of the chunk.
 * @property {number | undefined} chunkSize - The size of the chunk in tokens, if specified.
 * @property {number | undefined} overlapWords - The size of the overlap between chunks, in words (=2 * tokens) if specified.
 */
export interface IChunkRequest {
    text: string;
    chunkSize?: number | undefined;
    overlapWords?: number | undefined;
}
/**
 * Return type of chunk reqiest API.
 * @property {Array<string>} chunks - Array of text chunks
 */
export interface IChunkResponse {
    chunks: Array<string>;
}
//# sourceMappingURL=ChunkApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\ChunkRepositoryApi.d.ts
****************************************
/**
 * @module ChunkRepositoryApi
 *
 * This module provides an API wrapper for managing text chunking operations.
 * It extends the base Api class and implements IStorableRepostoryApiWrapper interface
 * to provide CRUD operations for text chunking.
 *
 * The module handles:
 * - Loading individual text chunks
 * - Finding text chunks by search key
 * - Saving new or updated text chunks
 * - Removing text chunks
 * - Retrieving recent text chunks with query specifications
 *
 * All operations require proper authentication via session key and communicate
 * with the appropriate environment-specific API endpoints.
 */
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IStorable, IStorableMultiQuerySpec } from "./IStorable";
import { IStorableRepostoryApiWrapper } from './StorableRepositoryApi';
/**
 * Represents an API for the Chunk repository
 *
 * @param {EEnvironment} environment_ - The environment to use for saving Chunks.
 * @param {string} sessionKey_ - The session key for authentication.
 *
 * @method save - Saves a record to the Chunk API.
 * @method remove - removes a record
 * @method load - load an Chunk given the key
 */
export declare class ChunkRepostoryApi extends Api implements IStorableRepostoryApiWrapper {
    private storableApi;
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously loads a record from the Chunk repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
     */
    load(recordId: string): Promise<IStorable | undefined>;
    /**
     * Asynchronously finds a record from the Chunk repository API.
     *
     * @param functionalSearchKey - The ID of the record to be removed.
     * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
     */
    find(functionalSearchKey: string): Promise<IStorable | undefined>;
    /**
     * Asynchronously saves a record to the chunk repository API.
     *
     * @param record - The record to be saved, must implement the IStoredChunk interface.
     * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
     */
    save(record: IStorable): Promise<boolean>;
    /**
     * Asynchronously removes a record from the Chunk repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @returns A Promise that resolves to true if the record is successfully removed, false otherwise.
     */
    remove(recordId: string): Promise<boolean>;
    /**
     * Asynchronously retrieves recent records from the activity repository API based on the provided query specifications.
     *
     * @param querySpec - The query specifications including the limit and storeClassName to filter the records.
     * @returns A Promise that resolves to an array of IStorable objects representing the recent records, or an empty array if an error occurs.
     */
    recent(querySpec: IStorableMultiQuerySpec): Promise<Array<IStorable>>;
}
//# sourceMappingURL=ChunkRepositoryApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\ChunkRepositoryApi.Types.d.ts
****************************************
/**
 * @module ChunkRepositoryApi.Types
 * @description Defines the core data types and interfaces for the ChunkRepository API.
 * This module contains type definitions for chunks, embeddings, and text renderings used
 * throughout the chunk storage system. It includes interfaces for storing and managing
 * text fragments with their associated metadata, embeddings, and relationships.
 *
 * Key components:
 * - IStoredEmbedding: For storing vector embeddings with their model ID
 * - IStoredTextRendering: For storing text generations with their model ID
 * - IStoredChunk: The main chunk interface that combines text, embeddings, and metadata
 */
import { IStorable } from "./IStorable";
export declare const storedChunkClassName = "Chunk";
/**
 * Represents an interface for storing embeddings with a model ID and an array of numbers representing the embedding.
 */
export interface IStoredEmbedding {
    modelId: string;
    embedding: Array<number>;
}
/**
 * Defines the structure of a stored text rendering object.
 */
export interface IStoredTextRendering {
    modelId: string;
    text: string;
}
/**
 * Interface representing a chunk of data.
 *
 * Core data for a chunk:
 * - parentChunkId: Primary key to parent document
 * - originalText: Original text; 0 if undefined, it has been thrown away (as maybe it can be reconstructed)
 * - url: string | undefined;                 // url to external resource, can be null
 * - storedEmbedding: Embedding of the original text
 * - storedSummary: Summary of the original text - generated with application-specific prompt
 * - storedTitle: A generated of the original text - generated with application-specific prompt
 * - related: Array of IDs to related chunks
 */
export interface IStoredChunk extends IStorable {
    parentChunkId: string | undefined;
    originalText: string | undefined;
    url: string | undefined;
    storedEmbedding: IStoredEmbedding | undefined;
    storedSummary: IStoredTextRendering | undefined;
    storedTitle: IStoredTextRendering | undefined;
    relatedChunks: Array<string> | undefined;
}
//# sourceMappingURL=ChunkRepositoryApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\ClassifyApi.Types.d.ts
****************************************
/**
 * @fileoverview Type definitions for the Classification API
 * Contains interfaces for classification requests and responses used in the text classification system.
 * These types ensure type safety when making classification API calls and handling responses.
 *
 * @module ClassifyApi.Types
 */
/**
 * Represents a classification request object with text and classifications.
 */
export interface IClassifyRequest {
    text: string;
    classifications: Array<string>;
}
/**
 * Interface for the classification response object.
 */
export interface IClassifyResponse {
    classification: string;
}
//# sourceMappingURL=ClassifyApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Compress.d.ts
****************************************
/**
 * Compresses a string using deflate algorithm
 * @param input The string to compress
 * @returns Base64 encoded compressed string
 */
export declare function compressString(input: string): string;
/**
 * Decompresses a string that was compressed using compressString
 * @param input Base64 encoded compressed string
 * @returns Original decompressed string
 */
export declare function decompressString(input: string): string;
//# sourceMappingURL=Compress.d.ts.map
****************************************

****************************************
CommonTs\dist\src\EmbedApi.Types.d.ts
****************************************
/**
 * @fileoverview Type definitions for the Embed API, which handles text embedding operations.
 * This module contains interfaces for embedding requests and responses, defining the
 * contract between clients and the embedding service.
 *
 * @module EmbedApi.Types
 */
import { EPromptPersona } from "./IPromptPersona";
/**
 * Interface for the embedding request object.
 */
export interface IEmbedRequest {
    persona: EPromptPersona;
    text: string;
}
/**
 * Interface for the embedding response object.
 */
export interface IEmbedResponse {
    embedding: Array<number>;
}
//# sourceMappingURL=EmbedApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\EnrichedChunk.d.ts
****************************************
/**
 * @fileoverview Defines the core data structures and interfaces for the Chunk API.
 * This module contains type definitions and interfaces for enriched chunks, which are
 * fundamental units of content that can be stored, queried, and retrieved based on
 * semantic similarity. It includes specifications for both client-side summaries and
 * server-side storage formats, as well as query parameters for retrieving relevant chunks.
 *
 * Key components:
 * - EChunkRepository: Enumeration of available chunk storage repositories
 * - IEnrichedChunk: Complete chunk representation with embeddings
 * - IEnrichedChunkSummary: simple chunk representation
 * - IChunkQuerySpec: Base query parameters for chunk retrieval
 *
 * @module EnrichedChunk
 */
export declare enum EChunkRepository {
    kBoxer = "Boxer",
    kWaterfall = "Waterfall"
}
export declare const kDefaultSimilarityThreshold = 0.5;
/**
 * Represents a Chunk enriched with specific properties.
 * This is a summary class that can be passed between client & server.
 * @property {string} url - The URL associated with the chunk.
 * @property {string} text - The textual content of the chunk.
 * @property {string} summary - The summary content of the chunk.
 */
export interface IEnrichedChunkSummary {
    url: string;
    text: string;
    summary: string;
}
/**
 * Represents a Chunk enriched with specific properties.
  * This is a server side class only - its for storage.
 * @property {string} id - The unique identifier of the chunk.
 * @property {Array<number>} embedding - An array of numbers representing the embedding of the chunk.
 */
export interface IEnrichedChunk extends IEnrichedChunkSummary {
    id: string;
    embedding: number[];
}
/**
 * Represents a relevant chunk with its associated relevance score.
 */
export interface IRelevantEnrichedChunk {
    chunk: IEnrichedChunkSummary;
    relevance: number;
}
/**
 * Defines the structure of a chunk query specification object.
 *
 * @property {EChunkRepository} repositoryId - The ID of the repository to query.
 * @property {number} maxCount - The maximum number of results to retrieve.
 * @property {number} similarityThreshold - The threshold for similarity comparison.
 */
export interface IChunkQuerySpec {
    repositoryId: EChunkRepository;
    maxCount: number;
    similarityThreshold: number;
}
/**
 * Extends the IChunkQuerySpec interface to include a 'url' property of type string.
 */
export interface IChunkQueryRelevantToUrlSpec extends IChunkQuerySpec {
    url: string;
}
/**
 * Extends the IChunkQuerySpec interface to include a 'summary' property of type string.
 */
export interface IChunkQueryRelevantToSummarySpec extends IChunkQuerySpec {
    summary: string;
}
//# sourceMappingURL=EnrichedChunk.d.ts.map
****************************************

****************************************
CommonTs\dist\src\EnrichedQuery.d.ts
****************************************
/**
 * @module EnrichedQuery
 *
 * This module defines the core interfaces and enums for the Query API, which handles
 * enriched conversations with AI assistants. It includes:
 *
 * - Conversation roles and elements
 * - Standard system prompts for different AI interactions
 * - Query and response interfaces for enriched conversations
 * - Structures for question generation and responses
 *
 * The interfaces defined here are used throughout the application to maintain
 * type safety when working with AI-enriched conversations and queries.
 */
import { EChunkRepository, IRelevantEnrichedChunk } from "./EnrichedChunk";
import { IModelConversationElement } from "./IModelDriver";
/**
 * Defines the structure of an enriched query object.
 * Contains information about the repository, persona prompt, question prompt,
 * enrichment document prompt, and conversation history.
 */
export interface IEnrichedQuery {
    repositoryId: EChunkRepository;
    similarityThreshold: number;
    maxCount: number;
    history: Array<IModelConversationElement>;
    question: string;
    wordTarget: number;
}
/**
 * Defines the structure of an enriched response object.
 * Contains an answer field of type string and a chunks field as an array of Relevant Enriched Chunk objects.
 */
export interface IEnrichedResponse {
    answer: string;
    chunks: Array<IRelevantEnrichedChunk>;
}
/**
 * Interface for generating questions query.
 * Contains a summary which after reading a developer might have a question
 * and a word target for the question
 */
export interface IGenerateQuestionQuery {
    summary: string;
    wordTarget: number;
}
/**
 * Defines the structure of a response object for question generation.
 * Contains a property 'question' of type string representing the generated question.
 */
export interface IQuestionGenerationResponse {
    question: string;
}
//# sourceMappingURL=EnrichedQuery.d.ts.map
****************************************

****************************************
CommonTs\dist\src\EnumerateModelsApi.Types.d.ts
****************************************
/**
 * Type definitions for the EnumerateModels and EnumerateRepositories APIs
 *
 * This module contains the interface definitions for requests and responses
 * used in model enumeration and repository listing operations. It defines:
 * - EnumerateModels API interfaces for listing available AI models
 * - EnumerateRepositories API interfaces for listing available chunk repositories
 *
 * @module EnumerateModelsApi.Types
 */
import { EChunkRepository } from './EnrichedChunk';
/**
 * Interface for the EnumerateModels request object.
 */
export interface IEnumerateModelsRequest {
}
/**
 * Interface for the EnumerateModels response object.
 */
export interface IEnumerateModelsResponse {
    defaultId: string;
    defaultEmbeddingId: string;
    largeId: string;
    largeEmbeddingId: string;
    smallId: string;
    smallEmbeddingId: string;
}
/**
 * Interface for the EnumerateRepositories request object.
 */
export interface IEnumerateRepositoriesRequest {
}
/**
 * Interface for the EnumerateModels response object.
 */
export interface IEnumerateReposotoriesResponse {
    repositoryIds: Array<EChunkRepository>;
}
//# sourceMappingURL=EnumerateModelsApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Environment.d.ts
****************************************
/**
 * @module Environment
 *
 * This module provides a base class for interacting with an environment.
 */
import { IEnvironment } from './IEnvironment';
/**
 * Class representing the Development Environment with methods to retrieve various API endpoints.
 * @class DevelopmentEnvironment
 */
export declare class DevelopmentEnvironment implements IEnvironment {
    name: string;
    checkSessionApi(): string;
    summariseApi(): string;
    findThemeApi(): string;
    classifyApi(): string;
    chunkApi(): string;
    embedApi(): string;
    testForSummariseFail(): string;
    saveActivityApi(): string;
    removeActivityApi(): string;
    getActivitiesApi(): string;
    getActivityApi(): string;
    findActivityApi(): string;
    loginWithLinkedInApi(): string;
    authFromLinkedInApi(): string;
    boxerHome(): string;
    findRelevantEnrichedChunksFromUrl(): string;
    findRelevantEnrichedChunksFromSummary(): string;
    findEnrichedChunkFromUrl(): string;
    queryModelWithEnrichment(): string;
    generateQuestion(): string;
    generateFluidTokenApi(): string;
    fluidApi(): string;
    fluidTenantId(): string;
    studioForTeamsBoxer(): string;
    saveChunkApi(): string;
    removeChunkApi(): string;
    getChunkApi(): string;
    findChunkApi(): string;
    getChunksApi(): string;
    savePageApi(): string;
    getPageApi(): string;
    hostProtocolAndName(): string;
}
/**
 * Class representing the Staging Environment with methods to retrieve various API endpoints.
 * @class StagingEnvironment
 */
export declare class StagingEnvironment implements IEnvironment {
    name: string;
    checkSessionApi(): string;
    summariseApi(): string;
    findThemeApi(): string;
    classifyApi(): string;
    chunkApi(): string;
    embedApi(): string;
    testForSummariseFail(): string;
    saveActivityApi(): string;
    removeActivityApi(): string;
    getActivityApi(): string;
    findActivityApi(): string;
    getActivitiesApi(): string;
    loginWithLinkedInApi(): string;
    authFromLinkedInApi(): string;
    boxerHome(): string;
    findRelevantEnrichedChunksFromUrl(): string;
    findRelevantEnrichedChunksFromSummary(): string;
    findEnrichedChunkFromUrl(): string;
    queryModelWithEnrichment(): string;
    generateQuestion(): string;
    generateFluidTokenApi(): string;
    fluidApi(): string;
    fluidTenantId(): string;
    studioForTeamsBoxer(): string;
    saveChunkApi(): string;
    removeChunkApi(): string;
    getChunkApi(): string;
    findChunkApi(): string;
    getChunksApi(): string;
    savePageApi(): string;
    getPageApi(): string;
    hostProtocolAndName(): string;
}
/**
 * Class representing a Production Environment with methods to retrieve various API endpoints.
 * @class ProductionEnvironment
 */
export declare class ProductionEnvironment implements IEnvironment {
    name: string;
    checkSessionApi(): string;
    summariseApi(): string;
    findThemeApi(): string;
    classifyApi(): string;
    chunkApi(): string;
    embedApi(): string;
    testForSummariseFail(): string;
    saveActivityApi(): string;
    removeActivityApi(): string;
    getActivityApi(): string;
    findActivityApi(): string;
    getActivitiesApi(): string;
    loginWithLinkedInApi(): string;
    authFromLinkedInApi(): string;
    boxerHome(): string;
    findRelevantEnrichedChunksFromUrl(): string;
    findRelevantEnrichedChunksFromSummary(): string;
    findEnrichedChunkFromUrl(): string;
    queryModelWithEnrichment(): string;
    generateQuestion(): string;
    generateFluidTokenApi(): string;
    fluidApi(): string;
    fluidTenantId(): string;
    studioForTeamsBoxer(): string;
    saveChunkApi(): string;
    removeChunkApi(): string;
    getChunkApi(): string;
    findChunkApi(): string;
    getChunksApi(): string;
    savePageApi(): string;
    getPageApi(): string;
    hostProtocolAndName(): string;
}
//# sourceMappingURL=Environment.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Errors.d.ts
****************************************
/**
 * Custom error classes for the Braid application.
 *
 * This module provides a collection of specialized error classes that extend the base Error class.
 * Each error type is designed to handle specific categories of errors that may occur within the
 * application, such as invalid parameters, connection issues, or environment-related problems.
 *
 * All error classes include:
 * - Proper prototype chain restoration for TypeScript
 * - Automatic error logging through logCoreError or logApiError
 * - Standardized error naming for stack traces
 *
 * @module Errors
 */
/**
 * Represents an error thrown when an invalid parameter is encountered.
 * @param {string} message - The error message describing the invalid parameter.
 */
export declare class InvalidParameterError extends Error {
    constructor(message?: string);
}
/**
 * Represents an error that occurs when an invalid operation is attempted.
 * @extends Error
 * @constructor
 * @param {string} [message] - The error message.
 */
export declare class InvalidOperationError extends Error {
    constructor(message?: string);
}
/**
 * Represents an error indicating an invalid state.
 * @param message - Optional. A message to describe the error.
 */
export declare class InvalidStateError extends Error {
    constructor(message?: string);
}
/**
 * Represents a custom error class for connection-related errors.
 * @class ConnectionError
 * @extends Error
 * @constructor
 * @param {string} [message] - The error message.
 */
export declare class ConnectionError extends Error {
    constructor(message?: string);
}
/**
 * Represents an error related to the environment.
 * @param {string} [message] - The error message.
 */
export declare class EnvironmentError extends Error {
    constructor(message?: string);
}
/**
 * Represents an error that occurs when an assertion fails.
 * @param message - Optional. A message to describe the error.
 */
export declare class AssertionFailedError extends Error {
    constructor(message?: string);
}
//# sourceMappingURL=Errors.d.ts.map
****************************************

****************************************
CommonTs\dist\src\FindEnrichedChunkApi.d.ts
****************************************
/**
 * @module   FindEnrichedChunkApi
 * @description Provides an API for finding and retrieving enriched chunks.
 *
 * This module contains the FindEnrichedChunkApi class which handles various API calls
 * related to finding enriched chunks based on URLs and summaries. It provides methods
 * for retrieving both individual chunk summaries and arrays of relevant chunks.
 *
 * The API supports:
 * - Finding single enriched chunk summaries by URL
 * - Finding relevant enriched chunks by URL
 * - Finding relevant enriched chunks by summary
 */
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IChunkQueryRelevantToSummarySpec, IChunkQueryRelevantToUrlSpec, IEnrichedChunkSummary, IRelevantEnrichedChunk } from './EnrichedChunk';
/**
 * Class representing an API for finding enriched chunks.
 */
export declare class FindEnrichedChunkApi extends Api {
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously finds an enriched chunk summary based on the provided URL query.
     *
     * @param urlQuery - The URL query specifying the URL to search for the enriched chunk.
     * @returns An IEnrichedChunkSummary objects representing the found enriched chunk summary, or undefined.
     */
    findChunkFromUrl(urlQuery: IChunkQueryRelevantToUrlSpec): Promise<IEnrichedChunkSummary | undefined>;
    /**
     * Asynchronously finds relevant enriched chunks based on the provided URL query.
     *
     * @param urlQuery - The URL query specifying the URL to search for relevant enriched chunks.
     * @returns A Promise that resolves to an array of IRelevantEnrichedChunk objects representing the found relevant enriched chunks.
     */
    findRelevantChunksFromUrl(urlQuery: IChunkQueryRelevantToUrlSpec): Promise<Array<IRelevantEnrichedChunk>>;
    /**
     * Asynchronously finds relevant enriched chunks based on the provided summary query.
     *
     * @param urlQuery - The summary query specifying the summary to search for relevant enriched chunks.
     * @returns A Promise that resolves to an array of IRelevantEnrichedChunk objects representing the found relevant enriched chunks.
     */
    findRelevantChunksFromSummary(urlQuery: IChunkQueryRelevantToSummarySpec): Promise<Array<IRelevantEnrichedChunk>>;
}
//# sourceMappingURL=FindEnrichedChunkApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\FindThemeApi.Types.d.ts
****************************************
/**
 * Types and interfaces for the FindTheme API.
 *
 * This module contains the type definitions for the request and response
 * objects used in the FindTheme API, which is responsible for analyzing
 * text content and identifying its primary theme.
 *
 * @module FindThemeApi.Types
 */
/**
 * Interface for the find theme request object.
 */
export interface IFindThemeRequest {
    text: string;
    length: number;
}
/**
 * Interface for the find theme response object.
 */
export interface IFindThemeResponse {
    theme: string;
}
//# sourceMappingURL=FindThemeApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Fluid.d.ts
****************************************
/**
 * @module Fluid
 * @description Defines the core interfaces for Fluid Framework token authentication.
 * Contains type definitions for user authentication, token requests, and token responses
 * used in the Fluid Framework integration.
 *
 * These interfaces facilitate the token-based authentication flow between the client
 * application and the Fluid service, supporting both local development and production
 * environments.
 */
/**
 * Represents a Fluid user.
 * @interface
 * @property {boolean} local - if true, we are running locally - use local tentantID
 * @property {string} userId - The ID of the user making the request.
 * @property {string} userName - The name of the user making the request.
 
 */
export interface IFluidUser {
    local: boolean;
    userId: string;
    userName: string;
}
/**
 * Represents a request for a Fluid token.
 * @interface
 * @property {string} documentId - ID of the shared document.
 */
export interface IFluidTokenRequest extends IFluidUser {
    documentId: string;
}
/**
 * Represents a response to a request for a Fluid token.
 * @interface
 * @property {string} token - the token
 */
export interface IFluidTokenResponse {
    token: string;
}
//# sourceMappingURL=Fluid.d.ts.map
****************************************

****************************************
CommonTs\dist\src\FluidApi.d.ts
****************************************
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IFluidTokenRequest } from './Fluid';
export declare class FluidApi extends Api {
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously generates a token using the provided query parameters.
     *
     * @param query - The request object containing documentId, userId, and userName.
     * @returns A Promise that resolves to a string if successful, otherwise undefined.
     */
    generateToken(query: IFluidTokenRequest): Promise<string | undefined>;
}
//# sourceMappingURL=FluidApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\FluidTokenProvider.d.ts
****************************************
/**
 * @module FluidTokenProvider
 * @description Provides token management and connection configuration for Azure Fluid Relay services.
 *
 * This module implements the necessary components to establish and manage connections
 * to Azure Fluid Relay, including:
 * - Token generation and management via FluidTokenProvider
 * - Connection configuration via FluidConnectionConfig
 * - Client properties setup via FluidClientProps
 *
 * The implementation supports both local and remote environments, with configurable
 * authentication through session keys and user contexts.
 */
import { AzureRemoteConnectionConfig, AzureClientProps, ITokenProvider, ITokenResponse } from "@fluidframework/azure-client";
import { IEnvironment } from "./IEnvironment";
import { IFluidUser, IFluidTokenRequest } from "./Fluid";
/**
 * Token Provider implementation for connecting to an Azure Function endpoint for
 * Azure Fluid Relay token resolution.
 */
export declare class FluidTokenProvider implements ITokenProvider {
    private _api;
    private _user;
    /**
     * Creates a new instance using configuration parameters.
     * @param environment The environment settings to be used.
     * @param sessionKey The session key for authentication
     * @param user - User object
     */
    constructor(environment: IEnvironment, sessionKey: string, user: IFluidUser);
    fetchOrdererToken(tenantId: string, documentId?: string): Promise<ITokenResponse>;
    fetchStorageToken(tenantId: string, documentId: string): Promise<ITokenResponse>;
    private getToken;
}
export declare class FluidConnectionConfig implements AzureRemoteConnectionConfig {
    tokenProvider: ITokenProvider;
    endpoint: string;
    type: any;
    tenantId: string;
    documentId: string;
    /**
     * Creates a new instance using configuration parameters.
     * @param sessionKey The session key for authentication
     * @param tokenRequest - Details to request a token
     * @param forceProduction - boolean, if true then connect to production else default
     */
    constructor(sessionKey: string, tokenRequest: IFluidTokenRequest, forceProduction: boolean);
}
export declare class FluidClientProps implements AzureClientProps {
    connection: FluidConnectionConfig;
    /**
     * Creates a new instance using configuration parameters.
     * @param sessionKey The session key for authentication
     * @param tokenRequest - Details to request a token
     * @param forceProduction - boolean, if true then connect to production else default
     */
    constructor(sessionKey: string, tokenRequest: IFluidTokenRequest, forceProduction: boolean);
}
//# sourceMappingURL=FluidTokenProvider.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IEnvironment.d.ts
****************************************
/**
 * @module IEnvironment
 * @description Defines the environment configuration interface and types for the Braid application.
 *
 * This module defines the environment configuration interface (IEnvironment) used across
 * the application to handle different deployment environments (Local, Staging, Production).
 * It provides type definitions for environment-specific API endpoints and service URLs.
 *
 * The interface includes methods for:
 * - Authentication and session management
 * - Content operations (summarization, classification, embedding)
 * - Activity tracking and management
 * - Chunk and page operations
 * - Integration endpoints (LinkedIn, Fluid, Teams)
 */
export declare const BRAID_ENVIRONMENT_KEY = "BRAID_ENVIRONMENT";
export declare enum EEnvironment {
    kLocal = "Local",
    kStaging = "Staging",
    kProduction = "Production"
}
export interface IEnvironment {
    name: string;
    hostProtocolAndName(): string;
    checkSessionApi(): string;
    summariseApi(): string;
    findThemeApi(): string;
    chunkApi(): string;
    classifyApi(): string;
    embedApi(): string;
    testForSummariseFail(): string;
    saveActivityApi(): string;
    removeActivityApi(): string;
    getActivityApi(): string;
    findActivityApi(): string;
    getActivitiesApi(): string;
    boxerHome(): string;
    loginWithLinkedInApi(): string;
    authFromLinkedInApi(): string;
    findRelevantEnrichedChunksFromUrl(): string;
    findRelevantEnrichedChunksFromSummary(): string;
    findEnrichedChunkFromUrl(): string;
    queryModelWithEnrichment(): string;
    generateQuestion(): string;
    generateFluidTokenApi(): string;
    fluidApi(): string;
    fluidTenantId(): string;
    studioForTeamsBoxer(): string;
    saveChunkApi(): string;
    removeChunkApi(): string;
    getChunkApi(): string;
    findChunkApi(): string;
    getChunksApi(): string;
    savePageApi(): string;
    getPageApi(): string;
}
//# sourceMappingURL=IEnvironment.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IEnvironmentFactory.d.ts
****************************************
/**
 * @module IEnvironmentFactory
 *
 * Factory module for creating environment instances that define application behavior
 * across different deployment contexts (Development, Staging, Production).
 *
 * This module provides factory functions to create appropriate environment instances
 * based on the current execution context (browser vs Node.js) and configuration.
 * It supports automatic environment detection and explicit environment selection
 * through the getEnvironment function.
 *
 * The module handles three main scenarios:
 * - Default environment detection
 * - Fluid-specific environment configuration
 * - Login-specific environment configuration
 */
import { EEnvironment, IEnvironment } from './IEnvironment';
/**
 * Returns the default environment based on the current execution context.
 * If running in a browser and on localhost, returns a DevelopmentEnvironment instance.
 * If the process environment variable BRAID_ENVIRONMENT is set to 'Local', returns a DevelopmentEnvironment instance.
 * Otherwise, returns a ProductionEnvironment instance.
 * @returns An instance of IEnvironment representing the default environment.
 */
export declare function getDefaultEnvironment(): IEnvironment;
export declare function getDefaultFluidEnvironment(): IEnvironment;
export declare function getDefaultLoginEnvironment(): IEnvironment;
/**
 * Returns an instance of IEnvironment based on the provided EEnvironment type.
 *
 * @param environmentString - The EEnvironment type to determine the environment.
 * @returns An instance of IEnvironment corresponding to the specified EEnvironment type.
 */
export declare function getEnvironment(environmentString: EEnvironment): IEnvironment;
//# sourceMappingURL=IEnvironmentFactory.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IModel.d.ts
****************************************
/**
 * @module IModel
 * @description Defines the core model interfaces and enums used for AI model management.
 * Contains the model size enumeration and the base interface for model implementations,
 * including deployment configuration and text processing capabilities.
 */
/**
 * Enum representing different sizes of a model.
 *
 * @enum {string}
 */
export declare enum EModel {
    kSmall = "Small",
    kLarge = "Large"
}
/**
 * Represents an interface for a model with deployment information.
 * @interface
 */
export interface IModel {
    implementsModel: EModel;
    deploymentName: string;
    embeddingDeploymentName: string;
    defaultChunkSize: number;
    maximumChunkSize: number;
    embeddingChunkSize: number;
    fitsInDefaultChunk(text: string): boolean;
    fitsInMaximumChunk(text: string): boolean;
    fitsInEmbeddingChunk(text: string): boolean;
    chunkText(text: string, chunkSize: number | undefined, overlapWords: number | undefined): Array<string>;
    estimateTokens(text: string): number;
}
//# sourceMappingURL=IModel.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IModelDriver.d.ts
****************************************
/**
 * @module IModelDriver
 *
 * This module defines the core interfaces and enums for model-driven conversations.
 * It provides the fundamental types used to structure conversations between users
 * and AI models, including role definitions and conversation formats.
 *
 * The module includes:
 * - EModelConversationRole: Enum for different conversation participant roles
 * - IModelConversationElement: Interface for individual conversation messages
 * - IModelConversationPrompt: Interface for complete conversation contexts
 */
import { EPromptPersona } from './IPromptPersona';
/**
 * Enum representing the roles in a conversation with a model.
 *
 * @enum {string} EModelConversationRole
 * @property {string} kSystem - System message role
 * @property {string} kAssistant - Assistant message role
 * @property {string} kUser - User message role
 */
export declare enum EModelConversationRole {
    kSystem = "system",
    kAssistant = "assistant",
    kUser = "user"
}
/**
 * Defines the structure of a conversation element.
 */
export interface IModelConversationElement {
    role: EModelConversationRole;
    content: string;
}
/**
 * Defines the structure of a conversation prompt used for model interactions.
 * This interface encapsulates both the conversation history and the current prompt.
 *
 * @interface IModelConversationPrompt
 * @property {Array<IModelConversationElement>} history - Array of previous conversation elements
 *           including system messages, user inputs, and assistant responses
 * @property {string} prompt - The current prompt or query to be processed by the model
 */
export interface IModelConversationPrompt {
    history: Array<IModelConversationElement>;
    prompt: string;
}
/**
 * Interface for drivers that provide text embedding capabilities.
 * Text embeddings are vector representations of text that capture semantic meaning,
 * allowing for operations like semantic search and similarity comparisons.
 *
 * @interface IEmbeddingModelDriver
 */
export interface IEmbeddingModelDriver {
    /**
     * Gets the type identifier of the model being driven.
     *
     * @returns {string} A string identifier representing the type of the underlying model
     */
    getDrivenModelType(): string;
    /**
     * Converts text into a vector embedding representation.
     *
     * @param {string} text - The input text to be embedded
     * @returns {Promise<Array<number>>} A promise that resolves to an array of numbers
     *         representing the text embedding vector
     */
    embed(text: string): Promise<Array<number>>;
}
export interface IChatModelDriverParams {
    wordTarget?: number | undefined;
    promptParam1?: string | undefined;
}
/**
 * Interface for drivers that provide chat model capabilities.
 *
 * @interface IChatModelDriver
 */
export interface IChatModelDriver {
    /**
  * Gets the type identifier of the model being driven.
  *
  * @returns {string} A string identifier representing the type of the underlying model
  */
    getDrivenModelType(): string;
    /**
     * Generates a response to a given conversation prompt.
     *
     * @param {EPromptPersona} persona - The persona to use for the response
     * @param {IModelConversationPrompt} prompt - The conversation prompt to be processed
     * @param {IChatModelDriverParams} params - The parameters for the prompt (optional)
     * @returns {Promise<IModelConversationElement>} A promise that resolves to the generated response
     */
    generateResponse(persona: EPromptPersona, prompt: IModelConversationPrompt, params?: IChatModelDriverParams): Promise<IModelConversationElement>;
}
//# sourceMappingURL=IModelDriver.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IModelFactory.d.ts
****************************************
/**
 * @module IModelFactory
 * @description Factory module for creating AI model instances.
 *
 * This module provides factory functions to create appropriate model instances
 * based on the requested model type. It supports:
 * - Default model creation through getDefaultModel()
 * - Specific model creation through getModel() based on EModel type
 *
 * The factory ensures consistent model instantiation across the application
 * while abstracting the concrete model implementation details.
 */
import { EModel, IModel } from './IModel';
import { IEmbeddingModelDriver, IChatModelDriver } from './IModelDriver';
/**
 * Returns the default model which is an instance of GPT4oMini.
 * @returns {IModel} The default model.
 */
export declare function getDefaultModel(): IModel;
/**
 * Returns an instance of IModel based on the provided EModel type.
 *
 * @param model - The EModel type to determine the model.
 * @returns An instance of IModel corresponding to the specified EModel type.
 */
export declare function getModel(model: EModel): IModel;
/**
 * Returns an instance of IEmbeddingModelDriver for the default embedding model.
 * @returns {IEmbeddingModelDriver} The default embedding model driver.
 */
export declare function getDefaultEmbeddingModelDriver(): IEmbeddingModelDriver;
/**
 * Returns an instance of IEmbeddingModelDriver based on the provided EModel type.
 * @param model - The EModel type to determine the model.
 * @returns {IEmbeddingModelDriver} An instance of IEmbeddingModelDriver corresponding to the specified EModel type.
 */
export declare function getEmbeddingModelDriver(model: EModel): IEmbeddingModelDriver;
export declare function getDefaultChatModelDriver(): IChatModelDriver;
/**
 * Returns an instance of IChatModelDriver based on the provided EModel type.
 * @param model - The EModel type to determine the model.
 * @returns {IChatModelDriver} An instance of IChatModelDriver corresponding to the specified EModel type.
 */
export declare function getChatModelDriver(model: EModel): IChatModelDriver;
//# sourceMappingURL=IModelFactory.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IPromptPersona.d.ts
****************************************
/**
 * @module IPromptPersona
 * @description Defines interfaces and enums for managing different prompt personas.
 *
 * This module provides the core types for configuring different AI prompt personas,
 * each specialized for specific summarization tasks. It includes:
 * - EPromptPersona enum for different persona types (Article, Code, Survey)
 * - IPromptPersona interface defining the structure of a prompt persona
 *
 * Each persona contains configuration for system-level and item-level prompting,
 * allowing for specialized behavior across different summarization contexts.
 */
export declare enum EPromptPersona {
    kDefault = "Default",
    kArticleSummariser = "ArticleSummariser",
    kCodeSummariser = "CodeSummariser",
    kSurveySummariser = "SurveySummariser",
    kTestForSummariseFail = "TestForSummariseFail",
    kClassifier = "Classifier",
    kThemeFinder = "ThemeFinder",
    kDeveloperAssistant = "DeveloperAssistant",
    kDeveloperImaginedAnswerGenerator = "DeveloperImaginedAnswerGenerator",
    kDeveloperQuestionGenerator = "DeveloperQuestionGenerator"
}
export interface IPromptPersona {
    name: string;
    systemPrompt: string;
    itemPrompt: string;
}
//# sourceMappingURL=IPromptPersona.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IPromptPersonaFactory.d.ts
****************************************
/**
 * @module IPromptPersonaFactory
 *
 * This module provides functionality to generate specialized AI prompt personas
 * for different types of content summarization (articles, code, surveys).
 * Each persona includes a system prompt and an item prompt tailored to the
 * specific summarization task.
 *
 * The module exports:
 * - Predefined persona templates for Article, Code, and Survey summarization
 * - getSummariser function to generate configured prompt personas with
 *   customized word count targets
 */
import { IChatModelDriverParams } from "./IModelDriver";
import { EPromptPersona, IPromptPersona } from "./IPromptPersona";
export declare function getChatPersona(persona: EPromptPersona, userPrompt: string, params: IChatModelDriverParams): IPromptPersona;
//# sourceMappingURL=IPromptPersonaFactory.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IStorable.d.ts
****************************************
/**
 * @module IStorable
 * @description Defines core interfaces and types for persistent storage functionality.
 *
 * This module provides the foundational types for object persistence across the application,
 * including:
 * - IStorable interface for objects that can be stored in the database
 * - EStorableApplicationIds enum for identifying different applications
 * - Query specification interfaces for database operations
 *
 * The module enables consistent storage patterns across different applications while
 * maintaining flexibility through application-specific extensions of the base interfaces.
 */
/**
 * Enum representing application names
 *
 * @enum {string}
 */
export declare enum EStorableApplicationIds {
    kBoxer = "Boxer",
    kWaterfall = "Waterfall"
}
/**
 * Represents an interface for objects that can be stored.
 *
 * Contains properties:
 * - id: string - the primary key of the stored object
 * - applicationId: string - identifies the application - one of the Enums above.
 * - contextId: string - identifies the context, e.g., a conversation in Boxer
 * - userId: string | undefined - identifies the user; undefined if no direct user
 * - functionalSearchKey: string | undefined - used if the app needs to searcg by an attribute other than primary key
 * - created: Date - timestamp of creation
 * - amended: Date - timestamp of amendment
 * - className: string - class name; further fields are class-specific
 * - schemaVersion: string - allows versioning on the schema*
 */
export interface IStorable {
    id: string | undefined;
    applicationId: string;
    contextId: string | undefined;
    functionalSearchKey: string | undefined;
    userId: string | undefined;
    created: string;
    amended: string;
    className: string;
    schemaVersion: string;
}
/**
 * Defines the structure of a query specification for searching for multiple records.
 * Includes the limit of records to return and the class name of the records to be stored / retrieved.
 */
export interface IStorableMultiQuerySpec {
    limit: number;
    className: string;
}
/**
 * Defines the structure of a query specification for searching for a single record.
 * Includes the id (primary key) of the record.
 */
export interface IStorableQuerySpec {
    id: string | undefined;
    functionalSearchKey: string | undefined;
}
/**
 * Defines the structure of a query specification for searching for a single record.
 * Includes the id (primary key) of the record.
 */
export interface IStorableOperationResult {
    ok: boolean;
}
//# sourceMappingURL=IStorable.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Logging.d.ts
****************************************
/**
 * @module Logging
 * @description Provides logging functionality for different parts of the application.
 *
 * This module contains utility functions for logging errors and information across
 * different domains of the application, including:
 * - Core system errors
 * - Database errors
 * - API errors and information
 *
 * Each logging function follows a consistent pattern of accepting a description
 * and details parameter, formatting them appropriately for the logging context.
 * The module helps maintain consistent logging practices across the application
 * while differentiating between error domains for easier debugging.
 */
/**
 * Logs a core error with the provided description and details.
 *
 * @param description - A brief description of the core error.
 * @param details - Additional details related to the core error.
 * @returns void
 */
export declare function logCoreError(description: string, details: any): void;
/**
 * Logs a database error with the provided description and details.
 *
 * @param description - A brief description of the error.
 * @param details - Additional details about the error.
 * @returns void
 */
export declare function logDbError(description: string, details: any): void;
/**
 * Logs an API error with the provided description and details.
 *
 * @param description A brief description of the API error.
 * @param details Additional details related to the API error.
 * @returns void
 */
export declare function logApiError(description: string, details: any): void;
/**
 * Logs API information.
 *
 * @param description - A brief description of the API information.
 * @param details - Additional details about the API information.
 * @returns void
 */
export declare function logApiInfo(description: string, details: any): void;
//# sourceMappingURL=Logging.d.ts.map
****************************************

****************************************
CommonTs\dist\src\LoginApi.d.ts
****************************************
/**
 * @module LoginApi
 * @description Provides an API for handling login operations.
 *
 * This module contains the LoginApi class, which handles the login process
 * using LinkedIn API. It provides methods for:
 * - Logging in using LinkedIn API
 * - Handling errors and retries for login operations
 */
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
/**
 * Represents a class for handling login operations.
 * @constructor
 * @param environment_ - The environment settings for the login operations.
 * @param sessionKey_ - The session key for the current login session.
 * @returns A Promise that resolves to a string indicating the login status.
 */
export declare class LoginApi extends Api {
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously logs in using LinkedIn API.
     *
     * @returns A Promise that resolves to a string indicating the status after attempting to log in.
     */
    login(): Promise<string>;
}
//# sourceMappingURL=LoginApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\LooseObject.d.ts
****************************************
/**
 * @module LooseObject
 * @description Defines a type for a loose object that can contain any key-value pairs.
 *
 * This module provides a type alias for an object that allows for dynamic key-value
 * assignments, useful for creating flexible data structures without specifying
 * a fixed schema.
 */
export interface LooseObject {
    [key: string]: any;
}
//# sourceMappingURL=LooseObject.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Model.OAI.d.ts
****************************************
/**
 * @module Model
 * @description Provides a class for managing AI models and their deployment settings.
 *
 * This module contains the GPT4 class, which implements the IModel interface.
 * It provides methods for:
 * - Checking if a text fits within the context window size with buffer
 * - Chunking text into smaller pieces with optional overlap
 * - Estimating the number of tokens in a given text
 */
import { EModel, IModel } from './IModel';
/**
 * GPTM class implementing IModel interface.
 * Represents a model with specific deployment settings and context window sizes.
 */
export declare class GPT4 implements IModel {
    deploymentName: string;
    embeddingDeploymentName: string;
    defaultChunkSize: number;
    maximumChunkSize: number;
    embeddingChunkSize: number;
    defaultChunkSizeWithBuffer: number;
    maximumChunkSizeWithBuffer: number;
    embeddingChunkSizeWithBuffer: number;
    implementsModel: EModel;
    constructor();
    /**
     * Checks if the given text fits within the context window size with buffer.
     *
     * @param text The text to check if it fits within the context window size with buffer.
     * @returns True if the text fits within the context window size with buffer, false otherwise.
     */
    fitsInDefaultChunk(text: string): boolean;
    /**
     * Checks if the given text fits within the maximum context window size with buffer.
     *
     * @param text The text to check if it fits within the context window size with buffer.
     * @returns True if the text fits within the context window size with buffer, false otherwise.
     */
    fitsInMaximumChunk(text: string): boolean;
    /**
     * Checks if the given text fits within the embedding context window size with buffer.
     *
     * @param text The text to check if it fits within the context window size with buffer.
     * @returns True if the text fits within the context window size with buffer, false otherwise.
     */
    fitsInEmbeddingChunk(text: string): boolean;
    /**
     * Splits the input text into chunks based on the specified overlap of words.
     *
     * @param text The text to be chunked.
     * @param overlapWords The number of overlapping words between consecutive chunks. If undefined, we chunk with no obverlap.
     * @returns An array of strings representing the chunked text.
     */
    chunkText(text: string, chunkSize: number | undefined, overlapWords: number | undefined): Array<string>;
    /**
     * Estimates the number of tokens in the provided text using the tokenizer.
     *
     * @param text The text for which to estimate the number of tokens.
     * @returns The estimated number of tokens in the text.
     */
    estimateTokens(text: string): number;
}
//# sourceMappingURL=Model.OAI.d.ts.map
****************************************

****************************************
CommonTs\dist\src\ModelDrivers.OAI.d.ts
****************************************
/**
 * @module IModelDrivers.OAI
 *
 * This module provides OpenAI-specific implementations for embedding model drivers.
 * It includes functionality to calculate text embeddings using Azure OpenAI services.
 *
 * Key components:
 * - OpenAIEmbeddingModelDriver: Implementation of IEmbeddingModelDriver for OpenAI
 * - calculateEmbedding: Utility function to compute embeddings via Azure OpenAI API
 *
 */
import { IEmbeddingModelDriver, IChatModelDriver, IModelConversationElement, IModelConversationPrompt, IChatModelDriverParams } from './IModelDriver';
import { EPromptPersona } from './IPromptPersona';
/**
 * Class representing an OpenAI embedding model driver.
 * Implements the IEmbeddingModelDriver interface.
 *
 * @method embed
 * @param {string} text - The text to be embedded.
 * @returns {Promise<Array<number>>} A promise that resolves to an array of numbers representing the embedding.
 * @throws {Error} Throws an error if the method is not implemented.
 */
export declare class OpenAIEmbeddingModelDriver implements IEmbeddingModelDriver {
    getDrivenModelType(): string;
    embed(text: string): Promise<Array<number>>;
}
/**
 * Asynchronously calculates the embedding for the given text using the Azure AI service.
 *
 * @param text The text for which the embedding needs to be calculated.
 * @returns A Promise that resolves to an array of numbers representing the calculated embedding.
 */
export declare function calculateEmbedding(text: string): Promise<Array<number>>;
/**
 * Class representing a driver for OpenAI chat models.
 * Implements the IChatModelDriver interface to provide methods for
 * retrieving the model type and generating responses to conversation prompts.
 */
export declare class OpenAIChatModelDriver implements IChatModelDriver {
    getDrivenModelType(): string;
    generateResponse(persona: EPromptPersona, prompt: IModelConversationPrompt, params: IChatModelDriverParams): Promise<IModelConversationElement>;
}
//# sourceMappingURL=ModelDrivers.OAI.d.ts.map
****************************************

****************************************
CommonTs\dist\src\PageRepositoryApi.d.ts
****************************************
/**
 * @module PageRepositoryApi
 * @description Provides an API for managing page storage and retrieval.
 *
 * This module contains the PageRepositoryApi class which handles storage operations
 * for pages in the application. It provides methods for:
 * - Saving pages to persistent storage
 * - Compressing page content for efficient storage
 *
 * The module extends the base Api class and implements IStorablePageRepositoryApiWrapper
 * to provide consistent storage patterns while handling page-specific requirements
 * like content compression.
 */
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IStorable } from "./IStorable";
import { IStorablePageRepostoryApiWrapper } from './StorableRepositoryApi';
/**
 * Represents an API for the Page repository
 *
 * @param {EEnvironment} environment_ - The environment to use for saving Pages.
 * @param {string} sessionKey_ - The session key for authentication.
 *
 * @method save - Saves a record to the Page API.
 * Does not provide a 'load' as Pages are loaded directly into the browser
 */
export declare class PageRepostoryApi extends Api implements IStorablePageRepostoryApiWrapper {
    private storableApi;
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously saves a record to the page repository API.
     *
     * @param record - The record to be saved, must implement the IStoredPage interface.
     * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
     */
    save(record: IStorable): Promise<boolean>;
    /**
     * Compresses a string using deflate algorithm
     * @param input The string to compress
     * @returns Base64 encoded compressed string
     */
    compressString(input: string): string;
    /**
     * Decompresses a string that was compressed using compressString
     * @param input Base64 encoded compressed string
     * @returns Original decompressed string
     */
    decompressString(input: string): string;
}
//# sourceMappingURL=PageRepositoryApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\PageRepositoryApi.Types.d.ts
****************************************
/**
 * @module PageRepositoryApi.Types
 * @description Defines the data types and interfaces used by the PageRepository API.
 *
 * This module contains the interfaces that define the structure of:
 * - Stored pages and their HTML content
 * - Request and response types for page storage operations
 *
 * These types support the PageRepositoryApi module in providing type-safe
 * page storage and retrieval operations.
 */
import { IStorable, IStorableQuerySpec } from "./IStorable";
/**
 * Interface representing a web page Chunk.
 *
 * Core data for a Page:
 * - html: HTML content
 */
export interface IStoredPage extends IStorable {
    html: string;
}
export interface IStoredPageRequest extends IStorableQuerySpec {
}
export interface IStoredPageResponse extends IStoredPage {
}
//# sourceMappingURL=PageRepositoryApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\QueryModelApi.d.ts
****************************************
/**
 * @module QueryModelApi
 * @description Provides an API for querying models with enrichment and generating questions.
 *
 * This module contains the QueryModelApi class, which handles the interaction with the specified environment
 * to query models with enrichment and generate questions. It provides methods for:
 * - Querying models with enrichment
 * - Generating questions
 */
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IEnrichedQuery, IEnrichedResponse, IGenerateQuestionQuery, IQuestionGenerationResponse } from './EnrichedQuery';
/**
 * Represents a QueryModelApi class that interacts with the specified environment to query models with enrichment and generate questions.
 * @constructor
 * @param environment_ - The environment to interact with.
 * @param sessionKey_ - The session key for authentication.
 */
export declare class QueryModelApi extends Api {
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously queries the model with enrichment data.
     *
     * @param query - The enriched query data to be sent.
     * @returns A promise that resolves to the enriched response data, or undefined if an error occurs.
     */
    queryModelWithEnrichment(query: IEnrichedQuery): Promise<IEnrichedResponse | undefined>;
    /**
     * Asynchronously generates a question based on the provided query data.
     *
     * @param query - The data containing persona prompt, question generation prompt, and summary.
     * @returns A promise that resolves to the generated question response, or undefined if an error occurs.
     */
    generateQuestion(query: IGenerateQuestionQuery): Promise<IQuestionGenerationResponse | undefined>;
}
//# sourceMappingURL=QueryModelApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\SessionApi.d.ts
****************************************
/**
 * @module SessionApi
 * @description Provides an API for managing user sessions and authentication.
 *
 * This module contains the SessionApi class which handles session validation
 * and authentication operations. It provides methods for:
 * - Checking session key validity
 * - Managing session authentication state
 *
 * The module extends the base Api class to provide consistent authentication
 * patterns while handling session-specific requirements.
 */
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
export declare class SessionApi extends Api {
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously checks the validity of a session key by sending a POST request to the session API endpoint.
     *
     * @returns A Promise that resolves to a boolean value indicating the validity of the session key.
     */
    checkSessionKey(): Promise<string>;
}
//# sourceMappingURL=SessionApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\StorableRepositoryApi.d.ts
****************************************
/**
 * @module StorableRepositoryApi
 * @description Provides base classes and interfaces for storable object repositories.
 *
 * This module contains the StorableRepositoryApi class and related interfaces which handle
 * generic storage operations for objects implementing the IStorable interface. It provides:
 * - Base repository API implementation for saving, loading, and querying storable objects
 * - Interface definitions for repository wrappers with different capabilities
 * - Common patterns for interacting with storage APIs
 *
 * The module serves as a foundation for specific repository implementations like
 * PageRepositoryApi while ensuring consistent storage patterns across the application.
 */
import { IStorable, IStorableMultiQuerySpec as IStorablesQuerySpec } from "./IStorable";
/**
 * Represents a wrapper for interacting with a repository of storable objects.
 * Provides methods to save storable records.
 */
export interface IStorablePageRepostoryApiWrapper {
    save(record: IStorable): Promise<boolean>;
}
/**
 * Represents a wrapper for interacting with a repository of storable objects.
 * Provides methods to save, remove, and load storable records.
 */
export interface IStorableRepostoryApiWrapper extends IStorablePageRepostoryApiWrapper {
    remove(recordId: string): Promise<boolean>;
    load(recordId: string): Promise<IStorable | undefined>;
    find(functionalSearchKey: string): Promise<IStorable | undefined>;
    recent(querySpec: IStorablesQuerySpec, url: string): Promise<Array<IStorable>>;
}
/**
 * Represents an API for Storables.
 *
 * @param {EEnvironment} environment_ - The environment to use for saving Storables.
 * @param {string} sessionKey_ - The session key for authentication.
 *
 * @method save - Saves a record to the Storables API.
 * @method remove - removes a record
 * @method recent - return a list of recent Storables
 */
export declare class StorableRepostoryApi {
    /**
     * Initializes a new instance of the class
     */
    constructor();
    /**
     * Asynchronously saves a record to the Storables repository API.
     *
     * @param record - The record to be saved, must implement the IStorable interface.
     * @param url - fully factored URL to the API to call
     * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
     */
    save(record: IStorable, url: string): Promise<boolean>;
    /**
     * Asynchronously removes a record from the Storables repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @param url - fully factored URL to the API to call
     * @returns A Promise that resolves to true if the record is successfully removed, false otherwise.
     */
    remove(recordId: string, url: string): Promise<boolean>;
    /**
     * Asynchronously loads a record from the Storable repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @param url - fully factored URL to the API to call
     * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
     */
    load(recordId: string, url: string): Promise<IStorable | undefined>;
    /**
     * Asynchronously finds a record from the Storable repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @param url - fully factored URL to the API to call
     * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
     */
    find(functionalSearchKey: string, url: string): Promise<IStorable | undefined>;
    /**
     * Asynchronously retrieves recent records from the Storables repository API based on the provided query specifications.
     *
     * @param querySpec - The query specifications including the limit and storeClassName to filter the records.
     * @param url - fully factored URL to the API to call
     * @returns A Promise that resolves to an array of IStorable objects representing the recent records, or an empty array if an error occurs.
     */
    recent(querySpec: IStorablesQuerySpec, url: string): Promise<Array<IStorable>>;
}
//# sourceMappingURL=StorableRepositoryApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\StudioApi.Types.d.ts
****************************************
/**
 * @module StudioApi.Types
 * @description Defines the data types and interfaces used by the Studio API.
 *
 * This module contains the interfaces that define the structure of:
 * - Studio boxer requests and responses
 * - Enrichment data structures for studio responses
 *
 * These types support the StudioApi module in providing type-safe
 * interactions with the Studio API endpoints.
 */
/**
 * Interface for the StudioBoxer request object.
 */
export interface IStudioBoxerRequest {
    question: string;
}
/**
 * Interface for the IStudioBoxerResponseEnrichment response object.
 */
export interface IStudioBoxerResponseEnrichment {
    id: string;
    summary: string;
    title: string | undefined;
    url: string | undefined;
    iconUrl: string | undefined;
}
//# sourceMappingURL=StudioApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\SummariseApi.Types.d.ts
****************************************
/**
 * @module SummariseApi.Types
 * @description Defines the data types and interfaces used by the Summarise API.
 *
 * This module contains the interfaces that define the structure of:
 * - Summarisation requests and responses
 * - Configuration options for summary generation
 *
 * These types support the SummariseApi module in providing type-safe
 * text summarisation operations.
 */
import { EPromptPersona } from "./IPromptPersona";
/**
 * Defines the structure of a summarise request object.
 */
export interface ISummariseRequest {
    persona: EPromptPersona;
    text: string;
    lengthInWords?: number | undefined;
}
/**
 * Defines the structure of a summarise response object.
 */
export interface ISummariseResponse {
    summary: string;
}
//# sourceMappingURL=SummariseApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\TestForSummariseFailApi.Types.d.ts
****************************************
/**
 * @module TestForSummariseFailApi.Types
 * @description Defines the data types and interfaces used by the TestForSummariseFail API.
 *
 * This module contains the interfaces that define the structure of:
 * - Test requests for summary validation
 * - Response types indicating summary validation status
 * - Enumeration of possible validation results
 *
 * These types support the TestForSummariseFailApi module in providing type-safe
 * validation of generated summaries.
 */
/**
 * Defines the structure of a summarise request object.
 */
export interface ITestForSummariseFailRequest {
    text: string;
    lengthInWords?: number | undefined;
}
export declare enum ETestForSummariseFail {
    kSummaryFailed = "SummaryFailed",
    kSummarySucceeded = "SummarySucceeded"
}
/**
 * Defines the structure of a summarise response object.
 */
export interface ITestForSummariseFailResponse {
    isValidSummary: ETestForSummariseFail;
}
//# sourceMappingURL=TestForSummariseFailApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\ThemeApi.d.ts
****************************************
/**
 * @module ThemeApi
 * @description Provides interfaces and types for theme detection and analysis.
 *
 * This module contains the interfaces that define the structure of:
 * - Theme detection requests and responses
 * - Criteria for finding themes in text
 *
 * These types support theme-related operations by providing type-safe
 * structures for analyzing and identifying thematic elements in content.
 */
/**
 * Interface for specifying the criteria to find a theme.
 * @interface
 */
export interface IFindThemeRequest {
    text: string;
    length: number;
}
//# sourceMappingURL=ThemeApi.d.ts.map
****************************************

****************************************
Salon\apis\ChunkApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from ChunkApi.Types.yaml with typeconv
  version: '1'
  x-id: ChunkApi.Types.yaml
  x-comment: >-
    Generated from src\ChunkApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IChunkRequest:
      properties:
        text:
          title: IChunkRequest.text
          type: string
        chunkSize:
          title: IChunkRequest.chunkSize
          type: number
        overlapWords:
          title: IChunkRequest.overlapWords
          type: number
      required:
        - text
      additionalProperties: false
      title: IChunkRequest
      description: >-
        Interface for chunk reqiest API.

        @property {string} text - The text content of the chunk.

        @property {number | undefined} chunkSize - The size of the chunk in
        tokens, if specified.

        @property {number | undefined} overlapWords - The size of the overlap
        between chunks, in words (=2 * tokens) if specified.
      type: object
    IChunkResponse:
      properties:
        chunks:
          items:
            type: string
          title: IChunkResponse.chunks
          type: array
      required:
        - chunks
      additionalProperties: false
      title: IChunkResponse
      description: |-
        Return type of chunk reqiest API.
        @property {Array<string>} chunks - Array of text chunks
      type: object
****************************************

****************************************
Salon\apis\ChunkRepositoryApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from ChunkRepositoryApi.Types.yaml with typeconv
  version: '1'
  x-id: ChunkRepositoryApi.Types.yaml
  x-comment: >-
    Generated from src\ChunkRepositoryApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IStoredEmbedding:
      properties:
        modelId:
          title: IStoredEmbedding.modelId
          type: string
        embedding:
          items:
            type: number
          title: IStoredEmbedding.embedding
          type: array
      required:
        - modelId
        - embedding
      additionalProperties: false
      title: IStoredEmbedding
      description: >-
        Represents an interface for storing embeddings with a model ID and an
        array of numbers representing the embedding.
      type: object
    IStoredTextRendering:
      properties:
        modelId:
          title: IStoredTextRendering.modelId
          type: string
        text:
          title: IStoredTextRendering.text
          type: string
      required:
        - modelId
        - text
      additionalProperties: false
      title: IStoredTextRendering
      description: Defines the structure of a stored text rendering object.
      type: object
    IStoredChunk:
      properties:
        parentChunkId:
          title: IStoredChunk.parentChunkId
          type: string
        originalText:
          title: IStoredChunk.originalText
          type: string
        url:
          title: IStoredChunk.url
          type: string
        storedEmbedding:
          $ref: '#/components/schemas/IStoredEmbedding'
          title: IStoredChunk.storedEmbedding
        storedSummary:
          $ref: '#/components/schemas/IStoredTextRendering'
          title: IStoredChunk.storedSummary
        storedTitle:
          $ref: '#/components/schemas/IStoredTextRendering'
          title: IStoredChunk.storedTitle
        relatedChunks:
          items:
            type: string
          title: IStoredChunk.relatedChunks
          type: array
      required:
        - parentChunkId
        - originalText
        - url
        - storedEmbedding
        - storedSummary
        - storedTitle
        - relatedChunks
      additionalProperties: false
      title: IStoredChunk
      description: "Interface representing a chunk of data.\r\n\r\nCore data for a chunk:\r\n- parentChunkId: Primary key to parent document\r\n- originalText: Original text; 0 if undefined, it has been thrown away (as maybe it can be reconstructed)\r\n- url: string | undefined;                 // url to external resource, can be null  \r\n- storedEmbedding: Embedding of the original text\r\n- storedSummary: Summary of the original text - generated with application-specific prompt \r\n- storedTitle: A generated of the original text - generated with application-specific prompt\r\n- related: Array of IDs to related chunks"
      type: object
****************************************

****************************************
Salon\apis\ClassifyApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from ClassifyApi.Types.yaml with typeconv
  version: '1'
  x-id: ClassifyApi.Types.yaml
  x-comment: >-
    Generated from src\ClassifyApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IClassifyRequest:
      properties:
        text:
          title: IClassifyRequest.text
          type: string
        classifications:
          items:
            type: string
          title: IClassifyRequest.classifications
          type: array
      required:
        - text
        - classifications
      additionalProperties: false
      title: IClassifyRequest
      description: >-
        Represents a classification request object with text and
        classifications.
      type: object
    IClassifyResponse:
      properties:
        classification:
          title: IClassifyResponse.classification
          type: string
      required:
        - classification
      additionalProperties: false
      title: IClassifyResponse
      description: Interface for the classification response object.
      type: object
****************************************

****************************************
Salon\apis\EmbedApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from EmbedApi.Types.yaml with typeconv
  version: '1'
  x-id: EmbedApi.Types.yaml
  x-comment: >-
    Generated from src\EmbedApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IEmbedRequest:
      properties:
        text:
          title: IEmbedRequest.text
          type: string
      required:
        - text
      additionalProperties: false
      title: IEmbedRequest
      description: Interface for the embedding request object.
      type: object
    IEmbedResponse:
      properties:
        embedding:
          items:
            type: number
          title: IEmbedResponse.embedding
          type: array
      required:
        - embedding
      additionalProperties: false
      title: IEmbedResponse
      description: Interface for the embedding response object.
      type: object
****************************************

****************************************
Salon\apis\EnumerateModelsApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from EnumerateModelsApi.Types.yaml with typeconv
  version: '1'
  x-id: EnumerateModelsApi.Types.yaml
  x-comment: >-
    Generated from src\EnumerateModelsApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IEnumerateModelsRequest:
      additionalProperties: false
      title: IEnumerateModelsRequest
      description: Interface for the EnumerateModels request object.
      type: object
    IEnumerateModelsResponse:
      properties:
        defaultId:
          title: IEnumerateModelsResponse.defaultId
          type: string
        defaultEmbeddingId:
          title: IEnumerateModelsResponse.defaultEmbeddingId
          type: string
        largeId:
          title: IEnumerateModelsResponse.largeId
          type: string
        largeEmbeddingId:
          title: IEnumerateModelsResponse.largeEmbeddingId
          type: string
        smallId:
          title: IEnumerateModelsResponse.smallId
          type: string
        smallEmbeddingId:
          title: IEnumerateModelsResponse.smallEmbeddingId
          type: string
      required:
        - defaultId
        - defaultEmbeddingId
        - largeId
        - largeEmbeddingId
        - smallId
        - smallEmbeddingId
      additionalProperties: false
      title: IEnumerateModelsResponse
      description: Interface for the EnumerateModels response object.
      type: object
    IEnumerateRepositoriesRequest:
      additionalProperties: false
      title: IEnumerateRepositoriesRequest
      description: Interface for the EnumerateRepositories request object.
      type: object
    IEnumerateReposotoriesResponse:
      properties:
        repositoryIds:
          items: {}
          title: IEnumerateReposotoriesResponse.repositoryIds
          type: array
      required:
        - repositoryIds
      additionalProperties: false
      title: IEnumerateReposotoriesResponse
      description: Interface for the EnumerateModels response object.
      type: object
****************************************

****************************************
Salon\apis\FindThemeApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from FindThemeApi.Types.yaml with typeconv
  version: '1'
  x-id: FindThemeApi.Types.yaml
  x-comment: >-
    Generated from src\FindThemeApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IFindThemeRequest:
      properties:
        text:
          title: IFindThemeRequest.text
          type: string
        length:
          title: IFindThemeRequest.length
          type: number
      required:
        - text
        - length
      additionalProperties: false
      title: IFindThemeRequest
      description: Interface for the find theme request object.
      type: object
    IFindThemeResponse:
      properties:
        theme:
          title: IFindThemeResponse.theme
          type: string
      required:
        - theme
      additionalProperties: false
      title: IFindThemeResponse
      description: Interface for the find theme response object.
      type: object
****************************************

****************************************
Salon\apis\FindThemeApi.Types_test.py
****************************************
import pytest
import jsonschema
from jsonschema import validate

# Define the schema for request and response
IFindThemeRequestSchema = {
    "type": "object",
    "properties": {
        "text": {"type": "string", "title": "IFindThemeRequest.text"},
        "length": {"type": "number", "title": "IFindThemeRequest.length"}
    },
    "required": ["text", "length"],
    "additionalProperties": False
}

IFindThemeResponseSchema = {
    "type": "object",
    "properties": {
        "theme": {"type": "string", "title": "IFindThemeResponse.theme"}
    },
    "required": ["theme"],
    "additionalProperties": False
}

# Test cases for IFindThemeRequest
def test_valid_ifind_theme_request():
    # Valid example
    payload = {
        "text": "Find the theme",
        "length": 17
    }
    # Test validation passes without exception
    validate(instance=payload, schema=IFindThemeRequestSchema)

def test_invalid_ifind_theme_request_missing_text():
    # Invalid example: missing 'text'
    payload = {
        "length": 10
    }
    with pytest.raises(jsonschema.exceptions.ValidationError):
        validate(instance=payload, schema=IFindThemeRequestSchema)

def test_invalid_ifind_theme_request_missing_length():
    # Invalid example: missing 'length'
    payload = {
        "text": "Missing length"
    }
    with pytest.raises(jsonschema.exceptions.ValidationError):
        validate(instance=payload, schema=IFindThemeRequestSchema)

def test_invalid_ifind_theme_request_additional_properties():
    # Invalid example: additional property
    payload = {
        "text": "Theme with extra",
        "length": 18,
        "extra": "This should not be here"
    }
    with pytest.raises(jsonschema.exceptions.ValidationError):
        validate(instance=payload, schema=IFindThemeRequestSchema)
        
def test_invalid_ifind_theme_request_wrong_type():
    # Invalid example: 'length' is string instead of a number
    payload = {
        "text": "Theme with wrong type",
        "length": "I am not a number"
    }
    with pytest.raises(jsonschema.exceptions.ValidationError):
        validate(instance=payload, schema=IFindThemeRequestSchema)

# Test cases for IFindThemeResponse
def test_valid_ifind_theme_response():
    # Valid example
    payload = {
        "theme": "Nature"
    }
    # Test validation passes without exception
    validate(instance=payload, schema=IFindThemeResponseSchema)
    
def test_invalid_ifind_theme_response_missing_theme():
    # Invalid example: missing 'theme'
    payload = {}
    with pytest.raises(jsonschema.exceptions.ValidationError):
        validate(instance=payload, schema=IFindThemeResponseSchema)

def test_invalid_ifind_theme_response_additional_properties():
    # Invalid example: additional property
    payload = {
        "theme": "History",
        "extra": "This should not be here"
    }
    with pytest.raises(jsonschema.exceptions.ValidationError):
        validate(instance=payload, schema=IFindThemeResponseSchema)

def test_invalid_ifind_theme_response_wrong_type():
    # Invalid example: 'theme' is number instead of a string
    payload = {
        "theme": 12345
    }
    with pytest.raises(jsonschema.exceptions.ValidationError):
        validate(instance=payload, schema=IFindThemeResponseSchema)

# Run the tests
pytest.main()
****************************************

****************************************
Salon\apis\PageRepositoryApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from PageRepositoryApi.Types.yaml with typeconv
  version: '1'
  x-id: PageRepositoryApi.Types.yaml
  x-comment: >-
    Generated from src\PageRepositoryApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
components:
  schemas:
    IStoredPage:
      properties:
        html:
          title: IStoredPage.html
          type: string
      required:
        - html
      additionalProperties: false
      title: IStoredPage
      description: "Interface representing a web page Chunk.\r\n\r\nCore data for a Page:\r\n- html: HTML content"
      type: object
    IStoredPageRequest:
      additionalProperties: false
      title: IStoredPageRequest
      type: object
    IStoredPageResponse:
      properties:
        html:
          title: IStoredPage.html
          type: string
      required:
        - html
      additionalProperties: false
      title: IStoredPageResponse, IStoredPage
      description: "Interface representing a web page Chunk.\r\n\r\nCore data for a Page:\r\n- html: HTML content"
      type: object
    StoredPageApi:
      title: StoredPageApi
    paths:
      /functions:
        get:
          operationId: get_page
          summary: Returns a page. 
          description: Returns a page. 
          parameters:
            - request: request
              in: query
              description: A spec for a Page
              schema:
                type: IStoredPageRequest
              required: true
          responses:
            '200':
              description: A Page
              content:
                application/json:
                  schema:
                    type: IStoredPageResponse    
            '400':
              description: An error 
              content:
                application/json:
                  schema:
                    type: string
****************************************

****************************************
Salon\apis\PagerepositoryApi.Types_test.py
****************************************
import pytest
import requests
from unittest.mock import patch

# Base URL for the API
BASE_URL = "http://api.example.com"

# Sample data for testing
sample_successful_html = "<html><body>Sample Page</body></html>"

def test_get_page_success():
    url = f"{BASE_URL}/functions"
    params = {
        'request': {"dummy_param": "SampleValue"} 
    }

    # Mocking the requests.get call to simulate a successful response
    with patch('requests.get') as mock_get:
        mock_get.return_value.status_code = 200
        mock_get.return_value.json.return_value = {"html": sample_successful_html}

        response = requests.get(url, params=params)
        assert response.status_code == 200
        assert "html" in response.json()
        assert response.json()["html"] == sample_successful_html

def test_get_page_missing_param():
    url = f"{BASE_URL}/functions"

    # Missing required 'request' parameter
    with patch('requests.get') as mock_get:
        mock_get.return_value.status_code = 400
        mock_get.return_value.json.return_value = "Bad Request: Missing required parameters"

        response = requests.get(url)
        assert response.status_code == 400
        assert response.json() == "Bad Request: Missing required parameters"
****************************************

****************************************
Salon\apis\ReadMe.Salon.md
****************************************
**FindThemeApi.Types_test.py**

This code defines and validates JSON schemas for request and response using the `jsonschema` library and tests these schemas using the `pytest` framework.

The `IFindThemeRequestSchema` specifies a request schema requiring `text` as a string and `length` as a number, with no additional properties allowed.

The `IFindThemeResponseSchema` outlines a response schema needing a `theme` as a string, disallowing any extra properties.

There are also test functions to validate the adherence to schemas. Functions like `test_valid_ifind_theme_request`, `test_invalid_ifind_theme_request_missing_text`, etc., check for valid and different invalid payloads, ensuring exceptions are raised when validations fail.

**PagerepositoryApi.Types_test.py**

This code is designed for testing an API endpoint at `http://api.example.com/functions` using the `pytest` framework and `unittest.mock` for mocking. 

The `test_get_page_success` function tests a successful request with a dummy parameter, verifying a 200 status code and checking the response contains the expected HTML content.

The `test_get_page_missing_param` function tests an unsuccessful request due to a missing required parameter, expecting a 400 status code and an appropriate error message in the response.

The important methods in this module are `test_get_page_success` and `test_get_page_missing_param`.
****************************************

****************************************
Salon\apis\StudioApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from StudioApi.Types.yaml with typeconv
  version: '1'
  x-id: StudioApi.Types.yaml
  x-comment: >-
    Generated from src\StudioApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IStudioBoxerRequest:
      properties:
        question:
          title: IStudioBoxerRequest.question
          type: string
      required:
        - question
      additionalProperties: false
      title: IStudioBoxerRequest
      description: Interface for the StudioBoxer request object.
      type: object
    IStudioBoxerResponseEnrichment:
      properties:
        id:
          title: IStudioBoxerResponseEnrichment.id
          type: string
        summary:
          title: IStudioBoxerResponseEnrichment.summary
          type: string
        title:
          title: IStudioBoxerResponseEnrichment.title
          type: string
        url:
          title: IStudioBoxerResponseEnrichment.url
          type: string
        iconUrl:
          title: IStudioBoxerResponseEnrichment.iconUrl
          type: string
      required:
        - id
        - summary
        - title
        - url
        - iconUrl
      additionalProperties: false
      title: IStudioBoxerResponseEnrichment
      description: Interface for the IStudioBoxerResponseEnrichment response object.
      type: object
****************************************

****************************************
Salon\apis\SummariseApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from SummariseApi.Types.yaml with typeconv
  version: '1'
  x-id: SummariseApi.Types.yaml
  x-comment: >-
    Generated from src\SummariseApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    ISummariseRequest:
      properties:
        text:
          title: ISummariseRequest.text
          type: string
        lengthInWords:
          title: ISummariseRequest.lengthInWords
          type: number
      required:
        - text
      additionalProperties: false
      title: ISummariseRequest
      description: Defines the structure of a summarise request object.
      type: object
    ISummariseResponse:
      properties:
        summary:
          title: ISummariseResponse.summary
          type: string
      required:
        - summary
      additionalProperties: false
      title: ISummariseResponse
      description: Defines the structure of a summarise response object.
      type: object
****************************************

****************************************
Salon\apis\SuppressSummariseFailApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from SuppressSummariseFailApi.Types.yaml with typeconv
  version: '1'
  x-id: SuppressSummariseFailApi.Types.yaml
  x-comment: >-
    Generated from src\SuppressSummariseFailApi.Types.ts by
    core-types-json-schema (https://github.com/grantila/core-types-json-schema)
    on behalf of typeconv (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    ISuppressSummariseFailRequest:
      properties:
        text:
          title: ISuppressSummariseFailRequest.text
          type: string
        lengthInWords:
          title: ISuppressSummariseFailRequest.lengthInWords
          type: number
      required:
        - text
      additionalProperties: false
      title: ISuppressSummariseFailRequest
      description: Defines the structure of a summarise request object.
      type: object
    ISuppressSummariseFailResponse:
      properties:
        isValidSummary:
          title: ISuppressSummariseFailResponse.isValidSummary
      required:
        - isValidSummary
      additionalProperties: false
      title: ISuppressSummariseFailResponse
      description: Defines the structure of a summarise response object.
      type: object
****************************************

****************************************
Salon\docs\repo_to_text_article_medium.md
****************************************
# Introduction

- Why large codebases are challenging
- Introducing NotebookLM as a solution for interactive code exploration

# Making the Code Chat-Ready
- why transform the data (Limitations of NotebookLM) File and word limits
- transforms a repository into NotebookLM-friendly text files

# 8 Ways to "Chat" with Your Code

1. Summarize All the Things: High-level and detailed summaries
2. Debugging Detective: How NotebookLM assists in troubleshooting code
3. Refactoring Coach: Suggestions for optimizing complex code sections
4. New Feature Prototyping: Generating initial code for new features
5. Test Case Generation: Proposing unit tests and edge case handling
6. Dependency Detective: Mapping dependencies and understanding data flow
7. Code Classroom: Educating and onboarding team members with code explanations

# Advantages of NotebookLM Over Other Tools

1. Contextually Grounded Responses: Staying focused on uploaded documents
2. Structured Summaries and Explanations: Ideal for complex documentation and technical data
3. Ease of Setup and Use: Minimal setup compared to RAG pipelines
4. Interactivity with Document-Rich Repositories: Seamless Q&A on multiple sources
5. Document Confidentiality and Security: Confidentiality benefits by avoiding external data pull

# Disadvantage of NotebookLM

# Conclusion

----------------

# introduction

Working with large codebases is like navigating an unfamiliar city without a map: each module and function is a new street, every dependency an intersection, and understanding the bigger picture can feel like solving a puzzle in the dark. For developers, this often leads to hours of poring over code, deciphering poorly documented functions, and trying to untangle dependencies, all while keeping the broader goals in mind.

To address these challenges, I turned to Google’s NotebookLM—a tool taht could be used for interactive exploration and document-based insights. With its powerful language model, NotebookLM lets me “converse” with a codebase, turning complex repositories into something closer to a dialogue. By uploading the code as text files, I can ask NotebookLM for summaries, explanations, and even new code suggestions. In short, it’s like having a knowledgeable (and very patient) coding partner, making large codebases easier to understand, manage, and expand.

This article will show you how I use NotebookLM to turn sprawling repositories into clear, accessible resources. With NotebookLM, I can quickly understand core functionalities, uncover how different parts of the code work together, and identify where new code can build on existing structures. From deciphering complex logic to pinpointing useful features and guiding implementation, NotebookLM transforms the way I interact with large codebases—making it easier and faster to harness their full potential.

For the purpose of this demo, I will use the repo of crewAI. crewAI is an agentic LLM framework. The repo is actually pretty well documented (https://docs.crewai.com/introduction), so this might be useful for repo that don't have that level of documentation.

# Making the code Chat-Ready

To interact with a large codebase using NotebookLM, the first step is transforming the code into a format that the tool can efficiently process. NotebookLM has specific limitations: it allows a maximum of 50 files per notebook, each capped at 500,000 words. While this capacity is ample for many text-based projects, a large repository with multiple files and thousands of lines of code can quickly surpass these limits.

To work within these constraints, I developed a script to convert an entire repository into NotebookLM-friendly text files. The script consolidates the contents of the repo, merging files into larger text files that contain structured comments and headers for easy navigation. This transformation ensures that all classes, functions, and dependencies are represented in a way that NotebookLM can digest—allowing me to interact with the full scope of the codebase without exceeding NotebookLM’s file and word limits.

The repo has the converted text files of the crewai repo as an example. 

# 8 Ways to "Chat" with the Code

First you upload the text files to your notebook.

Once the code is prepared for NotebookLM, it becomes an interactive guide through the repository, providing a range of helpful insights. Here are eight ways NotebookLM can assist in navigating, optimizing, and building on complex codebases.

1. Summarize All the Things

With NotebookLM, you can request high-level summaries of entire modules or drill down to specific functions. These summaries quickly reveal the purpose and function of different code sections, providing a clear map of what the repository offers without needing to manually review each part. It’s like getting a high-level overview combined with specific insights, helping you quickly assess the code’s capabilities and structure.

![prompt: generate a directory tree in ascii format](readme/repo_file_structure.png)

2. Onboarding and Learning Path Suggestions

NotebookLM can be a valuable tool for guiding beginners through a complex codebase with an onboarding path tailored to essential concepts and functions. By requesting an onboarding path, you can use NotebookLM to identify critical modules, functions, and dependencies in sequence, helping new team members navigate the repository in manageable steps. NotebookLM provides explanations of key classes and methods, often with relevant code snippets and usage examples, enabling beginners to understand each component’s role and interconnections within the codebase. This structured pathway allows newcomers to build foundational knowledge and gain hands-on familiarity with core functionalities, setting them up for success as they dive deeper into the project.

![prompt: Can you suggest an onboarding path for beginners or new team members to understand and work with this repository? Focus on the essential modules, functions, and dependencies, and provide clear learning steps with goals for each stage. Include specific code examples, key methods to explore, and practical checkpoints where they can test their understanding. If possible, suggest a small project or exercise for hands-on practice using the core functionalities.](readme/onboarding_path.png)

3. Generating Familiarization Code Snippets

You can use NotebookLM to generate a code example that helps you get familiar with a repository’s functionalities by requesting a small, practical implementation. For instance, simply ask, “implement a very simple example of a crew of agents”.
NotebookLM will reference the relevant parts of the codebase to provide an initial snippet, allowing you to see the function in action and understand how it interacts with other components, making it easier to start exploring and building on the repository’s capabilities.

![prompt: generate a code snippet](readme/code_example.png)

4. Dependency Detective

Large codebases often involve intricate interdependencies, which can be challenging to untangle. NotebookLM can map out these relationships, providing a clear view of how different modules interact. By understanding data flow and function dependencies, you gain a deeper insight into how changes in one area may impact others, allowing for more informed development decisions.

![prompt: Can you provide a detailed breakdown of the dependencies between the agent and task modules in the CrewAI framework? Include specific function calls, methods, or data structures where agent relies on task for execution. Also, list any parameter exchanges or direct references in the code, and if possible, provide code snippets that illustrate these dependencies.”](readme/agent_task_dependencies.png)

5. Identifying Vulnerabilities

One valuable use case for NotebookLM is performing a security review on a codebase to identify potential vulnerabilities before deployment. By guiding NotebookLM to examine areas prone to risks—such as code injection points, access control mechanisms, data handling practices, and dependencies—it can help flag sections of the code that may need tightening. For example, NotebookLM might pinpoint functions with unsanitized inputs, highlight dependency versions with known vulnerabilities, or recommend stronger access controls on sensitive modules. With these insights, developers can proactively address weaknesses, making the repository safer and more robust before it goes live.

![prompt: Can you analyze this codebase for any security vulnerabilities that I should address before deploying? Specifically, look for risks related to code injection, inadequate access control, improper data handling, dependency vulnerabilities, and any other common security issues in repositories. Provide examples of code sections or functions that might need security improvements, along with recommendations for mitigating these risks.”](readme/crewai_vulnerabilities.png)

6. Feature Exploration Guide

NotebookLM can act as a feature exploration guide, outlining optional features, hidden modules, or “nice-to-have” functionalities within the codebase that might be less apparent. This is helpful for exploring the repo’s full potential and discovering lesser-used but valuable components.

![prompt: Can you provide a feature exploration guide for this codebase? Outline any optional features, hidden modules, or ‘nice-to-have’ functionalities that may not be immediately obvious but could be valuable. Include a brief description of each feature, its purpose, and examples of how it might enhance or extend the core functionalities of the codebase”](readme/crewai_feature_exploration.png)



4. New Feature Prototyping

For expanding the functionality of a codebase, NotebookLM can propose starter code for new features based on the existing structure. By understanding the current architecture and dependencies, it suggests how to implement new modules or functions that integrate seamlessly with existing components. This feature accelerates prototyping by providing a solid foundation to build on.




7. Code Classroom

NotebookLM is an excellent tool for educating and onboarding team members, as it explains complex code sections in digestible language. For new developers or collaborators, NotebookLM can act as a “code classroom,” breaking down functions and algorithms to ensure everyone understands the code’s purpose and functionality. This is invaluable for bringing team members up to speed quickly and ensuring cohesive collaboration.

Together, these features make NotebookLM a powerful conversational partner for navigating, improving, and expanding large repositories, turning code from an opaque resource into a manageable and insightful guide.
****************************************

****************************************
Salon\src\api_to_test_code.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd


import argparse
import json
import os
import logging
from typing import Optional, Union
import yaml
from openai import OpenAI

# Configure logging
logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

client = OpenAI()
api_key = os.environ.get("OPENAI_API_KEY")

# Define code snippet markers for extraction
START_POINT_CODE = '```python'
END_POINT_CODE = '```'

def parse_arguments() -> argparse.Namespace:
    """Parse command-line arguments for the script.
    
    Returns:
        argparse.Namespace: Parsed command-line arguments containing the input file path.
    """
    parser = argparse.ArgumentParser(description="Generate Pytest code from API data in JSON or YAML format.")
    parser.add_argument("input_path", type=str, help="Path to the input JSON or YAML file.")
    return parser.parse_args()


def extract_code(content: str) -> Optional[str]:
    """Extracts the Python code snippet between specified start and end markers.
    
    Args:
        content (str): The content from which to extract the code snippet.
    
    Returns:
        Optional[str]: The extracted Python code snippet, or None if markers are not found.
    """
    start_index = content.find(START_POINT_CODE)
    end_index = content.rfind(END_POINT_CODE)

    if start_index != -1 and end_index != -1:
        start_index += len(START_POINT_CODE)
        return content[start_index:end_index].strip()
    else:
        logger.warning("Could not find code markers in the generated content.")
    return None


def load_api_data(file_path: str) -> Union[dict, None]:
    """Loads API data from a JSON or YAML file.
    
    Args:
        file_path (str): The path to the JSON or YAML file.
    
    Returns:
        Union[dict, None]: Parsed JSON or YAML data as a dictionary, or None on failure.
    """
    try:
        with open(file_path, 'r') as file:
            if file_path.endswith('.json'):
                data = json.load(file)
                logger.info("Successfully loaded input JSON file containing API data.")
            elif file_path.endswith('.yaml') or file_path.endswith('.yml'):
                data = yaml.safe_load(file)
                logger.info("Successfully loaded input YAML file containing API data.")
            else:
                logger.error("Unsupported file format. Only JSON and YAML files are accepted.")
                return None
            return data
    except (FileNotFoundError, json.JSONDecodeError, yaml.YAMLError) as e:
        logger.error(f"Failed to load data from {file_path}: {e}")
        return None


def main() -> None:
    """Main function to generate Pytest code from API data in JSON or YAML format."""
    args = parse_arguments()

    # Load API data from input file
    api_data = load_api_data(args.input_path)
    if api_data is None:
        logger.critical("Exiting program due to failure in loading API data.")
        print("Error: Failed to load API data. Please check the input file and try again.")
        exit(1)

    # Determine the file type based on the input file extension for prompt context
    file_type = "JSON" if args.input_path.endswith('.json') else "YAML"

    # Generate the content for the prompt with file type context
    content = (
        f"Please generate comprehensive Pytest test code from the following API data in {file_type} format:\n"
        f"{json.dumps(api_data) if file_type == 'JSON' else yaml.dump(api_data)}"
    )

    # Set up assistant and thread for code generation
    try:
        assistant = client.beta.assistants.create(
            name="API Test Code Generator",
            instructions="You are a Python expert. Generate Pytest test cases for all endpoints in the given API data. The tests should cover positive, negative, and edge cases, with appropriate assertions. The inputs to the API will usually have the word 'Request' in the name of the data structure, and the outputs will have 'Response'.",
            tools=[{"type": "code_interpreter"}],
            model="gpt-4o",
        )
        thread = client.beta.threads.create()
        client.beta.threads.messages.create(
            thread_id=thread.id,
            role="user",
            content=content
        )
        print(f"Successfully initialized assistant and sent API data in {file_type} format for test code generation.")
    except Exception as e:
        logger.error(f"Failed to initialize assistant or thread: {e}")
        print("Error: Unable to set up assistant for code generation.")
        exit(1)

    # Print static message to indicate response generation without delay
    print("Generating code...")

    # Poll for code generation results
    try:
        run = client.beta.threads.runs.create_and_poll(
            thread_id=thread.id,
            assistant_id=assistant.id,
            instructions="Return the error-free test code"
        )
        if run.status != 'completed':
            logger.error(f"Code generation failed with status: {run.status}")
            print("Error: Code generation did not complete successfully.")
            exit(1)
    except Exception as e:
        logger.error(f"Error during code generation: {e}")
        print("Error: There was an issue during code generation.")
        exit(1)

    # Retrieve generated code from messages
    try:
        messages = client.beta.threads.messages.list(thread_id=thread.id).data
        generated_content = "\n".join(
            text_block.text.value for msg in messages for text_block in msg.content
        )
        extracted_code = extract_code(generated_content)

        if extracted_code:
            # Save extracted code to a .py file in the same directory as the input file
            output_path = os.path.splitext(args.input_path)[0] + '_test.py'
            with open(output_path, 'w') as output_file:
                output_file.write(extracted_code)
            logger.info(f"Generated test code saved to {output_path}")
            print(f"Test code successfully generated and saved to {output_path}")
        else:
            logger.warning("No code snippet was extracted from the generated content.")
            print("Warning: No valid test code was generated. Please review the API data.")
    except Exception as e:
        logger.error(f"Failed to retrieve or process messages: {e}")
        print("Error: Could not retrieve the generated code.")
        exit(1)


if __name__ == "__main__":
    main()
****************************************

****************************************
Salon\src\ReadME.md
****************************************
## Features

- **Supports JSON and YAML API Specifications**: Accepts input in both JSON and YAML formats, adapting the output accordingly.
- **Prompt-Optimized Code Generation**: Provides context-aware prompts to OpenAI for more accurate and relevant test code generation.
- **Error Handling and Logging**: Logs critical issues and informs the user with helpful messages in case of any issues.
- **Automated File Output**: Saves generated test code directly to a Python file in the same directory as the input file.
- **Simple CLI Interface**: Command-line interface with clear prompts and instructions for easy usage.

## Installation

1. **Install Required Packages**:
   Ensure that you have the required Python packages installed. You can do this by running:

   ```bash
   pip install openai pyyaml
   ```

2. **Set Up Environment Variable**:
   Set up your OpenAI API key as an environment variable:
   ```bash
   export OPENAI_API_KEY="your_openai_api_key"
   ```

## Usage

### Command-Line Interface

Run the script from the command line with a single argument specifying the path to the JSON or YAML API specification file.

```bash
python api_to_test_code.py <path_to_api_file>
```

### Example

```bash
python api_to_test_code.py sample_api.json
```

### Output

The generated Pytest code will be saved in the same directory as the input file, with `_test.py` appended to the original filename.

## Code Overview

### 1. Argument Parsing

The `parse_arguments()` function parses the command-line arguments to accept a single input file path, which should point to either a JSON or YAML file.

### 2. Loading API Data

The `load_api_data(file_path: str) -> Union[dict, None]` function reads the JSON or YAML file, validates its content, and converts it into a Python dictionary. The function supports both file types and logs an error if the file format is unsupported or if parsing fails.

### 3. Setting Up the Assistant and Thread

The assistant is initialized using OpenAI’s API to generate Pytest code based on the provided API data. The assistant is configured with prompt instructions that include file format information to ensure precise code generation.

### 4. Extracting the Code Snippet

The `extract_code(content: str) -> Optional[str]` function isolates the generated Python code snippet, which is returned in a `Python` code block format. This is extracted by locating the `START_POINT_CODE` and `END_POINT_CODE` markers.

### 5. Generating and Saving Test Code

Once the code is generated, it is saved as a `.py` file with the original input file’s name followed by `_test.py`. This file is then saved in the same directory as the input file.

### 6. Logging and Error Handling

The tool uses logging to track errors, warnings, and other critical steps throughout the script. The logging level is set to `ERROR` to minimize verbosity unless the developer overrides this.

## Sample Output

After running the script, the generated Pytest code will be saved in a file named `<input_file_name>_test.py` (e.g., `sample_api_test.py`).

## Error Handling

In case of an error (such as an invalid input file or failure in code generation), clear and concise error messages will be displayed, and the program will exit gracefully.

## Dependencies

- `openai`: For connecting to the OpenAI API.
- `pyyaml`: For parsing YAML input files.
- `argparse`, `json`, `logging`, and `os`: Standard Python libraries for command-line argument parsing, JSON handling, logging, and file management.

## License

© 2024 Braid Technologies Ltd. All rights reserved.
****************************************

****************************************
Salon\src\ReadMe.Salon.md
****************************************
**api_to_test_code.py**

This script generates Pytest code from API data provided in JSON or YAML format.

**parse_arguments**: Parses command-line arguments to get the input file path.

**extract_code**: Extracts Python code snippets from a string using specified start and end markers.

**load_api_data**: Loads and parses API data from the specified JSON or YAML file, logging errors if the file is not found or contains invalid data.

**main**: The main execution function. It parses input arguments, loads API data, and sets up an OpenAI assistant to generate Pytest code. Generated code is saved to a new Python file.

**Classes/Functions**: `parse_arguments`, `extract_code`, `load_api_data`, `main`.

**repo_to_text.py**

### Important Classes and Functions:

1. **SummarisedDirectory**: Stores directory names and their summaries.

2. **RepoContentProcessor**: Handles repository processing:
   - `__init__`: Initializes the processor with paths, configurations, and word limits.
   - `make_common_file_name`: Creates unique identifiers for common files.
   - `format_file_block`: Formats content blocks with consistent indentation.
   - `count_words`: Utilizes NLTK to count words in a text.
   - `is_in_git_directory`, `is_skip_dir`, `is_in_common_dir`: Identifies paths to skip.
   - `should_resummarise_code`: Decides if a source file should be re-summarized.
   - `save_current_content`: Saves accumulated content into a text file.
   - `process_file`: Processes an individual file and accumulates its content.
   - `process_repo`: Orchestrates repository processing and stores summaries.

3. **summarise_code**: Summarizes source code using an external service.

4. **load_yaml**: Loads configuration from a YAML file, handles file and error management.

5. **parse_arguments**: Parses command-line arguments for script options and input paths.

6. **validate_args**: Validates parsed arguments to ensure paths exist and are directories.

### Script Workflow:

- **Argument Handling**: Arguments are parsed and validated.
- **Initialization**: Creates `RepoContentProcessor` with repository path, configuration, and max words.
- **Skip Patterns and Directories**: Updates processor with additional patterns or directories to skip.
- **Working Directory**: Changes to specified output directory.
- **Processing**: Calls `process_repo()` to process the repository.
- **Error Handling**: Catches exceptions, prints errors, and exits with a status code of 1.

### Entry Point:
- The script starts execution with the `main()` function when run directly.
****************************************

****************************************
Salon\src\repo_to_text.py
****************************************
"""
repo_to_text.py

This script processes a local GitHub repository by concatenating the contents of its files into text files, 
with a specified word limit per file.
When it encounters a source file it creates a summary, and acccumulates summaries for all source files ina given directory. 
These are written out at the end. 

Usage:
    python repo_to_text.py --cfg <path_to_config_yaml_file> --repo_path <path-to-repo> [options]

Options:
    --cfg             Path to the config file 
    --repo_path       Path to the local GitHub repository (absolute or relative).
    -w, --max_words   Maximum number of words per output file (default: 200,000).
    -o, --output_dir  Directory to save the output files (default: current directory).
    --skip_patterns   Additional file patterns to skip (e.g., "*.md" "*.txt").
    --skip_dirs       Additional directories to skip.
    -v, --verbose     Enable verbose output.

Example:
    python src/repo_to_text.py --cfg config.yaml --repo_path . -o test_output
    python src/repo_to_text.py --cfg config.yaml --repo_path ./my_repo -w 100000 -o ./output --skip_patterns "*.md" "*.txt" --skip_dirs "tests" -v
"""


import os
import fnmatch
import argparse
from datetime import datetime
from pathlib import Path
import requests
import yaml
import nltk
from nltk.tokenize import word_tokenize

from CommonPy.src.request_utilities import request_timeout

nltk.download('punkt', quiet=True)

SUMMARY_FILENAME='ReadMe.Salon.md'

class SummarisedDirectory:
    def __init__(self):
        self.name = ''
        self.summary = ''


# Dictionary to store processed content with string keys
directories = {}

# Dictionary to store common files with string keys
common_files = {}

def load_yaml(fname):
    # Load configuration from the YAML config file
    try:
        with open(fname, 'r') as config_file:
            config = yaml.safe_load(config_file)
    except FileNotFoundError:
        print(f"Error: Configuration file '{fname}' not found.")
        config = {}
    except yaml.YAMLError as e:
        print(f"Error parsing YAML file: {e}")
        config = {}

    return config

# Configure the base URL for the API.
BASE_URL = 'http://localhost:7071/api'
SESSION_KEY = os.environ['SessionKey']

def summarise_endpoint_url():
    # Construct the full URL for the summary endpoint
    return f'{BASE_URL}/Summarize?session=' + SESSION_KEY

def summarise_code(source: str) -> str:


    payload = {
        'persona': 'CodeSummariser',
        'text': source,
        'lengthInWords': 100
    }
    wrapped = {
        'request': payload
    }
    response = requests.post(summarise_endpoint_url(),
                             json=wrapped, timeout=request_timeout)
    if response.status_code == 200:
        data = response.json()
        if 'summary' in data:
            return data['summary']

    return None
    
    

class RepoContentProcessor:
    def __init__(self, repo_path, config_path={}, max_words=200000):
        # Convert relative path to absolute path
        self.repo_path = Path(repo_path).resolve()
        self.content = ""
        self.file_counter = 1
        self.current_word_count = 0
        self.MAX_WORDS = max_words
        
        config = load_yaml(config_path)

        # Define directories to skip
        self.skip_dirs = config.get("skip_dirs", [])
        # Define file patterns to skip
        self.skip_patterns = config.get("skip_patterns", [])
        # Define file patterns to use a source for chunk size assessment & active code summarisation
        self.source_patterns = config.get("source_patterns", [])
        # Define common directories to use for skipping duplicates where the directories are copied around for deployment reasons
        self.common_directories_patterns = config.get("common_directories_patterns", [])

    def make_common_file_name (self, directory_name, file_name):
        """Make a common file name by combining directory and file name"""
        return directory_name + "-" + file_name
    
    def format_file_block(self, relative_path, file_content):
        """Format a file's content block with consistent indentation"""
        separator = "*" * 40
        return f"{separator}\n{relative_path}\n{separator}\n{file_content}\n{separator}\n"

    def count_words(self, text):
        """Count words in the given text using NLTK tokenizer"""
        return len(word_tokenize(text))
    
    def is_in_git_directory(self, path):
        """Check if the path is inside a .git directory"""
        parts = path.relative_to(self.repo_path).parts
        return '.git' in parts
    
    def is_skip_dir (self, path):
        """Check if the path includes a component in the skip_dirs list"""
        for skip_item in self.skip_dirs:
            if skip_item in path.parts:
               return True
        return False

    def is_in_common_dir (self, path):
        """Check if the path includes a component in the common_directories_patterns list"""
        for common_dir in self.common_directories_patterns:
            if common_dir in path.parts:
               return True
        return False
    
    def extract_common_dir (self, path):
        """Extract the common directory from the path"""
        for common_dir in self.common_directories_patterns:
            if common_dir in path.parts:
               return common_dir
        return None
        
    def is_summary_file(self, path):
        """
        Check if a path is a summary file
        """

        if SUMMARY_FILENAME in path.parts:
            return True
        
        return False
            
    def is_source_file(self, path):
        """
        Check if a path is a source file
        """

        if path.is_file():
            base_name = os.path.basename(path)
            skip1 = any(fnmatch.fnmatch(base_name, pattern)
                      for pattern in self.source_patterns)
            if skip1:
                return True
        
        return False
    
    def should_resummarise_code(self, path):
        """
        Check if a path should be resummarised
        """
        earliest = datetime(1970, 1, 2)
        readme_timestamp = earliest.timestamp()

        # If there is no readme, we need to summarise
        directory = os.path.dirname(path)
        readme_path = os.path.join(directory, SUMMARY_FILENAME)
        if not os.path.exists(readme_path):
            return True
        
        # If the readme is older than the source file, we need to summarise
        readme_timestamp = os.path.getmtime(readme_path)
        
        # Check if any source files are newer than the readme
        for file in os.listdir(directory):
            file_path = os.path.join(directory, file)
            if os.path.isfile(file_path) and self.is_source_file(Path(file_path)):
                file_timestamp = os.path.getmtime(file_path)
                if file_timestamp > readme_timestamp:
                    return True
                    
        return False
    
    def should_skip_path(self, path):
        """
        Check if a path should be skipped
        """
        # Skip anything in .git directory
        if self.is_in_git_directory(path):
            return True
            
        # Skip directories in skip_dirs
        if self.is_skip_dir(path):
            return True
            
        # Skip summary files where there are amended- we add them later on
        if self.is_summary_file(path) and self.should_resummarise_code(path):
            return True
        
        # Skip files matching patterns
        if path.is_file():
            base_name = os.path.basename(path)
            skip1 = any(fnmatch.fnmatch(base_name, pattern)
                      for pattern in self.skip_patterns)
            if skip1:
                return True
        
        return False
    
    def save_directory_content(self):
        """
        Save the directory summaries to the repo path
        """
        
        # Save current working directory 
        current_working_directory = os.getcwd()

        # Change to the repo path
        os.chdir(self.repo_path)

        # Save current directory summaries 
        for directory, item in directories.items():
            if len (item.summary) > 0:
                full_file_path = os.path.join(item.name, SUMMARY_FILENAME)
                with open(full_file_path, 'w+', encoding='utf-8') as f:
                    f.write(item.summary)                
                    print(f"Created {full_file_path}")
        
        os.chdir(current_working_directory)

        # Add summaries to the text accumulation buckets
        for directory, item in directories.items():
            if len (item.summary) > 0:
                full_file_path = os.path.join(item.name, SUMMARY_FILENAME)
                repo_path = os.path.join(self.repo_path, full_file_path)
                self.process_file(Path(repo_path))                           


    def save_current_content(self):
        """Save current content to a numbered file"""
        if self.content:
            output_file = f'repo_content_{self.file_counter}.txt'
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(self.content.rstrip() + "\n")  # Ensure single newline at end of file
            print(f"Created {output_file} with {self.current_word_count} words")
            self.file_counter += 1
            self.content = ""
            self.current_word_count = 0
    
        
    def process_file(self, file_path):
        """Process a single file and add its content to the accumulator"""
        try:
            # Skip if the file is in a common directory and we have already processed a copy of it
            if self.is_in_common_dir(file_path):
                common_file_name = self.make_common_file_name(self.extract_common_dir (file_path), file_path.name)
                if common_file_name in common_files:
                    print(f"Skipping duplicate common file {file_path}")                    
                    return
            
            print(f"Processing: {file_path}")            
            with open(file_path, 'r', encoding='utf-8') as f:
                file_content = f.read().rstrip()  # Remove trailing whitespace
            
            # Create the content block with consistent formatting
            relative_path = str(file_path.relative_to(self.repo_path))
            path_block = self.format_file_block(relative_path, file_content)
            
            # Count words in the new block
            block_word_count = self.count_words(path_block)
            
            # Check if adding this block would exceed the word limit
            if self.current_word_count + block_word_count > self.MAX_WORDS:
                self.save_current_content()
            
            # Add the new block with a single newline for separation
            if self.content:
                self.content += "\n"  # Add separator line only between blocks
            self.content += path_block
            self.current_word_count += block_word_count
            
            if self.is_in_common_dir(file_path):
                common_file_name = self.make_common_file_name(self.extract_common_dir (file_path), file_path.name)
                common_files[common_file_name] = True    

        except (UnicodeDecodeError, IOError) as e:
            print(f"Skipping {file_path}: {str(e)}")
    
    def process_repo(self):
        """Process all files in the repository"""
        print(f"Processing repository at: {self.repo_path}")
        
        if not self.repo_path.exists():
            raise ValueError(f"Path does not exist: {self.repo_path}")
        
        file_count = 0
        skipped_count = 0
        skipped_dirs = set()
        
        # Use Path.rglob instead of os.walk for better path handling
        for file_path in self.repo_path.rglob('*'):
            try:
                rel_path = file_path.relative_to(self.repo_path)                
                # Skip if path should be skipped
                if self.should_skip_path(file_path):
                    if file_path.is_dir():
                        if str(rel_path) not in skipped_dirs:
                            skipped_dirs.add(str(rel_path))
                    else:
                        skipped_count += 1
                    continue
                else:
                    # Ingest only files, not directories
                    if file_path.is_file():
                        self.process_file(file_path)
                        file_count += 1

                        if self.is_source_file(file_path) and self.should_resummarise_code(file_path):
                            file_content = ""
                            summary = None
                            with open(file_path, 'r', encoding='utf-8') as f:
                                file_content = f.read().rstrip()  # Remove trailing whitespace
                            if (len(file_content) > 250):
                                summary = summarise_code(file_content)
                            if summary:
                                file_name = file_path.name
                                directory_path = file_path.parent
                                directory_rel_path = str(directory_path.relative_to(self.repo_path))
                                if directory_rel_path not in directories:
                                    directories[directory_rel_path] = SummarisedDirectory()
                                    (directories[directory_rel_path]).name = str(directory_rel_path)
                                name_and_summary = '**' + file_name + "**\n\n" + summary + '\n\n'
                                existing_summary = directories[directory_rel_path].summary
                                if existing_summary:
                                    accumulated_summary = existing_summary + name_and_summary
                                else:
                                    accumulated_summary = name_and_summary
                                directories[directory_rel_path].summary  = accumulated_summary
                    else:
                        # Keep a dictionary of directories - when we find source files, we add to the summary
                        print(f"Directory: {rel_path}")
                        directories[str(rel_path)] = SummarisedDirectory()
                        (directories[str(rel_path)]).name = str(rel_path)
                                                
                    
            except ValueError as e:
                print(f"Error processing path {file_path}: {e}")
                continue
        
        # Save the directory summaries
        self.save_directory_content()
                
        # Save any remaining content
        if self.content:
            self.save_current_content()
            
        print(f"\nProcessed {file_count} files, skipped {skipped_count} files")




def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description='Process a GitHub repository and concatenate file contents with word limit.',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    parser.add_argument(
        '--cfg',
        type=str,
        default="config.yaml",
        help='Path to the config.yaml file'
    )
    
    parser.add_argument(
        '--repo_path',
        type=str,
        help='Path to the local GitHub repository (absolute or relative)'
    )
    
    parser.add_argument(
        '-w', '--max_words',
        type=int,
        default=200000,
        help='Maximum number of words per output file'
    )
    
    parser.add_argument(
        '-o', '--output_dir',
        type=str,
        default='.',
        help='Directory to save the output files'
    )
    
    parser.add_argument(
        '--skip_patterns',
        type=str,
        nargs='+',
        help='Additional file patterns to skip (e.g., "*.md" "*.txt")'
    )
    
    parser.add_argument(
        '--skip_dirs',
        type=str,
        nargs='+',
        help='Additional directories to skip'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Enable verbose output'
    )
    
    return parser.parse_args()


def validate_args(args):
    """Validate command line arguments"""
    # Convert relative path to absolute path
    repo_path = Path(args.repo_path).resolve()
    
    # Check if repo path exists and is a directory
    if not repo_path.exists():
        raise ValueError(f"Repository path does not exist: {repo_path}")
    if not repo_path.is_dir():
        raise ValueError(f"Repository path is not a directory: {repo_path}")
    
    # Check if output directory exists, create if it doesn't
    output_dir = Path(args.output_dir).resolve()
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Validate max words
    if args.max_words <= 0:
        raise ValueError("Maximum words must be greater than 0")
    
    # Update args with resolved paths
    args.repo_path = repo_path
    args.output_dir = output_dir


def main():
    # Parse and validate arguments
    args = parse_arguments()
    try:
        validate_args(args)
    except ValueError as e:
        print(f"Error: {e}")
        return 1
       
    # Process the repository
    try:
        processor = RepoContentProcessor(args.repo_path, args.cfg, args.max_words)
        
        # Add any additional skip patterns from command line
        if args.skip_patterns:
            processor.skip_patterns.update(args.skip_patterns)
        
        # Add any additional skip directories from command line
        if args.skip_dirs:
            processor.skip_dirs.update(args.skip_dirs)
            
        # Change to output directory
        os.chdir(str(args.output_dir))

        processor.process_repo()
        return 0
    except Exception as e:
        print(f"Error during processing: {e}")
        return 1


if __name__ == "__main__":
    main()
****************************************

****************************************
Teams\infra\azure.bicep
****************************************
@maxLength(20)
@minLength(4)
param resourceBaseName string
param functionAppSKU string

param location string = resourceGroup().location
param serverfarmsName string = resourceBaseName
param functionAppName string = resourceBaseName

// Compute resources for Azure Functions
resource serverfarms 'Microsoft.Web/serverfarms@2021-02-01' = {
  name: serverfarmsName
  location: location
  sku: {
    name: functionAppSKU // You can follow https://aka.ms/teamsfx-bicep-add-param-tutorial to add functionServerfarmsSku property to provisionParameters to override the default value "Y1".
  }
  properties: {}
}

// Azure Functions that hosts your function code
resource functionApp 'Microsoft.Web/sites@2021-02-01' = {
  name: functionAppName
  kind: 'functionapp'
  location: location
  properties: {
    serverFarmId: serverfarms.id
    httpsOnly: true
    siteConfig: {
      appSettings: [
        {
          name: 'FUNCTIONS_EXTENSION_VERSION'
          value: '~4' // Use Azure Functions runtime v4
        }
        {
          name: 'FUNCTIONS_WORKER_RUNTIME'
          value: 'node' // Set runtime to NodeJS
        }
        {
          name: 'WEBSITE_RUN_FROM_PACKAGE'
          value: '1' // Run Azure Functions from a package file
        }
        {
          name: 'WEBSITE_NODE_DEFAULT_VERSION'
          value: '~18' // Set NodeJS version to 18.x
        }
      ]
      ftpsState: 'FtpsOnly'
    }
  }
}
var apiEndpoint = 'https://${functionApp.properties.defaultHostName}'


// The output will be persisted in .env.{envName}. Visit https://aka.ms/teamsfx-actions/arm-deploy for more details.
output API_FUNCTION_ENDPOINT string = apiEndpoint
output API_FUNCTION_RESOURCE_ID string = functionApp.id
output OPENAPI_SERVER_URL string = apiEndpoint
****************************************

****************************************
Teams\appPackage\apiSpecificationFile\boxer.yml
****************************************
openapi: 3.0.0
info:
  title: The Braid Studio
  description: APIs to bring AI into Enterprise work environments
  version: 1.0.0
servers:
  - url: ${{OPENAPI_SERVER_URL}}/api
    description: The Braid api server
paths:
  /boxer:
    get:
      operationId: boxer
      summary: Returns answers to questions about AI. 
      description: Returns an answer to the question plus a set of links to related documents. 
      parameters:
        - name: question
          in: query
          description: A question about AI
          schema:
            type: string
          required: false
      responses:
        '200':
          description: An answer to the question plus a set of links to related documents
          content:
            application/json:
              schema:
                type: array
                items:
                  properties:
                    id:
                      type: string
                      description: The unique identifier of the item (unused, placeholder)
                    title:
                      type: string
                      description: A title for the link
                    description:
                      type: string
                      description: The detailed of the link
                    url:
                      type: string
                      format: uri
                      description: A link to the related document
                    image:
                      type: string
                      format: uri
                      description: The URL of the image to use to represent the link
****************************************

****************************************
Teams\src\functions\boxer.ts
****************************************
/* This code sample provides a starter kit to implement server side logic for your Teams App in TypeScript,
 * refer to https://docs.microsoft.com/en-us/azure/azure-functions/functions-reference for complete Azure Functions
 * developer guide.
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";
import axios from "axios";
import axiosRetry from 'axios-retry';

/**
 * This function handles the HTTP request and returns the boxer information.
 *
 * @param {HttpRequest} req - The HTTP request.
 * @param {InvocationContext} context - The Azure Functions context object.
 * @returns {Promise<Response>} - A promise that resolves with the HTTP response containing the boxer information.
 */
export async function boxer(
   req: HttpRequest,
   context: InvocationContext
): Promise<HttpResponseInit> {

   try {
      // Get the question query parameter.
      const question = req.query.get("question") || (await req.text());;

      if (question) {

         context.log(question);

         // Up to 5 retries if we hit rate limit
         axiosRetry(axios, {
            retries: 5,
            retryDelay: axiosRetry.exponentialDelay,
            retryCondition: (error) => {
               return error?.response?.status === 429 || axiosRetry.isNetworkOrIdempotentRequestError(error);
            }
         });

         // Initialize response.
         const res: HttpResponseInit = {
            status: 200,
            jsonBody: {
               results: [],
            },
         };         

         let braidApi = "https://braid-api.azurewebsites.net/api/StudioForTeams-Boxer";
         const postResult = await axios.post(braidApi, null,
            {
               params: { question: question }
            });

         console.log(postResult.data);

         let items = new Array();
         for (let i = 0; i < postResult.data.length; i++) {
            let item = {
               id: postResult.data[i].id,
               description: postResult.data[i].summary,
               url: postResult.data[i].url,
               title: postResult.data[i].title,
               image: postResult.data[i].iconUrl
            }
            items.push(item);
         }
         console.log(items);

         // Return filtered boxer records, or an empty array if no records were found.
         res.jsonBody.results = items;
         return res;
      }
      else {
         context.error("Invalid request, no qustion found in paremeters.");
         return {
            status: 400, // Internal error
            body: "Invalid request, no qusetion found in paremeters."
         };
      }
   }
   catch (e: any) {
         context.error("Internal error:", e);
         return {
            status: 500, // Internal error
            body: "Internal server error."
         };
      }
   }

app.http("boxer", {
      methods: ["GET"],
      authLevel: "anonymous",
      handler: boxer,
   });
****************************************

****************************************
Teams\src\functions\ReadMe.Salon.md
****************************************
**boxer.ts**

This code provides a server-side implementation for a Teams App using TypeScript and Azure Functions. It features the primary function `boxer` which handles HTTP requests and retrieves boxer information based on a query parameter.

The function `boxer(req, context)`:
1. Retrieves the "question" parameter from the request.
2. Logs the question and sets up Axios for handling potential rate limits with up to 5 retries.
3. Sends a POST request to the Braid API to fetch relevant boxer data.
4. Processes the API response to extract necessary details and formats them into an array.
5. Returns this array in the HTTP response or handles errors and invalid requests appropriately.

Classes/Functions: `boxer`, `app.http`.
****************************************

****************************************
Waterfall\src\boxer_pipeline.py
****************************************
'''driver for the entire Boxer data generation pipeline '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json

from src.workflow import YouTubePipelineSpec, HtmlDirectedPipelineSpec, PipelineItem, PipelineFileSpec
from src.youtube_searcher import YoutubePlaylistSearcher
from src.youtube_transcript_downloader import YouTubeTranscriptDownloader
from src.youtube_transcript_chunker import YouTubeTranscriptChunker
from src.html_link_crawler import HtmlLinkCrawler
from src.html_file_downloader import HtmlFileDownloader
from src.summariser import Summariser
from src.embedder import Embedder
from src.waterfall_pipeline_save_chunks import save_chunks

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


class BoxerDataPipeline:
    '''
    Searches for HTML & YouTube  from a list of links.

    Returns:
       list[str]: A list of HTML content downloaded from the specified links.
    '''

    def __init__(self, output_location: str):
        '''
        Initializes a BoxerDataPipeline object with the specified output location.

        Parameters:
            output_location (str): The location where the output will be stored.

        Returns:
            None
        '''
        self.output_location = output_location
        return

    def search(self,
               youtube_spec: YouTubePipelineSpec,
               html_spec: HtmlDirectedPipelineSpec,
               file_spec: PipelineFileSpec) -> list[PipelineItem]:
        '''
        Searches for HTML & YouTube content from a list of links.

        Returns:
            A list with all the donloaded pipline items
        '''
        youtube_searcher = YoutubePlaylistSearcher(self.output_location)
        youtube_downloader = YouTubeTranscriptDownloader(self.output_location)
        youtube_chunker = YouTubeTranscriptChunker(self.output_location)

        html_crawler = HtmlLinkCrawler(self.output_location)
        html_downloader = HtmlFileDownloader(self.output_location)

        summariser = Summariser(self.output_location)
        embedder = Embedder(self.output_location)

        all_chunks = []
        all_enriched_chunks = []

        for html_url in html_spec.urls:
            chunk = PipelineItem()
            chunk.path = html_url
            html_items = html_crawler.crawl(chunk)

            for html_item in html_items:
                downloaded = None
                summarised = None
                embedded = None

                downloaded = html_downloader.download(html_item)
                if downloaded:
                    summarised = summariser.summarise(downloaded)
                if summarised:
                    embedded = embedder.embed(summarised)
                if embedded:
                    all_enriched_chunks.append(embedded)

        youtube_items = youtube_searcher.search(youtube_spec)

        for chunk in youtube_items:
            chunk = youtube_downloader.download(chunk)
            chunks = youtube_chunker.chunk(
                chunk, youtube_spec.max_words, youtube_spec.overlap_words)
            if chunks:
                all_chunks.extend(chunks)

        for chunk in all_chunks:
            summarised = None
            embedded = None
            logger.info('Processing: %s', chunk.path)
            if chunk.text:
                summarised = summariser.summarise(chunk)
            if summarised:
                embedded = embedder.embed(summarised)
            if embedded:
                all_enriched_chunks.append(embedded)

        # Save all chunks to the DB
        save_chunks(all_enriched_chunks, file_spec)

        output_results = []
        for chunk in all_enriched_chunks:
            output_item = dict()
            output_item['summary'] = chunk.summary
            output_item['embedding'] = chunk.embedding
            output_item['url'] = chunk.path
            output_results.append(output_item)

        # save the test results to a json file
        output_file = os.path.join(
            self.output_location, file_spec.output_data_name)
        with open(output_file, 'w+', encoding='utf-8') as f:
            json.dump(output_results, f)

        return all_enriched_chunks
****************************************

****************************************
Waterfall\src\boxer_sources.py
****************************************
"""
Contains source material references for AI/ML education and research.

This module maintains curated lists of educational resources including:
- YouTube playlists covering machine learning, NLP, and AI fundamentals
- Key articles and tutorials from industry experts and educational institutions
- Reference documentation and learning materials from leading AI platforms

The sources serve as a knowledge base for understanding core AI/ML concepts
and staying current with developments in the field.
"""


youtube_playlists = [
    # "Stanford CS229: Machine Learning Full Course taught by Andrew Ng | Autumn 2018 - YouTube",
    "PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU",
    # "Stanford CS224N: Natural Language Processing with Deep Learning | Winter 2021 - YouTube",
    "PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ",
    # "Braid AI Canon",
    "PL9LkXkIUrSoxIlFSKcyB21XFFLCCYfPGv",
    # "Braid - Additional Content",
    "PL9LkXkIUrSozgkPNepSMzidqtAGR0b1F_",
    # "Augmented Language Models (LLM Bootcamp) (youtube.com)",
    "PL1T8fO7ArWleyIqOy37OVXsP4hFXymdOZ"
]

html_pages = [
    # "Learn | Pinecone",
    "https://www.pinecone.io/learn/",

    # "Software 2.0. by Andrej Karpathy",
    "https://karpathy.medium.com/software-2-0-a64152b37c35",

    # "Transformers, Explained: Understand the Model Behind GPT-3, BERT, and T5 (daleonai.com)",
    "https://daleonai.com/transformers-explained",

    # "What Is ChatGPT Doing … and Why Does It Work?—Stephen Wolfram",
    "https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/",

    # "How Stable Diffusion Works · Chris McCormick (mccormickml.com)",
    "https://mccormickml.com/2022/12/21/how-stable-diffusion-works/",

    # "Deep Learning in a Nutshell: Core Concepts | NVIDIA Technical Blog",
    "https://developer.nvidia.com/blog/deep-learning-nutshell-core-concepts/",

    # "Practical Deep Learning for Coders - Practical Deep Learning (fast.ai)",
    "https://course.fast.ai/",

    # "Word2Vec Explained. Explaining the Intuition of Word2Vec &… | by Vatsal | Towards Data Science",
    "https://towardsdatascience.com/word2vec-explained-49c52b4ccb71",

    # "Yes you should understand backprop | by Andrej Karpathy",
    "https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b",

    # "The Illustrated Transformer by Jay Alammar (jalammar.github.io)",
    "https://jalammar.github.io/illustrated-transformer/",

    # "The Annotated Transformer (harvard.edu)",
    "https://nlp.seas.harvard.edu/annotated-transformer/",

    # "The Illustrated Stable Diffusion by Jay Alammar Visualizing machine learning one concept at a time. (jalammar.github.io)",
    "https://jalammar.github.io/illustrated-stable-diffusion/",

    # "Huyen Chip's Blog",
    "https://huyenchip.com/",

    # "Stamford CS234 - Large Language Models",
    "https://stanford-cs324.github.io/winter2022/lectures/",

    # "The Scaling Hypothesis · Gwern.net",
    "https://gwern.net/scaling-hypothesis",

    # "chinchilla's wild implications — LessWrong",
    "https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications",

    # "The AI Revolution: How Auto-GPT Unleashes a New Era of Automation and Creativity | by Sriram Parthasarathy | Towards AI",
    "https://pub.towardsai.net/the-ai-revolution-how-auto-gpt-unleashes-a-new-era-of-automation-and-creativity-2008aa2ca6ae",

    # "The Waluigi Effect (mega-post) — LessWrong",
    "https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post",

    # "Build a GitHub Support Bot with GPT3, LangChain, and Python | Dagster Blog",
    "https://dagster.io/blog/chatgpt-langchain",

    # "Prompt Engineering Guide | Prompt Engineering Guide (promptingguide.ai)",
    "https://www.promptingguide.ai/",

    # "Use Cases | Langchain",
    "https://python.langchain.com/v0.1/docs/use_cases/",

    # "Hugging Face Cookbook",
    "https://huggingface.co/learn/cookbook",

    # "Open AI Cookbook",
    "https://cookbook.openai.com/",

    # "State of Open Source AI - 2023 Edition",
    "https://book.premai.io/state-of-open-source-ai/",

    # "Scaled Agile Framework 6.0",
    "https://scaledagileframework.com/",

    # "McKinsey on AI",
    "https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier",

    # "A16Z Market Analysis",
    "https://a16z.com/for-b2b-generative-ai-apps-is-less-more/",

    # "A16Z Market Analysis",
    "https://a16z.com/navigating-the-high-cost-of-ai-compute/",

    # "A16Z Market Analysis",
    "https://a16z.com/financial-services-will-embrace-generative-ai-faster-than-you-think/",

    # "A16Z Market Analysis",
    "https://a16z.com/who-owns-the-generative-ai-platform/",

    # "Interaction Design Foundation",
    "https://www.interaction-design.org/literature/topics/design-thinking",

    # "UX for AI",
    "https://www.uxforai.com/",

    # "Testing Machine Learning Systems: Code, Data and Models ",
    "https://madewithml.com/courses/mlops/testing/",

    # "Monitoring Machine Learning Systems: Code, Data and Models ",
    "https://madewithml.com/courses/mlops/monitoring/",

    # "Full Stack Machine learning"
    "https://leehanchung.github.io/"
]
****************************************

****************************************
Waterfall\src\chunker.py
****************************************
'''PipelineStep to create a summary for a text string'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json
import requests
from requests.adapters import HTTPAdapter, Retry

from CommonPy.src.request_utilities import request_timeout
from src.workflow import PipelineItem, PipelineStep


# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)

SESSION_KEY = os.environ['SessionKey']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}


class Chunker (PipelineStep):
    '''PipelineStep to chunk a text string'''

    # pylint: disable-next=useless-parent-delegation 
    def __init__(self, output_location: str):
        '''
        Initializes the Chunker object with the provided output location.
        '''
        super(Chunker, self).__init__(output_location)

    def chunk(self, pipeline_item: PipelineItem, chunk_size_words: int, overlap_words: int) -> list[PipelineItem]:
        '''
        Chunk a text string into smaller parts and return a list of PipelineItem objects representing each chunk. Uses an external API to perform the chunking process. 

        Parameters:
            - pipeline_item: PipelineItem - The item to be chunked.
            - max_words - maximum words per chunk. If 0, use the models context window size. 
            - overlap_words - how many words to use to overlap chunks. 0 = no overlap.             

        Returns:
            - List of PipelineItem - List of PipelineItem objects representing the chunks.
         ''' ''

        logger.debug('Chunking: %s', pipeline_item.path)

        session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[500, 502, 503, 504])
        session.mount('https://', HTTPAdapter(max_retries=retries))

        summary_url = f'https://braid-api.azurewebsites.net/api/Chunk?session={
            SESSION_KEY}'

        if chunk_size_words == 0:
            input_json = {
                'request': {
                    'text': pipeline_item.text,
                    'overlapWords': overlap_words
                }
            }
        else:
            input_json = {
                'request': {
                    'text': pipeline_item.text,
                    'chunkSize': chunk_size_words,
                    'overlapWords': overlap_words
                }
            }

        response = session.post(summary_url, json=input_json, 
                                headers=headers,
                                timeout=request_timeout)
        pipeline_chunks = []  # If there is an error in the API, return an empty list

        if response.status_code == 200:
            response_json = json.loads(response.text)
            chunks = response_json['chunks']

            for i, chunk in enumerate(chunks):
                new_item = PipelineItem()
                new_item.path = pipeline_item.path
                new_item.text = chunk
                new_item.chunk = i
                new_item.summary = pipeline_item.summary
                new_item.embedding = pipeline_item.embedding
                new_item.cluster = pipeline_item.cluster
                pipeline_chunks.append(new_item)

        return pipeline_chunks
****************************************

****************************************
Waterfall\src\cluster_analyser.py
****************************************
'''PipelineStep to analyse a set of embedding vectors by KMeans clustering'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
from sklearn.cluster import KMeans

from src.workflow import PipelineItem, PipelineStep

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


class ClusterAnalyser (PipelineStep):
    '''PipelineStep that analyses a set of embedding vectors by KMeans clustering'''

    def __init__(self, output_location: str, clusters: int):
        '''
        Initializes the ClusterAnalyser object with the provided output location and target cluster count
        '''
        super(ClusterAnalyser, self).__init__(output_location)
        self.clusters = clusters

    def analyse(self, items: list[PipelineItem]) -> list[PipelineItem]:
        '''
        Analyzes the given clusters using KMeans clustering algorithm.

        Parameters:
           items: a set of Pipeline items to analyse

        Returns:
           list[PipelineItem]: A list of PipelineItem objects with updated cluster assignments.
        '''

        x = len (items[0].embedding)
        y = len (items)

        embeddings = [[0 for _ in range(x)] for _ in range(y)]
        for i, item in enumerate (items):
            embeddings[i] = item.embedding

        logger.debug('Making cluster')
        kmeans = KMeans(n_clusters=self.clusters)
        kmeans.fit(embeddings)

        for i, item in enumerate(items):
            item.cluster = int(kmeans.labels_[i])

        return items
****************************************

****************************************
Waterfall\src\db_repository.py
****************************************
'''
Module to store data in the Chunk table of the BraidApis
This module takes in data as 'PipelineItem', as used in waterfall.
It converts to Chunk  to pass to the native Chunk API, which is common across multiple applications.

'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import datetime
import uuid

from CommonPy.src.chunk_repository_api_types import (IStoredChunk,
   IStoredEmbedding,
   IStoredTextRendering)
from CommonPy.src.chunk_repository_api import (ChunkRepository,
                                               chunk_class_name,
                                               chunk_schema_version)
from src.make_local_file_path import make_local_file_path
from src.workflow import PipelineItem

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


class DbRepository:
    '''
    Class providing load, save, and existence check for files in the Braid Cosmos database.
    '''

    def __init__(self, application_id: str, context_id: str):

        self.application_id = application_id
        self.context_id = context_id
        self.chunk_repository = ChunkRepository()

    def save(self, item: PipelineItem) -> bool:
        '''
        Save the provided item to the database.

        Parameters:
           functional_key (str): functionalKey to use for the record
           item (PipelineItem): The content to be saved.
        '''
        functional_key = make_local_file_path(item.path)
        logger.debug('Saving: %s', functional_key)

        utc_time = datetime.datetime.now(datetime.timezone.utc)
        utc_time_string = utc_time.strftime('%Y-%m-%d %H:%M:%S %Z')

        summary: IStoredTextRendering = IStoredTextRendering()
        summary.modelId = self.chunk_repository.default_model
        summary.text = item.summary

        embedding: IStoredEmbedding = IStoredEmbedding()
        embedding.modelId = self.chunk_repository.default_embedding_model
        embedding.embedding = item.embedding

        # Create a Chunk from the PipelineItem supplied
        chunk: IStoredChunk = IStoredChunk()
        if item.id:
            chunk.id = item.id
        else:
            chunk.id = str(uuid.uuid4())
        chunk.applicationId = self.application_id
        chunk.contextId = self.context_id
        chunk.userId = None
        chunk.created = utc_time_string
        chunk.amended = chunk.created
        chunk.className = chunk_class_name
        chunk.schemaVersion = chunk_schema_version
        chunk.functionalSearchKey = functional_key
        chunk.parentChunkId = item.parent_id
        chunk.originalText = item.text
        chunk.storedEmbedding = embedding
        chunk.storedSummary = summary
        chunk.storedTitle = None
        chunk.relatedChunks = None
        chunk.url = item.path

        return self.chunk_repository.save(chunk)

    def find(self, path: str) -> PipelineItem:
        '''
        Load content from the database based on the provided context and functional key.
        If the file exists in the output location, its contents are read and returned as a string.
        If the record is not found, return None

        Parameters:
           functional_key (str): functionalKey to use for the record

        Returns:
           item (PipelineItem): The loaded content or None
        '''

        functional_key = make_local_file_path(path)

        chunk = self.chunk_repository.find(functional_key)

        if chunk:
            # Map from a Chunk to a PipelineItem
            item = PipelineItem()
            item.id = chunk.id
            item.parent_id = chunk.parentChunkId
            item.path = chunk.url
            item.text = chunk.originalText
            if chunk.storedSummary:
                item.summary = chunk.storedSummary.text
            else:
                item.summary = None
            if chunk.storedEmbedding:
                item.embedding = chunk.storedEmbedding.embedding
            else:
                item.embedding = None
        else:
            item = None

        return item

    def exists(self, path: str) -> bool:
        '''
        Checks if a record with the specified key and context exists in the database

        Parameters:
           functional_key (str): functionalKey to use for the record

        Returns:
           bool: True if the record exists, False otherwise.
        '''

        functional_key = make_local_file_path(path)

        return self.chunk_repository.exists(functional_key)
****************************************

****************************************
Waterfall\src\embedder.py
****************************************
'''PipelineStep to create the embedding for a text string'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json
import requests
from requests.adapters import HTTPAdapter, Retry

from src.workflow import PipelineItem, PipelineStep
from src.embedder_repository_facade import EmbeddingRespositoryFacade
from CommonPy.src.request_utilities import request_timeout

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)

SESSION_KEY = os.environ['SessionKey']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}


class Embedder (PipelineStep):
    '''PipelineStep to create the embedding for a text string'''

    # pylint: disable-next=useless-parent-delegation
    def __init__(self, output_location: str):
        '''
        Initializes the Embedder object with the provided output location.
        '''
        # pylint: disable-next=useless-parent-delegation
        super(Embedder, self).__init__(output_location)

    def embed(self, pipeline_item: PipelineItem) -> PipelineItem:
        """
        Generates an embedding for the given PipelineItem. If an embedding
        already exists for the item's path, it is loaded from the repository.
        Otherwise, a new embedding is created using an external API, saved,
        and assigned to the PipelineItem.

        Args:
            pipeline_item (PipelineItem): The item containing text to be embedded.

        Returns:
            PipelineItem: The updated item with the generated embedding, or
            None if the embedding could not be calculated.
        """
        path = pipeline_item.path
        repository = EmbeddingRespositoryFacade(self.output_location)
        if repository.exists(path):
            embedding = repository.load(path)
            pipeline_item.embedding = embedding
            return pipeline_item

        logger.debug('Embedding: %s', path)

        session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[500, 502, 503, 504])
        session.mount('https://', HTTPAdapter(max_retries=retries))

        embed_url = f'https://braid-api.azurewebsites.net/api/Embed?session={
            SESSION_KEY}'
        json_input = {
            'request': {
                'text': pipeline_item.text
            }
        }

        response = session.post(embed_url, json=json_input, 
                                headers=headers,
                                timeout=request_timeout)

        if response.status_code == 200:
            response_json = json.loads(response.text)
            embedding = response_json['embedding']

            if path is not None:
                repository.save(path, embedding)

            pipeline_item.embedding = embedding

            return pipeline_item
        else:
            logger.error("Unable to calculate embedding item: %s", pipeline_item.path)
            return None
        

    def embed_text (self, text: str) -> list[float]:
        """
        Generates an embedding for the given text using an external API.

        Args:
            text (str): The text string to be embedded.

        Returns:
            list[float]: The generated embedding as a list of floats, or
            None if the embedding could not be calculated.
        """

        session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[500, 502, 503, 504])
        session.mount('https://', HTTPAdapter(max_retries=retries))

        embed_url = f'https://braid-api.azurewebsites.net/api/Embed?session={
            SESSION_KEY}'
        json_input = {
            'request': {
                'text': text
            }
        }

        response = session.post(embed_url, json=json_input, 
                                headers=headers,
                                timeout=request_timeout)

        if response.status_code == 200:
            response_json = json.loads(response.text)
            embedding = response_json['embedding']

            return embedding
        else:
            logger.error("Unable to calculate embedding: %s", text)
            return None
****************************************

****************************************
Waterfall\src\embedder_repository_facade.py
****************************************
'''Facade to store embeddings in local file system'''

# Copyright (c) 2024 Braid Technologies Ltd

import os
from glob import glob

from src.file_repository import FileRespository

SPEC = "embed.txt"

def read_file_names(path: str, file_spec: str):
    """
    Retrieve a list of file names matching a specified pattern within a given directory.

    Args:
     path (str): The directory path to search within.
     file_spec (str): The pattern to match file names against.

    Returns:
     list: A list of file names that match the specified pattern.
    """
    return list(glob(os.path.join(path, file_spec)))


class EmbeddingRespositoryFacade:
    '''
    Class providing an interface to load, save, and existence check for files in the file system.
    '''

    def __init__(self, output_location: str):
        """
        Initializes an instance of EmbeddingRespositoryFacade.

        Args:
            output_location (str): The directory path where files will be stored.

        Attributes:
            file__repository (FileRespository): An instance to manage file operations.
            output_location (str): The directory path for storing files.
            extension (str): The file extension pattern for stored files.
        """
        self.file__repository = FileRespository(output_location)
        self.output_location = output_location
        self.extension = SPEC

    @staticmethod
    def spec() -> str:
        """
        Returns the file extension pattern used for storing files.

        Returns:
        str: The file extension pattern prefixed with '*.'.
        """
        return "*." + SPEC

    def list_contents(self) -> list[str]:
        """
        Lists the contents of the output location by retrieving file names
        with the specified extension pattern, stripping double extensions,
        and returning the base file names.

        Returns:
            list[str]: A list of base file names without extensions.
        """
        paths = read_file_names(self.output_location,
                                EmbeddingRespositoryFacade.spec())

        file_names = []
        for path in paths:
            # strip twice as we have double extensions in file names
            stripped = os.path.splitext(os.path.splitext(path)[0])[0]
            filename = os.path.basename(stripped)
            file_names.append(filename)

        return file_names

    def save(self, path: str, embedding: list[float]) -> None:
        '''
        Save the provided text to a file at the specified path within the output location.

        Parameters:
           path (str): The path where the file will be saved.
           text (str): The text content to be saved in the file.
        '''
        return self.file__repository.save(path, self.extension, str(embedding))

    def load(self, path: str) -> list[float]:
        '''
        Load content from a file based on the provided path. 
        If the file exists in the output location, its contents are read and returned as a string. 
        If the file does not exist, an empty string is returned.

        Parameters:
           path (str): The path of the file.

        Returns:
           str: The contents of the file if it exists, otherwise an empty string.
        '''

        loaded = self.file__repository.load(path, self.extension)

        return self.text_to_float(loaded)

    def exists(self, path: str) -> bool:
        '''
        Checks if a file with the specified path exists in the output location.

        Parameters:
           path (str): The path of the file.

        Returns:
           bool: True if the file exists, False otherwise.
        '''
        return self.file__repository.exists(path, self.extension)

    def text_to_float(self, embedding: str) -> list[float]:
        '''
        Converts a string representation of numbers to a list of floating-point numbers.

        Parameters:
           embedding (str): A string containing numbers to be converted.

        Returns:
           list: A list of floating-point numbers extracted from the input string.
        '''
        characters_to_remove = '[]'
        translation_table = str.maketrans('', '', characters_to_remove)

        numbers = embedding.split(',')

        stripped_number_array = [number.translate(
            translation_table) for number in numbers]

        number_array = [float(number) for number in stripped_number_array]

        return number_array
****************************************

****************************************
Waterfall\src\embedding_finder.py
****************************************
'''Find the nearest embedding to the target text based on cosine similarity.'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import numpy as np
from numpy.linalg import norm

from src.embedder import Embedder
from src.workflow import PipelineItem

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


def cosine_similarity(a, b):
    result = np.dot(a, b) / (norm(a) * norm(b))
    return result


class EmbeddingFinder:
    '''Find the nearest embedding to the target text based on cosine similarity.'''

    def __init__(self, embeddings: list[float], output_location: str):

        self.embeddings = embeddings
        self.output_location = output_location

    def find_nearest(self, target_text: str) -> list[float]:
        '''
        Find the nearest embedding to the target text based on cosine similarity.

        Parameters:
        target_text (str): The text to find the nearest embedding for.

        Returns:
        list[float]: The nearest embedding to the target text.
        '''
        pipeline_item = PipelineItem()
        pipeline_item.text = target_text
        embedder = Embedder(self.output_location)
        enriched_embeddding: PipelineItem = embedder.embed(pipeline_item)

        best_similarity = 0.0
        this_similarity = 0.0
        best_match = None

        for embeddding in self.embeddings:
            this_similarity = cosine_similarity(
                embeddding, enriched_embeddding.embedding)
            if this_similarity > best_similarity:
                best_similarity = this_similarity
                best_match = embeddding

        return best_match
****************************************

****************************************
Waterfall\src\file_repository.py
****************************************
'''Module to store data in local file system'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json

from src.make_local_file_path import make_local_file_path

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


def strip_quotes(input_string):
    """
 Remove all single and double quotes from the input string.

 Args:
     input_string (str): The string from which quotes will be removed.

 Returns:
     str: The input string with all single and double quotes removed.
    """
    return input_string.replace('\"', '').replace("'", '')


class FileRespository:
    '''
    Class providing load, save, and existence check for files in the file system.
    '''

    def __init__(self, output_location: str):
        self.output_location = output_location

    def save(self, path: str, extension: str, text: str) -> None:
        '''
        Save the provided text to a file at the specified path within the output location.

        Parameters:
           path (str): An Http path.
           extension (str): The extension of the file.
           text (str): The text content to be saved in the file.
        '''

        if not os.path.exists(self.output_location):
            os.makedirs(self.output_location)

        fake_name = make_local_file_path(path)
        content_output_filename = os.path.join(
            self.output_location, f'{fake_name}.' + extension)

        with open(content_output_filename, 'w+', encoding='utf-8') as file:
            json.dump(text, file, indent=4, ensure_ascii=False)
            file.close()

        logger.debug('Saving: %s', path)

        return None

    def load(self, path: str, extension: str) -> str:
        '''
        Load content from a file based on the provided path and extension. 
        If the file exists in the output location, its contents are read and returned as a string. 
        If the file does not exist, an empty string is returned.

        Parameters:
           path (str): An Http path.
           extension (str): The extension of the file.

        Returns:
           str: The contents of the file if it exists, otherwise an empty string.
        '''

        fake_name = make_local_file_path(path)
        content_output_filename = os.path.join(
            self.output_location, f'{fake_name}.' + extension)

        if not os.path.exists(self.output_location):
            os.makedirs(self.output_location)
            return ''

        fake_name = make_local_file_path(path)
        if os.path.exists(content_output_filename):
            with open(content_output_filename, 'r', encoding='utf-8') as file:
                contents = file.read()
                file.close()
            return strip_quotes(contents)

        return ''

    def exists(self, path: str, extension: str) -> bool:
        '''
        Checks if a file with the specified path and extension exists in the output location 
        of the FileRepository.

        Parameters:
           path (str): An Http path.
           extension (str): The extension of the file.

        Returns:
           bool: True if the file exists, False otherwise.
        '''
        if not path:
            return False

        fake_name = make_local_file_path(path)
        content_output_filename = os.path.join(
            self.output_location, f'{fake_name}.' + extension)

        if not os.path.exists(self.output_location):
            os.makedirs(self.output_location)
            return False

        if os.path.exists(content_output_filename):
            return True

        return False
****************************************

****************************************
Waterfall\src\google_office_mailer.py
****************************************
'''Use Google Office to send a mail '''
import os
import os.path
import base64
import mimetypes
import logging

from email.message import EmailMessage
from email.mime.base import MIMEBase

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow

from src.workflow import WebSearchPipelineSpec

# If modifying these scopes, delete the file token.json.
SCOPES = ['https://www.googleapis.com/auth/gmail.send']

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


def send_mail(output_location: str, body: str, attachment: str, spec: WebSearchPipelineSpec):
    '''Use Gmail API to send the report
    Lists the user's Gmail labels.
    '''
    creds = None
    # The file token.json stores the user's access and refresh tokens, and is
    # created automatically when the authorization flow completes for the first
    # time.
    token_path = os.path.join(output_location, 'token.json')
    if os.path.exists(token_path):
        creds = Credentials.from_authorized_user_file(token_path, SCOPES)
    # If there are no (valid) credentials available, let the user log in.
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            credential_path = os.path.join('..', 'credential.json')
            flow = InstalledAppFlow.from_client_secrets_file(
                credential_path, SCOPES
            )
            creds = flow.run_local_server(port=0)
        # Save the credentials for the next run
        with open(token_path, 'w+', encoding='utf-8') as token:
            token.write(creds.to_json())

    try:
        # Call the Gmail API
        service = build('gmail', 'v1', credentials=creds)
        send_message_with_attachment(
            service, output_location, body, attachment, spec)

    except HttpError as error:
        # TODO(developer) - Handle errors from gmail API.
        logger.error('An error occurred: %s', error, exc_info=True)


def send_message_with_attachment(service, output_location: str, body: str, attachment: str, spec: WebSearchPipelineSpec):
    '''Create and insert a draft email with attachment.
     Print the returned draft's message and id.
    Returns: Draft object, including draft id and message meta data.

    Load pre-authorized user credentials from the environment.
    See https://developers.google.com/identity
    for guides on implementing OAuth2 for the application.
    '''

    try:
        # create gmail api client
        message = EmailMessage()

        # Body in HTML format
        message.add_header('Content-Type', 'text/html')
        message.set_payload(body)

        # headers
        message['To'] = spec.mail_to
        message['From'] = 'waterfall@braidapps.io'
        message['Subject'] = spec.description

        # attachment
        try:
            attachment_path = os.path.join(output_location, attachment)

            # guessing the MIME type
            type_subtype, _ = mimetypes.guess_type(attachment_path)
            maintype, subtype = type_subtype.split('/')

            with open(attachment_path, 'rb') as fp:
                attachment_data = fp.read()
            message.add_attachment(attachment_data, maintype, subtype)
        
        # pylint: disable-broad-exception-caught
        except Exception:
            # we allow the message to be sent event if we have an error adding the attachment
            ok = True
            ok
         
        encoded_message = base64.urlsafe_b64encode(message.as_bytes()).decode()

        create_message = {'raw': encoded_message}

        # pylint: disable=E1101
        send_message = (
            service.users()
            .messages()
            .send(userId='me', body=create_message)
            .execute()
        )

    except HttpError as error:
        logger.error('An error occurred:%s', error, exc_info=True)
        send_message = None
    return send_message


def build_file_part(file):
    '''Creates a MIME part for a file.

    Args:
      file: The path to the file to be attached.

    Returns:
      A MIME part that can be attached to a message.
    '''
    content_type, encoding = mimetypes.guess_type(file)

    if content_type is None or encoding is not None:
        content_type = 'application/octet-stream'
    main_type, sub_type = content_type.split('/', 1)
    with open(file, 'rb'):
        msg = MIMEBase(main_type, sub_type)
        msg.set_payload(file.read())

    filename = os.path.basename(file)
    msg.add_header('Content-Disposition', 'attachment', filename=filename)

    return msg
****************************************

****************************************
Waterfall\src\html_file_downloader.py
****************************************
'''PipelineStep to download thw text of a web page '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
from selenium import webdriver
from bs4 import BeautifulSoup

from src.workflow import PipelineItem, PipelineStep
from src.text_repository_facade import TextRespositoryFacade

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
    'Accept-Encoding': 'none',
    'Accept-Language': 'en-US,en;q=0.8',
    'Connection': 'keep-alive'
}


class HtmlFileDownloader (PipelineStep):
    '''Utility class to download an HTML file

     Args:
         output_location (str): The location to save the downloaded file.
    '''

    # pylint: disable-next=useless-parent-delegation
    def __init__(self, output_location: str):
        '''
        Initializes the HtmlFileDownloader object with the provided output location.
        '''
        super(HtmlFileDownloader, self).__init__(output_location)

    def download(self, pipeline_item: PipelineItem) -> PipelineItem:
        '''
         Downloads the HTML content from the specified path and saves it to the output location.

         Returns:
             PipelineItem: Enriched with the content of the downloaded HTML file.
        '''

        path = pipeline_item.path
        repository = TextRespositoryFacade(self.output_location)
        if path is not None and repository.exists(path):
            full_text = repository.load(path)
            pipeline_item.text = full_text
            return pipeline_item

        logger.debug('Downloading: %s', path)

        if path.find('http') != -1:
            # These lines left from version using session library
            # Switched to webdriver as it has fewer failures to parse
            # Add headers in case the website expects cookies and/or JavaScript
            # session = requests.Session()
            # html_content = session.get(path, headers=headers).text
            driver = webdriver.Chrome()
            driver.get(path)
            html_content = driver.page_source
        else:
            with open(path, 'r', encoding='utf-8') as file:
                html_content = file.read()

        soup = BeautifulSoup(html_content, 'html.parser')
        full_text = soup.get_text()

        repository.save(path, full_text)

        pipeline_item.text = full_text

        return pipeline_item
****************************************

****************************************
Waterfall\src\html_link_crawler.py
****************************************
'''PipelineStep to crawl a web page and generate sub-links '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
from urllib.parse import urljoin, urlparse
import requests
from bs4 import BeautifulSoup

from src.workflow import PipelineItem, PipelineStep


# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
    'Accept-Encoding': 'none',
    'Accept-Language': 'en-US,en;q=0.8',
    'Connection': 'keep-alive'
}


class HtmlLinkCrawler (PipelineStep):
    '''PipelineStep to crawl a web page and generate sub-links '''

    def __init__(self, output_location: str, max_depth: int = 10):
        '''Initialize the HtmlLinkCrawler with the specified output location and maximum depth.

        Parameters:
           output_location (str): The location where the output will be stored.
           max_depth (int): The maximum depth for crawling links, default is 10.
        '''
        super(HtmlLinkCrawler, self).__init__(
            output_location)  # pylint: disable=useless-parent-delegation
        self.max_depth = max_depth

    def crawl(self, pipeline_item: PipelineItem) -> list[PipelineItem]:

        # recurse using strings for URLs as logic is simpler
        links: list[str] = []
        self.crawl_links_recursively(
            pipeline_item.path, links, 0)

        # Then make a pipeline
        pipleline_items = []
        for link in links:
            item = PipelineItem()
            item.path = link
            pipleline_items.append(item)

        return pipleline_items

    def crawl_links_recursively(self, path: str, current_items: list[str], current_depth: int):
        '''
        Recursively crawl links on an HTML page to build a full tree for file search within the same site.

        Args:
           path (str): The URL path to crawl.
           pipeline_items (list[PipelineItem]): List of links crawled so far.
           current_depth (int): The current depth of recursion.

        Returns:
           None
        '''
        logger.debug('Crawling: %s', path)

        # Bail if the link is a mailto
        if path.find('mailto:') != -1:
            return

        # Bail if we hit maximum depth
        current_depth = current_depth + 1
        if current_depth > self.max_depth:
            logger.debug('Depth exceeded: %s', path)
            return

        session = requests.Session()
        if path.find('http') != -1:
            # Add headers in case the website expects cookies and/or JavaScript
            html_content = session.get(path, headers=headers).text
        else:
            with open(path, 'r', encoding='utf-8') as file:
                html_content = file.read()

        soup = BeautifulSoup(html_content, 'html.parser')

        # Add current link to the pipeline
        current_items.append(path)

        sub_links = soup.find_all('a')
        sub_urls = []
        for link in sub_links:
            href = link.get('href')
            if href is not None:
                url = str(href)
                parsed = urlparse(url, "", False)
                parsed_domain = parsed.netloc
                parsed_path = parsed.path
                joined = urljoin('https://' + parsed_domain, parsed_path)
                if not parsed_path.startswith('#') and not find_matching_entry(current_items, joined):
                    sub_urls.append(url)

        full = add_prefix(path, sub_urls)
        deduped = deduplicate(current_items, full)
        trimmed = remove_exits(path, deduped)

        # Recurse where we have not already crawled it
        for link in trimmed:
            if not find_matching_entry(current_items, link):
                self.crawl_links_recursively(
                    link, current_items, current_depth + 1)


def find_matching_entry(array: list[any], target: any):
    '''
   Find a matching entry in the given array.

   Parameters:
   - array (list): The list to search for a matching entry.
   - target (any): The target element to find in the array.

   Returns:
   - any: The matching entry if found, otherwise None.
   '''
    for entry in array:
        if entry == target:
            return entry
    return None


# remove duplicates
def deduplicate(current_links: list[PipelineItem], new_links: list[str]) -> list[str]:
    '''Remove duplicates from a list of new links by comparing them with the current links list.

    Args:
       currentLinks (list): List of current links.
       newLinks (list): List of new links to be checked for duplicates.

    Returns:
       list: A list of new links without any duplicates.
    '''
    deduped = []

    for item in new_links:
        if (find_matching_entry(current_links, item) is None) and find_matching_entry(deduped, item) is None:
            deduped.append(item)

    return deduped


# remove links that point outside the main site being searched
# We keep the argument bcs might need it for more sophisticate checking of URLs leaving the current page
# pylint: disable-next=unused-argument
def remove_exits(source_url: str, links: list[str]) -> list[str]:
    # we also remove links starting with #as they are just the same page
    '''Remove links that point outside the main site being searched.

    Args:
        source_url (str): The URL of the main site being searched.
        links (list): List of links to be filtered.

    Returns:
        list: Filtered list of links that do not point outside the main site.
    '''

    trimmed = []

    parsed_target = urlparse(source_url)
    target_domain = parsed_target.netloc
    target_path = parsed_target.path

    for item in links:
        # No fragments as we dont want a part within a page
        parsed_item = urlparse(item, "", False)
        item_domain = parsed_item.netloc
        item_path = parsed_item.path
        item_joined = urljoin('https://' + item_domain, item_path)
        if (item_domain == target_domain) and (item_domain == '' or item_path.startswith(target_path)):
            if (not (find_matching_entry(trimmed, item_joined))) and (len(item_path.split('#')) == 1):
                trimmed .append(item)

    return trimmed


def add_prefix(source_url: str, links: str) -> str:
    '''Add prefixes to relative URLs

    Args:
        sourceUrl (str): The base URL to resolve relative links from.
        links (list): List of relative URLs to be prefixed.

    Returns:
        list: List of fully qualified URLs after adding prefixes.
    '''
    full = []

    for item in links:
        new_url = make_fully_qualified_path(source_url, item)
        full.append(new_url)

    return full


def make_fully_qualified_path(base: str, rel: str) -> str:
    return urljoin(base, rel)
****************************************

****************************************
Waterfall\src\make_local_file_path.py
****************************************
'''Module to make a local file system path from an http: path '''
# Copyright (c) 2024 Braid Technologies Ltd

from urllib.parse import urlsplit


def make_local_file_path(url: str) -> str:
    '''
    Generates a fake file name based on the URL by replacing certain characters with underscores.
    '''
    split_url = urlsplit(url)
    # split_url.scheme   "http"
    # split_url.netloc   "127.0.0.1"
    # split_url.path     "/asdf/login.php"
    clean_path = str(split_url.netloc) + split_url.path + split_url.query

    fake_name = clean_path.replace("//", "_").replace("\\", "_").replace("/", "_").replace("=", "_").replace("&", "_").replace("%", "_")

    return fake_name[0:200]
****************************************

****************************************
Waterfall\src\ReadMe.Salon.md
****************************************
**boxer_pipeline.py**

This Python module is a driver for the Boxer data generation pipeline by Braid Technologies Ltd. It sets up logging for the script execution, to log warnings and above.

The primary class, `BoxerDataPipeline`, initializes with an output location and handles the data pipeline operations. Its main function, `search`, processes specified HTML and YouTube content links to generate enriched data chunks.

Key imported classes and functions used include `YouTubePipelineSpec`, `HtmlDirectedPipelineSpec`, `PipelineItem`, `PipelineFileSpec`, `YoutubePlaylistSearcher`, `YouTubeTranscriptDownloader`, `YouTubeTranscriptChunker`, `HtmlLinkCrawler`, `HtmlFileDownloader`, `Summariser`, `Embedder`, and `save_chunks`.

The `search` function organizes tasks like YouTube playlist searching, HTML link crawling, downloading, summarization, embedding, and saving the resultant chunks to JSON.

**boxer_sources.py**

This module provides a curated list of educational resources for AI/ML (Artificial Intelligence/Machine Learning) education and research. 

Key sections include YouTube playlists, which cover full courses and detailed explanations of core topics like machine learning, natural language processing (NLP), deep learning, and AI fundamentals.

Additionally, it lists informative articles, tutorials, and reference documentation from respected industry experts and leading educational institutions. These resources provide insights into advanced topics, tools, and techniques relevant to AI and ML development.

The intention of the module is to build and maintain a comprehensive knowledge base to help individuals stay updated with developments in the AI/ML field.

**chunker.py**

This code outlines a `Chunker` class, which inherits from `PipelineStep`. It is designed to break a text string into smaller, manageable pieces (chunks). The `chunk` method takes a `PipelineItem`, chunk size, and overlap size, and interacts with an external API to perform chunking.

`Chunker` initializes with an output location provided to its constructor. 

The `chunk` method sets up a session with retry logic for HTTP requests, constructs a request payload based on given chunk parameters, and sends it to an external API for processing. Successful responses return chunks encapsulated in `PipelineItem` objects, which the function then returns as a list.

### Important Classes or Functions
1. `Chunker` (Class)
2. `chunk` (Method)
3. `__init__` (Constructor)

**cluster_analyser.py**

The code defines a `ClusterAnalyser` class, which is a subclass of `PipelineStep` from the `src.workflow` module.

The `ClusterAnalyser` class initializes with an output location and the number of clusters for KMeans clustering. This initialization is handled by the `__init__` method.

The main method in this class is `analyse`, which takes a list of `PipelineItem` objects. It extracts the embeddings from these items and applies the KMeans clustering algorithm to assign cluster labels to each item.

The class uses the `KMeans` functionality from the `sklearn.cluster` module for clustering.

Logging is configured to capture warning-level messages and higher, using Python's standard logging library. 

Important classes and functions in the module include `ClusterAnalyser`, `__init__`, and `analyse`.

**db_repository.py**

The provided module allows interaction with the BraidApis Chunk table by converting `PipelineItem` data into a format compatible with the native Chunk API. It is designed for compatibility across multiple applications.

**Important Classes:**
- `DbRepository`: Contains methods for saving, retrieving, and checking the existence of records in the Braid Cosmos database.

**Important Functions:**
- `save(self, item: PipelineItem) -> bool`: Saves a `PipelineItem` to the Chunk repository after converting it into a compatible `IStoredChunk` structure.
- `find(self, path: str) -> PipelineItem`: Retrieves a `PipelineItem` from the database based on a given path.
- `exists(self, path: str) -> bool`: Checks whether a record with a specific functional key and context exists in the database.

**embedder.py**

The Python code defines a class `Embedder` which extends the `PipelineStep` class and is tasked with creating the embedding for a given text string. 

The `Embedder` class is initialized with an `output_location`, where embeddings will be saved or loaded from. 

The `embed` method generates embeddings for a `PipelineItem`. If an embedding already exists, it is loaded from the repository; otherwise, a new one is created using an external API and saved.

The `embed_text` method directly generates embeddings for provided text strings, using an external API. 

The `requests` library with a retry mechanism is used to handle HTTP requests, logging handles execution information.

**embedder_repository_facade.py**

This code provides a facade to store and manage embeddings in the local file system. 

**Key Classes and Functions:**

1. **read_file_names(path: str, file_spec: str):**
   - Retrieves a list of file names matching a specified pattern within a directory.

2. **EmbeddingRespositoryFacade:**
   - Provides an interface to load, save, and check the existence of files in the file system.

3. **EmbeddingRespositoryFacade.__init__(self, output_location: str):**
   - Initializes the class with a file repository instance, output location, and file extension pattern.

4. **EmbeddingRespositoryFacade.spec() -> str:**
   - Returns the file extension pattern used for storing files.

5. **EmbeddingRespositoryFacade.list_contents() -> list[str]:**
   - Lists the contents of the output location by retrieving file names and stripping double extensions.

6. **EmbeddingRespositoryFacade.save(self, path: str, embedding: list[float]) -> None:**
   - Saves provided text to a file at the specified path.

7. **EmbeddingRespositoryFacade.load(self, path: str) -> list[float]:**
   - Loads content from a file at the provided path and returns it as a list of floats.

8. **EmbeddingRespositoryFacade.exists(self, path: str) -> bool:**
   - Checks if the file exists in the output location.

9. **EmbeddingRespositoryFacade.text_to_float(self, embedding: str) -> list[float]:**
   - Converts a string of numbers to a list of floating-point numbers.

**embedding_finder.py**

**Important Classes/Functions:**

1. **cosine_similarity(a, b)**: A function that computes the cosine similarity between two vectors `a` and `b`.

2. **EmbeddingFinder**: A class designed to find the nearest embedding to a given target text based on cosine similarity.

3. **__init__(self, embeddings, output_location)**: The constructor initializes the EmbeddingFinder with a list of embeddings and an output location.

4. **find_nearest(self, target_text)**: This method uses the `Embedder` class to transform `target_text` into an embedding and then finds the embedding from the list with the highest cosine similarity to it.

**Summary:**

This module contains a function to calculate cosine similarity, and a class, `EmbeddingFinder`, which uses this function to find the most similar embedding to a target text. It relies on classes `Embedder` and `PipelineItem` from other modules to generate text embeddings. Logging is configured to show warnings and above.

**file_repository.py**

This module handles file operations in the local file system, including saving, loading, and checking the existence of files. It has been created by Braid Technologies Ltd in 2024.

Logging is set up using the `logging` library to warn about potential issues during execution.

The function `strip_quotes` removes single and double quotes from a given string.

The `FileRepository` class is central to this module, providing methods to save (`save`), load (`load`), and check the existence (`exists`) of specific files. The file paths are derived using the `make_local_file_path` function.

Important classes and functions:
1. `strip_quotes`
2. `FileRepository`
3. `FileRepository.save`
4. `FileRepository.load`
5. `FileRepository.exists`

**google_office_mailer.py**

This script allows sending emails via the Gmail API, with support for attachments, using OAuth2 credentials.

`send_mail()` handles OAuth2 authentication with Gmail, either loading credentials from `token.json` or prompting the user to log in, then calls `send_message_with_attachment()`.

`send_message_with_attachment()` constructs an email with optional attachments and sends it using the Gmail API. The method encodes the message in a format accepted by the API.

`build_file_part()` creates a MIME part for file attachments, managing proper MIME type determination and attachment headers.

Important classes or functions: `send_mail()`, `send_message_with_attachment()`, `build_file_part()`.

**html_file_downloader.py**

This module handles the downloading and processing of HTML content from web pages, encapsulated within a `PipelineStep` subclass named `HtmlFileDownloader`.

The `HtmlFileDownloader` class is initialized with an output location where downloaded files will be saved. It includes a `download` method that either retrieves the HTML content from an online source using Selenium's WebDriver for full JS rendering or reads it from a local file.

The `TextRespositoryFacade` class ensures proper loading and saving of text files. The HTML content is processed and converted to plain text using BeautifulSoup before being saved and appended to the provided `PipelineItem`. 

Logging is configured to track execution details.

**html_link_crawler.py**

**HtmlLinkCrawler class**: This is a custom pipeline step inheriting from `PipelineStep`. It initializes with an output location and a maximum depth for crawling, making it responsible for crawling web pages and generating sub-links.

**crawl method**: This method is the primary function for crawling. It starts by calling a recursive function to fetch sub-links and creates pipeline items for each link, returning a list of `PipelineItem` objects.

**crawl_links_recursively**: A recursive method that processes the HTML content of a page, extracts links, and traverses sub-pages up to a specified depth, filtering unwanted links (e.g., same-page fragments and external links).

**helper functions**: `find_matching_entry`, `deduplicate`, `remove_exits`, `add_prefix`, and `make_fully_qualified_path` are used for filtering duplicates, ensuring links stay within the same site, adding prefixes to relative URLs, and constructing absolute URLs.

**make_local_file_path.py**

This module converts an HTTP URL into a local file system path.

The `make_local_file_path` function takes a URL string as input.

It uses the `urlsplit` function from the `urllib.parse` module to break down the URL into components: scheme, network location (netloc), path, and query.

It then constructs a clean path by concatenating the netloc, path, and query.

Special characters (//, \\, /, =, &, %) in the clean path are replaced with underscores to generate a file-safe name.

The resulting file name is truncated to a maximum length of 200 characters.

**summariser.py**

The code imports necessary libraries like `logging`, `requests`, and custom modules for handling pipeline items and a summary repository. Logging is configured to display warnings.

The `Summariser` class inherits from `PipelineStep` and is designed to create summaries for text strings. The `__init__` method initializes the `Summariser` with an output location.

The `summarise` method in `Summariser` checks if a summary exists. If it does, it loads and returns the summary. If not, it uses an external API to generate a new summary, saves it, and returns the updated `PipelineItem`.

Classes: `Summariser`
Functions: `__init__`, `summarise`

**summarise_fail_suppressor.py**

This code defines a class `SummariseFailSuppressor` that inherits from `PipelineStep`. It is designed to process text summaries and suppress any invalid ones based on specified criteria.

The `__init__` function initializes the object with an output location.

The `should_suppress` function checks a `PipelineItem` for suppression by calling an external API. It creates a session with retry logic for robustness and posts the text to a specified URL. If the API response indicates the summary is valid, the item is not suppressed.

Important classes/functions:
1. `SummariseFailSuppressor`
2. `__init__`
3. `should_suppress`

**summary_repository_facade.py**

The `SummaryRespositoryFacade` class offers an interface to interact with the file system, specifically for loading, saving, and checking the existence of files.

This class uses the `FileRespository` class from the `src.file_repository` module to perform actual file operations. It initializes with an `output_location` and has a fixed file extension `summary.txt`.

Key methods include:
- `spec()`: Returns the file extension as a string.
- `save(path, text)`: Saves a text file to the specified path.
- `load(path)`: Loads the file content from the path.
- `exists(path)`: Checks if the file exists at the path.

The class helps manage file operations uniformly across the application.

**text_repository_facade.py**

**Important Classes:**
1. `TextRespositoryFacade`

**Important Functions:**
1. `__init__(self, output_location: str)`
2. `spec() -> str`
3. `save(self, path: str, text: str) -> None`
4. `load(self, path: str) -> str`
5. `exists(self, path: str) -> bool`

`TextRespositoryFacade` provides a simplified interface to interact with the file system. It can save text to a specified path using the `save` method, load text from a specified path using the `load` method, and check if a file exists at a specified path using the `exists` method. This is done via a class from `src.file_repository` called `FileRespository`, which handles the actual file operations. The class also defines a standard file extension ("txt") and a static method `spec` to determine the file type specification.

**theme_finder.py**

The code defines a `ThemeFinder` class to generate a theme for input text paragraphs by querying an external API. 

Logging is configured to capture warnings and errors with a specific format.

The `SESSION_KEY` required for making API requests is fetched from the environment variables.

Essential HTTP headers, such as 'User-Agent', 'Content-Type', and 'Accept', are defined for the requests.

The `ThemeFinder` class contains an initialization method and a `find_theme` method. The `find_theme` method sets up a session with retry policies, sends a POST request with text and length to an external API, and returns the theme if the request is successful or logs an error message otherwise. 

Key components include `find_theme` and `ThemeFinder`.

**waterfall_pipeline.py**

This code serves as the driver for a data processing pipeline. Key classes and functions include `WaterfallDataPipeline`, `sort_array_by_another`, `make_path`, and `load_file`.

`WaterfallDataPipeline` is the main class orchestrating the data search, processing, and clustering workflow. It utilizes various other classes like `WebSearcher`, `HtmlFileDownloader`, `Summariser`, `SummariseFailSuppressor`, `Embedder`, `ClusterAnalyser`, `ThemeFinder`, and `EmbeddingFinder` to handle each part of the process.

It features methods such as `search_dynamic`, `search_static`, `search_and_cluster`, `cluster_from_files`, `cluster`, `create_themes`, and `create_report` to complete each step from data retrieval to report generation. The module also includes utility functions like `sort_array_by_another`, `make_path`, and `load_file` for sorting, path handling, and file reading, respectively.

**waterfall_pipeline_report.py**

This code generates and sends a final Waterfall report via email.

The `create_mail_report` function prepares an email summary report based on a list of `PipelineItem` objects, `Theme` objects, and a `WebSearchPipelineSpec` object. It organizes and formats the data into an HTML email.

The logging module is used to set up warning-level logging for debugging purposes.

The `send_mail` function from the `src.google_office_mailer` module sends the final formatted report email.

Key functions:
- `create_mail_report`
- `send_mail`

Key classes:
- `PipelineItem`
- `Theme`
- `WebSearchPipelineSpec`

**waterfall_pipeline_report_common.py**

This script generates and sends a final Waterfall report by mail.

- The `write_chart` function generates a scatter plot based on the embeddings of `PipelineItem` objects. It clusters the items using UMAP, adds theme names as legend entries, and saves an interactive HTML version of the chart to a specified directory. The function returns the file path of the saved chart.
  
- The `write_details_json` function writes detailed information about `PipelineItem` objects to a JSON file. Each item’s summary, embedding, path, and related theme are included. This data is saved to a specified directory.

Important classes or functions:
- `write_chart`
- `write_details_json`
- `PipelineItem`
- `Theme`
- `WebSearchPipelineSpec`

**waterfall_pipeline_save_chunks.py**

- **Logging Setup**: Configures logging for the script to record events at the ERROR level and sets up a logger.

- **set_timestamps Function**: Updates created and amended timestamps for an `IStoredChunk` object.

- **create_theme_chunk Function**: Creates a chunk from a theme's attributes, sets timestamps, generates embeddings, and assigns various properties.

- **save_chunks Function**: Saves a list of `PipelineItem` objects as chunks in the database. Each chunk includes fields like ID, path, summary, text, and embedding.

- **save_chunk_tree Function**: Saves chunks in a hierarchical structure based on `PipelineItem`, `Theme`, and `PipelineSpec` objects. It involves writing a chart, managing themes (both master and sub-themes), and saving related chunks and summary texts.

**Important Classes/Functions:**
- `set_timestamps`
- `create_theme_chunk`
- `save_chunks`
- `save_chunk_tree`
- `Embedder`
- `DbRepository`
- `ChunkRepository`
- `PipelineItem`
- `Theme`
- `WebSearchPipelineSpec`
- `PipelineFileSpec`

**waterfall_survey_pipeline.py**

The script is a driver for a web content pipeline that involves searching, downloading, summarizing, and analyzing HTML content.

**Important classes and functions:**
- `WaterfallDataPipeline`
- `search_and_cluster`
- `create_themes`
- `create_report`
- `sort_array_by_another`

The `WaterfallDataPipeline` class coordinates the workflow, encapsulating the processes of searching for web content, summarizing, and clustering them into themes.

The `search_and_cluster` method uses various components (like `WebSearcher`, `HtmlFileDownloader`, `ClusterAnalyser`) to process the web content iteratively, including downloading, summarizing, suppressing failure summaries, embedding, and clustering the results.

The `create_themes` method aggregates the clustered items, summarizes them, and uses `ThemeFinder` to create short and long descriptions of themes. Subsequently, it enriches these themes with relevant examples using the `EmbeddingFinder`.

The `create_report` function finalizes the pipeline by generating reports and saving details.

`sort_array_by_another` is a utility for ordering themes based on their importance.

**web_searcher.py**

This script is the first step in a Waterfall pipeline that involves searching the web and generating a list of `PipelineItem`. It imports necessary libraries such as `logging` and `requests`, and sets up logging to warn levels.

It retrieves the Google Developer API key from environment variables and contains various pre-defined search engine IDs used for specific searches.

The `WebSearcher` class is defined, with an initialization method setting the output location. The `search` method of this class employs the Google Custom Search Engine API to perform web searches using a specified query, extracting URLs from the search results, and then creating and returning a list of `PipelineItem` objects containing these URLs. 

Key classes/functions:
- `WebSearcher` class
- `WebSearcher.__init__`
- `WebSearcher.search`

**workflow.py**

**Freezable Class**

A generic class allowing instances to become immutable after being set up, using `_is_frozen` attribute and `_freeze` method.

**PipelineItem Class**

Inherits `Freezable`. Represents a work item for a processing pipeline with attributes like `path`, `text`, and `summary`. Overloads comparison operators, making instances comparable based on `path` and `summary`.

**Theme Class**

Inherits `Freezable`. Represents a documented cluster of pipeline items with attributes such as `short_description` and `long_description`. Overloads comparison operators, similar to `PipelineItem`.

**PipelineStep Class**

Represents a step in a pipeline, initialized with an `output_location`.

**PipelineSpec Class**

Inherits `Freezable`. Defines specifications for a workflow run, including attributes like `clusters` and `output_chart_name`.

**WebSearchPipelineSpec Class**

Inherits `PipelineSpec`. Adds web-specific attributes such as `pages` and `search_key`, freezing the instance post-initialization.

**YouTubePipelineSpec Class**

Inherits `Freezable`. Specifies configurations for downloading video playlists, with attributes like `playlists` and `max_words`, freezing the instance post-initialization.

**HtmlDirectedPipelineSpec Class**

Inherits `Freezable`. Specifies configurations for downloading web pages, using a list of URLs, and freezes the instance post-initialization.

**FileDirectedPipelineSpec Class**

Inherits `Freezable`. Specifies configurations for handling files, using a list of file paths, and freezes the instance post-initialization.

**PipelineFileSpec Class**

Inherits `Freezable`. Defines the specifications for a full workflow run, including `output_data_name` and `description`, freezing the instance post-initialization.

**youtube_searcher.py**

The code is for generating a list of `PipelineItem` objects from a YouTube playlist as the first step in a Waterfall pipeline.

Important classes and functions include:
- `parseVideoDurationMins`: This function parses the video's duration from ISO 8601 format into minutes.
- `YoutubePlaylistSearcher`: This class processes sets of YouTube playlists to create a list of `PipelineItem` objects representing the videos. The constructor initializes the class with an output location. The `search` method fetches videos from specified playlists using the YouTube Data API, creates request objects, retrieves video details, and appends them as `PipelineItem` objects into a list.

**youtube_transcript_chunker.py**

This code is designed to divide a transcript of a YouTube video into chunks for further processing. Important classes and functions include:

- **`make_start_time_offset`**: This function takes an integer (minutes) and converts it into a time offset string formatted for YouTube URLs.
  
- **`YouTubeTranscriptChunker`**: A class that extends `PipelineStep` to handle the utility of chunking transcripts. 

- **`__init__`**: Initializes the `YouTubeTranscriptChunker` object with an output location and a `Chunker` object.

- **`chunk`**: This method divides the transcript into chunks of specified word size and overlap, returning a list of new `PipelineItem` objects with updated URLs incorporating time offsets. The process includes handling cases with no chunks or a single chunk, and ensuring fair time distribution across chunks assuming evenly spread text.

Logging is set up to track execution details and is configured to show warnings and above.

**youtube_transcript_downloader.py**

The code facilitates downloading transcripts from YouTube videos in a playlist.

The main class is `YouTubeTranscriptDownloader`, a subclass of the `PipelineStep`. It initializes with an `output_location` for saving transcripts. Its primary method is `download`, which fetches the transcript for a given video, processes it by cleaning, and saves the result using `TextRespositoryFacade`.

The `clean_text` function adjusts specific textual artifacts such as newlines and special characters to improve text quality.

The `parse_video_id` function extracts the video ID from various YouTube URL formats.

The `logging` module is used for recording errors and information. 

The script handles exceptions like no transcript available, transcripts disabled, or video unavailable gracefully.
****************************************

****************************************
Waterfall\src\summariser.py
****************************************
'''PipelineStep to create a summary for a text string'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json
import requests
from requests.adapters import HTTPAdapter, Retry


from src.workflow import PipelineItem, PipelineStep
from src.summary_repository_facade import SummaryRespositoryFacade
from CommonPy.src.request_utilities import request_timeout

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)

SESSION_KEY = os.environ['SessionKey']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}


class Summariser (PipelineStep):
    '''PipelineStep to create a summary for a text string'''

    # pylint: disable-next=useless-parent-delegation
    def __init__(self, output_location: str):
        '''
        Initializes the Summariser object with the provided output location.
        '''
        # pylint: disable-next=useless-parent-delegation
        super(Summariser, self).__init__(output_location)

    def summarise(self, pipeline_item: PipelineItem) -> PipelineItem:
        '''
        Summarises the text content by either loading an existing summary from the specified path or generating a new summary using an external API. 
        If an existing summary is found, it is returned; otherwise, a new summary is generated and saved at the specified path. 
        Returns the generated or loaded summary as an enriched PipelineItem.
        '''
        path = pipeline_item.path
        repository = SummaryRespositoryFacade(self.output_location)

        if repository.exists(path):
            summary = repository.load(path)
            pipeline_item.summary = summary
            return pipeline_item

        logger.debug('Summarising: %s', path)

        session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[500, 502, 503, 504])
        session.mount('https://', HTTPAdapter(max_retries=retries))

        print("Summarising: " + pipeline_item.path)

        #summary_url = f'http://localhost:7071/api/Summarize?session={
        summary_url = f'https://braid-api.azurewebsites.net/api/Summarize?session={
            SESSION_KEY}'
        input_json = {
            'request': {
                'persona': "SurveySummariser",
                'text': pipeline_item.text,
                'lengthInWords': 50
            }
        }

        response = session.post(summary_url, json=input_json, 
                                headers=headers,
                                timeout=request_timeout)

        if response.status_code == 200:
            response_json = json.loads(response.text)
            summary = response_json['summary']

            repository.save(path, summary)
            pipeline_item.summary = summary

            return pipeline_item
        else:
            logger.error("Unable to summarise item: %s", pipeline_item.path)
            return None
****************************************

****************************************
Waterfall\src\summarise_fail_suppressor.py
****************************************
'''PipelineStep to create a summary for a text string'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json
import requests
from requests.adapters import HTTPAdapter, Retry

from src.workflow import PipelineItem, PipelineStep
from CommonPy.src.request_utilities import request_timeout

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)

SESSION_KEY = os.environ['SessionKey']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}


class SummariseFailSuppressor (PipelineStep):
    '''PipelineStep to create a summary for a text string'''

    # pylint: disable-next=useless-parent-delegation
    def __init__(self, output_location: str):
        '''
        Initializes the SummariseFailSuppressor object with the provided output location.
        '''
        super(SummariseFailSuppressor, self).__init__(output_location)

    def should_suppress(self, pipeline_item: PipelineItem) -> PipelineItem:
        '''
        Checks if the given PipelineItem should be suppressed based on evaluation criteria.

        Args:
          pipeline_item (PipelineItem): The PipelineItem to evaluate for suppression.

        Returns:
          PipelineItem: The PipelineItem if suppression is not needed, otherwise None.
        '''

        logger.debug('Evaluation for suppression: %s', pipeline_item.path)

        session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[500, 502, 503, 504])
        session.mount('https://', HTTPAdapter(max_retries=retries))

        summary_url = f'https://braid-api.azurewebsites.net/api/TestForSummariseFail?session={
            SESSION_KEY}'
        input_json = {
            'request': {
                'text': pipeline_item.summary
            }
        }

        response = session.post(summary_url, json=input_json, 
                                headers=headers,
                                timeout=request_timeout)

        keep: bool = True  # If there is an error in the API, we default to 'keep'
        if response.status_code == 200:
            response_json = json.loads(response.text)
            keep = response_json['isValidSummary'] == 'SummarySucceeded'

        if keep:
            return pipeline_item
****************************************

****************************************
Waterfall\src\summary_repository_facade.py
****************************************
'''Facade to store summaries in local file system'''
# Copyright (c) 2024 Braid Technologies Ltd

from src.file_repository import FileRespository


class SummaryRespositoryFacade:
    '''
    Class providing an interface to load, save, and existence check for files in the file system.
    '''

    def __init__(self, output_location: str):
        self.file__repository = FileRespository(output_location)
        self.output_location = output_location
        self.extension = "summary.txt"

    @staticmethod
    def spec() -> str:
        return "*.summary.txt"

    def save(self, path: str, text: str) -> None:
        '''
        Save the provided text to a file at the specified path within the output location.

        Parameters:
           path (str): The path where the file will be saved.
           text (str): The text content to be saved in the file.
        '''

        return self.file__repository.save(path, self.extension, text)

    def load(self, path: str) -> str:
        '''
        Load content from a file based on the provided path. 
        If the file exists in the output location, its contents are read and returned as a string. 
        If the file does not exist, an empty string is returned.

        Parameters:
           path (str): The path of the file.

        Returns:
           str: The contents of the file if it exists, otherwise an empty string.
        '''

        return self.file__repository.load(path, self.extension)

    def exists(self, path: str) -> bool:
        '''
        Checks if a file with the specified path exists in the output location.

        Parameters:
           path (str): The path of the file.

        Returns:
           bool: True if the file exists, False otherwise.
        '''
        return self.file__repository.exists(path, self.extension)
****************************************

****************************************
Waterfall\src\text_repository_facade.py
****************************************
'''Facade to store text in local file system'''
# Copyright (c) 2024 Braid Technologies Ltd

from src.file_repository import FileRespository


class TextRespositoryFacade:
    '''
    Class providing an interface to load, save, and existence check for files in the file system.
    '''

    def __init__(self, output_location: str):
        self.file__repository = FileRespository(output_location)
        self.output_location = output_location
        self.extension = "txt"

    @staticmethod
    def spec() -> str:
        return "*.txt"

    def save(self, path: str, text: str) -> None:
        '''
        Save the provided text to a file at the specified path within the output location.

        Parameters:
           path (str): The path where the file will be saved.
           text (str): The text content to be saved in the file.
        '''

        return self.file__repository.save(path, self.extension, text)

    def load(self, path: str) -> str:
        '''
        Load content from a file based on the provided path. 
        If the file exists in the output location, its contents are read and returned as a string. 
        If the file does not exist, an empty string is returned.

        Parameters:
           path (str): The path of the file.

        Returns:
           str: The contents of the file if it exists, otherwise an empty string.
        '''

        return self.file__repository.load(path, self.extension)

    def exists(self, path: str) -> bool:
        '''
        Checks if a file with the specified path exists in the output location.

        Parameters:
           path (str): The path of the file.

        Returns:
           bool: True if the file exists, False otherwise.
        '''
        return self.file__repository.exists(path, self.extension)
****************************************

****************************************
Waterfall\src\theme_finder.py
****************************************
'''Class to create a theme for a number of input paragraphs of text'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json
import requests
from requests.adapters import HTTPAdapter, Retry

from CommonPy.src.request_utilities import request_timeout

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)

SESSION_KEY = os.environ['SessionKey']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}


class ThemeFinder:
    '''Class to create a theme for a number of input paragraphs of text'''

    def __init__(self):
        return

    def find_theme(self, text: str, length: int) -> str:
        """
        Finds a theme for the given text by sending a request to an external API.

        Args:
        text (str): The input text for which the theme needs to be found.
        length (int): The desired length of the theme.

        Returns:
        str: The theme extracted from the text if the request is successful.
        None: If the request fails or an error occurs.

        Logs an error message if unable to find a theme.
        """
        session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[502, 503, 504])
        session.mount('https://', HTTPAdapter(max_retries=retries))

        summary_url = f'https://braid-api.azurewebsites.net/api/FindTheme?session={
            SESSION_KEY}'
        input_json = {
            'request': {
                'text': text,
                'length': length
            }
        }

        response = session.post(summary_url, json=input_json, 
                                headers=headers,
                                timeout=request_timeout)
        
        if response.status_code == 200:
            response_json = json.loads(response.text)
            theme = response_json['theme']

            return theme
        else:
            logger.error("Unable to find theme for: %s", text)
            return None
****************************************

****************************************
Waterfall\src\waterfall_pipeline.py
****************************************
'''driver for the entire pipeline '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os

from src.workflow import PipelineItem, Theme, WebSearchPipelineSpec, FileDirectedPipelineSpec, PipelineSpec
from src.web_searcher import WebSearcher
from src.html_file_downloader import HtmlFileDownloader
from src.summariser import Summariser
from src.summarise_fail_suppressor import SummariseFailSuppressor
from src.embedder import Embedder
from src.cluster_analyser import ClusterAnalyser
from src.theme_finder import ThemeFinder
from src.embedding_finder import EmbeddingFinder
from src.waterfall_pipeline_report_common import write_details_json
from src.waterfall_pipeline_save_chunks import save_chunk_tree
from src.text_repository_facade import TextRespositoryFacade

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


def sort_array_by_another(arr1: list[Theme], arr2: list[int]) -> list[Theme]:
    '''
   orders list 1 using list 2 to drive the sort order

    Returns:
       list[Theme]: Ordered list of Themes.
    '''

    # Combine the two arrays into a list of tuples
    combined = list(zip(arr2, arr1))

    # Sort the combined list by the first element of each tuple (values in arr2)
    combined.sort(reverse=True)

    # Extract the sorted arr1 from the combined list
    sorted_arr1: list[Theme] = [x for _, x in combined]

    return sorted_arr1


def make_path(directory: str, filename: str) -> str:
    '''
    Concatenates a directory path and filename to create a full path.
    Handles path separators appropriately for the current operating system.

    Parameters:
        directory (str): The directory path
        filename (str): The filename to append

    Returns:
        str: The complete file path
    '''
    return os.path.join(directory, filename)


def load_file(filename: str) -> str:
    '''
    Loads the contents of a text file.

     Parameters:
         filename (str): Path to the file to load

     Returns:
         str: Contents of the file

     Raises:
         FileNotFoundError: If the file doesn't exist
         IOError: If there's an error reading the file
     '''
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            return file.read()
    except FileNotFoundError:
        logger.error(f"File not found: {filename}")
        raise
    except IOError as e:
        logger.error(f"Error reading file {filename}: {str(e)}")
        raise


class WaterfallDataPipeline:
    '''
    Searches for HTML content from a list of links.

    Returns:
       list[str]: A list of HTML content downloaded from the specified links.
    '''

    def __init__(self, output_location: str):
        self.output_location = output_location
        return

    def search_dynamic(self, spec: WebSearchPipelineSpec) -> list[Theme]:
        '''
        Searches for HTML content from a list of links.

        Returns:
            list[Theme]: A list of Theme objects 
        '''

        items: list[WebSearchPipelineSpec] = self.search_and_cluster(spec)

        themes: list[Theme] = self.create_themes(items, spec.clusters)

        self.create_report(items, themes, spec)

        return themes

    def search_static(self, spec: PipelineSpec, file_spec: FileDirectedPipelineSpec) -> list[Theme]:
        '''
        Searches for HTML content from a list of links.

        Returns:
            list[Theme]: A list of Theme objects 
        '''

        items: list[WebSearchPipelineSpec] = self.cluster_from_files(
            file_spec.files, spec.clusters)

        themes: list[Theme] = self.create_themes(items, spec.clusters)

        self.create_report(items, themes, spec)

        return themes

    def search_and_cluster(self, spec: WebSearchPipelineSpec) -> list[PipelineItem]:
        '''
        Create themes based on the provided PipelineSpec.

        Parameters:
           spec (WebSearchPipelineSpec): The WebSearchPipelineSpec object containing specifications for 
           theme creation.

        Returns:
           list[Theme]: A list of Theme objects created based on the provided PipelineItems 
           and PipelineSpec.
        '''
        searcher = WebSearcher(self.output_location)

        input_items = searcher.search(spec)

        return self.cluster(input_items, spec.clusters)

    def cluster_from_files(self, items: list[str], clusters: int) -> list[PipelineItem]:
        '''
        Create themes based on the provided PipelineItems and PipelineSpec.

        Parameters:
           items (list[str]): A list of files to create themes from.
           clusters (int): The number of clusters to create.

        Returns:
           list[Theme]: A list of Theme objects created based on the provided PipelineItems 
           and PipelineSpec.
        '''
        pipeline_items: list[PipelineItem] = []

        repository = TextRespositoryFacade(self.output_location)

        for file in items:
            file_path = make_path(self.output_location, file) + "." + repository.extension
            file_contents = load_file(file_path)
            pipeline_item: PipelineItem = PipelineItem()
            pipeline_item.path = file
            pipeline_item.text = file_contents
            pipeline_items.append(pipeline_item)

        return self.cluster(pipeline_items, clusters)

    def cluster(self, input_items: list[PipelineItem], clusters: int) -> list[PipelineItem]:
        '''
        Create themes based on the provided PipelineItems.

        Parameters:
           input_items (list[PipelineItem]): A list of PipelineItem objects to create themes from.
           clusters (int): The number of clusters to create.

        Returns:
           list[Theme]: A list of Theme objects created based on the provided PipelineItems 
           and PipelineSpec.
        '''

        downloader = HtmlFileDownloader(self.output_location)
        summariser = Summariser(self.output_location)
        suppressor = SummariseFailSuppressor(self.output_location)
        embedder = Embedder(self.output_location)
        cluster_analyser = ClusterAnalyser(self.output_location, clusters)

        items: list[PipelineItem] = []

        for item in input_items:
            downloaded = None
            suppression_checked = None
            summarised = None
            embedded = None

            downloaded = downloader.download(item)
            if downloaded:
                summarised = summariser.summarise(downloaded)
            if summarised:
                suppression_checked = suppressor.should_suppress(summarised)
            if suppression_checked:
                embedded = embedder.embed(suppression_checked)
            if embedded:
                items.append(embedded)

        clustered_items = cluster_analyser.analyse(items)

        return clustered_items

    def create_themes(self, items: list[PipelineItem], clusters: int) -> list[Theme]:
        '''
        Create themes based on the provided PipelineItems and PipelineSpec.

        Parameters:
           items (list[PipelineItem]): A list of PipelineItem objects to create themes from.
           spec (PipelineSpec): The PipelineSpec object containing specifications 
                for theme creation.

        Returns:
           list[Theme]: A list of Theme objects created based on the provided 
              PipelineItems and PipelineSpec.
        '''
        themes: list[Theme] = []

        accumulated_summaries: list[str] = [''] * clusters
        accumulated_counts: list[int] = [0] * clusters
        accumulated_members: list[list[PipelineItem]] = [None] * clusters
        for x in range(clusters):
            accumulated_members[x] = []

        # Accumulate a set of summaries and counts of summaries according to classification
        for i, item in enumerate(items):
            cluster = items[i].cluster
            accumulated_summaries[cluster] = accumulated_summaries[cluster] + \
                item.summary + "\n "
            accumulated_counts[cluster] = accumulated_counts[cluster] + 1
            accumulated_members[cluster].append(item)

        # Ask the theme finder to find a theme, then store it
        for i, accumulated_summary in enumerate(accumulated_summaries):
            theme_finder = ThemeFinder()
            short_description = theme_finder.find_theme(
                accumulated_summary, 15)
            long_description = theme_finder.find_theme(accumulated_summary, 50)
            theme = Theme()
            theme.member_pipeline_items = accumulated_members[i]
            theme.short_description = short_description
            theme.long_description = long_description + "\n\n" + "There are " + \
                str(accumulated_counts[i]) + " members in this cluster."
            themes.append(theme)

        # Ask the embedding finder to find nearest article for each theme
        enriched_themes = []
        for i, theme in enumerate(themes):
            logger.debug('Finding nearest embedding')

            # Accumulate the embeddings that are part of the cluster
            embeddings_for_theme = []
            for item in items:
                if item.cluster == i:
                    embeddings_for_theme.append(item.embedding)

            # Build embedding finder with the right embeddings,
            # then find the nearest one to the theme that is in the cluster
            embedding_finder = EmbeddingFinder(
                embeddings_for_theme, self.output_location)
            nearest_items: list[PipelineItem] = []
            nearest_embedding = embedding_finder.find_nearest(
                theme.long_description)

            # Store nearest item
            for item in items:
                if item.embedding == nearest_embedding:
                    nearest_items.append(item)
                    theme.example_pipeline_items = nearest_items
                    enriched_themes.append(theme)
                    break

        logger.debug('Ordering themes')
        ordered_themes = sort_array_by_another(
            enriched_themes, accumulated_counts)

        return ordered_themes

    def create_report(self, items: list[PipelineItem],
                      themes: list[Theme],
                      spec: PipelineSpec) -> None:
        '''
        Generates a report based on the provided PipelineItems, Themes, and PipelineSpec. 

        Parameters:
        - items (list[PipelineItem]): A list of PipelineItem objects to generate the report from.
        - themes (list[Theme]): A list of Theme objects associated with the PipelineItems.
        - spec (PipelineSpec): The PipelineSpec object containing specifications for the report.
        - send_final - set to false to suppress ending the report - used in testing
        '''
        write_details_json(self.output_location, items, themes, spec)
        save_chunk_tree(self.output_location, items, themes, spec)

    def load_file(self, filename: str) -> str:
        '''
        Loads the contents of a text file.

        Parameters:
            filename (str): Path to the file to load

        Returns:
            str: Contents of the file

        Raises:
            FileNotFoundError: If the file doesn't exist
            IOError: If there's an error reading the file
        '''
        try:
            with open(filename, 'r', encoding='utf-8') as file:
                return file.read()
        except FileNotFoundError:
            logger.error(f"File not found: {filename}")
            raise
        except IOError as e:
            logger.error(f"Error reading file {filename}: {str(e)}")
            raise
****************************************

****************************************
Waterfall\src\waterfall_pipeline_report.py
****************************************
''' Send a final Waterfall report by mail '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
from src.workflow import PipelineItem, Theme, WebSearchPipelineSpec
from src.waterfall_pipeline_report_common import write_chart
from src.google_office_mailer import send_mail

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


def create_mail_report(output_location: str, items: list[PipelineItem], themes: list[Theme], spec: WebSearchPipelineSpec, send_final: bool) -> None:
    '''
    Generates a report based on the provided PipelineItems, Themes, and PipelineSpec.

        Parameters:
        - output_location - directory to store file output
        - items (list[PipelineItem]): A list of PipelineItem objects to generate the report from.
        - themes (list[Theme]): A list of Theme objects associated with the PipelineItems.
        - spec (PipelineSpec): The PipelineSpec object containing specifications for the report.
        - send_final - set to false to suppress ending the report - used in testing
    '''


    logger.debug('Writing summary')
    size = min(len(themes), spec.clusters_in_summary)
    top_themes = themes[:size]
    summary = '<p>Dear Braid Leadership,</p><p>This is an automated mail, please do not reply to this address.</p><p>Please find below the result of the ' + \
        spec.description + \
        ' cluster analysis (' + str(len(items)) + ' samples).</p>'
    summary = summary + '<p>The top ' + \
        str(len(top_themes)) + ' clusters are:</p>'
    for i, theme in enumerate(top_themes):
        summary = summary + '<p>' + \
            str(int(i+1)) + '.' + theme.short_description + '</p>'
        summary = summary + '<p>The closest example of this theme is: ' + \
            theme.example_pipeline_items[0].summary + ', ' + \
            theme.example_pipeline_items[0].path + '</p>'
        summary = summary + '<p>This cluster has ' + \
            str(len(theme.member_pipeline_items)) + ' members.</p>'

    summary = summary + '<p>This message is for the designated recipient only and may contain privileged, proprietary, or otherwise confidential information.' + \
        'If you have received it in error, please notify the sender immediately and delete the original. Any other use of the e-mail by you is prohibited.' + \
        'Where allowed by local law, electronic communications with Braid Technologies Ltd (Braid), including e-mail and instant messaging (including content),' + \
        'may be scanned for the purposes of information security, and assessment of internal compliance with Braid policy.</p>' + \
        '<p>Your privacy is important to us. Braid uses your personal data only in compliance with data protection laws.' + \
        'For further information on how Braid processes your personal data, please see our privacy statement at https://braidtech.ai/privacy</p>'

    encoded_summery = summary.encode('utf-8', errors='ignore')
    if send_final:
        send_mail(output_location, encoded_summery,
                  spec.output_chart_name, spec)

    # output_file = os.path.join(self.output_location, 'summary.txt')
    # with open(output_file, 'w+', encoding='utf-8') as f:
        # f.write(summary)

    return
****************************************

****************************************
Waterfall\src\waterfall_pipeline_report_common.py
****************************************
''' Send a final Waterfall report by mail '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json
import plotly
import plotly.express as px
import umap.umap_ as umap__

from src.workflow import PipelineItem, Theme, WebSearchPipelineSpec

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


def write_chart(output_location: str,
                items: list[PipelineItem],
                themes: list[Theme],
                spec: WebSearchPipelineSpec) -> str:
    '''
    Generates a report based on the provided PipelineItems, Themes, and PipelineSpec.

        Parameters:
        - output_location - directory to store file output
        - items (list[PipelineItem]): A list of PipelineItem objects to generate the report from.
        - themes (list[Theme]): A list of Theme objects associated with the PipelineItems.
        - spec (WebSearchPipelineSpec): The PipelineSpec object containing specifications for the report.

        Returns:
        - path to the created file
    '''

    reducer = umap__.UMAP()
    logger.debug('Reducing cluster')
    embeddings_as_float = []

    for item in items:
        embeddings_as_float.append(item.embedding)
    embeddings_2d = reducer.fit_transform(embeddings_as_float)

    logger.debug('Generating chart')

    # Make a list of theme names which gets used as the legend in the chart
    theme_names: list[str] = []
    for item in items:
        theme_name = themes[item.cluster].short_description
        theme_names.append(theme_name)

    fig = px.scatter(
        x=embeddings_2d[:, 0], y=embeddings_2d[:, 1], color=theme_names)

    # save an interactive HTML version
    html_path = os.path.join(output_location, spec.output_chart_name)
    plotly.offline.plot(fig, filename=html_path)

    return html_path


def write_details_json(output_location: str,
                       items: list[PipelineItem],
                       themes: list[Theme],
                       spec: WebSearchPipelineSpec) -> None:
    '''
    write the detailed items to a JSON file in case manual inspection is needed
    '''

    logger.debug('Writing output file')

    output_results = []
    for item in items:
        output_item = dict()
        output_item['summary'] = item.summary
        output_item['embedding'] = item.embedding
        output_item['path'] = item.path
        output_item['theme'] = themes[item.cluster].short_description
        output_results.append(output_item)

    # save the test results to a json file
    output_file = os.path.join(output_location, spec.output_data_name)
    with open(output_file, 'w+', encoding='utf-8') as f:
        json.dump(output_results, f)
****************************************

****************************************
Waterfall\src\waterfall_pipeline_save_chunks.py
****************************************
''' Send a final Waterfall report to the DB as Chunks '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import uuid
import datetime

from CommonPy.src.chunk_repository_api import (ChunkRepository,
                                               chunk_class_name,
                                               chunk_schema_version,
                                               waterfall_application_name,
                                               boxer_application_name)
from CommonPy.src.chunk_repository_api_types import (IStoredChunk, create_text_rendering, create_embedding)

from CommonPy.src.page_repository_api import (PageRepository,
                                              page_class_name,
                                              page_schema_version,
                                              make_page_from_file)
from CommonPy.src.page_repository_api_types import (IStoredPage)

from src.workflow import PipelineItem, Theme, WebSearchPipelineSpec, PipelineFileSpec
from src.waterfall_pipeline_report_common import write_chart
from src.db_repository import DbRepository
from src.embedder import Embedder


# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.ERROR,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.ERROR)

def set_timestamps (chunk: IStoredChunk, existing: bool) -> None:
    ''' Set timestamps on Chunk depending it it is new or amended '''
    utc_time = datetime.datetime.now(datetime.timezone.utc)
    utc_time_string = utc_time.strftime('%Y-%m-%d %H:%M:%S %Z')
    if existing:
        chunk.amended = utc_time_string
    else:
        chunk.created = utc_time_string
        chunk.amended = utc_time_string

def create_theme_chunk (short_description: str,
                        context: str,
                        long_description : str,
                        output_location: str,
                        chunk_repository: ChunkRepository) -> IStoredChunk:
    ''' Utility function to create a chunk from Theme attributes '''
    existing_theme = chunk_repository.find (short_description)
    if existing_theme:
        theme_to_save = existing_theme
    else:
        theme_to_save = IStoredChunk()

    embedder = Embedder(output_location)

    set_timestamps (theme_to_save, existing_theme is not None)

    embedding = embedder.embed_text (long_description)

    theme_to_save.storedSummary = create_text_rendering (long_description,
                                                         chunk_repository.default_model)
    theme_to_save.storedTitle = create_text_rendering (short_description,
                                                       chunk_repository.default_model)
    theme_to_save.storedEmbedding = create_embedding (embedding,
                                                      chunk_repository.default_embedding_model)

    theme_to_save.applicationId = waterfall_application_name
    theme_to_save.contextId = context
    theme_to_save.className = chunk_class_name
    theme_to_save.schemaVersion = chunk_schema_version
    theme_to_save.functionalSearchKey = short_description

    theme_to_save.userId = None
    theme_to_save.originalText = long_description
    theme_to_save.relatedChunks = None

    return theme_to_save

def save_chunks (items: list[PipelineItem],
                 spec: PipelineFileSpec) -> None:
    """
    Save a list of PipelineItem objects as chunks in the database.

    Parameters:
        items (list[PipelineItem]): A list of PipelineItem objects to be saved.
        spec (PipelineFileSpec): The specification for the pipeline file.

    Returns:
        None
    """
    db_repository = DbRepository(boxer_application_name, spec.description)
    for item in items:
        loaded_item = db_repository.find(item.path)
        if loaded_item is None:
            loaded_item = PipelineItem()
            loaded_item.id = str(uuid.uuid4())
        loaded_item.parent_id = None
        loaded_item.path = item.path
        loaded_item.embedding = item.embedding
        loaded_item.summary = item.summary
        loaded_item.text = item.text
        db_repository.save(loaded_item)

def save_chunk_tree(output_location: str,
                items: list[PipelineItem],
                themes: list[Theme],
                spec: WebSearchPipelineSpec) ->None:
    '''
    saves chunks in a tree based on the provided PipelineItems, Themes, and PipelineSpec. 
    There is one root chunk, then one per Theme, then one per Item. 

        Parameters:
        - output_location - directory to store file output
        - items (list[PipelineItem]): A list of PipelineItem objects to generate the report from.
        - themes (list[Theme]): A list of Theme objects associated with the PipelineItems.
        - spec (PipelineSpec): The PipelineSpec object containing specifications for the report.
        '''

    write_chart (output_location, items, themes, spec)

    logger.debug('Writing chunk tree to DB')
    embedder = Embedder(output_location)
    db_repository = DbRepository (waterfall_application_name, spec.description)
    chunk_repository = ChunkRepository ()

    # First we either load the master theme if it exists, or create a new one
    loaded_master_theme = chunk_repository.find (spec.description)
    if loaded_master_theme is None:
        master_id = str(uuid.uuid4())
        master_theme = create_theme_chunk (spec.description,
                                           spec.description,
                                           '',
                                           output_location,
                                           chunk_repository)
        master_theme.id = master_id
        master_theme.parentChunkId = None
    else:
        master_id = loaded_master_theme.id
        master_theme = loaded_master_theme
        master_theme.relatedChunks = None
        master_theme.storedSummary = None
        master_theme.storedTitle = None
        master_theme.originalText = None
        master_theme.storedEmbedding = None

    master_theme.originalText = 'Please find below the result of the ' + \
        spec.description + \
        ' cluster analysis (' + str(len(items)) + ' samples).'
    
    
    for theme in themes:

        loaded_theme = chunk_repository.find (theme.short_description)
        if loaded_theme is None:
            theme_id = str(uuid.uuid4())            
        else:
            theme_id = loaded_theme.id

        theme_to_save = create_theme_chunk (theme.short_description,
                                            spec.description,
                                            theme.long_description,
                                            output_location,
                                            chunk_repository)
        theme_to_save.id = theme_id
        theme_to_save.parentChunkId = master_id       

        # Save all the member items
        for item in theme.member_pipeline_items:
            loaded_item = db_repository.find (item.path)
            if loaded_item is None:
                loaded_item = PipelineItem()
                loaded_item.id = str(uuid.uuid4())
            loaded_item.parent_id = theme_id
            loaded_item.path = item.path
            loaded_item.embedding = item.embedding
            loaded_item.summary = item.summary
            loaded_item.text = item.text
            db_repository.save (loaded_item)

            # Accumulate the related items in the parent Theme
            if theme_to_save.relatedChunks is None:
                theme_to_save.relatedChunks = []
            theme_to_save.relatedChunks.append (loaded_item.id)

        # Save the Theme
        chunk_repository.save (theme_to_save)

        # Save the Theme as a related item to the master theme
        if master_theme.relatedChunks is None:
            master_theme.relatedChunks = []
        master_theme.relatedChunks.append (theme_id)

        # Build up summary text on the main entry
        if master_theme.originalText is None:
            master_theme.originalText = theme.long_description
        else:
            master_theme.originalText = master_theme.originalText + '\n\n' + theme.long_description

    # Save the Theme
    master_theme.url = "https://braid-api.azurewebsites.net/api/GetPage?id=" + str(master_theme.id)
    
    master_theme_embedding = embedder.embed_text (master_theme.originalText)
    master_theme.storedEmbedding = create_embedding (master_theme_embedding, chunk_repository.default_embedding_model)
    master_theme.storedSummary = create_text_rendering (master_theme.originalText, chunk_repository.default_model)
    master_theme.storedTitle = create_text_rendering (spec.description, chunk_repository.default_model)    

    chunk_repository.save (master_theme)

    # Save the Page - use functional search key and id from the parent theme
    page_repository = PageRepository()

    page : IStoredPage= make_page_from_file (waterfall_application_name,
                                spec.description,
                                master_theme.functionalSearchKey,
                                page_class_name,
                                page_schema_version,
                                master_theme.id,
                                output_location,
                                spec.output_chart_name)
    page_repository.save (page)
****************************************

****************************************
Waterfall\src\waterfall_survey_pipeline.py
****************************************
'''driver for the entire pipeline '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging

from src.workflow import PipelineItem, Theme, WebSearchPipelineSpec
from src.web_searcher import WebSearcher
from src.html_file_downloader import HtmlFileDownloader
from src.summariser import Summariser
from src.summarise_fail_suppressor import SummariseFailSuppressor
from src.embedder import Embedder
from src.cluster_analyser import ClusterAnalyser
from src.theme_finder import ThemeFinder
from src.embedding_finder import EmbeddingFinder
from src.waterfall_pipeline_report import create_mail_report
from src.waterfall_pipeline_report_common import write_details_json
from src.waterfall_pipeline_save_chunks import save_chunk_tree

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


def sort_array_by_another(arr1: list[Theme], arr2: list[int]) -> list[Theme]:
    '''
   orders list 1 using list 2 to drive the sort order

    Returns:
       list[Theme]: Ordered list of Themes.
    '''

    # Combine the two arrays into a list of tuples
    combined = list(zip(arr2, arr1))

    # Sort the combined list by the first element of each tuple (values in arr2)
    combined.sort(reverse=True)

    # Extract the sorted arr1 from the combined list
    sorted_arr1: list[Theme] = [x for _, x in combined]

    return sorted_arr1


class WaterfallDataPipeline:
    '''
    Searches for HTML content from a list of links.

    Returns:
       list[str]: A list of HTML content downloaded from the specified links.
    '''

    def __init__(self, output_location: str):
        self.output_location = output_location
        return

    def search(self, spec: WebSearchPipelineSpec, send_final: bool) -> list[Theme]:
        '''
        Searches for HTML content from a list of links.

        Returns:
            list[Theme]: A list of Theme objects 
        '''

        items: list[WebSearchPipelineSpec] = self.search_and_cluster(spec)

        themes: list[Theme] = self.create_themes(items, spec)

        self.create_report(items, themes, spec, send_final)

        return themes

    def search_and_cluster(self, spec: WebSearchPipelineSpec) -> list[PipelineItem]:
        '''
        Create themes based on the provided PipelineItems and PipelineSpec.

        Parameters:
           items (list[PipelineItem]): A list of PipelineItem objects to create themes from.
           spec (PipelineSpec): The PipelineSpec object containing specifications for 
           theme creation.

        Returns:
           list[Theme]: A list of Theme objects created based on the provided PipelineItems 
           and PipelineSpec.
        '''
        searcher = WebSearcher(self.output_location)

        input_items = searcher.search(spec)

        items: list[PipelineItem] = []

        downloader = HtmlFileDownloader(self.output_location)
        summariser = Summariser(self.output_location)
        suppressor = SummariseFailSuppressor(self.output_location)
        embedder = Embedder(self.output_location)
        cluster_analyser = ClusterAnalyser(self.output_location, spec.clusters)

        for item in input_items:
            downloaded = None
            suppression_checked = None
            summarised = None
            embedded = None

            downloaded = downloader.download(item)
            if downloaded:
                summarised = summariser.summarise(downloaded)
            if summarised:
                suppression_checked = suppressor.should_suppress(summarised)
            if suppression_checked:
                embedded = embedder.embed(suppression_checked)
            if embedded:
                items.append(embedded)

        items = cluster_analyser.analyse(items)

        return items

    def create_themes(self, items: list[PipelineItem], spec: WebSearchPipelineSpec) -> list[Theme]:
        '''
        Create themes based on the provided PipelineItems and PipelineSpec.

        Parameters:
           items (list[PipelineItem]): A list of PipelineItem objects to create themes from.
           spec (PipelineSpec): The PipelineSpec object containing specifications 
                for theme creation.

        Returns:
           list[Theme]: A list of Theme objects created based on the provided 
              PipelineItems and PipelineSpec.
        '''
        themes: list[Theme] = []

        accumulated_summaries: list[str] = [''] * spec.clusters
        accumulated_counts: list[int] = [0] * spec.clusters
        accumulated_members: list[list[PipelineItem]] = [None] * spec.clusters
        for x in range(spec.clusters):
            accumulated_members[x] = []

        # Accumulate a set of summaries and counts of summaries according to classification
        for i, item in enumerate(items):
            cluster = items[i].cluster
            accumulated_summaries[cluster] = accumulated_summaries[cluster] + \
                item.summary + "\n "
            accumulated_counts[cluster] = accumulated_counts[cluster] + 1
            accumulated_members[cluster].append(item)

        # Ask the theme finder to find a theme, then store it
        for i, accumulated_summary in enumerate(accumulated_summaries):
            theme_finder = ThemeFinder()
            short_description = theme_finder.find_theme(
                accumulated_summary, 15)
            long_description = theme_finder.find_theme(accumulated_summary, 50)
            theme = Theme()
            theme.member_pipeline_items = accumulated_members[i]
            theme.short_description = short_description
            theme.long_description = long_description
            themes.append(theme)

        # Ask the embedding finder to find nearest article for each theme
        enriched_themes = []
        for i, theme in enumerate(themes):
            logger.debug('Finding nearest embedding')

            # Accumulate the embeddings that are part of the cluster
            embeddings_for_theme = []
            for item in items:
                if item.cluster == i:
                    embeddings_for_theme.append(item.embedding)

            # Build embedding finder with the right embeddings,
            # then find the nearest one to the theme that is in the cluster
            embedding_finder = EmbeddingFinder(
                embeddings_for_theme, self.output_location)
            nearest_items: list[PipelineItem] = []
            nearest_embedding = embedding_finder.find_nearest(
                theme.long_description)

            # Store nearest item
            for item in items:
                if item.embedding == nearest_embedding:
                    nearest_items.append(item)
                    theme.example_pipeline_items = nearest_items
                    enriched_themes.append(theme)
                    break

        logger.debug('Ordering themes')
        ordered_themes = sort_array_by_another(
            enriched_themes, accumulated_counts)

        return ordered_themes

    def create_report(self, items: list[PipelineItem],
                      themes: list[Theme],
                      spec: WebSearchPipelineSpec,
                      send_final: bool) -> None:
        '''
        Generates a report based on the provided PipelineItems, Themes, and PipelineSpec. 

        Parameters:
        - items (list[PipelineItem]): A list of PipelineItem objects to generate the report from.
        - themes (list[Theme]): A list of Theme objects associated with the PipelineItems.
        - spec (PipelineSpec): The PipelineSpec object containing specifications for the report.
        - send_final - set to false to suppress ending the report - used in testing
        '''
        write_details_json( self.output_location, items, themes, spec)
        save_chunk_tree (self.output_location, items, themes, spec)
        create_mail_report(self.output_location, items, themes, spec, send_final)
****************************************

****************************************
Waterfall\src\web_searcher.py
****************************************
''' first step of Waterfall pipeline - search web and generate input list of PipelineItems'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import requests

from src.workflow import PipelineItem, WebSearchPipelineSpec

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)

# get the API KEY here: https://developers.google.com/custom-search/v1/overview
GOOGLE_DEVELOPER_API_KEY = os.environ['GOOGLE_DEVELOPER_API_KEY']

# get your Search Engine ID on your CSE control panel
# https://programmablesearchengine.google.com/controlpanel/all
AI_SUPPLY_STACK_SEARCH_ENGINE_ID = '00d305498d8da42e1'
AI_DEMAND_STACK_SEARCH_ENGINE_ID = '22fafd262192b4c06'
AI_TELECOM_SEARCH_ENGINE_ID = '7789e6bd5a1d54069'
AI_NATIONWIDE_SEARCH_ENGINE_ID= '3498036ca64b54980'
AI_BNY_SEARCH_ENGINE_ID= 'a4521230dc31a4716'

class WebSearcher:
    '''
    Searches for links related to a specific query using the Google Custom Search Engine API.
    Returns a list of URLs extracted from the search results.
    '''

    def __init__(self, output_location: str):
        self.output_location = output_location
        return

    def search(self, pipeline: WebSearchPipelineSpec) -> list[PipelineItem]:
        '''
        Searches for links related to a specific query using the Google Custom Search Engine API.
        Returns a list of URLs extracted from the search results.
        '''
        # See this link for details of what we are doing here
        # https://thepythoncode.com/article/use-google-custom-search-engine-api-in-python?utm_content=cmp-true

        pipeline_items = []

        # the search query you want
        query = 'Generative AI'

        # Pull back 1- pages of results (100 items ...)
        for page in range(1, pipeline.pages + 1):
            # constructing the URL
            # doc: https://developers.google.com/custom-search/v1/using_rest
            # calculating start, (page=2) => (start=11), (page=3) => (start=21)
            start = (page - 1) * 10 + 1
            url = f'https://www.googleapis.com/customsearch/v1?key={GOOGLE_DEVELOPER_API_KEY}&cx={
                pipeline.search_key}&q={query}&start={start}&dateRestrict=m[1]'

            # make the API request
            data = requests.get(url, timeout=20).json()

            # get the result items
            search_items = data.get('items')

            # iterate over the results
            if search_items is not None:
                for search_item in search_items:
                    # extract the page url
                    link = search_item.get('link')
                    pipeline_item = PipelineItem()
                    pipeline_item.path = link
                    pipeline_items.append(pipeline_item)
            else:
                break

        return pipeline_items
****************************************

****************************************
Waterfall\src\workflow.py
****************************************
'''Classes shared across the entire workflow'''
# Copyright (c) 2024 Braid Technologies Ltd

import functools


class Freezable(object):
    '''Class that can be frozen to stop it being given new attributes'''
    _is_frozen = False

    def __setattr__(self, key, value):
        if self._is_frozen and not hasattr(self, key):
            raise TypeError(f'%r is frozen ' % self) # pylint: disable=f-string-without-interpolation
        object.__setattr__(self, key, value)

    def _freeze(self):
        self._is_frozen = True


@functools.total_ordering
class PipelineItem(Freezable):
    '''A work item that is passed along the processsing pipeline'''
    def __init__(self):
        '''
        Initializes the PipelineItem class with attributes path, summary, and embedding.
        Freeze the object to prevent adding spurious variables.
        '''
        self.id = None
        self.parent_id = None
        self.path = None
        self.text = None
        self.chunk = 0
        self.summary = None
        self.embedding = None
        self.cluster = None
        self.length_minutes = 0

        self._freeze()

    def _is_valid_operand(self, other):
        return (hasattr(other, 'path') and
                hasattr(other, 'long_description'))

    # https://stackoverflow.com/questions/5824382/enabling-comparison-for-classes
    def __eq__(self, other):
        if not self._is_valid_operand(other):
            return NotImplemented
        return ((self.path.lower(), self.summary.lower()) ==
                (other.path.lower(), other.summary.lower()))

    def __lt__(self, other):
        if not self._is_valid_operand(other):
            return NotImplemented
        return ((self.path.lower(), self.summary.lower()) <
                (other.path.lower(), other.summary.lower()))



@functools.total_ordering
class Theme(Freezable):
    '''A theme is a fully documented cluster of items '''

    def __init__(self):
        '''Initialize the Theme object with default attributes and freeze the object.
           Freeze the object to prevent adding spurious variables.'''
        self.short_description = None
        self.long_description = None
        self.example_pipeline_items = None
        self.member_pipeline_items = None

        self._freeze()

    def _is_valid_operand(self, other):
        return (hasattr(other, 'short_description') and
                hasattr(other, 'long_description'))

    # https://stackoverflow.com/questions/5824382/enabling-comparison-for-classes
    def __eq__(self, other):
        if not self._is_valid_operand(other):
            return NotImplemented
        return ((self.short_description.lower(), self.long_description.lower()) ==
                (other.short_description.lower(), other.long_description.lower()))

    def __lt__(self, other):
        if not self._is_valid_operand(other):
            return NotImplemented
        return ((self.short_description.lower(), self.long_description.lower()) <
                (other.short_description.lower(), other.long_description.lower()))

class PipelineStep ():
    '''Super class for a step in the Waterfall pipeline'''
    def __init__(self, output_location: str):
        '''
        Initialize the PipelineStep with the specified output location.

        Parameters:
        output_location (str): The location in the file systems where the output will be stored.
        '''
        self.output_location = output_location

class PipelineSpec(Freezable):
    '''The spec for a full run of the Waterfall workflow'''

    def __init__(self):
        '''
        Initialize the PipelineSpec object with default attributes.
        '''
        self.clusters = 2
        self.clusters_in_summary = 2
        self.description = None
        self.output_chart_name = None
        self.output_data_name = None
        self.themes = None


class WebSearchPipelineSpec(PipelineSpec):
    '''The spec for a full run of the Waterfall workflow'''

    def __init__(self):
        '''
        Initialize the WebPipelineSpec object with default attributes and freeze the object.
        Freeze the object to prevent adding spurious variables.
        '''
        super().__init__()
        self.pages = 1  # default is to pull back one page
        self.search_key = None
        self.mail_to = None

        self._freeze()

class YouTubePipelineSpec(Freezable):
    '''The spec for a batch of video playlists to download'''

    def __init__(self):
        '''
        Initialize the YouTubePipelineSpec object with default attributes and freeze the object.
        Freeze the object to prevent adding spurious variables.
        '''
        self.playlists = []
        self.max_words = 3500 # This seems to come out at about 15 minutes of video
        self.overlap_words = 100

        self._freeze()


class HtmlDirectedPipelineSpec(Freezable):
    '''The spec for a batch of web pages to download'''

    def __init__(self):
        '''
        Initialize the WebDirectedPipelineSpec object with default attributes and freeze the object.
        Freeze the object to prevent adding spurious variables.
        '''
        self.urls = list[str]

        self._freeze()

class FileDirectedPipelineSpec(Freezable):
    '''The spec for a batch of web pages to download'''

    def __init__(self):
        '''
        Initialize the WebDirectedPipelineSpec object with default attributes and freeze the object.
        Freeze the object to prevent adding spurious variables.
        '''
        self.files = list[str]

        self._freeze()

class PipelineFileSpec(Freezable):
    '''The spec for a full run of the Waterfall workflow'''

    def __init__(self):
        '''
        Initialize the PipelineFileSpec object with default attributes and freeze the object.
        Freeze the object to prevent adding spurious variables.
        '''
        self.output_data_name = None
        self.description = None

        self._freeze()
****************************************

****************************************
Waterfall\src\youtube_searcher.py
****************************************
''' first step of Waterfall pipeline - generate input list of PipelineItems from a Youtube playlist'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import datetime

import googleapiclient.discovery
import googleapiclient.errors

from src.workflow import PipelineItem, YouTubePipelineSpec
from src.boxer_sources import youtube_playlists

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)

# get the API KEY here: https://developers.google.com/custom-search/v1/overview
GOOGLE_DEVELOPER_API_KEY = os.environ['GOOGLE_DEVELOPER_API_KEY']
GOOGLE_API_SERVICE_NAME = "youtube"
GOOGLE_API_VERSION = "v3"
MAX_RESULTS = 100


def parseVideoDurationMins(duration: str) -> int:
    """Parse the duration of a video in minutes.

    Args:
        duration (str): The duration of the video in ISO 8601 format.

    Returns:
        int: The duration of the video in minutes.

    Derived from : https://stackoverflow.com/questions/73495868/converting-youtube-data-api-v3-video-duration-format-to-seconds-in-python3
    But WARNING - that saple has incorrect logic for minutes- corrected below. 
    """
    new_string = duration.split('T')[1]

    if 'H' in new_string and 'M' in new_string and 'S' in new_string:
        dt = datetime.datetime.strptime(new_string, '%HH%MM%SS')
        time_sec = int(dt.hour) * 3600 + int(dt.minute) * 60 + int(dt.second)

    elif 'M' in new_string and 'S' in new_string:
        dt = datetime.datetime.strptime(new_string, '%MM%SS')
        time_sec = int(dt.minute) * 60 + int(dt.second)

    elif 'H' in new_string and 'M' in new_string:
        dt = datetime.datetime.strptime(new_string, '%HH%MM')
        time_sec = int(dt.hour) * 3600 + int(dt.minute) * 60

    elif 'H' in new_string and 'S' in new_string:
        dt = datetime.datetime.strptime(new_string, '%HH%SS')
        time_sec = int(dt.hour) * 3600 + int(dt.second)

    elif 'H' in new_string:
        dt = datetime.datetime.strptime(new_string, '%HH')
        time_sec = int(dt.hour) * 3600

    elif 'M' in new_string:
        dt = datetime.datetime.strptime(new_string, '%MM')
        time_sec = int(dt.minute) * 60

    else:
        dt = datetime.datetime.strptime(new_string, '%SS')
        time_sec = int(dt.second)

    return time_sec / 60


class YoutubePlaylistSearcher:
    '''Processes a set of playlists and creates a list of PipelineItem objects representing the videos found in the playlists'''

    def __init__(self, output_location: str):
        '''
        Initialize the class with the specified output location.

        Parameters:
        - output_location (str): The location where the output will be stored.
        '''
        self.output_location = output_location
        return

    def search(self, pipeline: YouTubePipelineSpec) -> list[PipelineItem]:
        '''
        Search for videos in the specified playlists and generate a list of PipelineItems.

        Parameters:
            pipeline (YouTubePipelineSpec): The pipeline specification containing playlists to search.

        Returns:
            list[PipelineItem]: A list of PipelineItem objects representing the videos found in the playlists.
        '''

        pipeline_items = []

        youtube = googleapiclient.discovery.build(
            GOOGLE_API_SERVICE_NAME, GOOGLE_API_VERSION, developerKey=GOOGLE_DEVELOPER_API_KEY
        )

        for playlist in pipeline.playlists:
            # Create a request object with the playlist ID and the max results
            playlist_request = youtube.playlistItems().list(
                part="snippet", playlistId=playlist, maxResults=MAX_RESULTS
            )

            # Loop through the pages of results until there is no next page token
            while playlist_request:
                # Execute the request and get the response
                playlist_response = playlist_request.execute()

                # Iterate over the items in the response and append the video IDs to the list
                for item in playlist_response["items"]:
                    video_id = item["snippet"]["resourceId"]["videoId"]

                    # Create a request object with the Video ID
                    # Note - to optimise, should really batch request this for all videos in the page returned
                    video_request = youtube.videos().list(
                        id=video_id,
                        part="contentDetails"
                    )
                    video_response = video_request.execute()
                    duration = video_response["items"][0]["contentDetails"]["duration"]

                    minutes = parseVideoDurationMins(duration)

                    pipeline_item = PipelineItem()
                    pipeline_item.length_minutes = int(minutes)
                    pipeline_item.path = "https://www.youtube.com/watch?v=" + \
                        str(video_id)
                    pipeline_items.append(pipeline_item)

                # Get the next page token from the response and create a new request object
                next_page_token = playlist_response.get("nextPageToken")
                if next_page_token:
                    playlist_request = youtube.playlistItems().list(
                        part="snippet",
                        playlistId=playlist,
                        maxResults=MAX_RESULTS,
                        pageToken=next_page_token,
                    )
                else:
                    playlist_request = None

        return pipeline_items
****************************************

****************************************
Waterfall\src\youtube_transcript_chunker.py
****************************************
''' Divide the transcript of a Youtube video into chunks '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import math
import logging
import datetime

from src.workflow import PipelineItem, PipelineStep
from src.chunker import Chunker

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


def make_start_time_offset(minutes: int) -> str:

    hours = math.floor(minutes / 60)
    minutes_left = minutes - (hours * 60)

    time_marker = datetime.time(int(hours), int(minutes_left))
    if hours > 0:
        return '&t=' + time_marker.strftime("%Hh%Mm")
    return '&t=' + time_marker.strftime("%Mm")


class YouTubeTranscriptChunker (PipelineStep):
    '''
    Utility class to chunk a transcript for a YouTube video
    '''

    def __init__(self, output_location: str):
        '''
        Initializes the YouTubeTranscriptChunker object.
        '''
        # pylint: disable-next=useless-parent-delegation
        super(YouTubeTranscriptChunker, self).__init__(output_location)
        self.chunker = Chunker(output_location)

    def chunk(self, pipeline_item: PipelineItem, chunk_size_words: int, overlap_words: int) -> list[PipelineItem]:
        '''
         Divides the transcript of the specific video into chunks and new PipelineItems.

         Parameters:
            pipeline_item: PipelineItem - The item to be chunked.
            chunk_size_words - maximum words per chunk. If 0, use the models context window size. 
            overlap_words - how many words to use to overlap chunks. 0 = no overlap.
         Returns:
             list[PipelineItem]: The chunks of the Video transcript.
        '''
        chunks = self.chunker.chunk(
            pipeline_item, chunk_size_words, overlap_words)

        # special case if we only have one chunk
        number_of_chunks = len(chunks)
        if number_of_chunks == 1:
            return pipeline_item

        if number_of_chunks == 0:
            return None

        # linear interpolation by chunk size after correction for overlap
        # this assumes text is evenly spread throughout the video, but this seems ok for lectures / presentations
        original_length = len(pipeline_item.text)
        chunked_length = 0
        for chunk in chunks:
            chunked_length = chunked_length + len(chunk.text)

        overlap_length = (chunked_length - original_length) / number_of_chunks

        start_minutes = 0
        # irat chunk has only one overlap. So does last but we dont use that for the start point calulation
        number_of_overlaps = 1

        for chunk in chunks:
            base_url = chunk.path
            time_marker = make_start_time_offset(start_minutes)
            chunk.path = base_url + time_marker
            chunk_minutes = ((len(chunk.text) - (number_of_overlaps * overlap_length))
                             * pipeline_item.length_minutes / original_length)
            number_of_overlaps = 2
            start_minutes = start_minutes + chunk_minutes

        return chunks
****************************************

****************************************
Waterfall\src\youtube_transcript_downloader.py
****************************************
''' Download the transcript of a YouTube playlist'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
from urllib.parse import urlparse, parse_qs
from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled, VideoUnavailable
# from youtube_transcript_api.formatters import WebVTTFormatter

from src.workflow import PipelineStep, PipelineItem
from src.text_repository_facade import TextRespositoryFacade

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)


def clean_text(text: str) -> str:
    """clean the text"""
    text = text.replace("\n", " ")  # remove new lines
    text = text.replace("&#39;", "'")
    text = text.replace(">>", "")  # remove '>>'
    text = text.replace("  ", " ")  # remove double spaces
    text = text.replace("[inaudible]", "")  # [inaudible]

    return text


def parse_video_id(value: str) -> str:
    """
    Examples:
    - http://youtu.be/SA2iWivDJiE
    - http://www.youtube.com/watch?v=_oPAwA_Udwc&feature=feedu
    - http://www.youtube.com/embed/SA2iWivDJiE
    - http://www.youtube.com/v/SA2iWivDJiE?version=3&amp;hl=en_US
    """
    query = urlparse(value)
    if query.hostname == 'youtu.be':
        return query.path[1:]
    if query.hostname in ('www.youtube.com', 'youtube.com'):
        if query.path == '/watch':
            p = parse_qs(query.query)
            return p['v'][0]
        if query.path[:7] == '/embed/':
            return query.path.split('/')[2]
        if query.path[:3] == '/v/':
            return query.path.split('/')[2]
    # fail?
    return None


class YouTubeTranscriptDownloader (PipelineStep):
    '''Utility class to download the transcript for a YouTube video

     Args:
         output_location (str): The location to save the text of the downloaded file.
    '''

    # pylint: disable=useless-parent-delegation
    def __init__(self, output_location: str):
        '''
        Initializes the YouTubeTranscriptDownloader object with the provided output location.
        '''
        super(YouTubeTranscriptDownloader, self).__init__(
            output_location)  

    def download(self, pipeline_item: PipelineItem) -> PipelineItem:
        '''
         Downloads the transcript of the specific video and saves it to the output location.

         Returns:
             PipelineItem: The content of the downloaded Video transcript.
        '''
        path = pipeline_item.path
        repository = TextRespositoryFacade(self.output_location)
        if repository.exists(path):
            text = repository.load(path)
            pipeline_item.text = text
            return pipeline_item

        try:
            full_text = ""
            video_id = parse_video_id(pipeline_item.path)
            if not video_id:
                raise RuntimeError ("Unable to parse video id")
            transcript = YouTubeTranscriptApi.get_transcript(video_id)
            # Remove \n from the text
            for item in transcript:
                full_text = full_text + clean_text(item["text"])

        except NoTranscriptFound:
            logger.error("No transcript found for video: %s", path)
            return False
        except TranscriptsDisabled:
            logger.error("Transcripts are disabled for video: %s", path)
            return False
        except VideoUnavailable:
            logger.error("Video unavailable: %s", path)
            return False
        # pylint: disable-broad-exception-caught
        except Exception as exception:
            logger.error("An error occurred: %s", str(exception))
            logger.v("Transcription not found for video: %s", path)

        pipeline_item.text = full_text
        repository.save(path, full_text)

        return pipeline_item
****************************************

****************************************
Waterfall\test\ReadMe.Salon.md
****************************************
**test_boxer_pipeline.py**

This module tests the Boxer Pipeline implementation by setting up different pipeline configurations and ensuring they produce the expected outputs.

- **Imports**: It imports necessary standard libraries and specific modules like `YouTubePipelineSpec`, `HtmlDirectedPipelineSpec`, `PipelineFileSpec`, `youtube_playlists`, `html_pages`, and `BoxerDataPipeline` for pipeline specification and data sources.
- **Logging**: It configures logging to capture and display error-level logs for debugging purposes.
- **Classes and Functions**:
  - `test_youtube_boxer_pipeline()`: Tests the pipeline with YouTube data source.
  - `test_html_boxer_pipeline()`: Tests the pipeline with HTML pages as data sources.
  - `test_full_boxer_pipeline()`: Intended to perform a full pipeline test combining YouTube playlists and HTML pages; currently, it returns immediately to prevent full execution.

**test_chunker.py**

This module is a pytest suite that tests the functionality of three main classes: `PipelineItem`, `Chunker`, and `HtmlFileDownloader` from the `src` directory.

The `test_output_dir` fixture creates a temporary directory for test output, and ensures it is cleaned up after tests run.

The `test_basic` function verifies if the `Chunker` is correctly initialized with the test output directory.

The `test_with_output` function tests the downloading and chunking of a simple HTML file to ensure the chunker produces the expected number of chunks.

The `test_long` function checks how the `Chunker` handles very long text content by verifying multiple chunks are created.

The `test_long_with_overlap` and `test_long_overlap` functions specifically test chunking with overlapping words, ensuring that overlapping is correctly managed by checking the boundaries and overlaps between chunks.

Logging is configured at the beginning of the module to capture ERROR level logs, to facilitate debugging the test execution process.

**test_cluster_analyser.py**

This code is a test suite using the `pytest` framework to verify the functionality of a pipeline involving several components from the `src` directory.

The `test_output_dir` function is a `pytest` fixture that creates a temporary directory for test outputs and ensures cleanup after the test execution.

The `test_basic` function tests the basic creation and attributes of a `ClusterAnalyser` object using a single `PipelineItem`.

The `test_with_output` function tests the full pipeline by iterating over a list of HTML test files, processing them through `HtmlFileDownloader`, `Summariser`, and `Embedder`, and finally analyzing them with `ClusterAnalyser`.

Important classes or functions:
- `test_output_dir` (fixture)
- `test_basic` (test function)
- `test_with_output` (test function)
- `PipelineItem`
- `ClusterAnalyser`
- `HtmlFileDownloader`
- `Summariser`
- `Embedder`

**test_db_repository.py**

This code contains unit tests for the `DbRepository` class from the `src.db_repository` module.

The `test_basic` function assesses the creation of a `DbRepository` object and checks if its context ID is set correctly.

The `test_does_not_exist` function verifies that the `exists` method of `DbRepository` accurately identifies a non-existing item.

The `test_save` function tests the `save` method by attempting to save a `PipelineItem` instance and checking if the operation is successful.

The `test_save_exists` function first saves a `PipelineItem` and then verifies its existence with the `exists` method.

The `test_save_load` function saves a `PipelineItem` and then confirms that it can be loaded back correctly with the `find` method.

Key classes and functions: `DbRepository`, `PipelineItem`, `test_basic`, `test_does_not_exist`, `test_save`, `test_save_exists`, and `test_save_load`.

**test_embedder.py**

This code involves setting up and executing pytest cases to test the functionality of classes `Embedder` and `HtmlFileDownloader` from a source directory.

Logging is configured to capture and display script execution details above the warning level, with an error level for the module-specific logger.

A pytest fixture creates a temporary directory for test outputs, and ensures cleanup after tests run.

The `test_basic` function ensures the `Embedder` class correctly sets its output location.

The `test_with_output` function tests the process of downloading HTML content using `HtmlFileDownloader`, enriching it, and then embedding that content using `Embedder`, verifying that the embedding is successfully generated.

Important classes/functions:
- `test_output_dir` (pytest fixture)
- `test_basic` (test function)
- `test_with_output` (test function)

**test_embedding_finder.py**

This code is for testing a workflow involving text processing and embeddings:

- `test_output_dir` is a pytest fixture that sets up and cleans up a temporary directory for test output. It logs the directory creation and cleanup.
- `test_basic` checks that an `EmbeddingFinder` instance is correctly initialized with a list of embeddings.
- `test_with_output` tests the full flow of processing HTML files: downloading them using `HtmlFileDownloader`, summarizing them with `Summariser`, embedding them with `Embedder`, and finally finding the nearest embeddings using `EmbeddingFinder`.

Key components:
- `test_output_dir` (fixture)
- `test_basic` (test function)
- `test_with_output` (test function)
- `EmbeddingFinder`
- `HtmlFileDownloader`
- `PipelineItem`
- `Summariser`
- `Embedder`

**test_embedding_repository.py**

This Python script uses the pytest framework to perform unit tests for the `EmbeddingRespositoryFacade` class from the `embedder_repository_facade` module.

Logging is set up to log warnings and errors, helping diagnose issues during test execution.

The `test_output_dir` fixture creates a temporary directory for test outputs and ensures its cleanup post-test.

The `test_basic` function verifies that the `EmbeddingRespositoryFacade` initializes correctly with a given output location.

The `test_with_output` function ensures that saving, checking existence, and loading embeddings work correctly.

The `test_with_no_output` function tests that loading a non-existent file raises an exception.

**test_errors.py**

This script sets up the environment for importing from the 'src' directory, including adjusting the system path.

The logging module is configured to record information about script execution, with the default logging level set to ERROR.

The script imports and utilises the 'PipelineItem' and 'Summariser' classes from the 'workflow' and 'summariser' modules respectively.

The `test_basic()` function contains assertions and log statements for different logging levels to test logging.

The `test_with_output()` function sets the working directory, creates a `PipelineItem`, populates it with text, uses a `Summariser` to summarize the text, and verifies the summary is generated.

**test_file_repository.py**

This code tests the File System API, particularly the `FileRespository` class from the `file_repository` module.

The script sets up the test environment by importing necessary modules, configuring logging, and extending the Python path to include the source directory.

The `test_output_dir` fixture creates a temporary directory for test outputs, logs its creation, and ensures cleanup by removing the directory after tests run.

The `test_basic` function tests that the repository’s output location is correctly set upon initialization.

The `test_with_output` function verifies that a file can be saved to and loaded from the repository correctly.

The `test_with_no_output` function ensures that the repository correctly handles attempts to load non-existent files.

**test_html_file_downloader.py**

This module sets up an environment for testing with pytest, and includes the following key functions and classes:

1. **test_output_dir (fixture)**: Creates a temporary directory for test output and ensures cleanup after tests run, logging the creation and deletion of the directory.

2. **test_basic**: Tests if the `HtmlFileDownloader` instance has the correct output location by asserting equality of expected and actual output location paths.

3. **test_with_output**: Tests the `HtmlFileDownloader` by downloading an HTML file ('simple_test.html') and checking that the downloaded content has text. Uses the `PipelineItem` class to manage the path of the file.

4. **test_connected**: Similar to `test_with_output`, but downloads content from a URL ('https://openai.com/') to ensure online functionality.

The important classes are `PipelineItem` and `HtmlFileDownloader`.

**test_html_link_crawler.py**

This code is a pytest module designed for testing the `HtmlLinkCrawler` from the `src.html_link_crawler` module and `PipelineItem` from the `src.workflow` module.

Logging is set up to report execution details, configured at the ERROR level.

`test_output_dir` is a pytest fixture that creates and cleans up a temporary directory for test outputs.

There are several test functions: `test_basic`, `test_with_output`, `test_with_one_recursion`, `test_with_two_recursions`, `test_many_sublinks`, and `test_mad_page`, all of which create an `HtmlLinkCrawler` instance and verify its functionality by asserting the number of links it finds during a crawl.

**test_summariser.py**

This code is a Python module containing tests for a summarisation workflow, utilising the `pytest` framework.

It sets up the paths and logging configuration for the tests. The `sys.path` is extended to include the parent and `src` directories to ensure that module imports work correctly.

The `test_output_dir` fixture creates a temporary directory for test outputs, provides its path to the tests, and ensures clean-up by deleting the directory post-test.

Two test functions are defined: `test_basic` creates a `Summariser` instance and checks the designated output location, `test_with_output` simulates the complete summarisation workflow by downloading an HTML file and then summarising it.

Important classes/functions:
- `test_output_dir` (fixture)
- `test_basic` (function)
- `test_with_output` (function)

**test_summarise_fail_suppressor.py**

This script is a set of tests for components in a Python project, which uses the `pytest` framework.

The logging module is configured to report warnings and errors, ensuring the script's execution is logged comprehensively.

A pytest fixture `test_output_dir` creates a temporary directory for test outputs and ensures clean-up after tests.

Functions `test_basic`, `test_with_no_suppression`, and `test_with_suppression` test the functionality of the `SummariseFailSuppressor` class. `test_basic` verifies the assignment of the output location. The other two tests assess how summaries are handled when suppressing conditions are and aren't met.

Important classes/functions:
- SummariseFailSuppressor
- PipelineItem
- test_output_dir (fixture)
- test_basic (test function)
- test_with_no_suppression (test function)
- test_with_suppression (test function)

**test_summary_repository.py**

This code is a test module for a repository system that handles summaries, using `pytest` for testing. The essential classes and functions are:

- **`test_output_dir` fixture**: This creates a temporary directory for test outputs, provides its path to the tests, and cleans up the directory afterward.
- **`test_basic` function**: It tests the basic creation of a `SummaryRepositoryFacade` object and verifies that the output location is set correctly.
- **`test_with_output` function**: It verifies that a repository can save, check the existence of, and load a text file correctly.
- **`test_with_no_output` function**: It tests the repository's behavior when trying to access a file that wasn't saved, ensuring proper handling of non-existent entries.

**test_text_repository.py**

This module contains tests for the text repository API, primarily using the pytest framework.

The `test_output_dir` is a pytest fixture that creates a temporary directory for test output and ensures cleanup after tests.

`TextRespositoryFacade` is the class from the module `text_repository_facade` that's being tested.

`test_basic` checks that a `TextRespositoryFacade` instance correctly identifies the output location.

`test_with_output` verifies that text can be saved and retrieved correctly from the repository.

`test_with_no_output` checks that attempting to retrieve non-existent text properly indicates failure.

Logging is set up at the ERROR level to capture execution details.

**test_theme_finder.py**

This script is a test module for a summarisation pipeline using classes from the `src` library.

**Logging setup**: Configures logging to display warnings and higher-level messages, while the script logs errors specifically.

**test_basic function**: It verifies the instantiation of the `ThemeFinder` class to ensure it is not `None`.

**test_with_output function**: 
- Changes the current working directory to the script's location.
- Defines test HTML file paths and an output location.
- Iterates through each test file, creating `PipelineItem` objects.
- Downloads the HTML content and then summarises it using the `HtmlFileDownloader` and `Summariser` classes, respectively.
- Combines the summaries, finds common themes via the `ThemeFinder` class, and asserts that the themes are generated.

**Key Classes/Functions**: `PipelineItem`, `HtmlFileDownloader`, `Summariser`, `ThemeFinder`, `test_basic`, `test_with_output`.

**test_waterfall_pipeline.py**

The code is designed to test the Waterfall data pipeline from Braid Technologies Ltd. 

It starts with necessary imports, sets up logging, and defines a root directory for tests. The main class used is `WaterfallDataPipeline`, and it is tested using `pytest`.

The `test_basic()` function checks if the pipeline outputs to the specified location. 

Several tests (`test_with_search_supply`, `test_with_search_demand`, `test_with_search_telecom`, `test_with_search_nationwide`, `test_with_search_bny`) initialize the pipeline, create a `WebSearchPipelineSpec` with search configurations, and assert if links are retrieved. 

One test (`test_with_search_vf_survey_01`) uses `PipelineSpec` and `FileDirectedPipelineSpec` for file-based data.

Key classes/functions include `WaterfallDataPipeline`, `WebSearchPipelineSpec`, `PipelineSpec`, and `FileDirectedPipelineSpec`.

**test_web_searcher.py**

The code imports several standard libraries such as `os`, `sys`, and `logging`, and adjusts the `sys.path` to include parent and source directories.

Logging is configured to show messages of level WARNING or higher and the logger is set to the ERROR level to log only errors.

The `WebSearcher` class and the `AI_SUPPLY_STACK_SEARCH_ENGINE_ID` constant are imported from `src.waterfall_pipeline` and `src.web_searcher`, respectively.

There are two test functions, `test_basic` and `test_with_search`. `test_basic` checks if a `WebSearcher` object's `output_location` attribute is correctly set. `test_with_search` sets up a web search pipeline, initiates a search with one page, and verifies that at least one item is returned.

Important classes/functions:
- `WebSearchPipelineSpec`
- `WebSearcher`
- `test_basic`
- `test_with_search`

**test_workflow.py**

The script sets up a test environment by modifying the system path to include the parent and source directories, enabling module imports. It also configures logging to handle errors and display warning level logs.

Three testing functions are defined: `test_pipeline_item`, `test_theme`, and `test_pipeline`.

- `test_pipeline_item` creates a `PipelineItem` object, sets attributes, and verifies that invalid attribute assignment raises a `TypeError`.
- `test_theme` creates a `Theme` object with associated `PipelineItem` objects, sets descriptions, and tests for correct attribute behavior.
- `test_pipeline` configures a `WebSearchPipelineSpec` object, links `Theme` objects, and verifies invalid attribute assignment raises a `TypeError`.

Important classes include `WebSearchPipelineSpec`, `PipelineItem`, and `Theme`.

**test_youtube_playlist.py**

1. The script handles various imports including `os`, `sys`, and `logging` from the standard library and several module-specific imports such as `YouTubePipelineSpec`, `YoutubePlaylistSearcher`, `YouTubeTranscriptDownloader`, and `youtube_playlists`.

2. The script sets up the system paths to include parent directories, making it possible to access specific modules in the `src` directory.

3. Logging is configured to display warnings and errors, and a logger named `__name__` logs error-level messages.

4. The script contains three test functions: `test_basic`, `test_with_search`, and `test_download`.

5. `test_basic` tests the initialization of `YoutubePlaylistSearcher` by verifying the output location.

6. `test_with_search` changes the working directory, sets up an output location, uses `YoutubePlaylistSearcher` to search through playlists, and asserts that at least one item is found.

7. `test_download` initializes both `YoutubePlaylistSearcher` and `YouTubeTranscriptDownloader`, performs searches and downloads transcripts, then asserts the length of the retrieved items and ensures there is at least one item in the results.

Key Classes/Functions: 
- `YoutubePlaylistSearcher`
- `YouTubePipelineSpec`
- `YouTubeTranscriptDownloader`
- `youtube_playlists`
- `test_basic`
- `test_with_search`
- `test_download`
****************************************

****************************************
Waterfall\test\test_boxer_pipeline.py
****************************************
"""Test module for the Boxer Pipeline implementation."""

# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import sys
import logging

from src.workflow import YouTubePipelineSpec, HtmlDirectedPipelineSpec, PipelineFileSpec
from src.boxer_sources import youtube_playlists, html_pages
from src.boxer_pipeline import BoxerDataPipeline

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(
    level=logging.WARNING,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

def test_youtube_boxer_pipeline():
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_output_location = 'boxer_output'

    pipeline = BoxerDataPipeline (test_output_location)

    file_spec = PipelineFileSpec()
    file_spec.output_data_name = "test_youtube_only.json"
    file_spec.description = "Boxer Pipeline"

    html_spec = HtmlDirectedPipelineSpec()
    html_spec.urls = []

    # make a short playlist from first entry
    youtube_spec = YouTubePipelineSpec()
    youtube_spec.playlists = []
    youtube_spec.playlists.append (youtube_playlists[0])

    pipeline_items = pipeline.search (youtube_spec, html_spec, file_spec)

    assert len(pipeline_items) >= 1

def test_html_boxer_pipeline():
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_output_location = 'boxer_output'

    pipeline = BoxerDataPipeline (test_output_location)

    file_spec = PipelineFileSpec()
    file_spec.output_data_name = "test_html_only.json"
    file_spec.description = "Boxer Pipeline"

    youtube_spec = YouTubePipelineSpec()

    # make a short playlist from first entry
    html_spec = HtmlDirectedPipelineSpec()
    html_spec.urls = []
    html_spec.urls.append (html_pages[0])
    html_spec.urls.append (html_pages[1])
    html_spec.urls.append (html_pages[2])
    html_spec.urls.append (html_pages[3])
    html_spec.urls.append (html_pages[4])
    html_spec.urls.append (html_pages[5])
    html_spec.urls.append (html_pages[6])

    pipeline_items = pipeline.search (youtube_spec, html_spec, file_spec)

    assert len(pipeline_items) >= 1

def test_full_boxer_pipeline():

    # Normally we return immediately - only comment out when you want to do a full production build
    return

    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_output_location = 'boxer_output'

    pipeline = BoxerDataPipeline (test_output_location)

    file_spec = PipelineFileSpec()
    file_spec.output_data_name = "api_embeddings_lite.json"
    file_spec.description = "Boxer Pipeline"

    youtube_spec = YouTubePipelineSpec()
    youtube_spec.playlists = youtube_playlists

    html_spec = HtmlDirectedPipelineSpec()
    html_spec.urls = html_pages

    pipeline_items = pipeline.search (youtube_spec, html_spec, file_spec)

    assert len(pipeline_items) >= 1
****************************************

****************************************
Waterfall\test\test_chunker.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import pytest
import os
import shutil
import sys
import logging
import json

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.workflow import PipelineItem
from src.chunker import Chunker
from src.html_file_downloader import HtmlFileDownloader

# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    shutil.rmtree(str(dir_path))

def test_basic (test_output_dir):
    test_output_location = test_output_dir

    sumchunkerariser = Chunker (test_output_location)
    assert sumchunkerariser.output_location == test_output_location 

def test_with_output (test_output_dir):
    test_root = os.path.dirname(__file__)
    test_path = os.path.join (test_root, 'simple_test.html')
    os.chdir (test_root)
    test_output_location = test_output_dir
    
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path

    downloader = HtmlFileDownloader (test_output_location)
    enriched_text: PipelineItem = downloader.download (pipeline_item) 

    chunker = Chunker (test_output_location)
    chunks : PipelineItem = chunker.chunk (enriched_text, 0, 0)  

    assert len(chunks) == 1

def test_long (test_output_dir):
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_path = 'simple_test.html'
    test_output_location = test_output_dir
    
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path

    downloader = HtmlFileDownloader (test_output_location)
    enriched_text: PipelineItem = downloader.download (pipeline_item) 

    chunker = Chunker (test_output_location)

    max = 15
    i = 0
    long_text = "this is going to be long "
    while i < max:
       long_text = long_text + long_text
       i = i + 1

    enriched_text.text = long_text
    chunks_overlapped : list[PipelineItem] = chunker.chunk (enriched_text, 0, 0)  

    assert len(chunks_overlapped) > 1

def test_long_with_overlap (test_output_dir):
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_path = 'simple_test.html'
    test_output_location = test_output_dir
    
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path

    downloader = HtmlFileDownloader (test_output_location)
    enriched_text: PipelineItem = downloader.download (pipeline_item) 

    chunker = Chunker (test_output_location)

    max = 15
    i = 0
    long_text = "this is going to be long "
    while i < max:
       long_text = long_text + long_text
       i = i + 1

    enriched_text.text = long_text
    chunks : list[PipelineItem] = chunker.chunk (enriched_text, 0, 0)      
    chunks_overlapped : list[PipelineItem] = chunker.chunk (enriched_text, 0, 1024)  

    assert len(chunks_overlapped) > len (chunks)

def test_long_overlap (test_output_dir):
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_path = 'simple_test.html'
    test_output_location = test_output_dir
    
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path

    downloader = HtmlFileDownloader (test_output_location)
    enriched_text: PipelineItem = downloader.download (pipeline_item) 

    chunker = Chunker (test_output_location)

    max = 1
    i = 0
    long_text = "this is going to be long but also needs to be long enough so we can see overlap errors when degugging and also needs to be more than 20 words"
    while i < max:
       long_text = long_text + long_text
       i = i + 1

    enriched_text.text = long_text  
    chunk_words = 20
    overlap_words = 5   
    chars_per_word = 4
    chunks_overlapped : list[PipelineItem] = chunker.chunk (enriched_text, chunk_words, overlap_words) 

    chunk_0 = chunks_overlapped[0].text
    chunk_1 = chunks_overlapped[1].text
    length = len(chunk_0)
    last_block = chunk_0[length-(overlap_words * chars_per_word):length]

    start_point = chunk_1.find (last_block)
    test_depth = (overlap_words * chars_per_word * 4)

    assert  start_point < test_depth
****************************************

****************************************
Waterfall\test\test_cluster_analyser.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import pytest
import os
import shutil
import sys
import logging

# Set paths tp find the 'src' directory
test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.workflow import PipelineItem
from src.cluster_analyser import ClusterAnalyser
from src.html_file_downloader import HtmlFileDownloader
from src.summariser import Summariser
from src.embedder import Embedder

# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    shutil.rmtree(str(dir_path))

def test_basic (test_output_dir):
    test_path = 'test'
    test_output_location = test_output_dir

    items: list [PipelineItem] = []
    item: PipelineItem = PipelineItem()
    item.path = test_path
    item.embedding = [1.0,2.0]   
    items.append (item)
        
    analyser = ClusterAnalyser (test_output_location, 2)

    assert analyser.output_location == test_output_location
  

def test_with_output (test_output_dir):
    
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_paths = ['cluster_test_1.html', 'cluster_test_2.html', 'cluster_test_3.html', 'cluster_test_4.html', 'cluster_test_5.html']
    test_output_location = 'test_output'

    items: list [PipelineItem] = []
 
    for test_path in test_paths:
       item: PipelineItem = PipelineItem() 
       item.path = test_path

       downloader = HtmlFileDownloader (test_output_location)
       item = downloader.download (item) 

       summariser = Summariser (test_output_location)   
       item = summariser.summarise (item) 

       embedder = Embedder (test_output_location)
       item = embedder.embed (item)   
       
       items.append (item)

    cluster_analyser = ClusterAnalyser (test_output_location, 2) 
    cluster_labels = cluster_analyser.analyse (items)

    assert len(cluster_labels) == len (items)
****************************************

****************************************
Waterfall\test\test_db_repository.py
****************************************
''' Tests for the DB API '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import sys
import logging

from src.workflow import PipelineItem
from src.db_repository import DbRepository

test_root = os.path.dirname(__file__)
parent = os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)


def test_basic():
    ''' Test construction '''
    application_id = "TestApplication"
    test_context = 'TestContext'
    repository = DbRepository(application_id, test_context)
    assert repository.context_id == test_context


def test_does_not_exist():
    ''' Test non-existence '''
    test_path = 'fail_test.html'

    application_id = "TestApplication"
    test_context = 'TestContext'
    repository = DbRepository(application_id, test_context)
    exists = repository.exists(test_path)

    assert not exists


def test_save():
    ''' Test save '''
    item = PipelineItem()
    item.path = 'https://microsoft.com'
    item.summary = 'Summary'
    item.embedding = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]

    application_id = "TestApplication"
    test_context = 'TestContext'
    repository = DbRepository(application_id, test_context)
    saved = repository.save(item)

    assert saved


def test_save_exists():
    ''' Test save & then that it exists '''

    item = PipelineItem()
    item.path = 'https://microsoft.com'
    item.summary = 'Summary'
    item.embedding = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]

    application_id = "TestApplication"
    test_context = 'TestContext'
    repository = DbRepository(application_id, test_context)
    saved = repository.save(item)

    exists = False

    if saved:
        exists = repository.exists(item.path)

    assert saved
    assert exists


def test_save_load():
    ''' Test save & then that it can be loaded '''

    item = PipelineItem()
    item.path = 'https://microsoft.com'
    item.summary = 'Summary'
    item.embedding = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]

    application_id = "TestApplication"
    test_context = 'TestContext'
    repository = DbRepository(application_id, test_context)
    saved = repository.save(item)

    loaded = False

    if saved:
        loaded = repository.find(item.path)

    assert saved
    assert loaded
    assert loaded.path == item.path
    assert loaded.embedding == item.embedding
    assert loaded.summary == item.summary
****************************************

****************************************
Waterfall\test\test_embedder.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import pytest
import os
import shutil
import sys
import logging

# Set paths tp find the 'src' directory
test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.workflow import PipelineItem
from src.embedder import Embedder
from src.html_file_downloader import HtmlFileDownloader

# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    shutil.rmtree(str(dir_path))

def test_basic (test_output_dir):
    test_output_location = test_output_dir

    embedder = Embedder (test_output_location) 
    assert embedder.output_location == test_output_location 

def test_with_output (test_output_dir):
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_path = 'simple_test.html'
    test_output_location = test_output_dir

    pipeline_item = PipelineItem()
    pipeline_item.path = test_path

    downloader = HtmlFileDownloader (test_output_location)
    enriched_text: PipelineItem = downloader.download (pipeline_item) 

    embedder = Embedder (test_output_location)
    enriched_embedding : PipelineItem = embedder.embed (enriched_text)    
    assert len(enriched_embedding.embedding) > 0
****************************************

****************************************
Waterfall\test\test_embedding_finder.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import pytest
import os
import shutil
import sys
import logging

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.workflow import PipelineItem
from src.embedding_finder import EmbeddingFinder
from src.html_file_downloader import HtmlFileDownloader
from src.summariser import Summariser
from src.embedder import Embedder

# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    shutil.rmtree(str(dir_path))

def test_basic (test_output_dir):

    embeddings = []
    proxy_embedding = 0.0 * 10
    embeddings.append (proxy_embedding)
        
    finder = EmbeddingFinder (embeddings, test_output_dir)

    assert finder.embeddings == embeddings  

def test_with_output (test_output_dir):
    
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_paths = ['cluster_test_1.html', 'cluster_test_2.html', 'cluster_test_3.html', 'cluster_test_4.html', 'cluster_test_5.html']
    test_output_location = test_output_dir

    texts = []
    embeddings = []

    for test_path in test_paths:
       item: PipelineItem = PipelineItem() 
       item.path = test_path

       downloader = HtmlFileDownloader (test_output_location)
       item = downloader.download (item) 
       texts.append(item.text)

       summariser = Summariser (test_output_location)   
       item = summariser.summarise (item) 

       embedder = Embedder (test_output_location)
       item = embedder.embed (item)   

       embeddings.append (item.embedding)

    embedding_finder = EmbeddingFinder (embeddings, test_output_dir) 
    found = embedding_finder.find_nearest (texts[0])

    assert len(found) > 0
****************************************

****************************************
Waterfall\test\test_embedding_repository.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import pytest
import os
import shutil
import sys
import logging

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.embedder_repository_facade import EmbeddingRespositoryFacade

# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output_file")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    os.chdir ("..")    
    shutil.rmtree(str(dir_path))

def test_basic (test_output_dir):
    test_output_location = test_output_dir
    repository = EmbeddingRespositoryFacade (test_output_location)
    assert repository.output_location == test_output_location   

def test_with_output (test_output_dir):

    os.chdir (test_output_dir)
    test_path = 'pass_test.html'
    test_output_location = test_output_dir
    test = [0.0, 1.0]

    repository = EmbeddingRespositoryFacade (test_output_location)  
    repository.save (test_path, test)
    exists = repository.exists (test_path)
    caught = False
    try:
       saved = repository.load (test_path)
    except:
        caught = True

    assert exists == True
    assert caught == False
    assert saved == test

def test_with_no_output (test_output_dir):

    os.chdir (test_output_dir)
    test_path = 'fail_test.html'
    test_output_location = test_output_dir
    test = [0.0, 1.0]

    repository = EmbeddingRespositoryFacade (test_output_location)  
    try:
       saved = repository.load (test_path)
    except:
        caught = True

    assert caught == True
****************************************

****************************************
Waterfall\test\test_errors.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import sys
import logging

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

from src.workflow import PipelineItem
from src.summariser import Summariser

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

def test_basic ():

    logger.error('Error')  
    logger.warning ('Warning')
    logger.info ('Info')
    logger.debug ('Debug')

    assert(True)

def test_with_output ():
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_path = 'simple_test.html'
    test_output_location = "test+output"
    
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path

    pipeline_item.text = "Let’s be real, the war has started, a former minister tells me. What happens in the Middle East never stays in the Middle East.\
It’s hard not to be moved by the burning conflict – the killing of Israelis by Hamas almost a year ago and agony of the families of hostages snatched; the killing of thousands of Gazans by Israel in its response and the terrible suffering there.\
And now Lebanon, where Israel has struck again after almost a year of cross-border hostilities, killing hundreds in air strikes against Hezbollah. Hundreds of thousands more civilians are on the move, desperate to find safety.\
But it can feel bewildering, and far away. So why does it matter at home?\
There’s the humanitarian horror, says a former diplomat. And of course there are many families in the UK worried about the safety of friends or relatives still in Lebanon, Israel and Gaza. There is a potential bump in the number of refugees likely to head for Europe from Lebanon if all-out war begins.\
The conflict has stirred tensions here as well. We see it on our streets, the former minister says, whether that’s at Gaza protests, the rise in antisemitism or even a handful of pro-Palestinian politicians winning seats in Parliament.\
If - as US President Joe Biden has acknowledged in public - Israel goes ahead and hits Iran’s oil industry, the costs could hit us all.\
The price of oil jumped 5% after Biden’s remarks. Iran is the seventh biggest oil producer in the world. Just at a time when the world has been getting used to inflation cooling down, spiralling costs of energy could pump it right back up again and we’d all feel it.\
One source suggested if the conflict keeps intensifying, the Iranians might block the crucial Strait of Hormuz to show their power which could, they suggest, tip us into a 70s style crisis.\
Around 20% of the world’s oil passes through the narrow channel of water. It’s the pocket book effect, says another Whitehall source. The impact on the economy could be huge.\
So what can the UK do about a hellishly complicated situation, especially with a new government that is still finding its feet? There’s the practical, the defence, and the diplomatic."

    summariser = Summariser (test_output_location)
    enriched_summary : PipelineItem = summariser.summarise (pipeline_item)  

    assert len(enriched_summary.summary) > 0
****************************************

****************************************
Waterfall\test\test_file_repository.py
****************************************
''' Tests for the File System API '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports

import os
import shutil
import sys
import logging
import pytest

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.file_repository import FileRespository

# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output_file")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    os.chdir ("..")
    shutil.rmtree(str(dir_path))

def test_basic (test_output_dir):
    test_output_location = test_output_dir
    repository = FileRespository (test_output_location)
    assert repository.output_location == test_output_location   

def test_with_output (test_output_dir):

    os.chdir (test_output_dir)
    test_path = 'pass_test.html'
    test_extention = "text"
    test_output_location = test_output_dir
    text = "Here is some text"

    repository = FileRespository (test_output_location)  
    repository.save (test_path, test_extention, text)
    exists = repository.exists (test_path, test_extention)
    saved = repository.load (test_path, test_extention)

    assert exists == True
    assert saved == text

def test_with_no_output (test_output_dir):

    os.chdir (test_output_dir)
    test_path = 'fail_test.html'
    test_extention = "text"
    test_output_location = test_output_dir
    text = "Here is some text"

    repository = FileRespository (test_output_location)  
    exists = repository.exists (test_path, test_extention)
    saved = repository.load (test_path, test_extention)

    assert exists == False
    assert saved != text
****************************************

****************************************
Waterfall\test\test_html_file_downloader.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import pytest
import os
import shutil
import sys
import logging

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.workflow import PipelineItem
from src.html_file_downloader import HtmlFileDownloader

# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    shutil.rmtree(str(dir_path))    

def test_basic (test_output_dir):
    test_output_location = test_output_dir
    downloader = HtmlFileDownloader (test_output_location)
    assert downloader.output_location == test_output_location   


def test_with_output (test_output_dir):
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_path = 'simple_test.html'
    test_output_location = test_output_dir

    downloader = HtmlFileDownloader (test_output_location)
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path

    enriched : PipelineItem = downloader.download (pipeline_item)    

    assert len(enriched.text) > 0


def test_connected (test_output_dir):
    test_path = 'https://openai.com/'
    test_output_location = test_output_dir

    downloader = HtmlFileDownloader (test_output_location)
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path

    enriched : PipelineItem = downloader.download (pipeline_item) 
      
    assert len(enriched.text) > 0
****************************************

****************************************
Waterfall\test\test_html_link_crawler.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import shutil
import sys
import logging
import pytest

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.workflow import PipelineItem
from src.html_link_crawler import HtmlLinkCrawler

# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    shutil.rmtree(str(dir_path))

def test_basic (test_output_dir):
    test_path = 'test'
    test_output_location = test_output_dir
    crawler = HtmlLinkCrawler (test_output_location, 5)
    assert crawler.output_location == test_output_location
    assert crawler.max_depth == 5    

def test_with_output (test_output_dir):
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_path = 'simple_test.html'
    test_output_location = test_output_dir

    crawler = HtmlLinkCrawler (test_output_location, 5)
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path
    links = crawler.crawl (pipeline_item)    
    assert len(links) == 1


def test_with_one_recursion(test_output_dir):
    test_root = os.path.dirname(__file__)
    test_path = os.path.join (test_root, 'two.html')    
    os.chdir (test_root)

    test_output_location = test_output_dir

    crawler = HtmlLinkCrawler (test_output_location, 5)
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path
    links = crawler.crawl (pipeline_item)     
    assert len(links) == 2

def test_with_two_recursions(test_output_dir):
    test_root = os.path.dirname(__file__)
    test_path = os.path.join (test_root, 'three.html')        
    os.chdir (test_root)

    test_output_location = test_output_dir

    crawler = HtmlLinkCrawler (test_output_location, 5)
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path
    links = crawler.crawl (pipeline_item)   
    assert len(links) == 3

def test_many_sublinks(test_output_dir):
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_path = 'https://course.fast.ai/'  
    test_output_location = test_output_dir

    crawler = HtmlLinkCrawler (test_output_location, 5)
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path
    links = crawler.crawl (pipeline_item)   
    assert len(links) > 5


def test_mad_page(test_output_dir):
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_path = 'https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/'  
    test_output_location = test_output_dir

    crawler = HtmlLinkCrawler (test_output_location, 5)
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path
    links = crawler.crawl (pipeline_item)   
    assert len(links) == 1
****************************************

****************************************
Waterfall\test\test_summariser.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import pytest
import os
import shutil
import sys
import logging

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.workflow import PipelineItem
from src.summariser import Summariser
from src.html_file_downloader import HtmlFileDownloader

# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    shutil.rmtree(str(dir_path))

def test_basic (test_output_dir):
    test_output_location = test_output_dir

    summariser = Summariser (test_output_location)
    assert summariser.output_location == test_output_location 

def test_with_output (test_output_dir):
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_path = 'simple_test.html'
    test_output_location = test_output_dir
    
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path

    downloader = HtmlFileDownloader (test_output_location)
    enriched_text: PipelineItem = downloader.download (pipeline_item) 

    summariser = Summariser (test_output_location)
    enriched_summary : PipelineItem = summariser.summarise (enriched_text)  

    assert len(enriched_summary.summary) > 0
****************************************

****************************************
Waterfall\test\test_summarise_fail_suppressor.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import pytest
import os
import shutil
import sys
import logging

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.workflow import PipelineItem
from src.summarise_fail_suppressor import SummariseFailSuppressor
from src.html_file_downloader import HtmlFileDownloader

# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    shutil.rmtree(str(dir_path))

def test_basic (test_output_dir):
    test_output_location = test_output_dir

    summariser = SummariseFailSuppressor (test_output_location)
    assert summariser.output_location == test_output_location 

def test_with_no_suppression ():
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_path = 'simple_test.html'
    test_output_location = test_output_dir
    
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path 
    pipeline_item.summary = "This article explains how generative AI can drive customer value growth in various areas such as product development, marketing, and customer service. It discusses the challenges of implementing generative AI and mentions that Accenture is using AI to transform its operations."

    summariser = SummariseFailSuppressor (test_output_location)
    enriched : PipelineItem = summariser.should_suppress (pipeline_item)  

    assert enriched 

def test_with_suppression (test_output_dir):
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_path = 'simple_test.html'
    test_output_location = test_output_dir
    
    pipeline_item = PipelineItem()
    pipeline_item.path = test_path 
    pipeline_item.summary = "Im sorry, but it seems that the text you provided is not the main body of the text but rather website navigation and cookie preferences. Therefore, I cannot provide a summary."

    summariser = SummariseFailSuppressor (test_output_location)
    enriched : PipelineItem = summariser.should_suppress (pipeline_item)  

    assert enriched is None
****************************************

****************************************
Waterfall\test\test_summary_repository.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import pytest
import os
import shutil
import sys
import logging

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.summary_repository_facade import SummaryRespositoryFacade

# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output_file")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    os.chdir ("..")    
    shutil.rmtree(str(dir_path))

def test_basic (test_output_dir):
    test_output_location = test_output_dir
    repository = SummaryRespositoryFacade (test_output_location)
    assert repository.output_location == test_output_location   

def test_with_output (test_output_dir):

    os.chdir (test_output_dir)
    test_path = 'pass_test.html'
    test_output_location = test_output_dir
    text = "Here is some text"

    repository = SummaryRespositoryFacade (test_output_location)  
    repository.save (test_path, text)
    exists = repository.exists (test_path)
    saved = repository.load (test_path)

    assert exists == True
    assert saved == text

def test_with_no_output (test_output_dir):

    os.chdir (test_output_dir)
    test_path = 'fail_test.html'
    test_output_location = test_output_dir
    text = "Here is some text"

    repository = SummaryRespositoryFacade (test_output_location)  
    exists = repository.exists (test_path)
    saved = repository.load (test_path)

    assert exists == False
    assert saved != text
****************************************

****************************************
Waterfall\test\test_text_repository.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd
''' Tests for the text repository API '''
# Standard Library Imports
import pytest
import os
import shutil
import sys
import logging

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.text_repository_facade import TextRespositoryFacade

# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output_text")
    logger.info("Created temporary test output directory: %s", dir_path)
    yield str(dir_path)
    # Clean up after the test
    logger.info("Cleaning up test output directory: %s", dir_path)
    os.chdir ("..")    
    shutil.rmtree(str(dir_path))

def test_basic (test_output_dir):
    test_output_location = test_output_dir
    repository = TextRespositoryFacade (test_output_location)
    assert repository.output_location == test_output_location   

def test_with_output (test_output_dir):

    os.chdir (test_output_dir)
    test_path = 'pass_test.html'
    test_output_location = test_output_dir
    text = "Here is some text"

    repository = TextRespositoryFacade (test_output_location)  
    repository.save (test_path, text)
    exists = repository.exists (test_path)
    saved = repository.load (test_path)

    assert exists == True
    assert saved == text

def test_with_no_output (test_output_dir):

    os.chdir (test_output_dir)
    test_path = 'fail_test.html'
    test_output_location = test_output_dir
    text = "Here is some text"

    repository = TextRespositoryFacade (test_output_location)  
    exists = repository.exists (test_path)
    saved = repository.load (test_path)

    assert exists == False
    assert saved != text
****************************************

****************************************
Waterfall\test\test_theme_finder.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import sys
import logging

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.workflow import PipelineItem
from src.theme_finder import ThemeFinder
from src.summariser import Summariser
from src.html_file_downloader import HtmlFileDownloader

def test_basic ():
    test_text = "This is some text"

    summariser = ThemeFinder  ()
    assert summariser != None

def test_with_output ():
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_paths = ['cluster_test_4.html','cluster_test_5.html']
    test_output_location = 'test_output'

    accumulated_summary = ""
    for test_path in test_paths:
       item: PipelineItem = PipelineItem() 
       item.path = test_path

       downloader = HtmlFileDownloader (test_output_location)
       item = downloader.download (item) 

       summariser = Summariser (test_output_location)
       item = summariser.summarise (item)    

       accumulated_summary = accumulated_summary + "\n\n" + item.summary

    theme_finder = ThemeFinder ()
    theme = theme_finder.find_theme (accumulated_summary, 15)    
    assert len(theme) > 0
****************************************

****************************************
Waterfall\test\test_waterfall_pipeline.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd
''' Tests for the entite Waterfall pipeline '''
# Standard Library Imports
import os
import logging

import pytest

from src.workflow import WebSearchPipelineSpec, FileDirectedPipelineSpec
from src.waterfall_pipeline import WaterfallDataPipeline, PipelineSpec
from src.web_searcher import (AI_SUPPLY_STACK_SEARCH_ENGINE_ID,
                              AI_DEMAND_STACK_SEARCH_ENGINE_ID,
                              AI_TELECOM_SEARCH_ENGINE_ID,
                              AI_NATIONWIDE_SEARCH_ENGINE_ID,
                              AI_BNY_SEARCH_ENGINE_ID)

test_root = os.path.dirname(__file__)

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

def test_basic ():
    test_output_location = 'test_output'
    pipeline = WaterfallDataPipeline (test_output_location)
    assert pipeline.output_location == test_output_location

@pytest.mark.timeout(9000)
def test_with_search_supply ():
    os.chdir (test_root)
    test_output_location = 'supply_output'

    pipeline = WaterfallDataPipeline (test_output_location)

    pipeline_spec = WebSearchPipelineSpec()
    pipeline_spec.search_key = AI_SUPPLY_STACK_SEARCH_ENGINE_ID
    pipeline_spec.pages = 1
    pipeline_spec.clusters = 3
    pipeline_spec.clusters_in_summary = 2
    pipeline_spec.description = "GenAI Supply Side"
    pipeline_spec.mail_to = "jon@braidtech.ai"
    pipeline_spec.output_chart_name = 'supply_cluster.html'
    pipeline_spec.output_data_name = "supply_cluster_output.json"

    links = pipeline.search_dynamic (pipeline_spec)
    assert len(links) >= 1

@pytest.mark.timeout(9000)
def test_with_search_demand ():
    os.chdir (test_root)
    test_output_location = 'demand_output'

    pipeline = WaterfallDataPipeline (test_output_location)

    pipeline_spec = WebSearchPipelineSpec()
    pipeline_spec.search_key = AI_DEMAND_STACK_SEARCH_ENGINE_ID
    pipeline_spec.pages = 1
    pipeline_spec.clusters = 3
    pipeline_spec.clusters_in_summary = 2
    pipeline_spec.description = "GenAI Demand Side"
    pipeline_spec.mail_to = "jon@braidtech.ai"
    pipeline_spec.output_chart_name = 'demand_cluster.html'
    pipeline_spec.output_data_name = "demand_cluster_output.json"

    links = pipeline.search_dynamic (pipeline_spec)
    assert len(links) >= 1

@pytest.mark.timeout(9000)
def test_with_search_telecom ():
    os.chdir (test_root)
    test_output_location = 'telecom_output'

    pipeline = WaterfallDataPipeline (test_output_location)

    pipeline_spec = WebSearchPipelineSpec()
    pipeline_spec.search_key = AI_TELECOM_SEARCH_ENGINE_ID
    pipeline_spec.pages = 1
    pipeline_spec.clusters = 3
    pipeline_spec.clusters_in_summary = 2
    pipeline_spec.description = "GenAI Telecoms"
    pipeline_spec.mail_to = "jon@braidtech.ai"
    pipeline_spec.output_chart_name = 'telco_cluster.html'
    pipeline_spec.output_data_name = "telco_cluster_output.json"

    links = pipeline.search_dynamic (pipeline_spec)
    assert len(links) >= 1

@pytest.mark.timeout(9000)
def test_with_search_nationwide ():
    os.chdir (test_root)
    test_output_location = 'nationwide_output'

    pipeline = WaterfallDataPipeline (test_output_location)

    pipeline_spec = WebSearchPipelineSpec()
    pipeline_spec.search_key = AI_NATIONWIDE_SEARCH_ENGINE_ID
    pipeline_spec.pages = 1
    pipeline_spec.clusters = 3
    pipeline_spec.clusters_in_summary = 2
    pipeline_spec.description = "GenAI Nationwide"
    pipeline_spec.mail_to = "jon@braidtech.ai"
    pipeline_spec.output_chart_name = 'nationwide_cluster.html'
    pipeline_spec.output_data_name = "nationwide_cluster_output.json"

    links = pipeline.search_dynamic (pipeline_spec)
    assert len(links) >= 1

@pytest.mark.timeout(15000)
def test_with_search_bny ():
    os.chdir (test_root)
    test_output_location = 'bny_output'

    pipeline = WaterfallDataPipeline (test_output_location)

    pipeline_spec = WebSearchPipelineSpec()
    pipeline_spec.search_key = AI_BNY_SEARCH_ENGINE_ID
    pipeline_spec.pages = 1
    pipeline_spec.clusters = 3
    pipeline_spec.clusters_in_summary = 2
    pipeline_spec.description = "GenAI BNY"
    pipeline_spec.mail_to = "jon@braidtech.ai"
    pipeline_spec.output_chart_name = 'bny_cluster.html'
    pipeline_spec.output_data_name = "bny_cluster_output.json"

    links = pipeline.search_dynamic (pipeline_spec)
    assert len(links) >= 1

def test_with_search_vf_survey_01 ():
    os.chdir (test_root)
    test_output_location = 'vf_survey_01_output'

    pipeline = WaterfallDataPipeline (test_output_location)

    pipeline_spec = PipelineSpec()
    pipeline_spec.clusters = 3
    pipeline_spec.clusters_in_summary = 3
    pipeline_spec.description = "Vodafone Cohort 1 Survey 1"
    pipeline_spec.output_chart_name = 'vf_survey_01.html'
    pipeline_spec.output_data_name = "vf_survey_01_output.json"

    file_spec = FileDirectedPipelineSpec()
    file_spec.files = ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10"]

    links = pipeline.search_static (pipeline_spec, file_spec)
    assert len(links) >= 1
****************************************

****************************************
Waterfall\test\test_web_searcher.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import sys
import logging

from src.workflow import WebSearchPipelineSpec

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.waterfall_pipeline import WebSearcher
from src.web_searcher import AI_SUPPLY_STACK_SEARCH_ENGINE_ID

def test_basic ():
    test_output_location = 'test_output'
    searcher = WebSearcher (test_output_location)
    assert searcher.output_location == test_output_location 

def test_with_search ():
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_output_location = 'test_output'

    searcher = WebSearcher (test_output_location)
    pipeline = WebSearchPipelineSpec()
    pipeline.search_key = AI_SUPPLY_STACK_SEARCH_ENGINE_ID
    pipeline.pages = 1
    pipeline_items = searcher.search (pipeline)    
    assert len(pipeline_items) >= 1
****************************************

****************************************
Waterfall\test\test_workflow.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
from src.workflow import WebSearchPipelineSpec, PipelineItem, Theme
import os
import sys
import logging

test_root = os.path.dirname(__file__)
parent = os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)


def test_pipeline_item():
    item = PipelineItem()
    item.path = "https://microsoft.com"
    item.summary = "Summary"
    item.embedding = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]

    caught = False
    try:
        item.wont_work = ""
    except TypeError:
        caught = True

    assert caught == True


def test_theme():
    item = PipelineItem()
    items = [item]

    theme = Theme()
    theme.short_description = "Short"
    theme.long_description = "Long long long"
    theme.example_pipeline_items = items

    caught = False
    try:
        theme.wont_work = ""
    except TypeError:
        caught = True
    assert len(theme.example_pipeline_items) == 1
    assert caught == True


def test_pipeline():
    pipeline = WebSearchPipelineSpec()
    items = [pipeline]

    theme = Theme()
    theme.short_description = "Short"
    theme.long_description = "Long long long"
    theme.example_pipeline_items = items
    themes = [theme]

    pipeline = WebSearchPipelineSpec()
    pipeline.search_key = "1234"
    pipeline.description = "Description"
    pipeline.themes = themes
    pipeline.output_chart_name = "test.html"

    caught = False
    try:
        pipeline.wont_work = ""
    except TypeError:
        caught = True

    assert len(pipeline.themes) == 1
    assert caught == True
****************************************

****************************************
Waterfall\test\test_youtube_playlist.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import sys
import logging

from src.workflow import YouTubePipelineSpec

test_root = os.path.dirname(__file__)
parent= os.path.abspath(os.path.join(test_root, '..'))
src_dir = os.path.join(parent, 'src')
sys.path.extend([parent, src_dir])

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

from src.youtube_searcher import YoutubePlaylistSearcher
from src.youtube_transcript_downloader import YouTubeTranscriptDownloader
from src.boxer_sources import youtube_playlists

def test_basic ():
    test_output_location = 'test_output'
    searcher = YoutubePlaylistSearcher (test_output_location)
    assert searcher.output_location == test_output_location 

def test_with_search ():
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_output_location = 'test_output'

    searcher = YoutubePlaylistSearcher (test_output_location)
    pipeline = YouTubePipelineSpec()
    pipeline.playlists = youtube_playlists
    pipeline_items = searcher.search (pipeline)    
    assert len(pipeline_items) >= 1   

def test_download():
    test_root = os.path.dirname(__file__)
    os.chdir (test_root)
    test_output_location = 'test_output'

    searcher = YoutubePlaylistSearcher (test_output_location)
    downloader = YouTubeTranscriptDownloader (test_output_location)
    pipeline = YouTubePipelineSpec()

    pipeline.playlists = []
    pipeline.playlists.append (youtube_playlists[0])
    pipeline_items = searcher.search (pipeline)  

    for item in pipeline_items:
       item = downloader.download (item)
       assert len(item.text) >= 1 

    assert len(pipeline_items) >= 1
****************************************

****************************************
Waterfall\test\bny_output\www.investmentweek.co.uk
****************************************

****************************************

****************************************
Waterfall\test\boxer_output\huyenchip.com_ml-interviews-book_contents_8.1.1-overview
****************************************

****************************************

****************************************
Waterfall\test\telecom_output\courses.nvidia.com_courses_course-v1
****************************************

****************************************

****************************************
Waterfall\test\telecom_output\learn.nvidia.com_courses_course-detailcourse_id_course-v1
****************************************

****************************************
