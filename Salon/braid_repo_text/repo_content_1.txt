****************************************
BraidApi.code-workspace
****************************************
{
	"folders": [
		{
			"path": "Api"
		},
		{
			"path": "."
		}
	],
   "settings": {
      "debug.internalConsoleOptions": "neverOpen"
   }
}
****************************************

****************************************
LICENSE
****************************************
                    GNU AFFERO GENERAL PUBLIC LICENSE
                       Version 3, 19 November 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU Affero General Public License is a free, copyleft license for
software and other kinds of works, specifically designed to ensure
cooperation with the community in the case of network server software.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
our General Public Licenses are intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  Developers that use our General Public Licenses protect your rights
with two steps: (1) assert copyright on the software, and (2) offer
you this License which gives you legal permission to copy, distribute
and/or modify the software.

  A secondary benefit of defending all users' freedom is that
improvements made in alternate versions of the program, if they
receive widespread use, become available for other developers to
incorporate.  Many developers of free software are heartened and
encouraged by the resulting cooperation.  However, in the case of
software used on network servers, this result may fail to come about.
The GNU General Public License permits making a modified version and
letting the public access it on a server without ever releasing its
source code to the public.

  The GNU Affero General Public License is designed specifically to
ensure that, in such cases, the modified source code becomes available
to the community.  It requires the operator of a network server to
provide the source code of the modified version running there to the
users of that server.  Therefore, public use of a modified version, on
a publicly accessible server, gives the public access to the source
code of the modified version.

  An older license, called the Affero General Public License and
published by Affero, was designed to accomplish similar goals.  This is
a different license, not a version of the Affero GPL, but Affero has
released a new version of the Affero GPL which permits relicensing under
this license.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  "This License" refers to version 3 of the GNU Affero General Public License.

  "Copyright" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  "The Program" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as "you".  "Licensees" and
"recipients" may be individuals or organizations.

  To "modify" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a "modified version" of the
earlier work or a work "based on" the earlier work.

  A "covered work" means either the unmodified Program or a work based
on the Program.

  To "propagate" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To "convey" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays "Appropriate Legal Notices"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The "source code" for a work means the preferred form of the work
for making modifications to it.  "Object code" means any non-source
form of a work.

  A "Standard Interface" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The "System Libraries" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
"Major Component", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The "Corresponding Source" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    "keep intact all notices".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
"aggregate" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A "User Product" is either (1) a "consumer product", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, "normally used" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  "Installation Information" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  "Additional permissions" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered "further
restrictions" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An "entity transaction" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A "contributor" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's "contributor version".

  A contributor's "essential patent claims" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, "control" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a "patent license" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To "grant" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  "Knowingly relying" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is "discriminatory" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Remote Network Interaction; Use with the GNU General Public License.

  Notwithstanding any other provision of this License, if you modify the
Program, your modified version must prominently offer all users
interacting with it remotely through a computer network (if your version
supports such interaction) an opportunity to receive the Corresponding
Source of your version by providing access to the Corresponding Source
from a network server at no charge, through some standard or customary
means of facilitating copying of software.  This Corresponding Source
shall include the Corresponding Source for any work covered by version 3
of the GNU General Public License that is incorporated pursuant to the
following paragraph.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the work with which it is combined will remain governed by version
3 of the GNU General Public License.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU Affero General Public License from time to time.  Such new versions
will be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU Affero General
Public License "or any later version" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU Affero General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU Affero General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    <one line to give the program's name and a brief idea of what it does.>
    Copyright (C) <year>  <name of author>

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as published
    by the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If your software can interact with users remotely through a computer
network, you should also make sure that it provides a way for users to
get its source.  For example, if your program is a web application, its
interface could display a "Source" link that leads users to an archive
of the code.  There are many ways you could offer source, and different
solutions will be better for different programs; see section 13 for the
specific requirements.

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a "copyright disclaimer" for the program, if necessary.
For more information on this, and how to apply and follow the GNU AGPL, see
<https://www.gnu.org/licenses/>.
****************************************

****************************************
pylintrc
****************************************
# This Pylint rcfile contains a best-effort configuration to uphold the
# best-practices and style described in the Google Python style guide:
#   https://google.github.io/styleguide/pyguide.html
#
# Its canonical open-source location is:
#   https://google.github.io/styleguide/pylintrc

[MAIN]

# Files or directories to be skipped. They should be base names, not paths.
ignore=third_party

# Files or directories matching the regex patterns are skipped. The regex
# matches against base names, not paths.
ignore-patterns=

# Pickle collected data for later comparisons.
persistent=no

# List of plugins (as comma separated values of python modules names) to load,
# usually to register additional checkers.
load-plugins=

# Use multiple processes to speed up Pylint.
jobs=4

# Allow loading of arbitrary C extensions. Extensions are imported into the
# active Python interpreter and may run arbitrary code.
unsafe-load-any-extension=no


[MESSAGES CONTROL]

# Only show warnings with the listed confidence levels. Leave empty to show
# all. Valid levels: HIGH, INFERENCE, INFERENCE_FAILURE, UNDEFINED
confidence=

# Enable the message, report, category or checker with the given id(s). You can
# either give multiple identifier separated by comma (,) or put this option
# multiple time (only on the command line, not in the configuration file where
# it should appear only once). See also the "--disable" option for examples.
#enable=

# Disable the message, report, category or checker with the given id(s). You
# can either give multiple identifiers separated by comma (,) or put this
# option multiple times (only on the command line, not in the configuration
# file where it should appear only once).You can also use "--disable=all" to
# disable everything first and then reenable specific checks. For example, if
# you want to run only the similarities checker, you can use "--disable=all
# --enable=similarities". If you want to run only the classes checker, but have
# no Warning level messages displayed, use"--disable=all --enable=classes
# --disable=W"
disable=R,
        abstract-method,
        apply-builtin,
        arguments-differ,
        attribute-defined-outside-init,
        backtick,
        bad-option-value,
        basestring-builtin,
        buffer-builtin,
        c-extension-no-member,
        consider-using-enumerate,
        cmp-builtin,
        cmp-method,
        coerce-builtin,
        coerce-method,
        delslice-method,
        div-method,
        eq-without-hash,
        execfile-builtin,
        file-builtin,
        filter-builtin-not-iterating,
        fixme,
        getslice-method,
        global-statement,
        hex-method,
        idiv-method,
        implicit-str-concat,
        import-error,
        import-self,
        import-star-module-level,
        input-builtin,
        intern-builtin,
        invalid-str-codec,
        locally-disabled,
        long-builtin,
        long-suffix,
        map-builtin-not-iterating,
        misplaced-comparison-constant,
        missing-function-docstring,
        metaclass-assignment,
        next-method-called,
        next-method-defined,
        no-absolute-import,
        no-init,  # added
        no-member,
        no-name-in-module,
        no-self-use,
        nonzero-method,
        oct-method,
        old-division,
        old-ne-operator,
        old-octal-literal,
        old-raise-syntax,
        parameter-unpacking,
        print-statement,
        raising-string,
        range-builtin-not-iterating,
        raw_input-builtin,
        rdiv-method,
        reduce-builtin,
        relative-import,
        reload-builtin,
        round-builtin,
        setslice-method,
        signature-differs,
        standarderror-builtin,
        suppressed-message,
        sys-max-int,
        trailing-newlines,
        unichr-builtin,
        unicode-builtin,
        unnecessary-pass,
        unpacking-in-except,
        useless-else-on-loop,
        useless-suppression,
        using-cmp-argument,
        wrong-import-order,
        xrange-builtin,
        zip-builtin-not-iterating,


[REPORTS]

# Set the output format. Available formats are text, parseable, colorized, msvs
# (visual studio) and html. You can also give a reporter class, eg
# mypackage.mymodule.MyReporterClass.
output-format=text

# Tells whether to display a full report or only the messages
reports=no

# Python expression which should return a note less than 10 (10 is the highest
# note). You have access to the variables errors warning, statement which
# respectively contain the number of errors / warnings messages and the total
# number of statements analyzed. This is used by the global evaluation report
# (RP0004).
evaluation=10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10)

# Template used to display messages. This is a python new-style format string
# used to format the message information. See doc for all details
#msg-template=


[BASIC]

# Good variable names which should always be accepted, separated by a comma
good-names=main,_

# Bad variable names which should always be refused, separated by a comma
bad-names=

# Colon-delimited sets of names that determine each other's naming style when
# the name regexes allow several styles.
name-group=

# Include a hint for the correct naming format with invalid-name
include-naming-hint=no

# List of decorators that produce properties, such as abc.abstractproperty. Add
# to this list to register other decorators that produce valid properties.
property-classes=abc.abstractproperty,cached_property.cached_property,cached_property.threaded_cached_property,cached_property.cached_property_with_ttl,cached_property.threaded_cached_property_with_ttl

# Regular expression matching correct function names
function-rgx=^(?:(?P<exempt>setUp|tearDown|setUpModule|tearDownModule)|(?P<camel_case>_?[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_?[a-z][a-z0-9_]*)||(?P<pascal_case>_?[a-z][a-z0-9_]*))$

# Regular expression matching correct variable names
variable-rgx=^[a-z][a-z0-9_]*$

# Regular expression matching correct constant names
const-rgx=^(_?[A-Z][A-Z0-9_]*|__[a-z0-9_]+__|_?[a-z][a-z0-9_]*)$

# Regular expression matching correct attribute names
attr-rgx=^_{0,2}[a-z][a-z0-9_]*$

# Regular expression matching correct argument names
argument-rgx=^[a-z][a-z0-9_]*$

# Regular expression matching correct class attribute names
class-attribute-rgx=^(_?[A-Z][A-Z0-9_]*|__[a-z0-9_]+__|_?[a-z][a-z0-9_]*)$

# Regular expression matching correct inline iteration names
inlinevar-rgx=^[a-z][a-z0-9_]*$

# Regular expression matching correct class names
class-rgx=^_?[A-Z][a-zA-Z0-9]*$

# Regular expression matching correct module names
module-rgx=^(_?[a-z][a-z0-9_]*|__init__)$

# Regular expression matching correct method names
method-rgx=(?x)^(?:(?P<exempt>_[a-z0-9_]+__|runTest|setUp|tearDown|setUpTestCase|tearDownTestCase|setupSelf|tearDownClass|setUpClass|(test|assert)_*[A-Z0-9][a-zA-Z0-9_]*|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9_]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$

# Regular expression which should only match function or class names that do
# not require a docstring.
no-docstring-rgx=(__.*__|main|test.*|.*test|.*Test)$

# Minimum line length for functions/classes that require docstrings, shorter
# ones are exempt.
docstring-min-length=12


[TYPECHECK]

# List of decorators that produce context managers, such as
# contextlib.contextmanager. Add to this list to register other decorators that
# produce valid context managers.
contextmanager-decorators=contextlib.contextmanager,contextlib2.contextmanager

# List of module names for which member attributes should not be checked
# (useful for modules/projects where namespaces are manipulated during runtime
# and thus existing member attributes cannot be deduced by static analysis. It
# supports qualified module names, as well as Unix pattern matching.
ignored-modules=

# List of class names for which member attributes should not be checked (useful
# for classes with dynamically set attributes). This supports the use of
# qualified names.
ignored-classes=optparse.Values,thread._local,_thread._local

# List of members which are set dynamically and missed by pylint inference
# system, and so shouldn't trigger E1101 when accessed. Python regular
# expressions are accepted.
generated-members=


[FORMAT]

# Maximum number of characters on a single line.
max-line-length=200

# TODO(https://github.com/pylint-dev/pylint/issues/3352): Direct pylint to exempt
# lines made too long by directives to pytype.

# Regexp for a line that is allowed to be longer than the limit.
ignore-long-lines=(?x)(
  ^\s*(\#\ )?<?https?://\S+>?$|
  ^\s*(from\s+\S+\s+)?import\s+.+$)

# Allow the body of an if to be on the same line as the test if there is no
# else.
single-line-if-stmt=yes

# Maximum number of lines in a module
max-module-lines=99999

# String used as indentation unit.  The internal Google style guide mandates 2
# spaces.  Google's externaly-published style guide says 4, consistent with
# PEP 8.  Here, we use 4 spaces, for conformity with many open-sourced Google
# projects (like TensorFlow).
indent-string='    '

# Number of spaces of indent required inside a hanging  or continued line.
indent-after-paren=4

# Expected format of line ending, e.g. empty (any line ending), LF or CRLF.
expected-line-ending-format=


[MISCELLANEOUS]

# List of note tags to take in consideration, separated by a comma.
notes=TODO


[STRING]

# This flag controls whether inconsistent-quotes generates a warning when the
# character used as a quote delimiter is used inconsistently within a module.
check-quote-consistency=yes


[VARIABLES]

# Tells whether we should check for unused import in __init__ files.
init-import=no

# A regular expression matching the name of dummy variables (i.e. expectedly
# not used).
dummy-variables-rgx=^\*{0,2}(_$|unused_|dummy_)

# List of additional names supposed to be defined in builtins. Remember that
# you should avoid to define new builtins when possible.
additional-builtins=

# List of strings which can identify a callback function by name. A callback
# name must start or end with one of those strings.
callbacks=cb_,_cb

# List of qualified module names which can have objects that can redefine
# builtins.
redefining-builtins-modules=six,six.moves,past.builtins,future.builtins,functools


[LOGGING]

# Logging modules to check that the string format arguments are in logging
# function parameter format
logging-modules=logging,absl.logging,tensorflow.io.logging


[SIMILARITIES]

# Minimum lines number of a similarity.
min-similarity-lines=4

# Ignore comments when computing similarities.
ignore-comments=yes

# Ignore docstrings when computing similarities.
ignore-docstrings=yes

# Ignore imports when computing similarities.
ignore-imports=no


[SPELLING]

# Spelling dictionary name. Available dictionaries: none. To make it working
# install python-enchant package.
spelling-dict=

# List of comma separated words that should not be checked.
spelling-ignore-words=

# A path to a file that contains private dictionary; one word per line.
spelling-private-dict-file=

# Tells whether to store unknown words to indicated private dictionary in
# --spelling-private-dict-file option instead of raising a message.
spelling-store-unknown-words=no


[IMPORTS]

# Deprecated modules which should not be used, separated by a comma
deprecated-modules=regsub,
                   TERMIOS,
                   Bastion,
                   rexec,
                   sets

# Create a graph of every (i.e. internal and external) dependencies in the
# given file (report RP0402 must not be disabled)
import-graph=

# Create a graph of external dependencies in the given file (report RP0402 must
# not be disabled)
ext-import-graph=

# Create a graph of internal dependencies in the given file (report RP0402 must
# not be disabled)
int-import-graph=

# Force import order to recognize a module as part of the standard
# compatibility libraries.
known-standard-library=

# Force import order to recognize a module as part of a third party library.
known-third-party=enchant, absl

# Analyse import fallback blocks. This can be used to support both Python 2 and
# 3 compatible code, which means that the block might have code that exists
# only in one or another interpreter, leading to false positives when analysed.
analyse-fallback-blocks=no


[CLASSES]

# List of method names used to declare (i.e. assign) instance attributes.
defining-attr-methods=__init__,
                      __new__,
                      setUp

# List of member names, which should be excluded from the protected access
# warning.
exclude-protected=_asdict,
                  _fields,
                  _replace,
                  _source,
                  _make

# List of valid names for the first argument in a class method.
valid-classmethod-first-arg=cls,
                            class_

# List of valid names for the first argument in a metaclass class method.
valid-metaclass-classmethod-first-arg=mcs

[MASTER]
init-hook='import sys; sys.path.append("/Code/Braid/CommonPy")'
****************************************

****************************************
README.md
****************************************
# Braid Technologies Studio
- [General Information](#general-information)
- [Technologies](#technologies)
- [Key Components](#key-components)
- [Practices](#practices)
- [License](#license)

## General Information

This repo contains Braid's pattern applications, for use by Braid's clients. Click [here](https://notebooklm.google.com/notebook/1c1a155f-8c18-4e66-abd3-9c73b85f024c/audio?pli=1) for an audio overview generated by NotebookLM.

The first pattern is '**Waterfall**'. Waterfall is a text analyser / classifier, build to illustrate a possible ticket-classification system for Braid's clients. It illustrates the following:

- **Cascade** (a small waterfall) - an Edge plug in, that scrapes the current web page test, summarises it, and then classifies the text into one of Business, Technology, Sport, Health, or Politics. This is the 'Cascade' directory. Cascade is written in typescript/javascript. 

- **Waterfall** - a data analysis back end pipeline. This illustrates a date pipline to download web pages, summarise them, and then use cluster analysis to find the most common topics. This is the 'Waterfall' directory. Waterfall is written in Python. 

'**Api**' contains Azure functions that make calls to an Azure hosted OpenAI model to summrise and classify text. Waterfall, Cascade, and Boxer all call Braid Apis for any function requiring server side keys (database or AI model access).

'**ApiTest**' - code generated by Salon to test the Apis from Python classes.

'**CommonTs**' contains typescript utility classes used across both clients & server - especially API definitions and Types used to generate test scripts. Both subsystems are written in Typescript. Both Cascade and Waterfall make calls to the Apis.

'**CommonPy**' contains Python utility classes used to access the typescript server Apis and to hold common code used in multiple apps.

'**Salon**' - (a place where you do Braiding) is a set of scripts to help the engineering process. One script uses the OpenAI Assistant API to generate test code. It processes API definitions written in JSON and generates Python code to test them. The resulting code is in the 'ApiTest' directory. The second script, repo_to_text, scans a directory system and procduces a set of text files containing concatenated code. These files can be loaded into almost any LLM, to use for a 'Chat to your code' assistant. 

'**Boxer**', an AI-enabled learning assistant to help developers build generative AI applications more quickly.  It is a full web front end that passes questions to an LLM, and then enriches them with links to relevant document chunks found in its database of useful material - the A16Z AI Cannon. 

'**Teams**' contains a Teams plug-in that brings Boxer & Waterfall into the teams environment.

'**BoxerEval**' - evals for Boxer. 

## **Technologies**

For front end development Braid uses Typescript (https://www.typescriptlang.org/), using the Microsoft Fluent UI framework (https://react.fluentui.dev/). Tests are written in Mocha (https://mochajs.org/).

For data processing and AI evaluation, Braid uses Python (https://www.python.org/). Tests are written in Pytest (https://docs.pytest.org/en/stable/).

Braid uses Azure for all processing. 

## **Key Components**

1. Document Processing Pipeline:
    - Web scraping (using Beautiful Soup)
    - Text summarization
    - Embedding generation
    - Cluster analysis

2. API Layer:
    - Summarization endpoints
    - Classification services
    - Embedding generation
    - RESTful architecture

3. Testing Framework:
    - Mocha for TypeScript/JavaScript
    - pytest for Python components
    - Automated test generation through Salon

## **Practices**
   
1. Code Organization
    - Core online functionality in TypeScript
    - Use Python for data processing 
    - Maintain clear separation between UI and core logic

2. Testing
    - Write tests for all new features
    - Maintain test coverage above 90%
    - Use appropriate testing frameworks (Mocha for TypeScript, pytest for Python)

3. Documentation
    - Document all public APIs
    - Keep README files updated
    - Include code comments for complex logic

4. Version Control
    - Follow Git branching strategy
    - Write meaningful commit messages
    - Keep PRs focused and manageable

## **Licence**
GNU AFFERO GENERAL PUBLIC LICENSE.

This is intentionally a restrictive licence. The source is  available for non-commercial use (subject to the licence terms as listed, which enable use for learning, self study etc). Commercial use either must abide by the licence terms, which are strong, or a separate licence that enables more normal commercial use & distribution is available from Braid. Contact us for more details mailto:info@braidtech.io.
****************************************

****************************************
Teams.code-workspace
****************************************
{
	"folders": [
		{
			"path": "Teams"
		},
		{
			"path": "."
		}
	],
   "settings": {
      "debug.onTaskErrors": "abort",
      "azureFunctions.stopFuncTaskPostDebug": false,
      "azureFunctions.showProjectWarning": false
   }
}
****************************************

****************************************
Api\.funcignore
****************************************
*.js.map
*.ts
.git*
.vscode
local.settings.json
test
getting_started.md
node_modules/@types/
node_modules/azure-functions-core-tools/
node_modules/typescript/
****************************************

****************************************
Api\eslint.config.mjs
****************************************
// @ts-check

import eslint from '@eslint/js';
import tseslint from 'typescript-eslint';

export default tseslint.config(
  eslint.configs.recommended,
  tseslint.configs.recommended,
);
****************************************

****************************************
Api\README.md
****************************************
API Documentation

**Overview**
This is an Azure Functions-based API layer that centralizes interactions with OpenAI and CosmosDB. The API provides various text processing capabilities including summarization, classification, chunking, and theme detection.

**Text Processing**
- Summarization: Supports different types of content summarization (articles, code, surveys)
- Classification: Categorizes text into predefined categories (Technology, Business, Politics, Health)
- Chunking: Splits large texts into manageable pieces while maintaining context
- Theme Detection: Identifies common themes across text passages
- Embedding: Generates text embeddings using Azure AI services

**Storage & Authentication**
CosmosDB Integration: Handles CRUD operations for various storable objects
Session Management: Validates session keys for secure API access
LinkedIn Authentication: Supports OAuth integration with LinkedIn

**Repository Layer**
The codebase includes several repository implementations:
ActivityRepository
ChunkRepository
PageRepository
Each repository supports standard CRUD operations with session validation.

**Testing Framework**
The project uses Mocha and Expect for testing, with comprehensive test suites for:
Session validation
Text processing functions
Storage operations
API endpoints

**Utility Functions**
Session validation
Error handling
HTTP response formatting
Token generation for Azure services

**Testing**
The codebase includes extensive test coverage for:
Valid/invalid session handling
Text processing accuracy
API response validation
Error handling scenarios

**Deployment**
Deploy to Azure: func azure functionapp publish Braid-Api
Local development: npm start

**Architecture Notes**
Uses Azure Functions for serverless architecture
Implements retry logic for API calls
Centralizes key management and logging
Supports both local and production environments
Implements the repository pattern for data access

For detailed information about specific modules, refer to the individual test files in the test directory and their corresponding implementation files in src/functions
****************************************

****************************************
ApiTest\pytest.ini
****************************************
[pytest]
log_cli = 1
****************************************

****************************************
ApiTest\README.md
****************************************
**ApiTest** is generated source code to test Apis. The **Salon** application was used to generate the source. 

# API Test Suite Documentation

## Overview
This test suite validates various endpoints of a text processing API that handles operations like chunking, classification, embedding, and summarization. The API appears to be running locally on port 7071 and requires session-based authentication.

## Setup Requirements
- Python with pytest and requests libraries
- Environment Variables:
  - `SESSION_KEY`: Required for authentication
  - `BASE_URL`: Typically set to `http://localhost:7071/api`

## Endpoint Test Coverage

### Text Processing Endpoints
1. **Chunk (`/chunk`)**
   - Validates text splitting with configurable size and overlap
   - Tests request structure and response validation

2. **Classify (`/classify`)**
   - Tests text classification functionality
   - Includes validation for both valid and invalid request scenarios

3. **Embed (`/embed`)**
   - Validates vector embedding generation from text input
   - Tests response structure and error handling

4. **Find Theme (`/findtheme`)**
   - Tests theme identification in text
   - Validates required parameters (text and length)

5. **Summarize (`/summarise`)**
   - Tests text summarization capabilities
   - Supports different modes:
     - Standard text summarization
     - Survey response summarization
     - Code summarization
   - Includes edge case handling

### System Endpoints
1. **Enumerate Models (`/enumerateModels`)**
   - Tests model listing functionality
   - Includes schema validation for requests and responses

2. **Enumerate Repositories (`/enumerateRepositories`)**
   - Validates repository ID listing
   - Includes response schema validation

3. **Page Repository (`/getpage`)**
   - Tests page retrieval functionality
   - Validates successful retrieval and error cases

4. **Studio Boxer**
   - Tests Studio Boxer-specific endpoints
   - Includes response structure validation and error handling

## Test Structure
Each endpoint has its own dedicated test file following these common patterns:
- Request validation
- Response structure verification
- Error case handling
- Schema validation where applicable

## Running Tests
Tests can be run using pytest
****************************************

****************************************
Boxer\LICENSE
****************************************
                    GNU AFFERO GENERAL PUBLIC LICENSE
                       Version 3, 19 November 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU Affero General Public License is a free, copyleft license for
software and other kinds of works, specifically designed to ensure
cooperation with the community in the case of network server software.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
our General Public Licenses are intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  Developers that use our General Public Licenses protect your rights
with two steps: (1) assert copyright on the software, and (2) offer
you this License which gives you legal permission to copy, distribute
and/or modify the software.

  A secondary benefit of defending all users' freedom is that
improvements made in alternate versions of the program, if they
receive widespread use, become available for other developers to
incorporate.  Many developers of free software are heartened and
encouraged by the resulting cooperation.  However, in the case of
software used on network servers, this result may fail to come about.
The GNU General Public License permits making a modified version and
letting the public access it on a server without ever releasing its
source code to the public.

  The GNU Affero General Public License is designed specifically to
ensure that, in such cases, the modified source code becomes available
to the community.  It requires the operator of a network server to
provide the source code of the modified version running there to the
users of that server.  Therefore, public use of a modified version, on
a publicly accessible server, gives the public access to the source
code of the modified version.

  An older license, called the Affero General Public License and
published by Affero, was designed to accomplish similar goals.  This is
a different license, not a version of the Affero GPL, but Affero has
released a new version of the Affero GPL which permits relicensing under
this license.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  "This License" refers to version 3 of the GNU Affero General Public License.

  "Copyright" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  "The Program" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as "you".  "Licensees" and
"recipients" may be individuals or organizations.

  To "modify" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a "modified version" of the
earlier work or a work "based on" the earlier work.

  A "covered work" means either the unmodified Program or a work based
on the Program.

  To "propagate" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To "convey" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays "Appropriate Legal Notices"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The "source code" for a work means the preferred form of the work
for making modifications to it.  "Object code" means any non-source
form of a work.

  A "Standard Interface" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The "System Libraries" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
"Major Component", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The "Corresponding Source" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    "keep intact all notices".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
"aggregate" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A "User Product" is either (1) a "consumer product", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, "normally used" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  "Installation Information" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  "Additional permissions" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered "further
restrictions" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An "entity transaction" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A "contributor" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's "contributor version".

  A contributor's "essential patent claims" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, "control" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a "patent license" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To "grant" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  "Knowingly relying" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is "discriminatory" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Remote Network Interaction; Use with the GNU General Public License.

  Notwithstanding any other provision of this License, if you modify the
Program, your modified version must prominently offer all users
interacting with it remotely through a computer network (if your version
supports such interaction) an opportunity to receive the Corresponding
Source of your version by providing access to the Corresponding Source
from a network server at no charge, through some standard or customary
means of facilitating copying of software.  This Corresponding Source
shall include the Corresponding Source for any work covered by version 3
of the GNU General Public License that is incorporated pursuant to the
following paragraph.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the work with which it is combined will remain governed by version
3 of the GNU General Public License.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU Affero General Public License from time to time.  Such new versions
will be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU Affero General
Public License "or any later version" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU Affero General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU Affero General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    <one line to give the program's name and a brief idea of what it does.>
    Copyright (C) <year>  <name of author>

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as published
    by the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If your software can interact with users remotely through a computer
network, you should also make sure that it provides a way for users to
get its source.  For example, if your program is a web application, its
interface could display a "Source" link that leads users to an archive
of the code.  There are many ways you could offer source, and different
solutions will be better for different programs; see section 13 for the
specific requirements.

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a "copyright disclaimer" for the program, if necessary.
For more information on this, and how to apply and follow the GNU AGPL, see
<https://www.gnu.org/licenses/>.
****************************************

****************************************
Boxer\Procfile
****************************************
web:npm start
****************************************

****************************************
Boxer\README.md
****************************************
# Boxer - AI-Powered Chat Application

## Overview
Boxer is a real-time chat application that integrates AI capabilities using Large Language Models (LLMs). The application is built with TypeScript/React and uses the Fluid Framework for real-time collaboration.

## Project Structure

├── core/           # Core business logic and utilities
├── ui/             # UI components and styles
├── test/           # Test cases and utilities


### Core Components

#### Data Models
- `Message.ts` - Represents chat messages with support for streaming
- `Persona.ts` - User profile management
- `SharedEmbedding.ts` - Handles shared embedded content
- `Like.ts` - Manages user reactions

#### Services
- `AIConnection.ts` - Manages interactions with the LLM
- `BraidFluidConnection.ts` - Handles real-time collaboration
- `ActivityRepository.ts` - Stores user activities and message history
- `KeyRetriever.ts` - Manages API key authentication

#### Utilities
- `CaucusFramework.ts` - Framework for managing dynamic collections
- `NotificationFramework.ts` - Observer pattern implementation
- `StreamingFramework.ts` - Handles data streaming
- `Debounce.ts` - Rate limiting utility

### UI Components

#### Main Components
- `AnimatedIconButton.tsx` - Animated UI elements
- `ConversationPane.tsx` - Main chat interface
- `ConversationController.tsx` - Chat logic controller
- `JoinPane.tsx` - Session joining interface

#### Supporting Components
- `MessagePrompt.tsx` - Message input interface
- `MainPageMessage.tsx` - Status message display
- `ConversationMessagePrompt.tsx` - Enhanced message input

## Key Features
1. Real-time chat with AI integration
2. Collaborative document sharing
3. Message reactions and likes
4. User presence tracking
5. Embedded content support
6. Session management
7. Activity tracking

## Getting Started

### Prerequisites
- Node.js (v14 or higher)
- TypeScript
- React

### Installation
1. Clone the repository
2. Install dependencies:


## Architecture

### Data Flow
1. User actions trigger UI components
2. Controllers process actions and update state
3. Fluid Framework syncs changes across clients
4. Activity Repository persists relevant data
5. AI Connection processes LLM requests

### State Management
- Uses React hooks for local state
- Fluid Framework for shared state
- Notification system for cross-component communication

### Testing
- Comprehensive test suite using Mocha
- Unit tests for core functionality
- Integration tests for key features

## Best Practices
1. Use TypeScript for type safety
2. Follow the notification pattern for state updates
3. Implement error handling using custom error classes
4. Use debouncing for performance optimization
5. Write tests for new features

## Common Tasks

### Adding a New Feature
1. Create necessary data models in `/core`
2. Implement business logic
3. Create UI components in `/ui`
4. Add tests in `/test`
5. Update documentation

### Debugging
- Check browser console for errors
- Use the notification system for tracking state changes
- Review activity repository for historical data
- Check AI connection logs for LLM interactions

## Contributing
1. Create a feature branch
2. Write tests for new functionality
3. Update documentation
4. Submit a pull request

## Support
For questions or issues, please refer to:
1. Code documentation
2. Test cases for implementation examples
3. Core utility functions for common operations
****************************************

****************************************
Boxer\tsconfig.tsbuildinfo
****************************************
{"root":["./core/aiconnection.ts","./core/activityrecord.ts","./core/activityrepository.ts","./core/apicalls.ts","./core/asserts.ts","./core/boxerfluidconnection.ts","./core/caucusframework.ts","./core/configstrings.ts","./core/debounce.ts","./core/errors.ts","./core/fluidconnection.ts","./core/iactivityrepository.ts","./core/iactivityrepositoryfactory.ts","./core/iadminrepository.ts","./core/ikeygenerator.ts","./core/ikeygeneratorfactory.ts","./core/icons.ts","./core/joindetails.ts","./core/joinpagevalidator.ts","./core/keyretriever.ts","./core/keys.ts","./core/like.ts","./core/logging.ts","./core/media.ts","./core/message.ts","./core/notificationframework.ts","./core/persona.ts","./core/queue.ts","./core/sharedembedding.ts","./core/streamingframework.ts","./core/utilities.ts","./core/uuidkeygenerator.ts","./ui/animatediconbutton.tsx","./ui/appentry.tsx","./ui/columnstyles.tsx","./ui/conversationcontroller.tsx","./ui/conversationmessageprompt.tsx","./ui/conversationpane.tsx","./ui/joinpane.tsx","./ui/mainpagemessage.tsx","./ui/uistrings.ts","./test/activityrecord.test.ts","./test/adminrespository.test.ts","./test/aiconnection.test.ts","./test/caucus.test.ts","./test/chunk.test.ts","./test/debounce.test.ts","./test/embedding.test.ts","./test/errors.test.ts","./test/joinpagevalidator.test.ts","./test/like.test.ts","./test/message.test.ts","./test/notification.test.ts","./test/persona.test.ts","./test/queue.test.ts","./test/sharedembedding.test.ts","./test/uuid.test.ts","./scripts/make_new_container.ts"],"version":"5.7.2"}
****************************************

****************************************
BoxerEval\README.md
****************************************
# BoxerEval

BoxerEval is a testing framework for evaluating and generating AI-assisted questions using Azure OpenAI services. The framework supports multiple persona-based testing strategies and includes robust evaluation mechanisms.

## 🌟 Features

- Generate enriched questions using GPT models
- Calculate similarity embeddings using OpenAI's embedding models
- Support for multiple professional personas (Developer, Tester, Business Analyst)
- Quality evaluation using Google's Gemini model
- Robust retry mechanisms for API calls
- Comprehensive logging system
- Configurable test scenarios

## 🏗️ Architecture

The project consists of several key components:

### Core Testing Modules (v1-v5)
- `BoxerDataTest_v1.py` through `BoxerDataTest_v5.py`: Progressive versions of the testing framework
- Latest version (`v5`) includes enhanced features like follow-up question generation and improved evaluation metrics

### Supporting Components
- `GeminiEvaluator.py`: Evaluates generated content quality using Google's Gemini LLM
- `PersonaStrategy.py`: Implements different professional personas for question generation
- `TestRunner.py`: CLI interface for running different test scenarios

## 🚀 Getting Started

1. **Setup Environment**
   ```bash
   # Clone the repository
   git clone [repository-url]
   
   # Install dependencies
   pip install azure-openai numpy tenacity google-generative-ai
   ```

2. **Configure API Keys**
   - Set up Azure OpenAI API credentials
   - Configure Google Gemini API key (for evaluation)

3. **Run Tests**
   ```bash
   python TestRunner.py
   ```

## 💻 Usage

The framework supports two main testing modes:

1. **Static Question Tests**
   ```python
   from BoxerDataTest_v5 import run_tests
   run_tests(config, test_destination_dir, source_dir, num_questions, questions, None)
   ```

2. **Persona-Based Tests**
   ```python
   from PersonaStrategy import DeveloperPersonaStrategy
   run_tests(config, test_destination_dir, source_dir, num_questions, None, DeveloperPersonaStrategy())
   ```

## 📊 Output

Test results are saved in JSON format, including:
- Enriched questions
- Follow-up questions
- Similarity scores
- Quality evaluations

## 🔧 Configuration

The framework uses `ApiConfiguration` class to manage:
- API endpoints
- Model selections
- Retry settings
- Logging configurations
****************************************

****************************************
Build\build_subdirs.sh
****************************************
#!/bin/bash

# List of directories to process
directories=("CommonTs" "Api" "Cascade" "WaterfallBrowser" "Boxer" "Teams")

# Iterate through the specified directories
for dir in "${directories[@]}"; do
    if [ -d "$dir" ]; then
        echo "Entering directory: $dir"
        
        # Change to the directory
        cd "$dir"
        
        # Check if package.json exists
        if [ -f "package.json" ]; then
            echo "Running npm run build..."
            npm run build
        else
            echo "No package.json found, skipping..."
        fi
        
        # Go back to the original directory
        cd ..
    else
        echo "Directory $dir not found, skipping..."
    fi
done
****************************************

****************************************
Build\check_module_comments_subdirs.sh
****************************************
#!/bin/bash

# List of directories to process
ts_directories=("CommonTs" "Api" "Cascade" "WaterfallBrowser" "Boxer" "Teams")
#ts_directories=("CommonTs")

py_directories=("CommonPy" "ApiTest" "Waterfall" "BoxerEval")


# Iterate through the specified directories
for dir in "${ts_directories[@]}"; do
    if [ -d "$dir" ]; then
        echo "Entering directory: $dir"
        
        # Change to the directory
        cd "$dir"
        
        # Check if package.json exists
        if [ -f "package.json" ]; then
            echo "Running typescript linter..."
            for file in $(find . -name "*.ts" -not -path "./node_modules/*" -not -path "./dist/*"  -not -path "./src/CommonTs/*"); do      
                #echo "Linting file: $file"                  
                if !(grep -q "@module" $file); then
                    echo "No module comment found in file: $file"
                fi
            done         
        else
            echo "No package.json found, skipping..."
        fi
        
        # Go back to the original directory
        cd ..
    else
        echo "Directory $dir not found, skipping..."
    fi
done


for dir in "${py_directories[@]}"; do
    if [ -d "$dir" ]; then
        echo "Entering directory: $dir"
        cd "$dir"
        echo "Running python linter..."
        for file in $(find . -name "*.py"); do
            #echo "Linting file: $file"
            if grep -q "missing-module-docstring" <(pylint "$file"); then
                echo "No module comment found in file: $file"
            fi
        done
        cd ..
    fi
done
****************************************

****************************************
Build\clean_subdirs.sh
****************************************
#!/bin/bash

# Find all directories in the current path
for dir in */; do
    if [ -d "$dir" ]; then
        echo "Entering directory: $dir"
        
        # Change to the directory
        cd "$dir"
        
        # Check if package.json exists
        if [ -f "package.json" ]; then
            echo "Running npm run clean..."
            npm run clean
        else
            echo "No package.json found, skipping..."
        fi
        
        # Go back to the root directory
        cd ..
    fi
done
****************************************

****************************************
Build\count_loc.sh
****************************************
#!/bin/bash
ts_directories=("CommonTs/src" "Api/src" "Cascade/src" "WaterfallBrowser/src" "Boxer/core" "Boxer/ui" "Teams/src")

py_directories=("CommonPy/src" "ApiTest/src" "Waterfall/src" "BoxerEval/src")

ts_test_directories=("CommonTs/test" "Api/test" "Cascade/test" "WaterfallBrowser/test" "Boxer/test" "Teams/test")

py_test_directories=("CommonPy/test" "ApiTest/test" "Waterfall/test" "BoxerEval/test")


# Function to count non-whitespace lines in files
count_lines() {
    local dir=$1
    local file_type=$2
    local lines=0
    
    while IFS= read -r file; do
        lines=$((lines + $(grep -cve '^\s*$' "$file")))
    done < <(find "$dir" -type f -name "*.$file_type")
    
    #echo "$file_type files: $lines lines"
    echo "$lines"
}

# Main script
if [[ $# -eq 0 ]]; then
    echo "Usage: $0 <base_directory>"
    exit 1
fi

base_dir=$1

if [[ ! -d $base_dir ]]; then
    echo "Error: $base_dir is not a valid directory."
    exit 1
fi

total_py_lines=0
total_ts_lines=0
total_py_test_lines=0
total_ts_test_lines=0

# Process Python directories
echo "Processing Python directories..."
for dir in "${py_directories[@]}"; do
    full_path="$base_dir/$dir"
    if [[ -d $full_path ]]; then
        echo "Checking directory: $full_path"
        line_count=$(count_lines "$full_path" "py")        
        total_py_lines=$((total_py_lines + line_count))     
    fi
done

# Process TypeScript directories
#
echo -e "\nProcessing TypeScript directories..."
for dir in "${ts_directories[@]}"; do
    full_path="$base_dir/$dir"
    if [[ -d $full_path ]]; then
        echo "Checking directory: $full_path"
        line_count=$(count_lines "$full_path" "ts")        
        total_ts_lines=$((total_ts_lines + line_count))   
        line_count=$(count_lines "$full_path" "tsx")        
        total_ts_lines=$((total_ts_lines + line_count))         
    fi
done

# Process Python test directories
echo "Processing Python test directories..."
for dir in "${py_test_directories[@]}"; do
    full_path="$base_dir/$dir"
    if [[ -d $full_path ]]; then
        echo "Checking directory: $full_path"
        line_count=$(count_lines "$full_path" "py")        
        total_py_test_lines=$((total_py_test_lines + line_count))     
    fi
done

# Process TypeScript test directories
#
echo -e "\nProcessing TypeScript test directories..."
for dir in "${ts_test_directories[@]}"; do
    full_path="$base_dir/$dir"
    if [[ -d $full_path ]]; then
        echo "Checking directory: $full_path"
        line_count=$(count_lines "$full_path" "ts")        
        total_ts_test_lines=$((total_ts_test_lines + line_count))   
        line_count=$(count_lines "$full_path" "tsx")        
        total_ts_test_lines=$((total_ts_test_lines + line_count))         
    fi
done

echo -e "\nFinal Totals:"
echo "Total Python (.py) lines: $total_py_lines"
echo "Total TypeScript (.ts .tsx) lines: $total_ts_lines"
echo "Total Python test (.py) lines: $total_py_test_lines"
echo "Total TypeScript test (.ts .tsx) lines: $total_ts_test_lines"
****************************************

****************************************
Build\prune_subdirs.sh
****************************************
#!/bin/bash

# Find all directories in the current path
for dir in */; do
    if [ -d "$dir" ]; then
        echo "Entering directory: $dir"
        
        # Change to the directory
        cd "$dir"
        
        # Check if package.json exists
        if [ -f "package.json" ]; then
            echo "Running npm prune..."
            npm prune
        else
            echo "No package.json found, skipping..."
        fi
        
        # Go back to the root directory
        cd ..
    fi
done
****************************************

****************************************
Build\test_subdirs.sh
****************************************
#!/bin/bash

# List of directories to process
directories=("CommonTs" "CommonPy" "Api" "ApiTest" "Cascade" "Waterfall" "WaterfallBrowser" "Boxer" "Teams")

# Iterate through the specified directories
for dir in "${directories[@]}"; do
    if [ -d "$dir" ]; then
        echo "Entering directory: $dir"
        
        # Change to the directory
        cd "$dir"
        
        # Check if package.json exists
        if [ -f "package.json" ]; then
            echo "Running npm run test..."
            npm run test
        else
            echo "No package.json found, skipping..."
            pytest
        fi
        
        # Go back to the original directory
        cd ..
    else
        echo "Directory $dir not found, skipping..."
    fi
done
****************************************

****************************************
Cascade\README.md
****************************************
# Cascade Chrome Extension

A Chrome extension for web scraping, text summarization, and content classification. This extension helps users extract, analyze, and classify web content efficiently.

## 🚀 Features
 - Web content scraping using artoo.js
 - Text summarization
 - Content classification
 - Session-based authentication
 - Real-time visual feedback
 - Rate limiting for API calls
 - Fallback scraping strategies

## 🛠️ Technical Architecture
The extension consists of two main components:

### 1. Content Script (`content.ts`)
 Handles web scraping operations
 Manages text extraction with fallback mechanisms
 Implements text length limitations (100KB max)
 Provides visual feedback during operations
 Communicates with external APIs for processing

### 2. Popup Interface (`popup.js`)
 Manages user authentication via session keys
 Implements debounced input handling
 Validates session GUIDs (36-character format)
 Displays processing results and feedback
 Communicates with Braid API

## 🔧 Setup & Installation
1. Clone this repository
. Install dependencies (if any)
. Load the extension in Chrome:
  - Open Chrome and navigate to `chrome://extensions/`
  - Enable "Developer mode"
  - Click "Load unpacked" and select the extension directory

## 🔑 Authentication
The extension requires a valid session key (GUID format) to operate. Users must:
 Enter a 36-character session key in the popup interface
 Wait for validation from the Braid API
 Receive confirmation before proceeding with operations

## 🌐 API Integration
The extension communicates with:
 Braid API (`braid-api.azurewebsites.net`) for session validation
 External APIs for text summarization and classification

## 🔄 Message Flow
. User inputs session key in popup
. Popup validates format and communicates with Braid API
. On validation, messages are sent to content scripts
. Content script performs scraping and processing
. Results are displayed in popup interface

## ⚠️ Error Handling
. Unhandled promise rejection suppression
. Input validation
. API call error handling
. Graceful fallbacks for scraping operations
. Rate limiting protection
****************************************

****************************************
CommonPy\ReadMe.md
****************************************
# Common Python Library
A Python library providing repository patterns and utilities for interacting with the Braid API, specifically focused on managing chunks and pages of data.

## Overview
This library implements repository patterns for two main data types:
 **Chunks**: Pieces of content with associated embeddings, summaries, and metadata
 **Pages**: HTML content with associated metadata

## Core Components

### Chunk Management
 `ChunkRepository`: Manages CRUD operations for chunks via the Braid API
 `IStoredChunk`: Data model for chunks, including:
 - Embeddings
 - Text renderings
 - Summaries
 - Related chunks
 - Metadata

### Page Management
 `PageRepository`: Handles storage and retrieval of pages
 `IStoredPage`: Data model for pages, primarily storing HTML content
 Utilities for compression and file handling

### Common Types
 `IStorable`: Base class for storable entities
 `IStorableQuerySpec`: Query parameters for data retrieval
 `IStorableOperationResult`: Operation result wrapper
 `DictToObject`: Utility for JSON-to-object conversion

## Key Features
- Robust error handling and logging
- Retry mechanisms for API calls
- Base64 compression for HTML content
- Type-safe data models
- Functional key-based querying
****************************************

****************************************
CommonTs\README.md
****************************************
# Common TypeScript Components
This directory contains shared TypeScript components used across both frontend (Browser, Mocha test) and backend (API) components. It also defines the API contracts between client and server, which are used by the 'Salon' component for test code generation.

## Key Components

### API Classes
 **Api**: Base class for all API interactions, handling environment and session management
 **ActivityRepositoryApi**: Manages activity records (save, remove, load, find, recent)
 **ChunkRepositoryApi**: Handles text chunk operations
 **FindEnrichedChunkApi**: Finds and manages enriched text chunks
 **QueryModelApi**: Interfaces with AI models for queries and question generation
 **SessionApi**: Manages user sessions
 **StorableRepositoryApi**: Base repository operations for storable objects

### Data Models & Types
 **IStorable**: Base interface for all storable objects
 **IModel**: Interface defining AI model capabilities
 **EnrichedChunk**: Enhanced chunk data structures with embeddings
 **IEnvironment**: Environment configuration interface

### Utilities
 **Asserts**: Validation utilities
 **Compress**: String compression/decompression utilities
 **Logging**: Standardized logging functions
 **Errors**: Custom error types

### Environment Management
 **DevelopmentEnvironment**
 **StagingEnvironment**
 **ProductionEnvironment**

## Usage
Import components as needed:
****************************************

****************************************
Salon\config.yaml
****************************************
source_patterns:
    - "*.ts"
    - "*.tsx"
    - "*.py"

common_directories_patterns:
    - "CommonTs"
    - "CommonPy"

skip_dirs:
    - "__pycache__"
    - "node_modules"
    - "venv"
    - ".idea"
    - ".pytest_cache"
    - ".vscode"
    - ".coverage"
    - "data"    
    - "env"
    - ".nyc_output"
        
skip_patterns:
    - "*.pyc"
    - "*.pyo"
    - "*.so"
    - "*.o"
    - "*.jpg"
    - "*.jpeg"
    - "*.png"
    - "*.gif"
    - "*.pdf"
    - "*.bin"
    - "*.exe"
    - "*.dll"
    - "*.class"
    - ".DS_Store"
    - ".gitignore"
    - "*.pkl"
    - "*.pyd"
    - "*.dylib"
    - "*.json"    
    - "*.gitignore"
    - "*.log"
    - "*.js"
    - "*.map"
    - "*.txt"    
    - "*.mdd"       
    - "*.vtt"       
    - "*.html"
    - "__init__.py"
    - ".coverage"    
    - "*.xlsx"
    - "*.zip"
    - "*.wav"
    - "*.mov"
****************************************

****************************************
Salon\README.md
****************************************
# Salon

Salon is a technology demonstrator for automated softwareevelopment tools using Large Language Models (LLMs). It provides a suite of tools to assist in API testing and code analysis.
## Key Components

### api_to_test_code
 tool that automatically generates Python test code from API specifications.
**Features:**
 Supports both JSON and YAML API specification formats
 Generates comprehensive Python test code
 Used in **ApiTest** to achieve high test coverage with minimal input effort
 Provides context-aware prompts to OpenAI for accurate test generation
 Includes error handling and logging
 Automated file output generation

### repo_to_text
 utility for processing and analyzing codebases.
**Features:**
 Processes entire directories of source code
 Concatenates source files into consolidated text files
 Enables LLM-based code analysis and question answering
 Adapted from [NotebookLM solution for interactive code exploration](https://jmlbeaujour.medium.com/introducing-notebooklm-as-a-solution-for-interactive-code-exploration-704a44e690a6)

Example use:
```
py src\repo_to_text.py --cfg config.yaml --repo_path . -o test_output
```
****************************************

****************************************
Teams\.funcignore
****************************************
.funcignore
*.js.map
*.ts
.git*
.localConfigs
.vscode
local.settings.json
test
tsconfig.json
.DS_Store
.deployment
node_modules/.bin
node_modules/azure-functions-core-tools
README.md
tsconfig.json
teamsapp.yml
teamsapp.*.yml
/env/
/appPackage/
/infra/
/devTools/
****************************************

****************************************
Teams\README.md
****************************************
# Overview of Custom Search Results app template

## Build a message extension from a new API with Azure Functions

This app template allows Teams to interact directly with third-party data, apps, and services, enhancing its capabilities and broadening its range of capabilities. It allows Teams to:

- Retrieve real-time information, for example, latest news coverage on a product launch.
- Retrieve knowledge-based information, for example, my team’s design files in Figma.

## Get started with the template

> **Prerequisites**
>
> To run this app template in your local dev machine, you will need:
>
> - [Node.js](https://nodejs.org/), supported versions: 18, 20
> - A [Microsoft 365 account for development](https://docs.microsoft.com/microsoftteams/platform/toolkit/accounts)
> - [Teams Toolkit Visual Studio Code Extension](https://aka.ms/teams-toolkit) version 5.0.0 and higher or [Teams Toolkit CLI](https://aka.ms/teamsfx-toolkit-cli)

1. First, select the Teams Toolkit icon on the left in the VS Code toolbar.
2. In the Account section, sign in with your [Microsoft 365 account](https://docs.microsoft.com/microsoftteams/platform/toolkit/accounts) if you haven't already.
3. Select `Debug in Teams (Edge)` or `Debug in Teams (Chrome)` from the launch configuration dropdown.
4. To trigger the Message Extension, you can click the `+` under compose message area to find your message extension.
   > Note: Please make sure to switch to New Teams when Teams web client has launched

## What's included in the template

| Folder       | Contents                                                                                                    |
| ------------ | ----------------------------------------------------------------------------------------------------------- |
| `.vscode`    | VSCode files for debugging                                                                                  |
| `appPackage` | Templates for the Teams application manifest, the API specification and response template for API responses |
| `env`        | Environment files                                                                                           |
| `infra`      | Templates for provisioning Azure resources                                                                  |
| `src`        | The source code for the boxer API                                                                          |

The following files can be customized and demonstrate an example implementation to get you started.

| File                                         | Contents                                                            |
| -------------------------------------------- | ------------------------------------------------------------------- |
| `src/functions/boxer.ts`                    | The main file of a function in Azure Functions.                     |
| `src/repairsData.json`                       | The data source for the boxer API.                                 |
| `appPackage/apiSpecificationFile/boxer.yml` | A file that describes the structure and behavior of the boxer API. |
| `appPackage/responseTemplates/boxer.json`   | A generated Adaptive Card that used to render API response.         |

The following are Teams Toolkit specific project files. You can [visit a complete guide on Github](https://github.com/OfficeDev/TeamsFx/wiki/Teams-Toolkit-Visual-Studio-Code-v5-Guide#overview) to understand how Teams Toolkit works.

| File                 | Contents                                                                                                                                  |
| -------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| `teamsapp.yml`       | This is the main Teams Toolkit project file. The project file defines two primary things: Properties and configuration Stage definitions. |
| `teamsapp.local.yml` | This overrides `teamsapp.yml` with actions that enable local execution and debugging.                                                     |

## Addition information and references

- [Extend Teams platform with APIs](https://aka.ms/teamsfx-api-plugin)
****************************************

****************************************
Teams\teamsapp.local.yml
****************************************
# yaml-language-server: $schema=https://aka.ms/teams-toolkit/v1.7/yaml.schema.json
# Visit https://aka.ms/teamsfx-v5.0-guide for details on this file
# Visit https://aka.ms/teamsfx-actions for details on actions
version: v1.7

provision:
  # Creates a Teams app
  - uses: teamsApp/create
    with:
      # Teams app name
      name: bsft${{APP_NAME_SUFFIX}}
    # Write the information of created resources into environment file for
    # the specified environment variable(s).
    writeToEnvironmentFile:
      teamsAppId: TEAMS_APP_ID

  # Set required variables for local launch
  - uses: script
    with:
      run:
        echo "::set-teamsfx-env FUNC_NAME=boxer";
        echo "::set-teamsfx-env FUNC_ENDPOINT=http://localhost:7071";

  # Validate using manifest schema
  - uses: teamsApp/validateManifest
    with:
      # Path to manifest template
      manifestPath: ./appPackage/manifest.json

  # Build Teams app package with latest env value
  - uses: teamsApp/zipAppPackage
    with:
      # Path to manifest template
      manifestPath: ./appPackage/manifest.json
      outputZipPath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip
      outputFolder: ./appPackage/build

  # Validate app package using validation rules
  - uses: teamsApp/validateAppPackage
    with:
      # Relative path to this file. This is the path for built zip file.
      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip

  # Apply the Teams app manifest to an existing Teams app in
  # Teams Developer Portal.
  # Will use the app id in manifest file to determine which Teams app to update.
  - uses: teamsApp/update
    with:
      # Relative path to this file. This is the path for built zip file.
      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip

  # Extend your Teams app to Outlook and the Microsoft 365 app
  - uses: teamsApp/extendToM365
    with:
      # Relative path to the build app package.
      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip
    # Write the information of created resources into environment file for
    # the specified environment variable(s).
    writeToEnvironmentFile:
      titleId: M365_TITLE_ID
      appId: M365_APP_ID

deploy:
  # Install development tool(s)
  - uses: devTool/install
    with:
      func:
        version: ~4.0.5455
        symlinkDir: ./devTools/func
    # Write the information of installed development tool(s) into environment
    # file for the specified environment variable(s).
    writeToEnvironmentFile:
      funcPath: FUNC_PATH

  # Run npm command
  - uses: cli/runNpmCommand
    name: install dependencies
    with:
      args: install --no-audit
****************************************

****************************************
Teams\teamsapp.yml
****************************************
# yaml-language-server: $schema=https://aka.ms/teams-toolkit/v1.7/yaml.schema.json
# Visit https://aka.ms/teamsfx-v5.0-guide for details on this file
# Visit https://aka.ms/teamsfx-actions for details on actions
version: v1.7

environmentFolderPath: ./env

# Triggered when 'teamsapp provision' is executed
provision:
  # Creates a Teams app
  - uses: teamsApp/create
    with:
      # Teams app name
      name: bsft${{APP_NAME_SUFFIX}}
    # Write the information of created resources into environment file for
    # the specified environment variable(s).
    writeToEnvironmentFile:
      teamsAppId: TEAMS_APP_ID

  - uses: arm/deploy # Deploy given ARM templates parallelly.
    with:
      # AZURE_SUBSCRIPTION_ID is a built-in environment variable,
      # if its value is empty, TeamsFx will prompt you to select a subscription.
      # Referencing other environment variables with empty values
      # will skip the subscription selection prompt.
      subscriptionId: ${{AZURE_SUBSCRIPTION_ID}}
      # AZURE_RESOURCE_GROUP_NAME is a built-in environment variable,
      # if its value is empty, TeamsFx will prompt you to select or create one
      # resource group.
      # Referencing other environment variables with empty values
      # will skip the resource group selection prompt.
      resourceGroupName: ${{AZURE_RESOURCE_GROUP_NAME}}
      templates:
        - path: ./infra/azure.bicep # Relative path to this file
          # Relative path to this yaml file.
          # Placeholders will be replaced with corresponding environment
          # variable before ARM deployment.
          parameters: ./infra/azure.parameters.json
          # Required when deploying ARM template
          deploymentName: Create-resources-for-sme
      # Teams Toolkit will download this bicep CLI version from github for you,
      # will use bicep CLI in PATH if you remove this config.
      bicepCliVersion: v0.9.1

  # Validate using manifest schema
  - uses: teamsApp/validateManifest
    with:
      # Path to manifest template
      manifestPath: ./appPackage/manifest.json

  # Build Teams app package with latest env value
  - uses: teamsApp/zipAppPackage
    with:
      # Path to manifest template
      manifestPath: ./appPackage/manifest.json
      outputZipPath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip
      outputFolder: ./appPackage/build

  # Validate app package using validation rules
  - uses: teamsApp/validateAppPackage
    with:
      # Relative path to this file. This is the path for built zip file.
      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip

  # Apply the Teams app manifest to an existing Teams app in
  # Teams Developer Portal.
  # Will use the app id in manifest file to determine which Teams app to update.
  - uses: teamsApp/update
    with:
      # Relative path to this file. This is the path for built zip file.
      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip

  # Extend your Teams app to Outlook and the Microsoft 365 app
  - uses: teamsApp/extendToM365
    with:
      # Relative path to the build app package.
      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip
    # Write the information of created resources into environment file for
    # the specified environment variable(s).
    writeToEnvironmentFile:
      titleId: M365_TITLE_ID
      appId: M365_APP_ID

# Triggered when 'teamsapp deploy' is executed
deploy:
  # Run npm command
  - uses: cli/runNpmCommand
    name: install dependencies
    with:
      args: install

  - uses: cli/runNpmCommand
    name: build app
    with:
      args: run build --if-present

  # Deploy your application to Azure Functions using the zip deploy feature.
  # For additional details, see at https://aka.ms/zip-deploy-to-azure-functions
  - uses: azureFunctions/zipDeploy
    with:
      # deploy base folder
      artifactFolder: .
      # Ignore file location, leave blank will ignore nothing
      ignoreFile: .funcignore
      # The resource id of the cloud resource to be deployed to.
      # This key will be generated by arm/deploy action automatically.
      # You can replace it with your existing Azure Resource id
      # or add it to your environment variable file.
      resourceId: ${{API_FUNCTION_RESOURCE_ID}}

# Triggered when 'teamsapp publish' is executed
publish:
  # Validate using manifest schema
  - uses: teamsApp/validateManifest
    with:
      # Path to manifest template
      manifestPath: ./appPackage/manifest.json
  # Build Teams app package with latest env value
  - uses: teamsApp/zipAppPackage
    with:
      # Path to manifest template
      manifestPath: ./appPackage/manifest.json
      outputZipPath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip
      outputFolder: ./appPackage/build
  # Validate app package using validation rules
  - uses: teamsApp/validateAppPackage
    with:
      # Relative path to this file. This is the path for built zip file.
      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip
  # Apply the Teams app manifest to an existing Teams app in
  # Teams Developer Portal.
  # Will use the app id in manifest file to determine which Teams app to update.
  - uses: teamsApp/update
    with:
      # Relative path to this file. This is the path for built zip file.
      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip
  # Publish the app to
  # Teams Admin Center (https://admin.teams.microsoft.com/policies/manage-apps)
  # for review and approval
  - uses: teamsApp/publishAppPackage
    with:
      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip
    # Write the information of created resources into environment file for
    # the specified environment variable(s).
    writeToEnvironmentFile:
      publishedAppId: TEAMS_APP_PUBLISHED_APP_ID
projectId: c64e8ace-e99d-444b-bd99-6373ca681243
****************************************

****************************************
Waterfall\pytest.ini
****************************************
[pytest]
log_cli = 1
****************************************

****************************************
Waterfall\README.md
****************************************
**Waterfall** is a Python framework designed for processing documents using an AI enrichment pipeline. It automates document processing, enrichment, and analysis. The system is primarily focused on curated educational content related to AI/ML.

The framework is composed of two main pipelines:
*   **Waterfall Pipeline**: This is the core pipeline, which retrieves documents using the Google Search API. It generates AI-powered summaries of these documents and calculates document embeddings for semantic analysis. It then performs clustering to group related content and generates interactive analysis reports, sending email summaries to leadership.
*   **Boxer Pipeline**: This pipeline builds a knowledge base by downloading and processing content from web URLs and YouTube playlists. It chunks documents into processable segments, generates summaries and embeddings, and powers the semantic search functionality in the Boxer interface.

Key features of Waterfall include:
*   Document retrieval from multiple sources such as the Google Search API, web URLs, and YouTube playlists.
*   Text summarisation using AI models.
*   Embedding generation for semantic search and clustering.
*   Automated cluster analysis and reporting.
*   Email notifications with insights.
*   Integration with a Boxer search interface.

The system processes a range of source materials, including:
*   University course content (e.g., Stanford CS229, CS224N).
*   Industry expert articles and tutorials.
*   Technical documentation.
*   Educational video content.

The **Boxer pipeline** specifically handles:
*   Searching for YouTube playlists and transcripts using `YoutubePlaylistSearcher` and `YouTubeTranscriptDownloader`.
*   Breaking down YouTube transcripts into chunks via `YouTubeTranscriptChunker`.
*   Crawling and downloading HTML links with `HtmlLinkCrawler` and `HtmlFileDownloader`.
*   Summarising content using the `Summariser` class.
*   Embedding the summarised content using the `Embedder` class.

Several modules contribute to Waterfall's functionality, including:
*   **Chunker**: Segments text into smaller parts.
*   **ClusterAnalyser**: Performs KMeans clustering on the embedding vectors of PipelineItem objects.
*   **DbRepository**: Stores data in the Chunk table of the BraidApis database.
*  **Embedder**: Creates text string embeddings.
*   **EmbeddingFinder**: Computes the nearest embedding to a target text using cosine similarity.
*   **FileRespository**: Stores data in the local file system.
*  **HtmlFileDownloader**: Downloads the text of a web page and saves it locally.
*   **HtmlLinkCrawler**: Crawls web pages to extract sub-links.
*   **Summariser**: Creates summaries for a given text string.
*  **ThemeFinder**: Identifies themes for given paragraphs by calling an external API.
*   **WebSearcher**: Uses the Google Custom Search Engine API to find relevant URLs.
*   **YoutubePlaylistSearcher**: Gathers information about YouTube videos from specified playlists.
*  **YouTubeTranscriptChunker**: Divides the transcript of a YouTube video into manageable chunks.
*   **YouTubeTranscriptDownloader**: Downloads the YouTube transcript of videos in a playlist.

The system also includes reporting functionalities such as:
*   Generating reports in HTML and JSON formats.
*  Sending automated reports via email.
*   Saving chunks in a hierarchical structure within the database.

Waterfall uses classes like `PipelineItem`, `Theme`, and `PipelineSpec` to manage the workflow and data. The `PipelineItem` class represents a work item, while the `Theme` class represents a documented cluster of items.

Waterfall includes various tests for its components, ensuring the proper functioning of features like:
*   Boxer pipeline, chunker, cluster analyser, database repository, embedder, embedding finder, embedding repository, file repository, html file downloader, html link crawler, summariser, summarise fail suppressor, summary repository, text repository, theme finder, waterfall pipeline, web searcher, and youtube playlist.
****************************************

****************************************
WaterfallBrowser\mocha.cjs
****************************************
require("global-jsdom/register");
require("ignore-styles").default([".svg", ".css"]);
****************************************

****************************************
WaterfallBrowser\README.CreateReact.md
****************************************
# Getting Started with Create React App

This project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app).

## Available Scripts

In the project directory, you can run:

### `npm start`

Runs the app in the development mode.\
Open [http://localhost:3000](http://localhost:3000) to view it in the browser.

The page will reload if you make edits.\
You will also see any lint errors in the console.

### `npm test`

Launches the test runner in the interactive watch mode.\
See the section about [running tests](https://facebook.github.io/create-react-app/docs/running-tests) for more information.

### `npm run build`

Builds the app for production to the `build` folder.\
It correctly bundles React in production mode and optimizes the build for the best performance.

The build is minified and the filenames include the hashes.\
Your app is ready to be deployed!

See the section about [deployment](https://facebook.github.io/create-react-app/docs/deployment) for more information.

### `npm run eject`

**Note: this is a one-way operation. Once you `eject`, you can’t go back!**

If you aren’t satisfied with the build tool and configuration choices, you can `eject` at any time. This command will remove the single build dependency from your project.

Instead, it will copy all the configuration files and the transitive dependencies (webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except `eject` will still work, but they will point to the copied scripts so you can tweak them. At this point you’re on your own.

You don’t have to ever use `eject`. The curated feature set is suitable for small and middle deployments, and you shouldn’t feel obligated to use this feature. However we understand that this tool wouldn’t be useful if you couldn’t customize it when you are ready for it.

## Learn More

You can learn more in the [Create React App documentation](https://facebook.github.io/create-react-app/docs/getting-started).

To learn React, check out the [React documentation](https://reactjs.org/).
****************************************

****************************************
WaterfallBrowser\README.md
****************************************
# Waterfall Browser

A React-based web application for navigating and viewing hierarchical data chunks with a clean, responsive interface using Fluent UI components.

## Overview

Waterfall Browser is a modern web application that allows users to browse and navigate through interconnected data chunks. Each chunk can contain a title, summary, URL, and references to related chunks, creating a waterfall-like navigation experience.

## Technical Stack

- **React**: Frontend framework
- **Fluent UI**: Microsoft's design system for UI components
- **TypeScript**: For type-safe development
- **Web Vitals**: Performance monitoring

## Key Components

### Core Components

- **App**: Main application component handling routing and layout
- **ChunkRetriever**: Manages the data fetching logic and state
- **ChunkView**: Displays individual chunk data with navigation options
- **ChunkViewLoading**: Loading state component
- **ChunkViewError**: Error state component

### Features

- Responsive layout with fluid design
- Parent-child chunk navigation
- Related chunks cross-referencing
- Base64 decoding for secure API key handling
- Performance monitoring with Web Vitals
- Internationalization support through UIString module

## Project Structure
src/
├── App.tsx # Main application component
├── ChunkRetriever.tsx # Data fetching component
├── ChunkView.tsx # Chunk display component
├── ChunkViewError.tsx # Error state component
├── ChunkViewLoading.tsx # Loading state component
├── Defusc.tsx # Base64 decoding utility
├── reportWebVitals.ts # Performance monitoring
└── UIString.ts # UI text constants

## Getting Started

1. Clone the repository
2. Install dependencies:
   ```bash
   npm install
   ```
3. Start the development server:
   ```bash
   npm start
   ```

## URL Parameters

The application accepts a `chunkId` parameter in the URL to display specific chunks of data.

Example: `http://your-app-url/?chunk=example-chunk-id`

## Performance Monitoring

The application includes Web Vitals monitoring for key metrics:
- Largest Contentful Paint (LCP)
- First Input Delay (FID)
- Cumulative Layout Shift (CLS)
- First Contentful Paint (FCP)
- Time to First Byte (TTFB)

## Internationalization

UI strings are centralized in the `UIString.ts` module for easy maintenance and future internationalization support.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Submit a pull request

## License

[Add your license information here]
****************************************

****************************************
WaterfallBrowser\tsconfig.tsbuildinfo
****************************************
{"root":["./src/app.tsx","./src/chunkretriever.test.tsx","./src/chunkretriever.tsx","./src/chunktesthelpers.tsx","./src/chunkview.test.tsx","./src/chunkview.tsx","./src/chunkviewerror.tsx","./src/index.tsx","./src/uistring.ts","./src/react-app-env.d.ts","./src/reportwebvitals.ts","./src/setuptests.ts","../commonts/src/activityrepositoryapi.ts","../commonts/src/api.ts","../commonts/src/asserts.ts","../commonts/src/chunkapi.types.ts","../commonts/src/chunkrepositoryapi.types.ts","../commonts/src/chunkrepositoryapi.ts","../commonts/src/classifyapi.types.ts","../commonts/src/embedapi.types.ts","../commonts/src/enrichedchunk.ts","../commonts/src/enrichedquery.ts","../commonts/src/enumeratemodelsapi.types.ts","../commonts/src/environment.ts","../commonts/src/errors.ts","../commonts/src/findenrichedchunkapi.ts","../commonts/src/findthemeapi.types.ts","../commonts/src/fluid.ts","../commonts/src/fluidapi.ts","../commonts/src/fluidtokenprovider.ts","../commonts/src/ienvironment.ts","../commonts/src/ienvironmentfactory.ts","../commonts/src/imodel.ts","../commonts/src/imodelfactory.ts","../commonts/src/istorable.ts","../commonts/src/logging.ts","../commonts/src/loginapi.ts","../commonts/src/model.ts","../commonts/src/querymodelapi.ts","../commonts/src/sessionapi.ts","../commonts/src/storablerepositoryapi.ts","../commonts/src/studioapi.types.ts","../commonts/src/summariseapi.types.ts","../commonts/src/suppresssummarisefailapi.types.ts","../commonts/src/themeapi.ts"],"version":"5.6.3"}
****************************************

****************************************
Api\dist\tsconfig.tsbuildinfo
****************************************
{"root":["../src/functions/checksession.azure.ts","../src/functions/chunk.azure.ts","../src/functions/classify.azure.ts","../src/functions/cosmosrepositoryapi.ts","../src/functions/embed.azure.ts","../src/functions/enrichedchunkrepository.ts","../src/functions/enrichedchunkrepositorydb.ts","../src/functions/enrichedchunkrepositoryfactory.ts","../src/functions/enumeratemodels.azure.ts","../src/functions/enumeraterepositories.azure.ts","../src/functions/findenrichedchunks.azure.ts","../src/functions/findtheme.azure.ts","../src/functions/generatefluidtoken.azure.ts","../src/functions/generatequestion.azure.ts","../src/functions/ienrichedchunkrepository.ts","../src/functions/loginwithlinkedin.azure.ts","../src/functions/querymodelwithenrichment.ts","../src/functions/storableactivity.azure.ts","../src/functions/storableapi.azure.ts","../src/functions/storableapi.cosmos.ts","../src/functions/storablechunk.azure.ts","../src/functions/storablepage.azure.ts","../src/functions/studioforteams.azure.ts","../src/functions/summarize.azure.ts","../src/functions/summarize.ts","../src/functions/testforsummarisefail.azure.ts","../src/functions/utility.azure.ts","../../commonts/src/activityrepositoryapi.ts","../../commonts/src/api.ts","../../commonts/src/asserts.ts","../../commonts/src/chunkapi.types.ts","../../commonts/src/chunkrepositoryapi.types.ts","../../commonts/src/chunkrepositoryapi.ts","../../commonts/src/classifyapi.types.ts","../../commonts/src/compress.ts","../../commonts/src/embedapi.types.ts","../../commonts/src/enrichedchunk.ts","../../commonts/src/enrichedquery.ts","../../commonts/src/enumeratemodelsapi.types.ts","../../commonts/src/environment.ts","../../commonts/src/errors.ts","../../commonts/src/findenrichedchunkapi.ts","../../commonts/src/findthemeapi.types.ts","../../commonts/src/fluid.ts","../../commonts/src/fluidapi.ts","../../commonts/src/fluidtokenprovider.ts","../../commonts/src/ienvironment.ts","../../commonts/src/ienvironmentfactory.ts","../../commonts/src/imodel.ts","../../commonts/src/imodeldriver.ts","../../commonts/src/imodelfactory.ts","../../commonts/src/ipromptpersona.ts","../../commonts/src/ipromptpersonafactory.ts","../../commonts/src/istorable.ts","../../commonts/src/logging.ts","../../commonts/src/loginapi.ts","../../commonts/src/looseobject.ts","../../commonts/src/model.oai.ts","../../commonts/src/modeldrivers.oai.ts","../../commonts/src/pagerepositoryapi.types.ts","../../commonts/src/pagerepositoryapi.ts","../../commonts/src/querymodelapi.ts","../../commonts/src/sessionapi.ts","../../commonts/src/storablerepositoryapi.ts","../../commonts/src/studioapi.types.ts","../../commonts/src/summariseapi.types.ts","../../commonts/src/testforsummarisefailapi.types.ts","../../commonts/src/themeapi.ts"],"version":"5.7.2"}
****************************************

****************************************
Api\test\activitystore.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';

import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { getEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { ActivityRepostoryApi } from '../../CommonTs/src/ActivityRepositoryApi';
import { randomKey, saveLoadRemove, failSave } from './storable';
import { IStorable, IStorableMultiQuerySpec } from '../../CommonTs/src/IStorable';

declare var process: any;

describe("StorableActivity", async function () {

   let now = new Date().toUTCString();
   let record : IStorable = {
      id: randomKey(),
      applicationId: "Test",
      schemaVersion: "1",
      created: now,
      amended: now,      
      contextId: "madeupId",
      functionalSearchKey: undefined,
      userId: "madeeupId",
      className: "madeUpClass"      
   }

   let env = getEnvironment (EEnvironment.kLocal);
   let api = new ActivityRepostoryApi (env, process.env.SessionKey.toString());

   it("Needs to succeed with valid key", async function () {
      
      let myRecord = { ...record };
      myRecord.id = randomKey();   

      let ok = await saveLoadRemove (api, myRecord); 

      expect (ok).toBe (true) ;         

   }).timeout(20000);

   it("Needs to fail with invalid key", async function () {
      
      let apiFail = new ActivityRepostoryApi (env, "thiswillfail");      
      let myRecord = { ...record };
      myRecord.id = randomKey();   

      let ok = await failSave (apiFail, myRecord); 

      expect (ok).toBe (true) ;         

  }).timeout(20000);   

   it("Needs to pull multiple records with valid key", async function () {
   
      let myRecord = { ...record };
      myRecord.id = randomKey();
      let ok = await api.save (myRecord); 

      let myRecord2 = { ...record };
      myRecord2.id = randomKey();      
      ok = await api.save (myRecord2); 

      let mySpec : IStorableMultiQuerySpec = { className: "madeUpClass", limit: 2};

      let stored = await api.recent (mySpec);

      api.remove (myRecord.id);
      api.remove (myRecord2.id);      

      expect (stored.length).toBe (2) ;         

   }).timeout(20000);   

});
****************************************

****************************************
Api\test\chatdriver.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';

import { EModel } from '../../CommonTs/src/IModel';
import { IModelConversationPrompt, EModelConversationRole} from '../../CommonTs/src/IModelDriver';
import { getChatModelDriver, getDefaultChatModelDriver } from '../../CommonTs/src/IModelFactory';
import { EPromptPersona } from '../../CommonTs/src/IPromptPersona';

declare var process: any;

describe("Chat Driver", function () {

   it("Needs pass a single line prompt", function () {

      let driver1 = getChatModelDriver (EModel.kLarge);
      let driver2 = getDefaultChatModelDriver ();

      expect(driver1.getDrivenModelType ()).toEqual(driver2.getDrivenModelType ());    

   });

   it("Needs pass a single line prompt", async function () {

      let driver = getChatModelDriver (EModel.kLarge);

      let prompt : IModelConversationPrompt = {prompt: "Hi, how are you?", history: []};

      let response = await driver.generateResponse (EPromptPersona.kArticleSummariser, prompt, {wordTarget: 100});
      expect(response.content.length > 0).toEqual(true);   

   }).timeout(10000);

   it("Needs pass a multi line prompt", async function () {

      let driver = getChatModelDriver (EModel.kLarge);

      let prompt : IModelConversationPrompt = {prompt: "What time did I say it was?", 
         history: [ {role: EModelConversationRole.kUser, content: "It is 10:30"} ]};

      let response = await driver.generateResponse (EPromptPersona.kArticleSummariser, prompt, {wordTarget: 100});
      expect(response.content.includes("10:30")).toEqual(true);   

   }).timeout(10000);   

});
****************************************

****************************************
Api\test\checksession.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';

declare var process: any;

import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { getEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { SessionApi } from "../../CommonTs/src/SessionApi";

describe("CheckSession", async function () {

   it("Needs to succeed with valid key in local environment", async function () {
      
      let api = new SessionApi (getEnvironment (EEnvironment.kLocal), process.env.SessionKey.toString());

      let session = await api.checkSessionKey ();

      expect (session && session?.length > 0).toBe (true) ;         

   }).timeout(20000);

   it("Needs to succeed with valid key in production environment", async function () {
      
      let api = new SessionApi (getEnvironment (EEnvironment.kProduction), process.env.SessionKey.toString());

      let session = await api.checkSessionKey ();

      expect (session && session?.length > 0).toBe (true) ;   

   }).timeout(20000);

   it("Needs to fail with invalid key.", async function () {

      let api = new SessionApi (getEnvironment (EEnvironment.kLocal), "thiswillfail");

      let session = await api.checkSessionKey ();
      
      expect (session).toEqual ("") ;         

  }).timeout(20000);

  it("Needs to fail with invalid key in production environment.", async function () {

     let api = new SessionApi (getEnvironment (EEnvironment.kProduction), "thiswillfail");

     let session = await api.checkSessionKey ();
   
     expect (session).toEqual ("") ;              

   }).timeout(20000);

});
****************************************

****************************************
Api\test\chunk.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';
import axios from 'axios';

import { getEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { IChunkRequest, IChunkResponse } from '../../CommonTs/src/ChunkApi.Types';
import { lookLikeSameSource } from '../src/functions/EnrichedChunkRepository';

declare var process: any;

describe("Chunk URLs", function () {

   it("Needs to identify URLs from same YouTube video", function () {

      var url1 = "https://www.youtube.com/watch?v=roEKOzxilq4&t=00h00m00s";
      var url2 = "https://www.youtube.com/watch?v=roEKOzxilq4&t=00h05m00s";

      expect(lookLikeSameSource (url1, url2)).toEqual(true);     
   });

   it("Needs to identify URLs from different YouTube videos", function () {

      var url1 = "https://www.youtube.com/watch?v=roEKOzxilq4&t=00h00m00s";
      var url2 = "https://www.youtube.com/watch?v=xoEKOzailq4&t=00h00m00s";

      expect(lookLikeSameSource (url1, url2)).toEqual(false);        
   });

   it("Needs to identify URLs from same GitHub repo", function () {

      var url1 = "https://github.com/jonverrier/BraidEng";
      var url2 = "https://github.com/jonverrier/BraidEng/issues";

      expect(lookLikeSameSource (url1, url2)).toEqual(true);     
   });

   it("Needs to identify URLs from different GitHub repos", function () {

      var url1 = "https://github.com/jonverrier/BraidEng";
      var url2 = "https://github.com/jonverrier/BraidWeb";

      expect(lookLikeSameSource (url1, url2)).toEqual(false);        
   });

});

describe("Chunk", async function () {

   async function validChunkCall(apiUrl: string, text: string): Promise<IChunkResponse | undefined> {

      let chunkRequest: IChunkRequest = {
         text: text
      };
      let responseData: IChunkResponse | undefined = undefined;

      try {
         let response = await axios.post(apiUrl, {
            request: chunkRequest,
            headers: {
               'Content-Type': 'application/json'
            }
         });

         responseData = (response.data as IChunkResponse);

      } catch (e: any) {

         console.error(e);
      }

      return responseData;
   }

   async function invalidChunkCall(apiUrl: string, text: string): Promise<Boolean> {

      var response: any;
      let caught = false;

      try {
         response = await axios.get(apiUrl, {
         });

      } catch (e: any) {
         caught = true;
      }

      return caught;
   }

   it("Needs to fail if session key is incorrect", async function () {

      let sampleText = "OpenAI have release a new large language model aimed at coding.";
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.chunkApi() + "?session=" + "thiswillfail";

      let caught = await invalidChunkCall(apiUrl, sampleText);

      expect(caught).toBe(true);

   }).timeout(20000);

   it("Needs to chunk a short message", async function () {

      let sampleText = "OpenAI have release a new large language model aimed at coding.";

      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.chunkApi() + "?session=" + process.env.SessionKey.toString();

      let chunkResponse = await validChunkCall(apiUrl, sampleText);

      expect(chunkResponse && chunkResponse?.chunks.length === 1).toBe(true);

   }).timeout(20000);

   it("Needs to chunk a long message", async function () {

      let sampleText = "OpenAI have release a new large language model aimed at coding.";
      for (let i = 0; i < 15; i++)
         sampleText = sampleText + sampleText;

      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.chunkApi() + "?session=" + process.env.SessionKey.toString();

      let chunkResponse = await validChunkCall(apiUrl, sampleText);

      expect(chunkResponse && chunkResponse?.chunks.length > 1).toBe(true);

   }).timeout(20000);

});
****************************************

****************************************
Api\test\chunkstore.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';

import { failSave, randomKey, saveLoadRemove, saveFindRemove } from './storable';
import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { getEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { ChunkRepostoryApi } from '../../CommonTs/src/ChunkRepositoryApi'
import { IStoredChunk } from '../../CommonTs/src/ChunkRepositoryApi.Types';
import { IStorableMultiQuerySpec } from '../../CommonTs/src/IStorable';

declare var process: any;

describe("StorableChunk", async function () {

   let now = new Date().toUTCString();

   let record: IStoredChunk = {
      id: randomKey(),
      applicationId: "Test",
      schemaVersion: "1",
      created: now,
      amended: now,
      contextId: "madeupId",
      userId: "madeeupId",
      className: "madeUpClass",
      functionalSearchKey: "1234",
      parentChunkId: undefined,
      originalText: undefined,
      url: undefined,
      storedEmbedding: undefined,
      storedSummary: undefined,
      storedTitle: undefined,
      relatedChunks: undefined
   }

   let env = getEnvironment(EEnvironment.kLocal);
   let api = new ChunkRepostoryApi(env, process.env.SessionKey.toString());

   // Clean up temp objects we created
   afterEach (async function () {
      let spec: IStorableMultiQuerySpec = {
         className: "madeUpClass",
         limit: 10
      }
      let recent = await api.recent (spec);
      for (let i = 0; i < recent.length; i++) {
         if (recent[i].id)
            api.remove (recent[i].id as string);
      }
   }); 

   it("Needs to succeed with saveLoadRemove & valid key in local environment", async function () {

      let myRecord = { ...record };
      myRecord.id = randomKey();

      let ok = await saveLoadRemove(api, myRecord);

      expect(ok).toBe(true);

   }).timeout(20000);

   it("Needs to succeed with find & valid key in local environment", async function () {

      let myRecord = { ...record };
      myRecord.id = randomKey();

      let ok = await saveFindRemove(api, myRecord);

      expect(ok).toBe(true);

   }).timeout(20000);

   it("Needs to fail with invalid key", async function () {

      let apiFail = new ChunkRepostoryApi(env, "thiswillfail");
      let myRecord = { ...record };
      myRecord.id = randomKey();

      let ok = await failSave(apiFail, myRecord);

      expect(ok).toBe(true);

   }).timeout(20000);

});
****************************************

****************************************
Api\test\classify.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';
import axios from 'axios';

import { getEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { IClassifyRequest, IClassifyResponse } from '../../CommonTs/src/ClassifyApi.Types';

declare var process: any;

describe("Classify", async function () {

   async function validClassifyCall(apiUrl: string, text: string): Promise<string | undefined> {

      let classifications = ["Business", "Technology", "Politics", "Health", "Sport"];
      let classificationRequest: IClassifyRequest = {
         text: text,
         classifications: classifications
      };
      let classificationResponse: IClassifyResponse | undefined = undefined;


      try {
         let response = await axios.post(apiUrl, {
            request: classificationRequest,
            headers: {
               'Content-Type': 'application/json'
            }
         });

         classificationResponse = (response.data as IClassifyResponse);
         console.log(classificationResponse);

      } catch (e: any) {

         console.error(e);
      }

      return classificationResponse?.classification;
   }

   async function invalidClassifyCall(apiUrl: string, text: string): Promise<Boolean> {

      var response: any;
      let caught = false;

      try {
         response = await axios.get(apiUrl, {
         });

      } catch (e: any) {
         caught = true;
      }

      return caught;
   }

   it("Needs to fail if session key is incorrect", async function () {

      let sampleText = "OpenAI have release a new large language model aimed at coding.";
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.classifyApi() + "?session=" + "thiswillfail";

      let caught = await invalidClassifyCall(apiUrl, sampleText);

      expect(caught).toBe(true);

   }).timeout(20000);


   it("Needs to fail if session key is incorrect against production", async function () {

      let sampleText = "OpenAI have released a new large language model aimed at coding.";
      let environment = getEnvironment(EEnvironment.kProduction);

      let apiUrl = environment.classifyApi() + "?session=" + "thiswillfail";

      let caught = await invalidClassifyCall(apiUrl, sampleText);

      expect(caught).toBe(true);

   }).timeout(20000);

   it("Needs to summarise a simple message against Production", async function () {

      let sampleText = "OpenAI have release a new large language model aimed at coding.";
      let environment = getEnvironment(EEnvironment.kProduction);

      let apiUrl = environment.classifyApi() + "?session=" + process.env.SessionKey.toString();

      let summary = await validClassifyCall(apiUrl, sampleText);

      expect(summary && summary?.length > 0).toBe(true);

   }).timeout(20000);

   it("Needs to summarise a simple message about Technology", async function () {

      let sampleText = "OpenAI have released a new large language model aimed at coding.";
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.classifyApi() + "?session=" + process.env.SessionKey.toString();

      let summary = await validClassifyCall(apiUrl, sampleText);

      expect(summary && summary?.length > 0).toBe(true);
      expect(summary?.includes("Technology")).toBe(true);

   }).timeout(20000);

   it("Needs to summarise a simple message about Business", async function () {

      let sampleText = "The Coca-cola company has made a take-over bid for Pepsi.";
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.classifyApi() + "?session=" + process.env.SessionKey.toString();

      let summary = await validClassifyCall(apiUrl, sampleText);

      expect(summary && summary?.length > 0).toBe(true);
      expect(summary?.includes("Business")).toBe(true);

   }).timeout(20000);

   it("Needs to summarise a simple message about Politics", async function () {

      let sampleText = "The President is heading to emergecy talks with the German chancellor.";
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.classifyApi() + "?session=" + process.env.SessionKey.toString();

      let summary = await validClassifyCall(apiUrl, sampleText);

      expect(summary && summary?.length > 0).toBe(true);
      expect(summary?.includes("Politics")).toBe(true);

   }).timeout(20000);

   it("Needs to summarise a simple message about Health", async function () {

      let sampleText = "Taking a small dose of aspirin each day has been shown to reduce the chances of heart desease.";
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.classifyApi() + "?session=" + process.env.SessionKey.toString();

      let summary = await validClassifyCall(apiUrl, sampleText);

      expect(summary && summary?.length > 0).toBe(true);
      expect(summary?.includes("Health")).toBe(true);

   }).timeout(20000);

   /* 
    it("Needs to summarise a simple message against production", async function () {
 
       let sampleText = "OpenAI have release a new large language model aimed at coding." ;      
       let environment = getEnvironment(EEnvironment.kProduction);
 
       let apiUrl = environment.classifyApi() + "?session=" + process.env.SessionKey.toString();
 
       let summary = await validClassifyCall (apiUrl, sampleText);
 
       expect (summary && summary?.length > 0).toBe (true) ;     
 
    }).timeout(20000);
 */


});
****************************************

****************************************
Api\test\embed.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';
import axios from 'axios';

import {getEnvironment} from '../../CommonTs/src/IEnvironmentFactory';
import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { IEmbedRequest, IEmbedResponse } from "../../CommonTs/src/EmbedApi.Types";
import { EPromptPersona } from '../../CommonTs/src/IPromptPersona';

declare var process: any;

describe("Embed", async function () {

   async function validEmbedCall (apiUrl: string, text: string) : Promise<Array<number> | undefined> {

      let embedding: Array<number> | undefined = undefined;
      let embeddingRequest: IEmbedRequest = {
         persona: EPromptPersona.kArticleSummariser,
         text: text
      }

      try {
         let response = await axios.post(apiUrl, {
           request: embeddingRequest,
           headers: {
              'Content-Type': 'application/json'
           }
         });

         let embeddingResponse = (response.data as IEmbedResponse);
         embedding = embeddingResponse.embedding;
         console.log (embeddingResponse);
  
      } catch (e: any) {       

         console.error (e);           
      }   
      
      return embedding;
   }

   async function invalidEmbedCall (apiUrl: string, text: string) : Promise <Boolean> {
   
      var response: any;
      let caught = false;

      try {
         response = await axios.get(apiUrl, {
         });

      } catch (e: any) {       
         caught = true;
      }     

      return caught;
   }   

   it("Needs to fail if session key is incorrect", async function () {

      let sampleText : string | undefined = "My name is Jon and I am founding an AI project acceleration company." ;      
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.embedApi() + "?session=" + "thiswillfail";

      let caught = await invalidEmbedCall (apiUrl, sampleText);

      expect (caught).toBe (true) ;     

   }).timeout(20000);

   it("Needs to fail if session key is incorrect against production", async function () {

      let sampleText : string | undefined = "My name is Jon and I am founding an AI project acceleration company." ;      
      let environment = getEnvironment(EEnvironment.kProduction);

      let apiUrl = environment.embedApi() + "?session=" + "thiswillfail";

      let caught = await invalidEmbedCall (apiUrl, sampleText);

      expect (caught).toBe (true) ;     

   }).timeout(20000);

   it("Needs to embed a simple message", async function () {

      let sampleText = "My name is Jon and I am founding an AI project acceleration company." ;      
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.embedApi() + "?session=" + process.env.SessionKey.toString();

      let embedding = await validEmbedCall (apiUrl, sampleText);

      expect (embedding && embedding?.length > 0).toBe (true) ;     

   }).timeout(20000); 

   it("Needs to embed a simple message against production", async function () {

      let sampleText = "My name is Jon and I am founding an AI project acceleration company." ;      
      let environment = getEnvironment(EEnvironment.kProduction);

      let apiUrl = environment.embedApi() + "?session=" + process.env.SessionKey.toString();

      let embedding = await validEmbedCall (apiUrl, sampleText);

      expect (embedding && embedding?.length > 0).toBe (true) ;     

   }).timeout(20000); 

   it("Needs to embed a long message", async function () {

      let baseText = "My name is Jon and I am founding an AI project acceleration company." ;  
      let sampleText = baseText;  
      for (var i = 0; i < 1000; i++)  {
         sampleText = sampleText + " " + baseText;
      }

      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.embedApi() + "?session=" + process.env.SessionKey.toString();

      let summary = await validEmbedCall (apiUrl, sampleText);

      expect (summary && summary?.length > 0).toBe (true) ;     

   }).timeout(20000);     

});
****************************************

****************************************
Api\test\environment.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024

import { expect } from 'expect';
import { describe, it } from 'mocha';

import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { getEnvironment, getDefaultEnvironment } from '../../CommonTs/src/IEnvironmentFactory';

describe("Environment", async function () {

   it("Should be local in Mocha", async function () {
      
      let def = getDefaultEnvironment();
      let local = getEnvironment (EEnvironment.kLocal);

      expect (def.name === local.name).toBe (true);         
   });
});
****************************************

****************************************
Api\test\findenrichedchunks.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';

declare var process: any;

import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { getEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { EChunkRepository } from '../../CommonTs/src/EnrichedChunk';
import { FindEnrichedChunkApi } from '../../CommonTs/src/FindEnrichedChunkApi';

let boxerUrls = ["https://www.youtube.com/watch?v=roEKOzxilq4&t=00m",
   "https://karpathy.medium.com/software-2-0-a64152b37c35"];

let boxerSummaries = [
   "User experience is a very important aspect of building apps. Users need to be able to use your app in an efficient way to perform tasks. Being efficient is one thing but you also need to design apps so that they can be used by everyone, to make them accessible. This chapter will focus on this area so you hopefully end up designing an app that people can and want to use. Introduction User experience is how a user interacts with and uses a specific product or service be it a system, tool",
   "The State of Open Source AI Book discusses the role of hardware in machine learning, specifically GPUs. GPUs are well-suited for AI computations due to their parallelization capabilities and specialized hardware for deep learning operations.",
   "The video discusses the patterns for augmenting language models with external context, including retrieval augmentation, chaining, and tool use. It explores the limitations of language models and the need for additional data and tools to enhance their performance. The video provides an overview of information retrieval techniques and explains how to make the most of the limited context window of language models.",
   "Learn to Spell: Prompt Engineering (LLM Bootcamp) is a new course announcement for an in-person bootcamp in the SF Bay Area on November 14, 2023. The video provides high-level intuitions and a default playbook for prompting language models, covering techniques like decomposition, reasoning, and reflection."
];

let waterfallSummaries = [
   "BNY Mellon is investing in AI capabilities using an NVidia platform.",
];

let waterfallUrls = ["https://blog.google/products/search/generative-ai-google-search-may-2024/"];

async function commonChunkStoreTests(repo: EChunkRepository,
                                summaries: Array<string>,
                                urls: Array<string>): Promise<void> {

   it("Needs to find relevant chunks from a matching Summary.", async function () {

      for (let i = 0; i < summaries.length; i++) {

         let api = new FindEnrichedChunkApi(getEnvironment(EEnvironment.kLocal), process.env.SessionKey.toString());
         let urlQuery = {
            maxCount: 2,
            repositoryId: repo,
            summary: summaries[i],
            similarityThreshold: 0.15
         };

         let response = await api.findRelevantChunksFromSummary(urlQuery);
         console.log("\nLooking for:" + urlQuery.summary);
         for (let i = 0; i < response.length; i++) {
            console.log(response[i].chunk.summary);
            console.log(response[i].relevance.toString());
         }
         console.log("\n");
         expect(response.length > 0).toBe(true);
      }

   }).timeout(50000);

   it("Needs to find relevant chunks from a matching URL.", async function () {

      let api = new FindEnrichedChunkApi(getEnvironment(EEnvironment.kLocal), process.env.SessionKey.toString());

      for (let i = 0; i < urls.length; i++) {
         let urlQuery = {
            maxCount: 2,
            repositoryId: repo,
            url: urls[i],
            similarityThreshold: 0.15
         };

         let response = await api.findRelevantChunksFromUrl(urlQuery);
         console.log("Looking for:" + urlQuery.url);
         console.log(response);

         expect(response.length > 0).toBe(true);
      }
   }).timeout (50000);

   it("Needs to find chunks from a matching URL.", async function () {

      let api = new FindEnrichedChunkApi(getEnvironment(EEnvironment.kLocal), process.env.SessionKey.toString());

      for (let i = 0; i < urls.length; i++) {
         let urlQuery = {
            maxCount: 2,
            repositoryId: repo,
            url: urls[i],
            similarityThreshold: 0.75
         };

         let response = await api.findChunkFromUrl(urlQuery);

         expect(response !== undefined).toBe(true);
      }

   }).timeout(50000);   
}


describe("FindEnrichedChunks - Boxer", async function () {
   
   commonChunkStoreTests (EChunkRepository.kBoxer, boxerSummaries, boxerUrls);
   
}).timeout(20000);

describe("FindEnrichedChunks - Waterfall", async function () {

   commonChunkStoreTests (EChunkRepository.kWaterfall, waterfallSummaries, waterfallUrls);
}).timeout(50000);
****************************************

****************************************
Api\test\findtheme.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';
import axios from 'axios';

import {getEnvironment} from '../../CommonTs/src/IEnvironmentFactory';
import { EEnvironment } from '../../CommonTs/src/IEnvironment';

declare var process: any;

let themedText = "Surfing is a surface water sport in which an individual, a surfer (or two in tandem surfing), uses a board to ride on the forward section, or face, of a moving wave of water, which usually carries the surfer towards the shore. Waves suitable for surfing are primarily found on ocean shores, but can also be found as standing waves in the open ocean, in lakes, in rivers in the form of a tidal bore, or in wave pools." 
+ "\n\n"
+ "The term surfing refers to a person riding a wave using a board, regardless of the stance. There are several types of boards. The Moche of Peru would often surf on reed craft, while the native peoples of the Pacific surfed waves on alaia, paipo, and other such water craft. Ancient cultures often surfed on their belly and knees, while the modern-day definition of surfing most often refers to a surfer riding a wave standing on a surfboard; this is also referred to as stand-up surfing."

import { IFindThemeRequest, IFindThemeResponse } from "../../CommonTs/src/FindThemeApi.Types";

describe("FindTheme", async function () {

   async function validThemeCall (apiUrl: string, text: string, length: number) : Promise<string | undefined> {

      let theme: string | undefined = undefined;
      let findThemeRequest: IFindThemeRequest = {
         text: text,
         length: length
      }

      try {
         let response = await axios.post(apiUrl, {
           request: findThemeRequest,
           headers: {
              'Content-Type': 'application/json'
           }
         });

         theme = (response.data as IFindThemeResponse).theme;
         console.log (theme);
  
      } catch (e: any) {       

         console.error (e);           
      }   
      
      return theme;
   }

   async function invalidThemeCall (apiUrl: string, text: string) : Promise <Boolean> {
   
      var response: any;
      let caught = false;

      try {
         response = await axios.get(apiUrl, {
         });

      } catch (e: any) {       
         caught = true;
      }     

      return caught;
   }   

   it("Needs to fail if session key is incorrect", async function () {

      let sampleText : string | undefined = themedText ;      
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.findThemeApi() + "?session=" + "thiswillfail";

      let caught = await invalidThemeCall (apiUrl, sampleText);

      expect (caught).toBe (true) ;     

   }).timeout(20000);

   it("Needs to find theme of a simple message", async function () {

      let sampleText = themedText ;      
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.findThemeApi() + "?session=" + process.env.SessionKey.toString();

      let summary = await validThemeCall (apiUrl, sampleText, 10);

      expect (summary && summary?.length > 0).toBe (true) ;     

   }).timeout(20000);

   
   it("Needs to fail if session key is incorrect against production", async function () {

      let sampleText : string | undefined = themedText;      
      let environment = getEnvironment(EEnvironment.kProduction);

      let apiUrl = environment.findThemeApi() + "?session=" + "thiswillfail";

      let caught = await invalidThemeCall (apiUrl, sampleText);

      expect (caught).toBe (true) ;     

   }).timeout(20000);   
   
   it("Needs to find theme of a simple message against production", async function () {

      let sampleText = themedText;      
      let environment = getEnvironment(EEnvironment.kProduction);

      let apiUrl = environment.findThemeApi() + "?session=" + process.env.SessionKey.toString();

      let summary = await validThemeCall (apiUrl, sampleText, 10);

      expect (summary && summary?.length > 0).toBe (true) ;     

   }).timeout(20000);

});
****************************************

****************************************
Api\test\generatefluidtoken.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024

import { expect } from 'expect';
import { describe, it } from 'mocha';

import { AzureClient } from "@fluidframework/azure-client";
import { ContainerSchema } from "fluid-framework";
import { SharedString } from "fluid-framework/legacy";

import { getEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { FluidApi } from '../../CommonTs/src/FluidApi'
import { IFluidTokenRequest } from '../../CommonTs/src/Fluid';
import { FluidClientProps } from '../../CommonTs/src/FluidTokenProvider'

declare var process: any;

const schema : ContainerSchema = {
   initialObjects: {
      test: SharedString
   }
};

let documentUuid = "b03724b3-4be0-4491-b0fa-43b01ab80d50";

async function sleep(ms: number): Promise<void> {
   return new Promise(
       (resolve) => setTimeout(resolve, ms));
}

describe("Generate Fluid Token", async function () {

   it("Needs to fail if session key is incorrect", async function () {
  
      let environment = getEnvironment(EEnvironment.kLocal);

      let request: IFluidTokenRequest = {
         local: true,         
         documentId: "madeupdocument",
         userId: "madeup user Id",
         userName: "User"
      }

      let fluidApi = new FluidApi (environment, "thiswillfail");

      let token = await fluidApi.generateToken(request);      

      expect (typeof token).toBe ('undefined') ;     

   }).timeout(20000);


   it("Needs to return a valid token if session key is correct", async function () {
  
      let environment = getEnvironment(EEnvironment.kLocal);
      let token : string | undefined = "";

      let request: IFluidTokenRequest = {
         local: true,         
         userId: "madeup user Id",
         userName: "User",
         documentId: documentUuid         
      }

      let fluidApi = new FluidApi (environment, process.env.SessionKey.toString());

      token = await fluidApi.generateToken(request);
  
      expect (token && token.length > 0).toBe (true);    

   }).timeout(20000);

   it("Needs to return a valid token from production if session key is correct", async function () {
  
      let environment = getEnvironment(EEnvironment.kProduction);
      let token : string | undefined = "";

      let request: IFluidTokenRequest = {
         local: false,         
         userId: "madeup user Id",
         userName: "User",
         documentId: documentUuid         
      }

      let fluidApi = new FluidApi (environment, process.env.SessionKey.toString());

      token = await fluidApi.generateToken(request);
  
      expect (token && token.length > 0).toBe (true);    

   }).timeout(20000);   

   it("Needs to connect to a Fluid container.", async function () {

      let session = process.env.SessionKey.toString();

      let user: IFluidTokenRequest = {
         local: true,
         userId: "madeup user Id",
         userName: "User",
         documentId: documentUuid
      }

      let clientProps: FluidClientProps = new FluidClientProps(session, user, false);
      let client = new AzureClient(clientProps);   

      const { container: containerNew, services: servicesNew } = await client.createContainer(schema as any, "2");

      // Attach container to service and return assigned ID
      const containerId = await containerNew.attach();

      containerNew.initialObjects.test = "Hello";

      await sleep (2500);
      
      const { container: containerExisting, services: servicesExisting } = await client.getContainer(containerId, schema as any, "2");

      await sleep (2500);

      let read = (containerExisting.initialObjects.test as SharedString).getText();

      containerExisting.initialObjects.test = "Goodbye";

      containerNew.dispose();
      containerExisting.dispose();  


   }).timeout(20000);
 

});
****************************************

****************************************
Api\test\login.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';

declare var process: any;

import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { getEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { LoginApi } from "../../CommonTs/src/LoginApi"

describe("Login", async function () {

   it("Needs to succeed with valid key in local environment", async function () {
      
      let api = new LoginApi (getEnvironment (EEnvironment.kLocal), process.env.SessionKey.toString());

      let session = await api.login ();

      expect (session && session?.length > 0).toBe (true) ;         

   }).timeout(20000);


   it("Needs to fail with invalid key.", async function () {

      let api = new LoginApi (getEnvironment (EEnvironment.kLocal), "thiswillfail");

      let session = await api.login ();
      
      expect (session).toEqual ("") ;         

  }).timeout(20000);

  it("Needs to succeed with valid key in production environment", async function () {
      
   let api = new LoginApi (getEnvironment (EEnvironment.kProduction), process.env.SessionKey.toString());

   let session = await api.login ();

   expect (session && session?.length > 0).toBe (true) ;         

}).timeout(20000);


it("Needs to fail with invalid key in production environment.", async function () {

   let api = new LoginApi (getEnvironment (EEnvironment.kProduction), "thiswillfail");

   let session = await api.login ();
   
   expect (session).toEqual ("") ;         

}).timeout(20000);  


});
****************************************

****************************************
Api\test\model.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';

import { EModel } from '../../CommonTs/src/IModel';
import { getDefaultModel, getModel } from '../../CommonTs/src/IModelFactory';

describe("Model", async function () {

   it("Needs to provide default model", async function () {
      
      let model = getDefaultModel();

      expect (model.deploymentName.length > 0).toBe (true) ;   
      expect (model.defaultChunkSize > 0).toBe (true) ;             

   });

   it("Needs to provide specific model", async function () {
      
      let model = getModel(EModel.kSmall);

      expect (model.deploymentName.length > 0).toBe (true) ;   
      expect (model.defaultChunkSize > 0).toBe (true) ;   

   });

   it("Needs to judge small text", async function () {
      
      let model = getModel(EModel.kSmall);
      let text = "small text";

      expect (model.fitsInDefaultChunk(text)).toBe (true) ;     

   });   

   it("Needs to judge large text", async function () {
      
      let model = getModel(EModel.kSmall);

      let text = "small text";
      for (let i = 0; i < 12; i++)
          text = text + text;

      expect (model.fitsInDefaultChunk(text)).toBe (false) ;   

   });  

   it("Needs to chunk small text", async function () {
      
      let model = getModel(EModel.kSmall);
      let text = "small text";

      expect (model.chunkText(text, undefined, undefined).length).toBe (1);

   });   

   it("Needs to chunk large text", async function () {
      
      let model = getModel(EModel.kSmall);

      let text = "small text ";
      for (let i = 0; i < 12; i++)
          text = text + text;

      expect (model.chunkText(text, undefined, undefined).length > 1).toBe (true) ;   
   });  

   it("Needs to chunk large text with overlaps", async function () {
      
      let model = getModel(EModel.kSmall);

      let text = "small text ";
      for (let i = 0; i < 12; i++)
          text = text + text;

      let baseLength = model.chunkText(text, undefined, undefined).length;
      let overlappedLength = model.chunkText(text, undefined, 2048).length;

      expect (overlappedLength > baseLength).toBe (true) ;   
   });  

});
****************************************

****************************************
Api\test\pagestore.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024

import axios from 'axios';
import { expect } from 'expect';
import { describe, it } from 'mocha';

import { randomKey } from './storable';
import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { getEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { PageRepostoryApi } from '../../CommonTs/src/PageRepositoryApi'
import { IStoredPage } from '../../CommonTs/src/PageRepositoryApi.Types';

declare var process: any;

import { readFileSync } from 'fs';
import { join } from 'path';

/**
 * Loads HTML content from a file in the filesystem
 * 
 * @param fileName - The name of the HTML file to load
 * @returns The HTML content as a string
 * @throws Error if file cannot be read or does not exist
 */
function loadHtmlFromFile(fileName: string): string {
    try {
        // Read the file synchronously using absolute path
        const filePath = join(process.cwd(), fileName);
        const htmlContent = readFileSync(filePath, 'utf-8');
        return htmlContent;
    } catch (error: any) {
        throw new Error(`Failed to load HTML file ${fileName}: ${error.message}`);
    }
}

describe("StorablePage", async function () {

   let now = new Date().toUTCString();

   let env = getEnvironment(EEnvironment.kLocal);
   let api = new PageRepostoryApi(env, process.env.SessionKey.toString());

   let key = randomKey();
   let htmlFromFile = loadHtmlFromFile ("test/page_test.html");
   let htmlCompressed = api.compressString (htmlFromFile);

   it("Needs to succeed with save & valid key in local environment", async function () {
      
      let record: IStoredPage = {
         id: randomKey(),
         applicationId: "Test",
         schemaVersion: "1",
         created: now,
         amended: now,
         contextId: "madeupId",
         userId: "madeeupId",
         className: "madeUpClass",
         functionalSearchKey: "1234",
         html: htmlCompressed
      }

      let myRecord = { ...record };
      myRecord.id = key;

      let ok = await api.save (myRecord);

      expect(ok).toBe(true);

   }).timeout(40000);

   it("Needs to succeed with load & valid key in local environment", async function () {

      var response: any;

      let environment = getEnvironment(EEnvironment.kLocal);

      let url = environment.getPageApi() 
         + "?id=" + key.toString();

      response = await axios.post(url);     
      
      let html = response.data;

      expect(html).toBe(htmlFromFile);

   }).timeout(40000);   

});
****************************************

****************************************
Api\test\querymodel.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';

declare var process: any;

import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { getEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { EChunkRepository } from '../../CommonTs/src/EnrichedChunk';
import { QueryModelApi } from '../../CommonTs/src/QueryModelApi';
import { IEnrichedResponse, IQuestionGenerationResponse } from '../../CommonTs/src/EnrichedQuery';
import { IModelConversationElement, EModelConversationRole } from '../../CommonTs/src/IModelDriver';

let question = "What are the main user interface considerations for building an application using an LLM?"
let summary = "Financial services will adopt generative AI, powered by large language models (LLMs), faster than expected. LLMs can create new content by training on vast amounts of unstructured data, with unlimited computational power. This transformation has the potential to revolutionize the financial services market, going beyond traditional AI/ML capabilities.";

let priorQuestions = ["How does an LLM work?", "What are LLMs bad at?"];
let priorAnswers = ["Large Language Models (LLMs) use transformers, relying on self-attention mechanisms to understand word relationships in text. Trained on vast data, they predict the next word in a sequence by analyzing context. Over time, they learn language patterns, enabling them to generate coherent, context-aware responses.", 
   "LLMs struggle with reasoning, understanding context deeply, and handling ambiguous or nuanced inputs. They may generate incorrect or nonsensical information confidently, lack real-world awareness, and can't verify facts. They also have limited capacity for long-term memory and can be biased based on their training data."];


describe("QueryModel", async function () {

   it("Needs to make a simple query.", async function () {

      let api = new QueryModelApi(getEnvironment(EEnvironment.kLocal), process.env.SessionKey.toString());
      let query = {
         repositoryId: EChunkRepository.kBoxer,
         history: new Array<IModelConversationElement>(),
         question: question,
         similarityThreshold: 0.4,
         maxCount: 2,
         wordTarget: 50
      };

      let response = await api.queryModelWithEnrichment(query);

      let typedResponse: IEnrichedResponse = response as IEnrichedResponse;
      expect(typeof response === 'undefined').toBe(false);
      expect(typedResponse.answer.length > 0).toBe(true);      
      expect(typedResponse.chunks.length > 0).toBe(true);    
      if (typedResponse.chunks.length > 1)   {
         expect(typedResponse.chunks[0].relevance >= typedResponse.chunks[1].relevance).toBe(true);   
      }

   }).timeout(20000);

   it("Needs to make a query with history.", async function () {

      let api = new QueryModelApi(getEnvironment(EEnvironment.kLocal), process.env.SessionKey.toString());
      let query = {
         repositoryId: EChunkRepository.kBoxer,
         history: [{role: EModelConversationRole.kUser, content: priorQuestions[0]}, 
                   {role: EModelConversationRole.kAssistant, content: priorAnswers[0]}, 
                   {role: EModelConversationRole.kUser, content: priorQuestions[1]},
                   {role: EModelConversationRole.kAssistant, content: priorAnswers[1]}],
         question: question,
         similarityThreshold: 0.5,
         maxCount: 2,
         wordTarget: 50
      };

      let response = await api.queryModelWithEnrichment(query);

      expect(typeof response === 'undefined').toBe(false);

      let typedResponse: IEnrichedResponse = response as IEnrichedResponse;      
      expect(typedResponse.answer.length > 0).toBe(true);      
      expect(typedResponse.chunks.length > 0).toBe(true);    
      if (typedResponse.chunks.length > 1)   {
         expect(typedResponse.chunks[0].relevance >= typedResponse.chunks[1].relevance).toBe(true);   
      }

   }).timeout(20000);

   it("Needs to generate a questions based on a summary", async function () {

      let api = new QueryModelApi(getEnvironment(EEnvironment.kLocal), process.env.SessionKey.toString());
      let query = {
         summary: summary,
         wordTarget: 10
      };

      let response = await api.generateQuestion(query);

      expect(typeof response === 'undefined').toBe(false);
      expect((response as IQuestionGenerationResponse).question.length > 0).toBe(true);      

   }).timeout(20000);   
});
****************************************

****************************************
Api\test\storable.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024

import { expect } from 'expect';

import { IStorable } from '../../CommonTs/src/IStorable';
import { IStorableRepostoryApiWrapper } from '../../CommonTs/src/StorableRepositoryApi'; 

export function randomInt(min : number, max: number) : number {
   return Math.floor(Math.random() * (max - min)) + min;
}

export function randomKey () : string {
   return randomInt (0, 1000000000).toString();
}

export async function saveLoadRemove<TApi extends IStorableRepostoryApiWrapper> (api: TApi, record: IStorable) : Promise<boolean> {

   let saved = await api.save (record);    
   let loaded = await api.load (record.id as string);
   let removed = await api.remove (record.id as string);
   
   expect (saved === true).toEqual (true);
   expect (loaded && (loaded.id === record.id)).toBe (true);
   expect (removed === true).toEqual (true);

   return (saved === true) && (loaded?.id === record.id) && (removed === true);
}

export async function saveFindRemove<TApi extends IStorableRepostoryApiWrapper> (api: TApi, record: IStorable) : Promise<boolean> {

   let saved = await api.save (record);    
   let loaded = await api.find (record.functionalSearchKey as string);
   let removed = await api.remove (record.id as string);
   
   expect (saved === true).toEqual (true);
   expect (loaded && (loaded.id === record.id)).toBe (true);
   expect (removed === true).toEqual (true);

   return (saved === true) && (loaded?.id === record.id) && (removed === true);
}

export async function failSave <TApi extends IStorableRepostoryApiWrapper> (api: TApi, record: IStorable) : Promise<boolean> {

   let saved = await api.save (record);    
   expect (saved === false).toEqual (true);

   return (saved === false);
}
****************************************

****************************************
Api\test\summarise.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024

import { expect } from 'expect';
import { describe, it } from 'mocha';
import axios from 'axios';

import {getEnvironment} from '../../CommonTs/src/IEnvironmentFactory';
import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { ISummariseRequest, ISummariseResponse } from "../../CommonTs/src/SummariseApi.Types";
import { EPromptPersona } from '../../CommonTs/src/IPromptPersona';

declare var process: any;

describe("Summarise", async function () {

   async function validSummaryCall (apiUrl: string, text: string) : Promise<string | undefined> {

      let summary: string | undefined = undefined;
      let summariseRequest: ISummariseRequest = {
         persona: EPromptPersona.kArticleSummariser,
         text: text,
         lengthInWords: 50
      }

      try {
         let response = await axios.post(apiUrl, {
           request: summariseRequest,
           headers: {
              'Content-Type': 'application/json'
           }
         });

         summary = (response.data as ISummariseResponse).summary;
         console.log (summary);
  
      } catch (e: any) {       

         console.error (e);           
      }   
      
      return summary;
   }

   async function invalidSummaryCall (apiUrl: string, text: string) : Promise <Boolean> {
   
      var response: any;
      let caught = false;

      try {
         response = await axios.get(apiUrl, {
         });

      } catch (e: any) {       
         caught = true;
      }     

      return caught;
   }   

   it("Needs to fail if session key is incorrect", async function () {

      let sampleText : string | undefined = "My name is Jon and I am founding an AI project acceleration company." ;      
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.summariseApi() + "?session=" + "thiswillfail";

      let caught = await invalidSummaryCall (apiUrl, sampleText);

      expect (caught).toBe (true) ;     

   }).timeout(20000);

   it("Needs to fail if session key is incorrect against production", async function () {

      let sampleText : string | undefined = "My name is Jon and I am founding an AI project acceleration company." ;      
      let environment = getEnvironment(EEnvironment.kProduction);

      let apiUrl = environment.summariseApi() + "?session=" + "thiswillfail";

      let caught = await invalidSummaryCall (apiUrl, sampleText);

      expect (caught).toBe (true) ;     

   }).timeout(20000);

   it("Needs to summarise a simple message", async function () {

      let sampleText = "My name is Jon and I am founding an AI project acceleration company." ;      
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.summariseApi() + "?session=" + process.env.SessionKey.toString();

      let summary = await validSummaryCall (apiUrl, sampleText);

      expect (summary && summary?.length > 0).toBe (true) ;     

   }).timeout(20000);

   
   it("Needs to summarise a long message", async function () {

      let baseText = "My name is Jon and I am founding an AI project acceleration company." ;  
      let sampleText = baseText;  
      for (var i = 0; i < 1000; i++)  {
         sampleText = sampleText + " " + baseText;
      }

      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.summariseApi() + "?session=" + process.env.SessionKey.toString();

      let summary = await validSummaryCall (apiUrl, sampleText);

      expect (summary && summary?.length > 0).toBe (true) ;     

   }).timeout(20000);   

   
   it("Needs to summarise a simple message against production", async function () {

      let sampleText = "My name is Jon and I am founding an AI project acceleration company." ;      
      let environment = getEnvironment(EEnvironment.kProduction);

      let apiUrl = environment.summariseApi() + "?session=" + process.env.SessionKey.toString();

      let summary = await validSummaryCall (apiUrl, sampleText);

      expect (summary && summary?.length > 0).toBe (true) ;     

   }).timeout(20000);

   it("Needs to summarise a long message against production", async function () {

      let baseText = "My name is Jon and I am founding an AI project acceleration company." ;  
      let sampleText = baseText;  
      for (var i = 0; i < 500; i++)  {
         sampleText = sampleText + " " + baseText;
      }

      let environment = getEnvironment(EEnvironment.kProduction);

      let apiUrl = environment.summariseApi() + "?session=" + process.env.SessionKey.toString();

      let summary = await validSummaryCall (apiUrl, sampleText);

      expect (summary && summary?.length > 0).toBe (true) ;     

   }).timeout(10000);    

});
****************************************

****************************************
Api\test\testforsummarisefail.test.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024


import { expect } from 'expect';
import { describe, it } from 'mocha';
import axios from 'axios';

import {getEnvironment} from '../../CommonTs/src/IEnvironmentFactory';
import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { ITestForSummariseFailRequest, ITestForSummariseFailResponse, ETestForSummariseFail } from "../../CommonTs/src/TestForSummariseFailApi.Types";

declare var process: any;

let summariseFails = ["Im sorry, but it seems that the text you provided does not contain any main body information. It consists of web page navigation and cookie details. Please provide a different text for summarization.",
  "The given text is not the main body of the page and does not contain any relevant information for summarizing. It appears to be a website navigation menu and does not provide any meaningful content to summarize.",
  "There is no relevant information to summarise as the text appears to be a website navigation menu and includes irrelevant information such as contact information and other web page elements.",
  "Im sorry, but I cannot summarize the given text as the relevant information is not clear. It seems to be a mixture of web page navigation items, company descriptions, and consent form options for selecting cookies on a website. Please provide a specific body of text that you woild like me to summarise.",
  "I apologize for the inconvenience, but it appears that the text provided is not suitable for generating a meaningful summary. It contains irrelevant information or is incomplete. If you can provide a more specific and complete text, I would be happy to assist you in summasising other content.",
  "There is no main body of text.",
  "I apologize for the inconvenience, but there is no main body of text, I cannot provide a summary."]

describe("TestForSummariseFail", async function () {

   async function validCall (apiUrl: string, text: string, length: number) : Promise<string | undefined> {

      let failCode: string | undefined = undefined;
      let summariseRequest: ITestForSummariseFailRequest = {
         text: text,
         lengthInWords: 50
      }

      try {
         let response = await axios.post(apiUrl, {
           request: summariseRequest,
           headers: {
              'Content-Type': 'application/json'
           }
         });

         failCode = (response.data as ITestForSummariseFailResponse).isValidSummary;
  
      } catch (e: any) {       

         console.error (e);           
      }   
      
      return failCode;
   }

   async function invalidCall (apiUrl: string, text: string) : Promise <Boolean> {
   
      var response: any;
      let caught = false;

      try {
         response = await axios.get(apiUrl, {
         });

      } catch (e: any) {       
         caught = true;
      }     

      return caught;
   }   

   it("Needs to fail if session key is incorrect", async function () {

      let sampleText : string | undefined = summariseFails[0] ;      
      let environment = getEnvironment(EEnvironment.kLocal);

      let apiUrl = environment.testForSummariseFail() + "?session=" + "thiswillfail";

      let caught = await invalidCall (apiUrl, sampleText);

      expect (caught).toBe (true) ;     

   }).timeout(20000);

   it("Needs to suppress example fails", async function () {

      for (let i = 0; i < summariseFails.length; i++) {   
         let sampleText = summariseFails[i];

         let environment = getEnvironment(EEnvironment.kLocal);
  
         let apiUrl = environment.testForSummariseFail() + "?session=" + process.env.SessionKey.toString();

         let failCode = await validCall (apiUrl, sampleText, 10);

         expect (failCode && failCode?.length > 0).toBe (true) ;  
         expect (failCode).toBe (ETestForSummariseFail.kSummaryFailed.toString()) ;           
      }   

   }).timeout(20000);

   it("Needs to fail if session key is incorrect", async function () {

      let sampleText : string | undefined = summariseFails[0] ;      
      let environment = getEnvironment(EEnvironment.kProduction);

      let apiUrl = environment.testForSummariseFail() + "?session=" + "thiswillfail";

      let caught = await invalidCall (apiUrl, sampleText);

      expect (caught).toBe (true) ;     

   }).timeout(20000);

   it("Needs to suppress example fails against production", async function () {

      for (let i = 0; i < summariseFails.length; i++) {   
         let sampleText = summariseFails[i];

         let environment = getEnvironment(EEnvironment.kProduction);
  
         let apiUrl = environment.testForSummariseFail() + "?session=" + process.env.SessionKey.toString();

         let failCode = await validCall (apiUrl, sampleText, 10);

         expect (failCode && failCode?.length > 0).toBe (true) ;  
         let noValue = ETestForSummariseFail.kSummaryFailed;     
         expect (failCode == noValue).toBe (true) ;           
      }   

   }).timeout(20000);

});
****************************************

****************************************
Api\src\functions\CheckSession.Azure.ts
****************************************
/**
 * @module CheckSession
 * 
 * Azure Function module that provides session validation functionality.
 * This module exposes an HTTP endpoint that validates session keys against 
 * environment-configured valid sessions. It supports both GET and POST methods
 * and returns appropriate responses based on session validity.
 * 
 * The function is configured for anonymous access but requires a valid session key
 * in the request parameters to succeed. This serves as a basic authentication
 * mechanism for the Braid API.
 */

'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";
import { isSessionValid, sessionFailResponse, defaultOkResponse } from "./Utility.Azure";

/**
 * Validates the session key provided in the request query parameters.
 * If the session key matches either of the expected session keys stored in the environment variables,
 * logs a success message and returns a 200 status with the session key in the response body.
 * If the session key does not match, logs a failure message and returns a 401 status with an authorization failure message.
 * 
 * @param request - The HTTP request object containing the query parameters.
 * @param context - The invocation context for logging and other context-specific operations.
 * @returns A promise that resolves to an HTTP response object with the appropriate status and body.
 */
export async function checkSession(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   if (isSessionValid(request, context)) {

      return defaultOkResponse();
   }
   else {
      return sessionFailResponse();
   }
};

app.http('CheckSession', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: checkSession
});
****************************************

****************************************
Api\src\functions\Chunk.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024

/**
 * @module Chunk
 * @description Azure Function that provides text chunking capabilities. This module splits input text
 * into smaller, manageable chunks with configurable size and overlap settings. It's designed to work
 * with authenticated sessions and returns chunked text as part of the Braid API infrastructure.
 * 
 * Usage:
 * - Deployed via 'func azure functionapp publish Braid-Api'
 * - Local development via 'npm start'
 * 
 * The chunking process respects session validation and handles errors appropriately,
 * returning standardized API responses.
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

import { getDefaultModel } from "../../../CommonTs/src/IModelFactory";
import { IChunkRequest, IChunkResponse } from "../../../CommonTs/src/ChunkApi.Types"
import { sessionFailResponse, defaultErrorResponse } from "./Utility.Azure";
import { isSessionValid } from "./Utility.Azure";

const model = getDefaultModel();

/**
 * Splits the input text into chunks based on the specified chunk size and overlap words.
 * 
 * @param text The text to be chunked.
 * @param chunkSize The size of each chunk.
 * @param overlapWords The number of overlapping words between consecutive chunks.
 * @returns An array of strings representing the text divided into chunks.
 */
function chunkText(text: string, chunkSize: number | undefined, overlapWords: number | undefined): Array<string> {

   const chunks = model.chunkText(text, chunkSize, overlapWords);

   return chunks;
}

/**
 * Asynchronous function to chunk text based on the requested session key and input text.
 * 
 * @param request - The HTTP request object containing the text to be chunked.
 * @param context - The context object for the function invocation.
 * @returns A promise that resolves to an HTTP response with the chunks or an error message.
 */ 

export async function chunk(request: HttpRequest, context: InvocationContext): Promise < HttpResponseInit > {

   let text: string | undefined = undefined;
   let overlapWords : number | undefined = undefined;
   let chunkSize : number | undefined = undefined;   
   let chunks = new Array<string>();

   if (isSessionValid(request, context)) {

      try {
         const jsonRequest = await request.json();
         context.log(jsonRequest);

         const spec = (jsonRequest as any).request as IChunkRequest;
         text = spec.text;
         chunkSize = spec.chunkSize;         
         overlapWords = spec.overlapWords;         

         if (text)
            chunks = chunkText(text, chunkSize, overlapWords);

         const body: IChunkResponse = {
            chunks: chunks
         }

         context.log (body)
         return {
            status: 200, // Ok
            body: JSON.stringify(body)
         };
      }
      catch(error: any) {

         context.error ("Error chunking text:", error);
         return defaultErrorResponse();
      }
   }
   else {
      context.error ("Session validation failed.");      
      return sessionFailResponse();
   }
};

app.http('Chunk', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: chunk
});
****************************************

****************************************
Api\src\functions\Classify.Azure.ts
****************************************
// Copyright Braid Technologies Ltd, 2024
/**
 * @module Classify
 * @description Azure Function that provides text classification services using AI.
 * This module handles the classification of text into predefined subject areas
 * using OpenAI's API. It includes functionality for session validation, error handling,
 * and response formatting.
 * 
 * The classification process uses a single-shot approach where the AI model
 * categorizes the input text into one of the provided classification categories.
 * 
 * @copyright Braid Technologies Ltd, 2024
 */

'use strict';
// 'func azure functionapp publish Braid-Api to publish to Azure
// 'npm start' to run locally

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";
import { isSessionValid, sessionFailResponse, defaultErrorResponse, invalidRequestResponse } from "./Utility.Azure";
import { IClassifyRequest, IClassifyResponse } from "../../../CommonTs/src/ClassifyApi.Types";
import { IModelConversationPrompt } from "../../../CommonTs/src/IModelDriver";
import { getDefaultChatModelDriver } from "../../../CommonTs/src/IModelFactory";
import { EPromptPersona } from "../../../CommonTs/src/IPromptPersona";

/**
 * Decodes the initial classification string to a human-readable format.
 * 
 * @param initial - The initial classification string to decode.
 * @returns The decoded classification in a human-readable format, or "Unknown" if not found.
 */
function decodeClassification(initial: string, classifications: Array<string>): string {

   for (let i = 0; i < classifications.length; i++) {
      if (initial.includes(classifications[i])) {
         if (classifications[i] === "CurrentAffairs")
            return "Current Affairs";
         return classifications[i];
      }
   }

   return "Unknown";
}

/**
 * Asynchronously classifies the given text into one of the predefined subject areas using an AI assistant.
 * 
 * @param text The text to be classified.
 * @returns A Promise that resolves to a string representing the classification result.
 */
async function singleShotClassify(text: string, classifications: Array<string>): Promise<string> {

   let modelDriver = getDefaultChatModelDriver();
   
   let prompt : IModelConversationPrompt = {
      history: [],
      prompt: text
   }

   let response = await modelDriver.generateResponse (EPromptPersona.kClassifier, prompt, {promptParam1: classifications.join(",")});

   const decoded = decodeClassification(response.content, classifications);

   return (decoded);
}


/**
 * Handles the classification of text based on the provided session key and text content.
 * 
 * @param request - The HTTP request object containing the query parameters and JSON data.
 * @param context - The invocation context for logging and other context-specific operations.
 * @returns A Promise that resolves to an HTTP response with the classification result or an error message.
 */
export async function classify(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   let text: string | undefined = undefined;
   let classifications: Array<string> | undefined = undefined;

   if (isSessionValid(request, context)) {
      try {
         const jsonRequest = await request.json();
         context.log (jsonRequest);
         
         const spec = (jsonRequest as any).request as IClassifyRequest;
         text = spec.text;
         classifications = spec.classifications;

         if ((text && text.length > 0)
         && (classifications && classifications.length > 0)) {

            const summaryClassification = await singleShotClassify(text, classifications);

            const classificationResponse : IClassifyResponse = {
               classification: summaryClassification
            }
            
            context.log (classificationResponse);

            return {
               status: 200, // Ok
               body: JSON.stringify(classificationResponse)
            };
         }
         else {
            context.error ("Error classifying text: Text or classifications not provided.");
            return invalidRequestResponse("Text or classifications not provided.");
         }
      }
      catch (e: any) {
         context.error ("Error classifying text:", e);
         return defaultErrorResponse();
      }
   }
   else {
      context.error ("Session validation failed.");         
      return sessionFailResponse();
   }
};

app.http('Classify', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: classify
});
****************************************

****************************************
Api\src\functions\CosmosRepositoryApi.ts
****************************************
// Copyright Braid Technologies Ltd, 2024
/**
 * @module CosmosRepositoryApi
 * @description Provides utility functions for generating authorization tokens and headers
 * for interacting with Azure Cosmos DB. This module includes functions for:
 * - Generating authorization tokens using master keys
 * - Creating headers for POST, DELETE, and query operations
 * - Managing storable tokens for various CRUD operations
 * 
 * All functions in this module are designed to work with Azure Cosmos DB's REST API
 * and follow Microsoft's authentication requirements.
 */

'use strict';

// 3rd party imports
const crypto = require("crypto");

import { LooseObject } from "../../../CommonTs/src/LooseObject";

/**
 * Generates an authorization token using the provided master key for the given verb, resource type, resource ID, and date.
 * 
 * @param verb The HTTP verb for the request.
 * @param resourceType The type of the resource being accessed.
 * @param resourceId The ID of the resource being accessed.
 * @param date The date of the request.
 * @param masterKey The master key used for generating the token.
 * @returns The encoded authorization token.
 */
export function getAuthorizationTokenUsingMasterKey(verb: string, resourceType: string, resourceId: string, date: string, masterKey: string) {

   const key = Buffer.from(masterKey, "base64");

   const text = (verb || "").toLowerCase() + "\n" +
      (resourceType || "").toLowerCase() + "\n" +
      (resourceId || "") + "\n" +
      date.toLowerCase() + "\n" +
      "" + "\n";

   const body = Buffer.from(text, "utf8");
   const signature = crypto.createHmac("sha256", key).update(body).digest("base64");

   const MasterToken = "master";

   const TokenVersion = "1.0";

   const encoded = encodeURIComponent("type=" + MasterToken + "&ver=" + TokenVersion + "&sig=" + signature);

   return encoded;
}


/**
 * Generates an activity token for authorization using the provided verb, time, and key.
 * 
 * @param verb The HTTP verb for the request.
 * @param time The timestamp for the request.
 * @param path - path for which we need a token 
 * @param key The master key for authorization.
 * @returns The generated authorization token for the activity.
 */
export function storableToken(verb: string, time: string, path: string, key: string) {

   //throwIfUndefined(key);
   return getAuthorizationTokenUsingMasterKey(verb, "docs", path, time, key);
}

/**
 * Generates an authorization token for deleting an activity using the master key.
 * 
 * @param time The current time in lowercase.
 * @param collectionPath - path to the collection in Cosmos * 
 * @param key The master key used for authorization.
 * @param id The ID of the activity to be deleted.
 * @returns The authorization token for the delete operation.
 */
export function makeStorableDeleteToken(time: string, collectionPath: string, key: string, id: string) {

   return storableToken ("delete", time, collectionPath + "/docs/" + id, key);
}

/**
 * Generates a post activity token using the provided time and key.
 * 
 * @param time The timestamp for the token generation.
 * @param collectionPath - path to the collection in Cosmos
 * @param key The key used for generating the token.
 * @returns The post activity token.
 */
export function makeStorablePostToken(time: string, collectionPath: string, key: string) {

   return storableToken("post", time, collectionPath, key);
}

/**
 * Creates a header object for a POST to a table with the specified key, time, and partition key.
 * @param key The authorization key for the table.
 * @param time The timestamp for the operation.
 * @param partitionKey The default partition key for the table.
 * @returns An object containing the necessary header for the POST.
 */
export function makePostHeader(key: string, time: string, partitionKey: string): object {
   return {
      "Authorization": key,
      "Content-Type": "application/json",
      "Accept": "application/json",
      "x-ms-date": time,
      "x-ms-version": "2018-12-31",
      "Cache-Control": "no-cache",
      "x-ms-documentdb-is-upsert": "True",
      "x-ms-documentdb-partitionkey": "[\"" + partitionKey + "\"]",
      "x-ms-consistency-level": "Eventual"
   };
}

/**
 * Creates header for a delete activity request.
 * 
 * @param key - The authorization key.
 * @param time - The timestamp.
 * @param partitionKey - The default partition key.
 * @returns An object containing the header for the delete activity request.
 */
export function makeDeleteHeader(key: string, time: string, partitionKey: string): object {
   return {
      "Authorization": key,
      "Accept": "application/json",
      "x-ms-date": time,
      "x-ms-version": "2018-12-31",
      "Cache-Control": "no-cache",
      "x-ms-documentdb-partitionkey": "[\"" + partitionKey + "\"]",
      "x-ms-consistency-level": "Eventual"
   };
}

/**
 * Creates a header object for a POST activity query with the specified key, time, and default partition key.
 * @param key The authorization key for the query.
 * @param time The timestamp for the query.
 * @param partitionKey The default partition key for the query.
 * @param continuation Continuation key (optional)
 * @returns An object containing the necessary headers for the POST activity query.
 */
export function makePostQueryHeader(key: string, time: string, partitionKey: string, 
   continuation: string | undefined = undefined): object {

   const headers : LooseObject = {
      "Authorization": key,
      "Content-Type": "application/query+json",
      "Accept": "application/json",
      "x-ms-date": time,
      "x-ms-version": "2018-12-31",
      "Cache-Control": "no-cache",
      "x-ms-documentdb-partitionkey": "[\"" + partitionKey + "\"]",
      "x-ms-consistency-level": "Eventual",
      "x-ms-documentdb-isquery": "True"
   };

   if (continuation)
      headers["x-ms-continuation"] = continuation;

   return headers;
}
****************************************

****************************************
Api\src\functions\Embed.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024

/**
 * @module Embed
 * @description Azure Function module that provides text embedding capabilities using Azure AI services.
 * This module handles the conversion of text into numerical vector representations (embeddings),
 * with support for automatic text summarization when input exceeds the model's context window.
 * It includes retry logic for rate limiting and network errors, and validates session authentication
 * for all requests.
 */

// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

import { isSessionValid, sessionFailResponse, defaultErrorResponse, invalidRequestResponse } from "./Utility.Azure";
import { getDefaultModel, } from "../../../CommonTs/src/IModelFactory";
import { recursiveSummarize } from "./Summarize";
import { IEmbedRequest, IEmbedResponse } from "../../../CommonTs/src/EmbedApi.Types";
import { getEmbeddingModelDriver } from "../../../CommonTs/src/IModelFactory";

const model = getDefaultModel();
const driver = getEmbeddingModelDriver(model.implementsModel);

/**
 * Embed function processes a request to embed text data using CalculateEmbedding function.
 * 
 * @param request - The HTTP request containing the text data to embed.
 * @param context - The context object for logging and validation.
 * @returns A Promise that resolves to an HTTP response with the embedding or an authorization error.
 */
export async function embed(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   let text: string | undefined = undefined;

   if (isSessionValid(request, context)) {

      try {
         const jsonRequest = await request.json();
         context.log(jsonRequest);
         const spec = (jsonRequest as any).request as IEmbedRequest;
         text = spec.text;

         if ((text && text.length > 0)) {

            // If the text is bigger than available context, we have to summarise it
            if (!model.fitsInEmbeddingChunk(text)) {
               text = await recursiveSummarize(spec.persona, text, 0, model.embeddingChunkSize)

               context.log("Summarised to fit in maximum chunk.");
            }

            const embeddingResponse : IEmbedResponse = {
               embedding: await driver.embed(text)
            };

            return {
               status: 200, // Ok
               body: JSON.stringify(embeddingResponse)
            };
         }
         else {
            context.error("Error embedding text:");
            return invalidRequestResponse("Text not provided.");
         }         
      }
      catch (e: any) {
         context.error("Error embedding text:", e);
         return defaultErrorResponse();
      }   
   }
   else {
      context.error ("Sessionvalidation failed.");         
      return sessionFailResponse();
   }
};

app.http('Embed', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: embed
});
****************************************

****************************************
Api\src\functions\EnrichedChunkRepository.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * @module EnrichedChunkRepository
 * @description In-memory implementation of the IEnrichedChunkRepository interface for storing and querying enriched chunks.
 * This module provides methods to lookup relevant chunks based on URL and summary, as well as retrieving chunks by URL.
 * It includes helper functions for comparing URLs and calculating cosine similarity between embeddings.
 */

import { IEnrichedChunkRepository } from "./IEnrichedChunkRepository";
import { IChunkQueryRelevantToUrlSpec, IChunkQueryRelevantToSummarySpec, IEnrichedChunk, IEnrichedChunkSummary } from "../../../CommonTs/src/EnrichedChunk";
import { IRelevantEnrichedChunk, IChunkQuerySpec } from "../../../CommonTs/src/EnrichedChunk";
import { throwIfUndefined } from "../../../CommonTs/src/Asserts";
import { getEmbeddingModelDriver } from "../../../CommonTs/src/IModelFactory";
import { getDefaultModel } from "../../../CommonTs/src/IModelFactory";

/**
 * Calculates the cosine similarity between two vectors.
 * @param vector1 The first vector.
 * @param vector2 The second vector.
 * @returns The cosine similarity score.
 */
function cosineSimilarity(vector1: number[], vector2: number[]): number {
   
   if (vector1.length !== vector2.length) {
      return -1.0;
   }

   const dotProduct = vector1.reduce((acc, val, index) => acc + val * vector2[index], 0);
   const magnitude1 = Math.sqrt(vector1.reduce((acc, val) => acc + val ** 2, 0));
   const magnitude2 = Math.sqrt(vector2.reduce((acc, val) => acc + val ** 2, 0));

   if (magnitude1 === 0 || magnitude2 === 0) {
      return -1.0;
   }

   return dotProduct / (magnitude1 * magnitude2);
}

const youTubeHostname = "www.youtube.com";
const gitHubHostname = "github.com";

/**
 * Compares two URLs to determine if they are from the same source.
 * 
 * @param url1 - The first URL to compare.
 * @param url2 - The second URL to compare.
 * @returns True if the URLs are from the same source, false otherwise.
 */
export function lookLikeSameSource(url1: string, url2: string): boolean {

   if (!url1 || !url2 || url1 === "" || url2 === "")
      return false;

   try {
      const URLLeft = new URL(url1);
      const URLRight = new URL(url2);

      // Youtube format URL
      // https://www.youtube.com/watch?v=l5mG4z343qg&t=00h00m00s
      // To compare two YouTube URLs we look at the ?v= parameter for the video ID
      if (URLLeft.hostname === (youTubeHostname) && URLRight.hostname === (youTubeHostname)) {
         const videoLeft = URLLeft.searchParams.get('v');
         const videoRight = URLRight.searchParams.get('v');

         if (videoLeft === videoRight)
            return true;
         else
            return false;

      }

      // GitHub format URL
      // https://github.com/organisation/repo/...
      // To compare two GitHub URLs we look at the first two path paramters   
      const pathLeft = URLLeft.pathname.split('/').slice(1);
      const pathRight = URLRight.pathname.split('/').slice(1);

      if (URLLeft.hostname === (gitHubHostname) && URLRight.hostname === (gitHubHostname)
         && (pathLeft.length >= 2) && (pathRight.length >= 2)) {

         if (pathLeft[0] === pathRight[0] && pathLeft[1] === pathRight[1])
            return true;
         else
            return false;
      }

      // To compare two Web URLs we look at the first path paramters  
      if ((URLLeft.hostname === URLRight.hostname) &&
         (pathLeft.length >= 1) && (pathRight.length >= 1)) {

         if (pathLeft[0] === pathRight[0])
            return true;
         else
            return false;
      }
   }
   catch (e) {
      console.error (e);
      return false;
   }

   return false;
}

/**
 * Finds the index of the entry with the lowest relevance in the given array of IRelevantEnrichedChunk objects.
 * If a URL is provided, it checks for entries with the same source and replaces if a better one is found.
 * @param urlIn The URL to compare with the chunk URLs.
 * @param current An array of IRelevantEnrichedChunk objects to search for the lowest relevance.
 * @returns The index of the entry with the lowest relevance, or -1 if the array is empty.
 */
function lowestOfCurrent(urlIn: string | undefined, current: Array<IRelevantEnrichedChunk>): number {

   if (current.length === 0)
      return -1;

   let lowestRelevance = current[0].relevance;
   let lowestIndex = 0;
   let sameSource = false;
   let sameIndex = -1;

   if (urlIn) {
      for (let i = 1; i < current.length; i++) {
         if (lookLikeSameSource(urlIn, current[i].chunk?.url)) {
            sameSource = true;
            sameIndex = i;
         }
      }
   }

   if (sameSource) {

      // If we have an entry from the same source, replace if the new one looks better
      const comp = current[sameIndex].relevance;

      if (typeof comp !== 'undefined' && typeof lowestRelevance !== 'undefined') {

         const currentRelevance = current[sameIndex].relevance;

         if ((typeof comp !== 'undefined' && typeof currentRelevance !== 'undefined')
            && (comp < currentRelevance)) {
            lowestIndex = sameIndex;
         }
      }
   }
   else {
      // Else replace the lowest relevance entry
      for (let i = 1; i < current.length; i++) {

         const comp = current[i].relevance;

         if (typeof comp !== 'undefined' && typeof lowestRelevance !== 'undefined') {

            if (comp < lowestRelevance) {
               lowestRelevance = comp;
               lowestIndex = i;
            }
         }
      }
   }

   return lowestIndex;
}

/**
 * Replaces a candidate enriched chunk in the current array if it meets certain criteria.
 * 
 * @param candidate - The candidate enriched chunk to be considered for replacement.
 * @param spec - The query specification defining the maximum count and similarity threshold.
 * @param urlIn - The URL to compare with the candidate's URL for source similarity.
 * @param current - The array of current relevant enriched chunks to evaluate for replacement.
 * @returns True if the candidate is successfully replaced, false otherwise.
 */
function replaceIfBeatsCurrent(candidate: IRelevantEnrichedChunk,
   spec: IChunkQuerySpec,
   urlIn: string | undefined,
   current: Array<IRelevantEnrichedChunk>): boolean {

   // If we have a reference source, check if its just the same source as our reference e.g. different chunk of a Youtube video
   // If it is, we bail 
   if (urlIn && lookLikeSameSource(candidate.chunk.url, urlIn)) {
      return false;
   }

   // Now check we are not piling up multiple references to the same source
   // If it is, we bail 
   for (let i = 0; i < current.length; i++) {
      if (lookLikeSameSource(candidate.chunk.url, current[i].chunk.url))
         return false;
   }

   // If the array can grow we just add the new candidate
   if (current.length < spec.maxCount) {
      if (typeof candidate.relevance !== 'undefined' && candidate.relevance >= spec.similarityThreshold) {
         current.push(candidate);
      }
      return true;
   }

   // Else we do a search and insert the new one if it is better than a current candidate
   const lowestIndex = lowestOfCurrent(candidate.chunk.url, current);
   const currentLowest = current[lowestIndex];

   if (typeof currentLowest.relevance !== 'undefined'
      && typeof candidate.relevance !== 'undefined') {
      if (currentLowest.relevance < candidate.relevance && candidate.relevance >= spec.similarityThreshold) {
         current[lowestIndex] = candidate;
         return true;
      }
   }

   return false;
}


export class EnrichedChunkRepositoryInMemory implements IEnrichedChunkRepository {

   private _chunks: Array<IEnrichedChunk>;

   /**
    * Initializes a new instance of the class with the provided array of chunks.
    * 
    */
   public constructor(chunks: Array<IEnrichedChunk>) {

      this._chunks = chunks;      
   }  

   /**
    * lookupRelevantFromSummary 
    * look to see of we have similar content to the text in the summary field of the query
    */
   async lookupRelevantFromSummary(spec: IChunkQueryRelevantToSummarySpec): Promise<Array<IRelevantEnrichedChunk>> {

      const enrichedChunks = this._chunks;
      const accumulator = new Array<IRelevantEnrichedChunk>();

      const driver = getEmbeddingModelDriver(getDefaultModel().implementsModel);
      const validEmbedding = await driver.embed(spec.summary);

      for (let i = 0; i < enrichedChunks.length; i++) {

         const embedding = enrichedChunks[i].embedding;
         if (embedding) {
            let validIndexedEmbedding: number[];
            throwIfUndefined(embedding);
            validIndexedEmbedding = embedding;

            const relevance = Number(cosineSimilarity(validEmbedding, validIndexedEmbedding).toPrecision(2));

            const candidate: IRelevantEnrichedChunk = {
               chunk: {
                  url: enrichedChunks[i].url,
                  summary: enrichedChunks[i].summary,
                  text: ""
               },
               relevance: relevance
            };

            const changed = replaceIfBeatsCurrent(candidate, spec, undefined, accumulator);
         }
      }

      function compareFn (a: IRelevantEnrichedChunk, b: IRelevantEnrichedChunk) : number {
         return b.relevance - a.relevance;
      }

      accumulator.sort (compareFn);
      
      return accumulator;
   }

   /**
    * lookupRelevantfromUrl 
    * look to see of we have similar content to a given URL from other sources
    */
   async lookupRelevantFromUrl(spec: IChunkQueryRelevantToUrlSpec): Promise<Array<IRelevantEnrichedChunk>> {

      const enrichedChunks = this._chunks;
      let targetChunk: IEnrichedChunk | undefined = undefined;
      const accumulator = new Array<IRelevantEnrichedChunk>();

      let validTargetChunk: IEnrichedChunk;
      let validEmbedding: number[];

      for (let i = 0; i < enrichedChunks.length && !targetChunk; i++) {
         const url = enrichedChunks[i].url;
         if (url == spec.url) {
            targetChunk = enrichedChunks[i];
            break;
         }
      }

      if (!targetChunk || !targetChunk.embedding)
         return accumulator;

      throwIfUndefined(targetChunk);
      validTargetChunk = targetChunk;
      throwIfUndefined(validTargetChunk.embedding);
      validEmbedding = validTargetChunk.embedding;

      for (let i = 0; i < enrichedChunks.length && targetChunk; i++) {

         const embedding = enrichedChunks[i].embedding;
         if (embedding) {
            let validIndexedEmbedding: number[];
            throwIfUndefined(embedding);
            validIndexedEmbedding = embedding;

            const relevance = Number(cosineSimilarity(validEmbedding, validIndexedEmbedding).toPrecision(2));

            const candidate: IRelevantEnrichedChunk = {
               chunk: {
                  url: enrichedChunks[i].url,
                  summary: enrichedChunks[i].summary,
                  text: ""
               },
               relevance: relevance
            };

            const changed = replaceIfBeatsCurrent(candidate, spec, spec.url, accumulator);
         }
      }

      return accumulator;
   }

   /**
    * lookupFromUrl 
    * look to see of we have similar content to a given URL from other sources
    */
   async lookupFromUrl(spec: IChunkQueryRelevantToUrlSpec): Promise<IEnrichedChunkSummary | undefined> {

      const enrichedChunks = this._chunks;
      let accumulator : IEnrichedChunkSummary | undefined = undefined;
   
      for (let i = 0; i < enrichedChunks.length && !accumulator; i++) {
         const url = enrichedChunks[i].url;
         if (url == spec.url) {
            const targetChunk = { 
               url: enrichedChunks[i].url,
               summary: enrichedChunks[i].summary,
               text: enrichedChunks[i].text
            };
            accumulator = targetChunk;
            break;
         }
      }

      return accumulator;
   }   
}
****************************************

****************************************
Api\src\functions\EnrichedChunkRepositoryDb.ts
****************************************
/**
 * @module EnrichedChunkRepositoryDb
 * 
 * Database-backed implementation of the EnrichedChunk repository.
 * 
 * This module provides a persistent storage implementation for enriched chunks,
 * combining an in-memory cache with database backing. It handles asynchronous
 * loading of chunks from the database while providing a consistent interface
 * for chunk queries and lookups.
 * 
 * The repository supports:
 * - Loading and caching chunks from a database
 * - Looking up chunks relevant to a given summary
 * - Finding chunks relevant to a specific URL
 * - Retrieving chunk summaries by URL
 * 
 */

// Copyright (c) 2024 Braid Technologies Ltd

import { IEnrichedChunkRepository } from "./IEnrichedChunkRepository";
import { IChunkQueryRelevantToUrlSpec, IChunkQueryRelevantToSummarySpec, IEnrichedChunk, IEnrichedChunkSummary } from "../../../CommonTs/src/EnrichedChunk";
import { IRelevantEnrichedChunk } from "../../../CommonTs/src/EnrichedChunk";
import { EnrichedChunkRepositoryInMemory } from "./EnrichedChunkRepository";
import { throwIfFalse } from "../../../CommonTs/src/Asserts";
import { ConsoleLogger, loadStorables } from "./StorableApi.Cosmos";
import { EChunkRepository } from "../../../CommonTs/src/EnrichedChunk";
import { storedChunkClassName } from "../../../CommonTs/src/ChunkRepositoryApi.Types";
import { chunkStorableAttributes } from "./StorableApi.Cosmos";
import { IStorable } from "../../../CommonTs/src/IStorable";
import { IStoredChunk } from "../../../CommonTs/src/ChunkRepositoryApi.Types";


/**
 * EnrichedChunkRepositoryDb is a class that implements the IEnrichedChunkRepository interface.
 * It initializes an in-memory repository of enriched chunks and manages asynchronous loading
 * of chunk data from a database. The class provides methods to look up relevant enriched chunks
 * based on a summary or URL, and to retrieve a chunk summary by URL.
 * 
 * @constructor
 * Initializes a new instance of the class, setting up an in-memory repository and a semaphore
 * to manage asynchronous data loading from a database.
 * 
 * @method lookupRelevantFromSummary
 * Searches for enriched chunks that are relevant to the text in the summary field of the query.
 * 
 * @method lookupRelevantFromUrl
 * Searches for enriched chunks that are relevant to a given URL from other sources.
 * 
 * @method lookupFromUrl
 * Retrieves the summary of an enriched chunk given its URL.
 */
export class EnrichedChunkRepositoryDb implements IEnrichedChunkRepository {

   private _repositoryInMemory: IEnrichedChunkRepository;
   private _semaphore: Promise<boolean>;

   /**
    * Initializes a new instance of the class with the provided array of chunks.
    * 
    */
   public constructor() {

      const enrichedChunks = new Array<IEnrichedChunk>;    
      this._repositoryInMemory = new EnrichedChunkRepositoryInMemory (enrichedChunks);

      this._semaphore = new Promise<boolean> ((resolve) => {
   
         const query = {
            maxCount: 2,
            repositoryId: EChunkRepository.kWaterfall,
            limit: 2,
            className: storedChunkClassName,
            similarityThreshold: 0.15
         };
      
         const logger = new ConsoleLogger();
      
         try {
            const loaded = loadStorables (query, chunkStorableAttributes, logger).then ((values: Array<IStorable>) => {

               const loadedChunks = new Array<IEnrichedChunk>;

               for (let i = 0; i < values.length; i++) {

                  const storedChunk: IStoredChunk = values[i] as IStoredChunk;

                  if (!storedChunk.url) {
                     console.error ("No URL found for chunk", storedChunk.id);
                     continue;
                  }
                  if (!storedChunk.storedEmbedding) {
                     console.error ("No Embedding found for chunk", storedChunk.id);
                     continue;
                  }                  

                  const chunk: IEnrichedChunk = {
                     id: storedChunk.id as string,
                     embedding: storedChunk.storedEmbedding?.embedding as number[],
                     url: storedChunk.url as string,
                     text: storedChunk.originalText as string,
                     summary: storedChunk.storedSummary?.text as string
                  }

                  loadedChunks.push(chunk);
               }

               this._repositoryInMemory = new EnrichedChunkRepositoryInMemory (loadedChunks);   

               resolve (true);               

            }).catch ((e: any) => {

               resolve (false);
            });       
         }
         catch (err: any) {
            logger.error ("Error loading Chunks", err);
            
            resolve (false);
         }
      });
   }
   
   /**
    * lookupRelevantFromSummary 
    * look to see of we have similar content to the text in the summary field of the query
    */
   async lookupRelevantFromSummary(spec: IChunkQueryRelevantToSummarySpec): Promise<Array<IRelevantEnrichedChunk>> {

      const result = await this._semaphore;       
      return this._repositoryInMemory.lookupRelevantFromSummary (spec);
   }

   /**
    * lookupRelevantfromUrl 
    * look to see of we have similar content to a given URL from other sources
    */
   async lookupRelevantFromUrl(spec: IChunkQueryRelevantToUrlSpec): Promise<Array<IRelevantEnrichedChunk>> {

      const result = await this._semaphore;       
      return this._repositoryInMemory.lookupRelevantFromUrl (spec);
   }

   /**
    * lookupFromUrl 
    * look to see of we have similar content to a given URL from other sources
    */
   async lookupFromUrl(spec: IChunkQueryRelevantToUrlSpec): Promise<IEnrichedChunkSummary | undefined> {

      const result = await this._semaphore; 
      throwIfFalse(result)
      return this._repositoryInMemory.lookupFromUrl (spec);
   }
}
****************************************

****************************************
Api\src\functions\EnrichedChunkRepositoryFactory.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * @module EnrichedChunkRepositoryFactory
 * @description Factory for creating instances of IEnrichedChunkRepository.
 * This module provides a way to create and manage instances of IEnrichedChunkRepository
 * based on the specified repository type. It ensures that only one instance of each
 * repository type is created (singleton pattern) to optimize performance.
 */

// Internal imports
import { IEnrichedChunkRepository} from "./IEnrichedChunkRepository";
import { EnrichedChunkRepositoryDb } from "./EnrichedChunkRepositoryDb";
import { EChunkRepository } from "../../../CommonTs/src/EnrichedChunk";

let waterfallRepository: EnrichedChunkRepositoryDb | undefined = undefined;

/**
 * Returns an instance of IEnrichedChunkRepository based on the specified repository type.
 * 
 * @param repository - The type of repository to retrieve, specified as an EChunkRepository enum.
 * @returns An instance of IEnrichedChunkRepository corresponding to the specified repository type.
 * 
 * If the repository type is 'kWaterfall', it returns an instance of EnrichedChunkRepositoryDb.
 * If the repository type is 'kBoxer' or any other value, it does the same - parameters are reserved for future variation
 * The function ensures that only one instance of each repository type is created (singleton pattern). 
 * Repositories are relative expensive which is why we use singleton. 
 */
export function getEnrichedChunkRepository (repository: EChunkRepository) : IEnrichedChunkRepository {
   switch (repository) {

      case EChunkRepository.kWaterfall:
      case EChunkRepository.kBoxer:             
      default:
         if (!waterfallRepository)
            waterfallRepository = new EnrichedChunkRepositoryDb()
         return waterfallRepository;   
   }
}
****************************************

****************************************
Api\src\functions\EnumerateModels.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally

/**
 * @module EnumerateModels
 * @description Azure Function module that provides details of installed models.
 * This module handles the retrieval of model details, including default, large, and small models,
 * and returns them in a structured format. It includes validation for session authentication
 * and error handling for any issues encountered during the request processing.
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

import { getDefaultModel } from "../../../CommonTs/src/IModelFactory";
import { IEnumerateModelsRequest, IEnumerateModelsResponse} from "../../../CommonTs/src/EnumerateModelsApi.Types"
import { sessionFailResponse, defaultErrorResponse } from "./Utility.Azure";
import { isSessionValid } from "./Utility.Azure";

const model = getDefaultModel();



/**
 * Asynchronous function to send back details of installed models - used to keep Python code consistent with Typescript 
 * 
 * @param request - The HTTP request object .
 * @param context - The context object for the function invocation.
 * @returns A promise that resolves to an HTTP response with the model details or an error message.
 */ 

export async function enumerateModels(request: HttpRequest, context: InvocationContext): Promise < HttpResponseInit > {

   if (isSessionValid(request, context)) {

      try {
         const jsonRequest = await request.json();
         context.log(jsonRequest);

         const model = getDefaultModel();

         const spec = (jsonRequest as any).request as IEnumerateModelsRequest;        

         const body: IEnumerateModelsResponse = {
            defaultId: model.deploymentName,
            defaultEmbeddingId: model.embeddingDeploymentName,
            largeId: model.deploymentName,
            largeEmbeddingId: model.embeddingDeploymentName,            
            smallId: model.deploymentName,
            smallEmbeddingId: model.embeddingDeploymentName,            
         }

         context.log (body)
         return {
            status: 200, // Ok
            body: JSON.stringify(body)
         };
      }
      catch(error: any) {

         context.error ("Error finding models:", error);
         return defaultErrorResponse();
      }
   }
   else {
      context.error ("Session validation failed.");      
      return sessionFailResponse();
   }
};

app.http('EnumerateModels', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: enumerateModels
});
****************************************

****************************************
Api\src\functions\EnumerateRepositories.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally

/**
 * @module EnumerateRepositories
 * @description Azure Function module that provides details of installed repositories.
 * This module handles the retrieval of repository details, including Boxer and Waterfall repositories,
 * and returns them in a structured format. It includes validation for session authentication
 * and error handling for any issues encountered during the request processing.
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

import { IEnumerateRepositoriesRequest, IEnumerateReposotoriesResponse} from "../../../CommonTs/src/EnumerateModelsApi.Types"
import { sessionFailResponse, defaultErrorResponse } from "./Utility.Azure";
import { isSessionValid } from "./Utility.Azure"
import { EChunkRepository } from "../../../CommonTs/src/EnrichedChunk";



/**
 * Asynchronous function to send back details of installed repositories - used to keep Python code consistent with Typescript 
 * 
 * @param request - The HTTP request object .
 * @param context - The context object for the function invocation.
 * @returns A promise that resolves to an HTTP response with the respository details or an error message.
 */ 

export async function enumerateRepositories(request: HttpRequest, context: InvocationContext): Promise < HttpResponseInit > {

   if (isSessionValid(request, context)) {

      try {
         const jsonRequest = await request.json();
         context.log(jsonRequest);

         const spec = (jsonRequest as any).request as IEnumerateRepositoriesRequest;        

         const body: IEnumerateReposotoriesResponse = {
            repositoryIds: [EChunkRepository.kBoxer, EChunkRepository.kWaterfall]            
         }

         context.log (body)
         return {
            status: 200, // Ok
            body: JSON.stringify(body)
         };
      }
      catch(error: any) {

         context.error ("Error finding repositories:", error);
         return defaultErrorResponse();
      }
   }
   else {
      context.error ("Session validation failed.");      
      return sessionFailResponse();
   }
};

app.http('EnumerateRepositories', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: enumerateRepositories
});
****************************************

****************************************
Api\src\functions\FindEnrichedChunks.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally

/**
 * @module FindEnrichedChunks
 * @description Azure Function module that provides methods for finding enriched chunks based on URL and summary.
 * This module handles the retrieval of enriched chunks based on specified criteria, including URL and summary,
 * and returns them in a structured format. It includes validation for session authentication
 * and error handling for any issues encountered during the request processing.
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";
import { IChunkQueryRelevantToUrlSpec, IChunkQueryRelevantToSummarySpec } from "../../../CommonTs/src/EnrichedChunk";
import { isSessionValid, sessionFailResponse, defaultErrorResponse } from "./Utility.Azure";
import { getEnrichedChunkRepository } from "./EnrichedChunkRepositoryFactory";
import { EChunkRepository } from "../../../CommonTs/src/EnrichedChunk";

export async function FindRelevantEnrichedChunksFromSummary(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   if (isSessionValid(request, context)) {

      try {
         const spec: IChunkQueryRelevantToSummarySpec = (await (request.json() as any)).data as IChunkQueryRelevantToSummarySpec;

         const repository = getEnrichedChunkRepository(EChunkRepository.kWaterfall);

         const chunks = await repository.lookupRelevantFromSummary (spec);

         return {
            status: 200, // Ok
            body: JSON.stringify (chunks)
         };
      }
      catch (e) {
         context.error (e);         
         return defaultErrorResponse();
      }      
   }
   else {
      return sessionFailResponse();
   }
};

export async function FindRelevantEnrichedChunksFromUrl (request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   if (isSessionValid(request, context)) {

      try {
         const spec: IChunkQueryRelevantToUrlSpec = (await (request.json() as any)).data as IChunkQueryRelevantToUrlSpec;

         const repository = getEnrichedChunkRepository(EChunkRepository.kWaterfall);

         const chunks = await repository.lookupRelevantFromUrl (spec);

         return {
            status: 200, // Ok
            body: JSON.stringify (chunks)
         };
      }
      catch (e) {
         context.error (e);         
         return defaultErrorResponse();
      }
   }
   else {
      return sessionFailResponse();
   }
};

export async function FindEnrichedChunkFromUrl (request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   if (isSessionValid(request, context)) {

      try {
         const spec: IChunkQueryRelevantToUrlSpec = (await (request.json() as any)).data as IChunkQueryRelevantToUrlSpec;

         const repository = getEnrichedChunkRepository(EChunkRepository.kWaterfall);

         const chunk = await repository.lookupFromUrl (spec);

         return {
            status: 200, // Ok
            body: JSON.stringify (chunk)
         };
      }
      catch (e) {
         context.error (e);
         return defaultErrorResponse();
      }
   }
   else {
      return sessionFailResponse();
   }
};

app.http('FindRelevantEnrichedChunksFromSummary', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: FindRelevantEnrichedChunksFromSummary
});

app.http('FindRelevantEnrichedChunksFromUrl', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: FindRelevantEnrichedChunksFromUrl
});

app.http('FindEnrichedChunkFromUrl', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: FindEnrichedChunkFromUrl
});
****************************************

****************************************
Api\src\functions\FindTheme.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally

/**
 * @module FindTheme
 * @description Azure Function module that provides a method for finding a common theme from a number of paragraphs of text.
 * This module handles the retrieval of a common theme from a number of paragraphs of text,
 * and returns it in a structured format. It includes validation for session authentication
 * and error handling for any issues encountered during the request processing.
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";
import axios from 'axios';
import axiosRetry from 'axios-retry';

import { sessionFailResponse, defaultErrorResponse, isSessionValid, invalidRequestResponse } from "./Utility.Azure";

import { IFindThemeRequest, IFindThemeResponse } from "../../../CommonTs/src/FindThemeApi.Types";
import { throwIfUndefined } from "../../../CommonTs/src/Asserts";
import { IModelConversationPrompt } from "../../../CommonTs/src/IModelDriver";
import { getDefaultChatModelDriver } from "../../../CommonTs/src/IModelFactory";
import { EPromptPersona } from "../../../CommonTs/src/IPromptPersona";

const minimumTextLength = 64;

/**
 * Asynchronous function to find a common theme from a number of paragraphs of text.
 * Makes a POST request to an Azure endpoint to get the most common theme in the provided text.
 * Utilizes axios for HTTP requests and axiosRetry for up to 5 retries in case of rate limit errors.
 * @param text The text containing paragraphs to analyze for a common theme.
 * @param length The length for the theme text to return.
 * @returns A Promise that resolves to the most common theme found in the text.
 */
async function findThemeCall(text: string, length: number): Promise<string> {

   let modelDriver = getDefaultChatModelDriver();
   
   let prompt : IModelConversationPrompt = {
      history: [],
      prompt: text
   }

   let response = await modelDriver.generateResponse (EPromptPersona.kClassifier, prompt, {wordTarget: length});

   return (response.content);
}

/**
 * Finds a theme from the provided text based on certain criteria.
 * Validates the session key and returns an HTTP response with the theme summary or an authorization error message.
 * @param request - The HTTP request containing the text and session key.
 * @param context - The invocation context for logging and validation.
 * @returns A promise of an HTTP response with the theme summary or an authorization error message.
 */
export async function findTheme(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   let text: string | undefined = undefined;
   let length: number | undefined = undefined;
   let theme: string | undefined = undefined;
   const defaultLength = 15;

   if (isSessionValid(request, context)) {
      
      try {
         const jsonRequest = await request.json();
         context.log(jsonRequest);
         const themeSpec = (jsonRequest as any).request as IFindThemeRequest;                                        

         text = themeSpec.text;
         length = themeSpec.length;

         if (text && text.length >= minimumTextLength && length > 0) {

            const definitelyText: string = text;
            const definitelyLength: number = length ? length : defaultLength;
            theme = await findThemeCall(definitelyText, definitelyLength);

            throwIfUndefined (theme);
            const themeResponse : IFindThemeResponse = {
               theme: theme
            }
            context.log (themeResponse);

            return {
               status: 200, // Ok
               body: JSON.stringify (themeResponse)
            };      
         }
         else {
            context.error ("Text is below minimum length or invalid length for theme.");            
            return invalidRequestResponse ("Text is below minimum length or invalid length for theme.")
         }
      }
      catch (e: any) {
         context.error (e);
         return defaultErrorResponse();
      }      
   }
   else {
      context.error ("Session validation failed.");         
      return sessionFailResponse();
   }
};

app.http('FindTheme', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: findTheme
});
****************************************

****************************************
Api\src\functions\GenerateFluidToken.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally

/**
 * @module GenerateFluidToken
 * @description Azure Function module that provides a method for generating a Fluid token.
 * This module handles the generation of a Fluid token, which is used to authenticate requests to the Fluid framework.
 * It includes validation for session authentication and error handling for any issues encountered during the request processing.
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";
//import { ScopeType } from "@fluidframework/protocol-definitions/lib";
import { generateToken } from "@fluidframework/server-services-client";

import { isSessionValid, sessionFailResponse, defaultErrorResponse } from "./Utility.Azure";
import { IFluidTokenRequest } from "../../../CommonTs/src/Fluid";

const key = process.env.ConversationKey;
const tenantId = "b9576484-5c2e-4613-bfdf-039948cdd521";

// WARNING - this is a redefinition of a type from inside the Fluid library. Does not seem to be exported at present, and we need it. 
//
export enum ScopeType {
	/**
	 * Read access is supported on the Container/Document
	 */
	DocRead = "doc:read",

	/**
	 * Write access is supported on the Container/Document
	 */
	DocWrite = "doc:write",

	/**
	 * User can generate new summaries operations
	 */
	SummaryWrite = "summary:write",
}

export async function generateFluidToken(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   if (isSessionValid(request, context)) {

      if (!tenantId) {
         context.error ("No Fluid tenant ID found.")         
         return sessionFailResponse();
      }   

      if (!key) {
         context.error ("No Fluid key found.")
         return sessionFailResponse();
      }    

      try {
         const jsonRequest = await request.json();
         const fluidRequest = (jsonRequest as any).data as IFluidTokenRequest;

         // tenantId, documentId, userId and userName are required parameters
         const documentId = fluidRequest.documentId;
         const userId = fluidRequest.userId;
         const userName = fluidRequest.userName;
         const local = fluidRequest.local;

         const user = { name: userName, id: userId };

         context.log ("Generating token for:" + JSON.stringify(fluidRequest) + " tenantId:" + tenantId);

         // Generate the token returned by an ITokenProvider implementation to use with the AzureClient.
         const token = generateToken(      
            local? "local" : tenantId,
            documentId,
            key,
            [ScopeType.DocRead, ScopeType.DocWrite, ScopeType.SummaryWrite],
            user
            );

         return  {
            status: 200,
            body: token
         }; 
      }
      catch(error: any) {

         context.error ("Error generating Fluid token:", error);
         return defaultErrorResponse();
      }

     
   }
   else {
      return sessionFailResponse();
   }
};

app.http('GenerateFluidToken', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: generateFluidToken
});
****************************************

****************************************
Api\src\functions\GenerateQuestion.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally

/**
 * @module GenerateQuestion
 * @description Azure Function module that provides a method for generating a question based on a summary.
 * This module handles the generation of a question based on a summary,
 * and returns it in a structured format. It includes validation for session authentication
 * and error handling for any issues encountered during the request processing.
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

import { IQuestionGenerationResponse, IGenerateQuestionQuery} from "../../../CommonTs/src/EnrichedQuery";
import { IModelConversationPrompt } from "../../../CommonTs/src/IModelDriver";
import { isSessionValid, sessionFailResponse, defaultErrorResponse} from "./Utility.Azure";
import { getDefaultChatModelDriver } from "../../../CommonTs/src/IModelFactory";
import { EPromptPersona } from "../../../CommonTs/src/IPromptPersona";

async function askModel(query: IGenerateQuestionQuery): Promise<IQuestionGenerationResponse> {

   let modelDriver = getDefaultChatModelDriver();
   let prompt : IModelConversationPrompt = {
      history: [],
      prompt: query.summary
   }

   let response = await modelDriver.generateResponse (EPromptPersona.kDeveloperQuestionGenerator, prompt, {wordTarget: query.wordTarget});

   const queryResponse: IQuestionGenerationResponse = {
      question: response.content
   }

   return queryResponse;
}


export async function generateQuestion(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   if (isSessionValid(request, context)) {

      try {
         const jsonRequest = await request.json();
                  
         const query = (jsonRequest as any)?.data as IGenerateQuestionQuery;

         context.log (query);
         const response = await askModel(query);
         const responseText = JSON.stringify(response);
         context.log (responseText);

         return {
            status: 200, // Ok
            body: responseText
         };
      }
      catch (e: any) {
         context.error (e);
         return defaultErrorResponse();
      }
   }
   else {
      return sessionFailResponse();
   }
};

app.http('GenerateQuestion', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: generateQuestion
});
****************************************

****************************************
Api\src\functions\IEnrichedChunkRepository.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * @module IEnrichedChunkRepository
 * @description Interface for an enriched chunk repository.
 * This module provides methods for querying and retrieving enriched chunks based on URL and summary.
 * It includes validation for session authentication and error handling for any issues encountered during the request processing.
 */

// Internal import
import {IRelevantEnrichedChunk, IChunkQueryRelevantToSummarySpec, IEnrichedChunkSummary, IChunkQueryRelevantToUrlSpec} from '../../../CommonTs/src/EnrichedChunk';

export const kDefaultSearchChunkCount: number = 2;
export const kDefaultMinimumCosineSimilarity = 0.5;

export interface IEnrichedChunkRepository  {

   /**
    * lookupRelevantFromSummary 
    * look to see of we have similar content 
    */      
   lookupRelevantFromSummary (spec: IChunkQueryRelevantToSummarySpec) : Promise<Array<IRelevantEnrichedChunk>>;

   /**
    * lookupRelevantfromUrl 
    * look to see of we have similar content from other sources
    */   
   lookupRelevantFromUrl (spec: IChunkQueryRelevantToUrlSpec) : Promise<Array<IRelevantEnrichedChunk>>;  

   /**
    * lookupFromUrl 
    * find the whole chunk given its URL
    */   
   lookupFromUrl (spec: IChunkQueryRelevantToUrlSpec) : Promise<IEnrichedChunkSummary | undefined>;     
}
****************************************

****************************************
Api\src\functions\LoginWithLinkedIn.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally

/**
 * @module LoginWithLinkedIn
 * @description Azure Function module that provides a method for logging in with LinkedIn.
 * This module handles the login process with LinkedIn, including authentication and session management.
 * It includes validation for session authentication and error handling for any issues encountered during the request processing.
 */

import axios from "axios";
import * as QueryString from "qs";

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";
import { getDefaultEnvironment } from "../../../CommonTs/src/IEnvironmentFactory";
import { EEnvironment } from "../../../CommonTs/src/IEnvironment";

export async function LoginWithLinkedIn(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   let requestedSession: string | null = null;

   for (const [key, value] of request.query.entries()) {
      if (key === 'session')
         requestedSession = value;
   }

   if ((requestedSession === process.env.SessionKey) || (requestedSession === process.env.SessionKey2)) {

      context.log("Passed session key validation:" + requestedSession);

      return redirectToLinkedIn(request, context);
   }
   else {
      context.log("Failed session key validation:" + requestedSession);

      return {
         status: 401, // Unauthorised
         body: "Authorization check failed."
      };
   }
};

app.http('LoginWithLinkedIn', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: LoginWithLinkedIn
});

/**
 * Redirects the user to LinkedIn for authentication using the Authorization Code Flow.
 * 
 * @param request - The HTTP request object containing query parameters.
 * @param context - The invocation context for the Azure Function.
 * @returns A promise that resolves to an HTTP response object with a status of 302 for redirection,
 *          headers containing the redirect location, and a body message of 'Redirecting...'.
 */
async function redirectToLinkedIn(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   // Put all the query parameters into the 'state' parameter, where can retrieve them later
   const queryAsObject = Object.fromEntries(request.query.entries());
   const stringifiedQuery = JSON.stringify(queryAsObject);

   const environment = getDefaultEnvironment();

   // https://learn.microsoft.com/en-us/linkedin/shared/authentication/authorization-code-flow?context=linkedin%2Fcontext&tabs=HTTPS1
   const clientID = process.env.LinkedInAppId;
   const redirectUrl = environment.authFromLinkedInApi();
   const scope = 'openid profile email';
   const state = stringifiedQuery;
   const redirect = "https://www.linkedin.com/oauth/v2/authorization?response_type=code&client_id="
      + clientID + "&redirect_uri=" + redirectUrl + "&scope=" + scope + "&state=" + state;

   return {
      status: 302,
      headers: {
         'Location': redirect
      },
      body: 'Redirecting...'
   };
}

/**
 * Asynchronously redirects back to the home page with the full path after processing LinkedIn authentication.
 * 
 * @param code The authorization code received in the authentication process.
 * @param session The session identifier.
 * @param conversation The conversation identifier.
 * @param secret The secret key for authentication.
 * @param context The invocation context for logging and tracing.
 * @returns An object containing the redirection status, headers, and body for the response.
 */
async function redirectBackHomeWithFullPath(code: string, session: string, conversation: string, secret: string, context: InvocationContext) {

   const environment = getDefaultEnvironment();

   try {

      const accessConfig = {
         headers: {
            'Content-Type': 'application/x-www-form-urlencoded'
         }
      }

      // https://learn.microsoft.com/en-us/linkedin/shared/authentication/authorization-code-flow?context=linkedin%2Fcontext&tabs=HTTPS1
      // grant_type	string	The value of this field should always be: authorization_code	Yes
      // code	string	The authorization code you received in Step 2.	Yes
      // client_id	string	The Client ID value generated in Step 1.	Yes
      // client_secret	string	The Secret Key value generated in Step 1. See the Best Practices Guide for ways to keep your client_secret value secure.	Yes
      // redirect_uri	url	The same redirect_uri value that you passed in the previous step.	Yes

      const data = {
         grant_type: 'authorization_code',
         code: code,
         client_id: process.env.LinkedInAppId,
         client_secret: process.env.LinkedInSecret,
         redirect_uri: environment.authFromLinkedInApi()
      };

      const accessRes = await axios.post('https://www.linkedin.com/oauth/v2/accessToken', QueryString.stringify(data), accessConfig);

      const access_token = accessRes.data.access_token;

      const profileConfig = {
         headers: {
            'Content-Type': 'application/x-www-form-urlencoded',
            'Authorization': `Bearer ${access_token}`
         }
      }

      const profileRes = await axios.get(' https://api.linkedin.com/v2/userinfo', profileConfig);

      const redirect = environment.boxerHome() + "#&session=" + session +
         "&conversation=" + encodeURIComponent(conversation) +
         "&email=" + encodeURIComponent(profileRes.data.email) +
         "&name=" + encodeURIComponent(profileRes.data.name) +
         "&secret=" + encodeURIComponent(secret);

      return {
         status: 302,
         headers: {
            'Location': redirect
         },
         body: 'Redirecting...'
      }

   } catch (err) {

      console.error(err);

      return {
         status: 500
      };
   }
}

/**
* Process the authentication from LinkedIn based on the provided request and context.
* 
* @param request - The HTTP request containing query parameters for session, code, conversation, and secret.
* @param context - The invocation context for the Azure Function.
* @returns A promise that resolves to an HTTP response initialization object.
*/
async function processAuthFromLinkedIn(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   let code: string | null = null;
   let state: string | null = null;
   let parsedState: JSON | null = null;
   let session: string | null = null;
   let secret: string | null = null;
   let conversation: string = "";     // COnversation can actually be an emptry string. 

   for (const [key, value] of request.query.entries()) {
      if (key === 'state')
         state = value;
      if (key === 'code')
         code = value;
   }

   // Pull all the state variables out of the 'state' parameter, where we put them on doing the redurect to LinkedIn
   if (state) {
      parsedState = JSON.parse(state);
      if (parsedState) {
         session = (parsedState as any).session;
         conversation = (parsedState as any).conversation;
         secret = (parsedState as any).secret;
      }
   }

   if (((session === process.env.SessionKey) || (session === process.env.SessionKey2))
      && code && secret) {

      return await redirectBackHomeWithFullPath(code, session, conversation, secret, context);
   } else {
      return {
         status: 400
      };
   }
}
app.http('ProcessAuthFromLinkedIn', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: processAuthFromLinkedIn
});
****************************************

****************************************
Api\src\functions\QueryModelWithEnrichment.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024

/**
 * QueryModelWithEnrichment Module
 * 
 * This module provides functionality for querying an AI model with document enrichment.
 * It handles both direct model queries and enriched queries that incorporate relevant
 * document context from a repository. The module supports Azure Functions integration
 * and includes retry logic for handling rate limits.
 * 
 * Key features:
 * - Parallel processing of direct and enriched model queries
 * - Document enrichment based on similarity matching
 * - Session validation and error handling
 * - Configurable retry logic for API rate limits
 * 
 * @module QueryModelWithEnrichment
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

import { IModelConversationElement, EModelConversationRole, IModelConversationPrompt } from "../../../CommonTs/src/IModelDriver";
import { IEnrichedQuery, IEnrichedResponse } from "../../../CommonTs/src/EnrichedQuery";
import { IRelevantEnrichedChunk } from "../../../CommonTs/src/EnrichedChunk";
import { getDefaultChatModelDriver, getDefaultModel } from "../../../CommonTs/src/IModelFactory";

import { getEnrichedChunkRepository } from "./EnrichedChunkRepositoryFactory";
import { isSessionValid, sessionFailResponse, defaultErrorResponse} from "./Utility.Azure";
import { EPromptPersona } from "../../../CommonTs/src/IPromptPersona";

const model = getDefaultModel();
const minimumEnrichmentTokens = 50; // we use 50 word summaries. if we get half this, the key is too short for a meaningful search. 

/**
 * Asynchronously sends an enriched query to a model for processing and returns an enriched response.
 * 
 * @param query - The enriched query object containing details for the model to process.
 * @returns A promise that resolves to an enriched response object with the model's answer and relevant enriched chunks.
 */
export async function askModel(query: IEnrichedQuery): Promise<IEnrichedResponse> {

   let modelDriver = getDefaultChatModelDriver();

   let directPrompt : IModelConversationPrompt = {
      history: query.history,
      prompt: query.question
   }

   let directPromise = await modelDriver.generateResponse (EPromptPersona.kDeveloperAssistant, directPrompt, {wordTarget: query.wordTarget});

   let enrichedPrompt : IModelConversationPrompt = {
      history: query.history,
      prompt: query.question
   }

   let enrichmentPromise = await modelDriver.generateResponse (EPromptPersona.kDeveloperImaginedAnswerGenerator, enrichedPrompt, {wordTarget: query.wordTarget});

   const [directResponse, enrichedResponse] = await Promise.all ([directPromise, enrichmentPromise]);

   const answer = (directResponse.content);
   const imagined = (enrichedResponse.content);

   const tokens = model.estimateTokens (imagined);
   let chunks = new Array<IRelevantEnrichedChunk>();

   if (tokens >= minimumEnrichmentTokens) {
      const repository = getEnrichedChunkRepository(query.repositoryId);

      const spec = {
         repositoryId: query.repositoryId,
         summary: imagined,
         maxCount: query.maxCount,
         similarityThreshold: query.similarityThreshold
      }

      chunks = await repository.lookupRelevantFromSummary (spec);
   }

   const queryResponse: IEnrichedResponse = {
      answer: answer,
      chunks: chunks
   }

   return queryResponse;
}

/**
 * Handles a query with enrichment by validating the session and processing the request.
 * @param request - The HTTP request containing the query data.
 * @param context - The context for the function invocation.
 * @returns A promise that resolves to an HTTP response with the query result.
 */
export async function queryModelWithEnrichment(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   const jsonRequest = await request.json();

   if (isSessionValid(request, context)) {

      try {
         const query = (jsonRequest as any)?.data as IEnrichedQuery;

         context.log (query);
         const response = await askModel(query);
         const responseText = JSON.stringify(response);
         context.log (responseText);

         return {
            status: 200, // Ok
            body: responseText
         };
      }
      catch (e: any) {
         context.error (e);
         return defaultErrorResponse();
      }
   }
   else {
      return sessionFailResponse();
   }
};

app.http('QueryModelWithEnrichment', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: queryModelWithEnrichment
});
****************************************

****************************************
Api\src\functions\StorableActivity.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure 
// 'npm start' to run locally

/**
 * @module StorableActivity
 * @description Azure Function module that provides methods for managing storable activities.
 * This module handles the retrieval, saving, and removal of activity records, as well as fetching recent activities.
 * It includes validation for session authentication and error handling for any issues encountered during the request processing.
 */

// 3rd party imports
import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";
import { activityStorableAttributes } from "./StorableApi.Cosmos";
import { getStorableApi as getStorableApi, removeStorableApi, saveStorableApi, getRecentStorablesApi } from "./StorableApi.Azure";

app.http('GetActivity', {
   methods: ['POST'],
   authLevel: 'anonymous',
   handler: getActivity
});

/**
 * Saves an activity record based on the provided request and context.
 * Validates the session key from the request query parameters against predefined session keys.
 * If the session key is valid, logs the validation status, processes the JSON request, and saves the activity.
 * Returns an HTTP response with a status code and the session key or an error message.
 *
 * @param request - The HTTP request containing the activity data.
 * @param context - The context for the current invocation.
 * @returns A promise that resolves to an HTTP response with the status and response body.
 */
export async function getActivity(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {
   
   return getStorableApi (request, activityStorableAttributes, context);
};

app.http('SaveActivity', {
   methods: ['POST'],
   authLevel: 'anonymous',
   handler: saveActivity
});

/**
 * Saves an activity record based on the provided request and context.
 * Validates the session key from the request query parameters against predefined session keys.
 * If the session key is valid, logs the validation status, processes the JSON request, and saves the activity.
 * Returns an HTTP response with a status code and the session key or an error message.
 *
 * @param request - The HTTP request containing the activity data.
 * @param context - The context for the current invocation.
 * @returns A promise that resolves to an HTTP response with the status and response body.
 */
export async function saveActivity(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {
   
   return saveStorableApi (request, activityStorableAttributes, context);
};

app.http('RemoveActivity', {
   methods: ['POST'],
   authLevel: 'anonymous',
   handler: removeActivity
});

/**
 * Asynchronously removes an activity using the provided HTTP request and invocation context.
 * 
 * @param request - The HTTP request containing the activity information.
 * @param context - The context in which the activity removal is taking place.
 * @returns A promise that resolves to an HttpResponseInit object representing the removal operation result.
 */
export async function removeActivity(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   return removeStorableApi (request, activityStorableAttributes, context);
}

app.http('GetActivities', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: getRecentActivities
});

export async function getRecentActivities(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   return getRecentStorablesApi (request, activityStorableAttributes, context);
}
****************************************

****************************************
Api\src\functions\StorableApi.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
/**
 * @module AzureStorableApi
 * 
 * Provides Azure Functions HTTP endpoints for CRUD operations on IStorable objects in Azure Cosmos DB.
 * This module acts as a REST API layer between HTTP clients and the underlying Cosmos DB storage,
 * handling session validation, request parsing, and response formatting.
 * 
 * Key features:
 * - Session-validated endpoints for finding, getting, saving, and removing IStorable objects
 * - Support for custom transformers to modify data before storage and after retrieval
 * - Error handling and logging through Azure Functions context
 * - Query support for both ID-based and functional key-based searches
 * - Batch operations for retrieving recent storables
 * 
 * The module uses ICosmosStorableParams for database configuration and supports
 * custom response transformers for flexible API responses.
 */

// 3rd party imports
import { HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

// Internal imports
import { isSessionValid, sessionFailResponse, notFoundResponse } from "./Utility.Azure";
import { IStorable, IStorableQuerySpec, IStorableMultiQuerySpec, IStorableOperationResult} from "../../../CommonTs/src/IStorable";
import {AzureLogger, findStorable, loadStorable, saveStorable, removeStorable, 
        loadRecentStorables, ICosmosStorableParams, StorableTransformer} from './StorableApi.Cosmos';

// A transformer function that can be applied to a storable to transform it in some way to the HTTP response
export type StorableResponseTransformer = (storable: IStorable) => HttpResponseInit;

// A transformer function that can be applied to a storable to transform it in some way to the HTTP response
export type StorableArrayResponseTransformer = (storable: Array<IStorable>) => HttpResponseInit;

// Applies a transformer function to a storable if it is provided.
function applyTransformer (storable: IStorable, transformer: StorableResponseTransformer | undefined) : HttpResponseInit {

   if (transformer)
      return transformer (storable);

   return {
      status: 200,
      body: JSON.stringify(storable)
   };
}

// Applies a transformer function to a storable array if it is provided.
function applyArrayTransformer (storable: Array<IStorable>, transformer: StorableArrayResponseTransformer | undefined) : HttpResponseInit {

   if (transformer)
      return transformer (storable);   

   return {
      status: 200,
      body: JSON.stringify(storable)
   };
}

/**
 * Asynchronous function to load an Storable based on the provided request and context.
 * Validates the session key from the request query parameters and removes the Storable if the session key matches predefined keys.
 * Logs the validation and removal status, returning an HTTP response with the appropriate status and message.
 * 
 * @param request - The HTTP request containing the session key and Storable data.
 * @param params The parameters required for saving the record, including partition key and collection path.
 * @param context - The context object for logging and error handling.
 * @param transformer - An optional transformer function to apply to the loaded storable.
 * @param resultTransformer - An optional transformer function to apply to the result storable.
 * @returns A promise of an HTTP response indicating the status of the removal operation.
 */
export async function findStorableApi(request: HttpRequest, 
   params: ICosmosStorableParams, 
   context: InvocationContext,
   transformer: StorableTransformer | undefined = undefined,
   resultTransformer: StorableResponseTransformer | undefined = undefined): Promise<HttpResponseInit> {

   if (isSessionValid(request, context)) {

      try {      
         const jsonRequest = await request.json();
         const spec = (jsonRequest as any).request as IStorableQuerySpec;

         const logger = new AzureLogger(context);

         const result = await findStorable (spec.functionalSearchKey, params, logger, transformer);
         if (result)
            context.log("Found:" + result.id);
         else
            context.log("Found nothing.");
         
         if (result)
            return applyTransformer (result, resultTransformer);
         else {
            return notFoundResponse ();
         }
      }
      catch (e: any) {
         context.error ("Failed find:" + e?.toString());
         return {
            status: 500,
            body: "Failed find."
         };
      }
   }
   else {
      context.error("Failed session validation");           
      return sessionFailResponse();
   }
};

/**
 * Asynchronous function to load an Storable based on the provided request and context.
 * Validates the session key from the request query parameters and removes the Storable if the session key matches predefined keys.
 * Logs the validation and removal status, returning an HTTP response with the appropriate status and message.
 * 
 * @param request - The HTTP request containing the session key and Storable data.
 * @param params The parameters required for saving the record, including partition key and collection path.
 * @param context - The context object for logging and error handling.
 * @param transformer - An optional transformer function to apply to the loaded storable.
 * @param resultTransformer - An optional transformer function to apply to the result storable.
 * @returns A promise of an HTTP response indicating the status of the removal operation.
 */
export async function getStorableApi(request: HttpRequest, 
   params: ICosmosStorableParams, 
   context: InvocationContext,
   transformer: StorableTransformer | undefined = undefined,
   resultTransformer: StorableResponseTransformer | undefined = undefined): Promise<HttpResponseInit> {

   if (isSessionValid(request, context)) {

      try {      
         const jsonRequest = await request.json();
         const spec = (jsonRequest as any).request as IStorableQuerySpec;

         return await getStorableApiCommon (spec, params, context, transformer, resultTransformer);
      }
      catch (e: any) {
         context.error ("Failed load:" + e?.toString());
         return {
            status: 500,
            body: "Failed load."
         };
      }
   }
   else {
      context.error("Failed session validation");           
      return sessionFailResponse();
   }
};

/**
 * Asynchronous function to load an Storable based on the provided request and context.
 * Returns the Storable if the id matches a record in the database.
 * *Note* This function does not validate the session key. we are not proptecting GPU costs & we want browsers to be able to retrueve directly without the session key appearing in the URL parameters. 
 * @param request - The HTTP request containing the session key and Storable data.
 * @param params The parameters required for saving the record, including partition key and collection path.
 * @param context - The context object for logging and error handling.
 * @param transformer - An optional transformer function to apply to the loaded storable.
 * @param resultTransformer - An optional transformer function to apply to the result storable.
 * @returns A promise of an HTTP response indicating the status of the removal operation.
 */
export async function getStorableApiFromQuery(request: HttpRequest,
   params: ICosmosStorableParams,
   context: InvocationContext,
   transformer: StorableTransformer | undefined = undefined,
   resultTransformer: StorableResponseTransformer | undefined = undefined): Promise<HttpResponseInit> {

   let requestedId: string | undefined = undefined;

   for (const [key, value] of request.query.entries()) {
      if (key === 'id')
         requestedId = value;
   }

   const spec: IStorableQuerySpec = {
      id: requestedId,
      functionalSearchKey: undefined
   };

   try {
      return await getStorableApiCommon(spec, params, context, transformer, resultTransformer);
   }
   catch (e: any) {
      context.error("Failed load:" + e?.toString());
      return {
         status: 500,
         body: "Failed load."
      };
   }
};

/**
 * Asynchronous function to load an Storable based on the provided request and context.
 * Returns the Storable if the id matches a record in the database.
 * @param request - The HTTP request containing the session key and Storable data.
 * @param params The parameters required for saving the record, including partition key and collection path.
 * @param context - The context object for logging and error handling.
 * @param transformer - An optional transformer function to apply to the loaded storable.
 * @param resultTransformer - An optional transformer function to apply to the result storable.
 * @returns A promise of an HTTP response indicating the status of the removal operation.
 */
async function getStorableApiCommon(spec: IStorableQuerySpec,
   params: ICosmosStorableParams,
   context: InvocationContext,
   transformer: StorableTransformer | undefined = undefined,
   resultTransformer: StorableResponseTransformer | undefined = undefined): Promise<HttpResponseInit> {

   try {
      const logger = new AzureLogger(context);

      const result = await loadStorable(spec.id, params, logger, transformer);
      if (result)
         context.log("Loaded:" + result.id);
      else
         context.log("Loaded nothing.");

      if (result) {
         return applyTransformer(result, resultTransformer);
      }
      else {
         return notFoundResponse();
      }
   }
   catch (e: any) {
      context.error("Failed load:" + e?.toString());
      return {
         status: 500,
         body: "Failed load."
      };
   }
}

/**
 * Saves a Storable record based on the provided request and context.
 * Validates the session key from the request query parameters against predefined session keys.
 * If the session key is valid, logs the validation status, processes the JSON request, and saves the activity.
 * Returns an HTTP response with a status code and the session key or an error message.
 *
 * @param request - The HTTP request containing the Storable data.
 * @param params The parameters required for saving the record, including partition key and collection path. 
 * @param context - The context for the current invocation.
 * @returns A promise that resolves to an HTTP response with the status and response body.
 */
export async function saveStorableApi (request: HttpRequest,  
   params: ICosmosStorableParams,
   context: InvocationContext): Promise<HttpResponseInit> {


   if (isSessionValid(request, context)) {

      try {
         const jsonRequest = await request.json();
         const spec = (jsonRequest as any).request as IStorable;   

         const logger = new AzureLogger(context);
         await saveStorable(spec, params, logger);

         const result: IStorableOperationResult = {
            ok: true
         }
         return {
            status: 200,
            body: JSON.stringify(result)
         };         
      }
      catch (e: any) {
         context.error("Failed save:" + e?.toString());
         return {
            status: 500,
            body: "Failed save."
         };
      }
   }
   else {
      context.error("Failed session validation");      
      return sessionFailResponse();
   }
};

/**
 * Asynchronous function to handle the removal of an Storable based on the provided request and context.
 * Validates the session key from the request query parameters and removes the Storable if the session key matches predefined keys.
 * Logs the validation and removal status, returning an HTTP response with the appropriate status and message.
 * 
 * @param request - The HTTP request containing the session key and Storable data.
 * @param params The parameters required for saving the record, including partition key and collection path.
 * @param context - The context object for logging and error handling.
 * @returns A promise of an HTTP response indicating the status of the removal operation.
 */
export async function removeStorableApi(request: HttpRequest, 
   params: ICosmosStorableParams, 
   context: InvocationContext): Promise<HttpResponseInit> {


   if (isSessionValid(request, context)) {

      try {      
         const jsonRequest = await request.json();
         const spec = (jsonRequest as any).request as IStorableQuerySpec;   

         const logger = new AzureLogger(context);

         const ok = await removeStorable (spec.id, params, logger);

         const result: IStorableOperationResult = {
            ok: ok
         }
         return {
            status: 200,
            body: JSON.stringify(result)
         };
      }
      catch (e: any) {
         context.error ("Failed remove:" + e?.toString());
         return {
            status: 500,
            body: "Failed remove."
         };
      }
   }
   else {
      context.error("Failed session validation");           
      return sessionFailResponse();
   }
};


/**
 * Asynchronous function to handle retrieving activities based on the provided request and context.
 * 
 * @param request - The HTTP request object containing query parameters.
 * @param params - The parameters required for saving the record, including partition key and collection path.
 * @param context - The invocation context for logging and other operations.
 * @param transformer - An optional transformer function to apply to the loaded storable.
 * @param resultTransformer - An optional transformer function to apply to the result storable array.
 * @returns A promise that resolves to an HTTP response initialization object.
 */
export async function getRecentStorablesApi(request: HttpRequest, 
   params: ICosmosStorableParams,    
   context: InvocationContext,
   transformer: StorableTransformer | undefined = undefined,
   resultTransformer: StorableArrayResponseTransformer | undefined = undefined): Promise<HttpResponseInit> {

   if (isSessionValid(request, context)) {

      let loaded: Array<IStorable> | undefined = undefined;

      try {
         const jsonRequest = await request.json();
         const spec = (jsonRequest as any).request as IStorableMultiQuerySpec;         

         const logger = new AzureLogger(context);

         loaded = await loadRecentStorables (spec, params, logger, transformer);
         for (let i = 0; loaded && i < loaded.length; i++) {
            context.log("Loaded:" + loaded[i].id);
         }

         return applyArrayTransformer (loaded, resultTransformer);         
      }
      catch (e: any) {
         context.log("Failed load recent:" + e?.toString());
         return {
            status: 500,
            body: "Failed load recent."
         };
      }
   }
   else {
      return sessionFailResponse();
   }
};
****************************************

****************************************
Api\src\functions\StorableApi.Cosmos.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024

/**
* @module CosmosStorableApi
* @description Provides a high-level API for interacting with Azure Cosmos DB storage.
* This module implements CRUD operations (Create, Read, Update, Delete) for storable objects
* in Cosmos DB collections, along with query capabilities and logging interfaces.
* 
* Key features:
* - Storable object management (find, load, save, remove)
* - Batch loading operations
* - Collection-specific configurations
* - Logging interfaces for Azure Functions and Console
* - Support for data transformation during operations
*/

// 3rd party imports
import { InvocationContext } from "@azure/functions";
import axios from "axios";

// Internal imports
import { throwIfUndefined } from "../../../CommonTs/src/Asserts";
import { IStorable, IStorableMultiQuerySpec } from "../../../CommonTs/src/IStorable";

const chunkPartitionKey: string = "c02af798a60b48129c5e223e645a9b72";
const chunkCollectionPath = "dbs/Studio/colls/Chunk";
const chunkCollectionName = "Chunk";

const activityPartitionKey: string = "6ea3299d987b4b33a1c0b079a833206f";
const activityCollectionPath = "dbs/Studio/colls/Activity";
const activityCollectionName = "Activity";

const pagePartitionKey: string = "f11a7404e266499a84a58fead932eec4";
const pageCollectionPath = "dbs/Studio/colls/Page";
const pageCollectionName = "Page";

import { makeStorablePostToken, makeStorableDeleteToken, 
   makePostQueryHeader, makePostHeader, makeDeleteHeader } from './CosmosRepositoryApi';

// A transformer function that can be applied to a storable to transform it in some way.
export type StorableTransformer = (storable: IStorable) => IStorable;

// Applies a transformer function to a storable if it is provided.
function applyTransformer (storable: IStorable, transformer: StorableTransformer | undefined) : IStorable {

   if (transformer)
      return transformer (storable);

   return storable;
}

export interface ICosmosStorableParams {
   partitionKey: string;
   collectionPath: string;  
   collectionName: string; 
}

export interface ILoggingContext {
   log (message: string, details: any) : void;
   info (message: string, details: any) : void;   
   warning (message: string, details: any) : void;    
   error (message: string, details: any) : void;    
}

export const chunkStorableAttributes : ICosmosStorableParams = {
   partitionKey: chunkPartitionKey,
   collectionPath: chunkCollectionPath,
   collectionName: chunkCollectionName
}

export const activityStorableAttributes : ICosmosStorableParams = {
   partitionKey: activityPartitionKey,
   collectionPath: activityCollectionPath,
   collectionName: activityCollectionName
}

export const pageStorableAttributes : ICosmosStorableParams = {
   partitionKey: pagePartitionKey,
   collectionPath: pageCollectionPath,
   collectionName: pageCollectionName
}

export class AzureLogger implements ILoggingContext {

   invocationContext: InvocationContext;

   constructor (invocationContext_: InvocationContext) {

      this.invocationContext = invocationContext_;
   }

   log (message: string, details: any) : void {

      return this.invocationContext.log (message, JSON.stringify(details));
   }
   
   info (message: string, details: any) : void {
      return this.invocationContext.info (message, JSON.stringify(details));      
   }
   
   warning (message: string, details: any) : void {
      return this.invocationContext.warn (message, JSON.stringify(details));
   }  
   
   error (message: string, details: any) : void {
      return this.invocationContext.error (message, JSON.stringify(details));      
   }
}

export class ConsoleLogger implements ILoggingContext {


   constructor () {

   }

   log (message: string, details: any) : void {

      console.log (message, JSON.stringify(details));
   }
   
   info (message: string, details: any) : void {
      console.info (message, JSON.stringify(details));      
   }
   
   warning (message: string, details: any) : void {
      console.warn (message, JSON.stringify(details));
   }  
   
   error (message: string, details: any) : void {
      console.error (message, JSON.stringify(details));      
   }
}

/**
 * Asynchronously finds a Storable from the database.
 * 
 * @param id - The unique identifier of the Storable to be found.
 * @param params - the ICosmosStorableParams for the collection
 * @param context - The invocation context for logging purposes.
 * @param transformer - An optional transformer function to apply to the loaded storable.
 * @returns A Promise that resolves to a boolean indicating the success of the removal operation.
 */
export async function findStorable(id: string | undefined,    
   params: ICosmosStorableParams, 
   context: ILoggingContext,
   transformer: StorableTransformer | undefined = undefined): Promise<IStorable | undefined> {

   if (!id)
      return undefined;
   
   const dbkey = process.env.CosmosApiKey;

   const done = new Promise<IStorable | undefined>(function (resolve, reject) {

      const time = new Date().toUTCString();

      throwIfUndefined(dbkey); // Keep compiler happy, should not be able to get here with actual undefined key.       
      const key = makeStorablePostToken(time, params.collectionPath, dbkey);
      const headers = makePostQueryHeader(key, time, params.partitionKey);

      const query = "SELECT * FROM " + params.collectionName + " a WHERE a.functionalSearchKey = @id";

      axios.post('https://braidstudio.documents.azure.com:443/' + params.collectionPath + '/docs/',
         {
            "query": query,
            "parameters": [
               {
                  "name": "@id",
                  "value": id
               }
            ]
         },
         {
            headers: headers
         })
         .then((resp: any) => {

            const responseRecords = resp.data.Documents;
            const storedRecord = responseRecords[0] as IStorable;

            context.log ("Loaded storable:", storedRecord.id);
            resolve(applyTransformer(storedRecord, transformer));
         })
         .catch((error: any) => {

            context.error ("Error calling database:", error);
            reject(undefined);
         });
   });

   return done;
}

/**
 * Asynchronously loads a Storable from the database.
 * 
 * @param id - The unique identifier of the Storable to be removed.
 * @param params - the ICosmosStorableParams for the collection
 * @param context - The invocation context for logging purposes.
 * @param transformer - An optional transformer function to apply to the loaded storable.
 * @returns A Promise that resolves to a boolean indicating the success of the removal operation.
 */
export async function loadStorable(id: string | undefined, 
   params: ICosmosStorableParams, 
   context: ILoggingContext,
   transformer: StorableTransformer | undefined = undefined): Promise<IStorable | undefined> {

   if (!id)
      return undefined;
   
   const dbkey = process.env.CosmosApiKey;

   const done = new Promise<IStorable | undefined>(function (resolve, reject) {

      const time = new Date().toUTCString();

      throwIfUndefined(dbkey); // Keep compiler happy, should not be able to get here with actual undefined key.       
      const key = makeStorablePostToken(time, params.collectionPath, dbkey);
      const headers = makePostQueryHeader(key, time, params.partitionKey);

      const query = "SELECT * FROM " + params.collectionName + " a WHERE a.id = @id";

      axios.post('https://braidstudio.documents.azure.com:443/' + params.collectionPath + '/docs/',
         {
            "query": query,
            "parameters": [
               {
                  "name": "@id",
                  "value": id
               }
            ]
         },
         {
            headers: headers
         })
         .then((resp: any) => {

            const responseRecords = resp.data.Documents;
            const storedRecord = responseRecords[0] as IStorable;

            context.log ("Loaded storable:", storedRecord.id);
            resolve(applyTransformer(storedRecord, transformer));
         })
         .catch((error: any) => {

            context.error ("Error calling database:", error);
            reject(undefined);
         });
   });

   return done;
}

/**
 * Saves a storable record to a Cosmos database.
 * 
 * @param record The storable record to be saved.
 * @param params The parameters required for saving the record, including partition key and collection path.
 * @param context The logging context for capturing log messages during the save operation.
 * @returns A Promise that resolves to a boolean indicating the success of the save operation.
 */
export async function saveStorable(record: IStorable, params: ICosmosStorableParams, context: ILoggingContext): Promise<boolean> {

   const dbkey = process.env.CosmosApiKey;

   const done = new Promise<boolean>(function (resolve, reject) {

      const time = new Date().toUTCString();
      const stream = JSON.stringify(record);
      const document = JSON.parse(stream);

      throwIfUndefined(dbkey); // Keep compiler happy, should not be able to get here with actual undefined key. 
      const key = makeStorablePostToken(time, params.collectionPath, dbkey as string);
      const headers = makePostHeader(key, time, params.partitionKey);

      document.partition = params.partitionKey; // Dont need real partitions until 10 GB ... 

      axios.post('https://braidstudio.documents.azure.com:443/' + params.collectionPath + '/docs/',
         document,
         {
            headers: headers
         })
         .then((resp: any) => {

            context.log("Saved storable:", record.id);
            resolve(true);
         })
         .catch((error: any) => {

            context.error("Error calling database:", error);
            reject(false);
         });
   });

   return done;
}

/**
 * Asynchronously removes a Storable from the database.
 * 
 * @param id - The unique identifier of the Storable to be removed.
 * @param params - the ICosmosStorableParams for the collection
 * @param context - The invocation context for logging purposes.
 * @returns A Promise that resolves to a boolean indicating the success of the removal operation.
 */
export async function removeStorable(id: string | undefined, params: ICosmosStorableParams, context: ILoggingContext): Promise<boolean> {

   if (!id)
      return false;
   
   const dbkey = process.env.CosmosApiKey;

   const done = new Promise<boolean>(function (resolve, reject) {

      const time = new Date().toUTCString();
      throwIfUndefined(dbkey); // Keep compiler happy, should not be able to get here with actual undefined key. 
      const key = makeStorableDeleteToken (time, params.collectionPath, dbkey, id);
      const headers = makeDeleteHeader(key, time, params.partitionKey);
        
      const deletePath = 'https://braidstudio.documents.azure.com:443/' + params.collectionPath + '/docs/'+ id;

      axios.delete(deletePath,
         {
            headers: headers
         })
         .then((resp: any) => {

            context.log("Removed storable:", id);
            resolve(true);
         })
         .catch((error: any) => {
            context.error ("Error calling database:", error);
            reject(false);
         });
   });

   return done;
}

/**
 * Asynchronously loads recent activities based on the provided query specifications.
 * 
 * @param querySpec - The query specifications including the limit and className.
 * @param params - the ICosmosStorableParams for the collection
 * @param context - The invocation context for logging and tracing.
 * @param transformer - An optional transformer function to apply to the loaded storable.
 * @returns A promise that resolves to an array of storable objects representing the loaded activities.
 */
export async function loadRecentStorables(querySpec: IStorableMultiQuerySpec,
   params: ICosmosStorableParams,
   context: ILoggingContext,
   transformer: StorableTransformer | undefined = undefined): Promise<Array<IStorable>> {

   const dbkey = process.env.CosmosApiKey;

   const done = new Promise<Array<IStorable>>(function (resolve, reject) {

      const time = new Date().toUTCString();

      throwIfUndefined(dbkey); // Keep compiler happy, should not be able to get here with actual undefined key.       
      const key = makeStorablePostToken(time, params.collectionPath, dbkey);
      const headers = makePostQueryHeader(key, time, params.partitionKey);

      const query = "SELECT * FROM " + params.collectionName + " a WHERE a.className = @className ORDER BY a.created DESC OFFSET 0 LIMIT " + querySpec.limit.toString();

      axios.post('https://braidstudio.documents.azure.com:443/' + params.collectionPath + '/docs/',
         {
            "query": query,
            "parameters": [
               {
                  "name": "@className",
                  "value": querySpec.className
               }
            ]
         },
         {
            headers: headers
         })
         .then((resp: any) => {

            const responseRecords = resp.data.Documents;
            const storedRecords = new Array<IStorable>();

            for (let i = 0; i < responseRecords.length; i++) {
               storedRecords.push(applyTransformer(responseRecords[i], transformer));
               context.log("Loaded storable:", storedRecords[i].id);
            }
            resolve(storedRecords);
         })
         .catch((error: any) => {

            context.error("Error calling database:", error);
            reject(new Array<IStorable>());
         });
   });

   return done;
}

/**
 * Asynchronously loads recent activities based on the provided query specifications.
 * 
 * @param querySpec - The query specifications including the limit and className.
 * @param params - the ICosmosStorableParams for the collection
 * @param context - The invocation context for logging and tracing.
 * @param transformer - An optional transformer function to apply to the loaded storable.
 * @returns A promise that resolves to an array of storable objects representing the loaded activities.
 */
export async function loadStorables(querySpec: IStorableMultiQuerySpec,
   params: ICosmosStorableParams,
   context: ILoggingContext,
   transformer: StorableTransformer | undefined = undefined): Promise<Array<IStorable>> {

   const dbkey = process.env.CosmosApiKey;

   const done = new Promise<Array<IStorable>>(async function (resolve, reject) {

      const time = new Date().toUTCString();
      let continuation: string | undefined = undefined;
      let more = true;

      throwIfUndefined(dbkey); // Keep compiler happy, should not be able to get here with actual undefined key.       
      const key = makeStorablePostToken(time, params.collectionPath, dbkey);
      const accumulatedRecords = new Array<IStorable>();

      while (more) {

         try {
            const headers = makePostQueryHeader(key, time, params.partitionKey, continuation);

            const query = "SELECT * FROM " + params.collectionName + " a WHERE a.className = @className ORDER BY a.created DESC";

            const resp = await axios.post('https://braidstudio.documents.azure.com:443/' + params.collectionPath + '/docs/',
               {
                  "query": query,
                  "parameters": [
                     {
                        "name": "@className",
                        "value": querySpec.className
                     }
                  ]
               },
               {
                  headers: headers
               });

            if (resp.headers["x-ms-continuation"]) {
               continuation = resp.headers["x-ms-continuation"];
            }
            else {
               more = false;
            }
            const responseRecords = resp.data.Documents;

            for (let i = 0; i < responseRecords.length; i++) {
               accumulatedRecords.push(applyTransformer(responseRecords[i], transformer));
               context.log("Loaded storable:", accumulatedRecords[i].id);
            }
         }
         catch (error: any) {

            context.error("Error calling database:", error);
            resolve (new Array<IStorable>());
         };
      }

      resolve (accumulatedRecords);      
   });

   return done;
}
****************************************

****************************************
Api\src\functions\StorableChunk.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure 
// 'npm start' to run locally

/**
 * @module StorableChunk
 * @description Azure Function module that provides methods for managing storable chunks.
 * This module handles the retrieval, saving, and removal of chunk records, as well as fetching recent chunks.
 * It includes validation for session authentication and error handling for any issues encountered during the request processing.
 */

// 3rd party imports
import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

// Internal imports
import { chunkStorableAttributes } from './StorableApi.Cosmos';
import { findStorableApi, removeStorableApi, saveStorableApi, getStorableApi, getRecentStorablesApi } from "./StorableApi.Azure";

app.http('GetChunk', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: getChunk
});

/**
 * Loads a Chunk record based on the provided request and context.
 * Validates the session key from the request query parameters against predefined session keys.
 * If the session key is valid, logs the validation status, processes the JSON request, and loads the Chunk.
 * Returns an HTTP response with a status code and the session key or an error message.
 *
 * @param request - The HTTP request containing the Chunk data.
 * @param context - The context for the current invocation.
 * @returns A promise that resolves to an HTTP response with the status and response body.
 */
export async function getChunk(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {
   
   return getStorableApi (request, chunkStorableAttributes, context);
};

app.http('FindChunk', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: findChunk
});

/**
 * Loads a Chunk record based on the provided request and context.
 * Validates the session key from the request query parameters against predefined session keys.
 * If the session key is valid, logs the validation status, processes the JSON request, and loads the Chunk.
 * Returns an HTTP response with a status code and the session key or an error message.
 *
 * @param request - The HTTP request containing the Chunk data.
 * @param context - The context for the current invocation.
 * @returns A promise that resolves to an HTTP response with the status and response body.
 */
export async function findChunk(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {
   
   return findStorableApi (request, chunkStorableAttributes, context);
};

app.http('SaveChunk', {
   methods: ['POST'],
   authLevel: 'anonymous',
   handler: saveChunk
});

/**
 * Saves a chunk record based on the provided request and context.
 * Validates the session key from the request query parameters against predefined session keys.
 * If the session key is valid, logs the validation status, processes the JSON request, and saves the chunk.
 * Returns an HTTP response with a status code and the session key or an error message.
 *
 * @param request - The HTTP request containing the chunk data.
 * @param context - The context for the current invocation.
 * @returns A promise that resolves to an HTTP response with the status and response body.
 */
export async function saveChunk(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   return saveStorableApi (request, chunkStorableAttributes, context);
};

app.http('RemoveChunk', {
   methods: ['POST'],
   authLevel: 'anonymous',
   handler: removeChunk
});

/**
 * Asynchronously removes a chunk using the provided HTTP request and invocation context.
 * 
 * @param request - The HTTP request containing information about the chunk to be removed.
 * @param context - The invocation context for logging and error handling.
 * @returns A promise that resolves to an HttpResponseInit object representing the result of the removal operation.
 */
export async function removeChunk(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   return removeStorableApi (request, chunkStorableAttributes, context);
}

app.http('GetChunks', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: getRecentChunks
});

/**
 * Asynchronously retrieves recent chunks based on the provided HTTP request and invocation context.
 * @param request - The HTTP request object containing the necessary data.
 * @param context - The invocation context for the function execution.
 * @returns A promise that resolves to an HttpResponseInit object representing the response.
 */
export async function getRecentChunks(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   return getRecentStorablesApi (request, chunkStorableAttributes, context);
}
****************************************

****************************************
Api\src\functions\StorablePage.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure 
// 'npm start' to run locally

/**
 * @module StorablePage
 * @description Azure Function module that provides methods for managing storable pages.
 * This module handles the retrieval, saving, and removal of page records, as well as fetching recent pages.
 * It includes validation for session authentication and error handling for any issues encountered during the request processing.
 */

// 3rd party imports
import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

// Internal imports
import { pageStorableAttributes } from './StorableApi.Cosmos';
import { getStorableApiFromQuery, saveStorableApi } from "./StorableApi.Azure";
import { IStorable } from "../../../CommonTs/src/IStorable";
import { IStoredPage } from "../../../CommonTs/src/PageRepositoryApi.Types";
import { decompressString } from "../../../CommonTs/src/Compress";

// A transformer function that can be applied to a storable to transform it to decompress the html field
function decompressHtml (storable: IStorable) : IStorable {

   const storedPage: IStoredPage = storable as IStoredPage;

   if (storedPage.html)
      storedPage.html = decompressString (storedPage.html);

   return storedPage;
}

// A transformer function that can be applied to a storable to transform it to send the html field as the HTTP response
function sendHtml (storable: IStorable) : HttpResponseInit {

   const storedPage: IStoredPage = storable as IStoredPage;

   return {
      status: 200,
      headers: {
         "Content-Type": "text/html"
      },
      body: storedPage.html
   };
}

app.http('GetPage', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: getPage
});

/**
 * Loads a Page record based on the provided request and context.
 * Validates the session key from the request query parameters against predefined session keys.
 * If the session key is valid, logs the validation status, processes the JSON request, and loads the Chunk.
 * Returns an HTTP response with a status code and the session key or an error message.
 *
 * @param request - The HTTP request containing the Chunk data.
 * @param context - The context for the current invocation.
 * @returns A promise that resolves to an HTTP response with the status and response body.
 */
export async function getPage(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {
   
   return await getStorableApiFromQuery (request, pageStorableAttributes, context, decompressHtml, sendHtml);
};

app.http('SavePage', {
   methods: ['POST'],
   authLevel: 'anonymous',
   handler: savePage
});

/**
 * Saves a Page record based on the provided request and context.
 * Validates the session key from the request query parameters against predefined session keys.
 * If the session key is valid, logs the validation status, processes the JSON request, and saves the chunk.
 * Returns an HTTP response with a status code and the session key or an error message.
 *
 * @param request - The HTTP request containing the chunk data.
 * @param context - The context for the current invocation.
 * @returns A promise that resolves to an HTTP response with the status and response body.
 */
export async function savePage(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   return saveStorableApi (request, pageStorableAttributes, context);
};
****************************************

****************************************
Api\src\functions\StudioForTeams.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024

/**
 * @module StudioForTeams
 * 
 * This module provides Azure Functions endpoints for integrating Boxer's AI capabilities with Microsoft Teams.
 * It handles query requests from Teams, processes them through the Boxer backend, and returns enriched responses
 * formatted specifically for the Teams interface.
 * 
 * Key features:
 * - Processes natural language queries from Teams users
 * - Converts requests between Teams and Boxer API formats
 * - Generates enriched responses with relevant document links and summaries
 * - Handles favicon generation for source URLs
 * 
 * Deployment:
 * - 'func azure functionapp publish Braid-Api' to publish to Azure
 * - 'npm start' to run locally
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

import { IStudioBoxerResponseEnrichment} from "../../../CommonTs/src/StudioApi.Types";
import { IEnrichedQuery } from "../../../CommonTs/src/EnrichedQuery";
import { defaultErrorResponse, invalidRequestResponse } from "./Utility.Azure";
import { askModel } from "./QueryModelWithEnrichment";
import { EChunkRepository } from "../../../CommonTs/src/EnrichedChunk";
import { kDefaultMinimumCosineSimilarity } from "./IEnrichedChunkRepository";

function makeIconPath (url: string) : string {
   // https://dev.to/derlin/get-favicons-from-any-website-using-a-hidden-google-api-3p1e
   const urlParts = new URL(url);
   return 'https://www.google.com/s2/favicons?domain=' + urlParts.hostname + '&sz=32';
}

/**
 * Handles a boxer query request by processing the provided question and generating a response with enrichments.
 * 
 * @param request - The HTTP request containing the query information.
 * @param context - The context for the function invocation.
 * @returns A promise that resolves to an HTTP response with the processed query response and enrichments.
 */
export async function boxerQuery(request: HttpRequest, context: InvocationContext): Promise < HttpResponseInit > {

   try {

      const question = request.query.get('question') || (await request.text());  

      if (question) {
         context.log(question);

         // Translate from the simple MSTeams API to the one we use in Boxer app allowing more enrichments
         const passOnSpec: IEnrichedQuery = {

            repositoryId : EChunkRepository.kBoxer,
            similarityThreshold: kDefaultMinimumCosineSimilarity,
            maxCount: 4,
            wordTarget: 50,
            question: question,
            history: []
         }

         // Call common function - common the Boxer back end and to Teams API
         const passedResponse = await askModel (passOnSpec);
      
         // Translate back from the enriched Boxer app format to simpler MSTeams API 
         const enrichments: Array<IStudioBoxerResponseEnrichment> = new Array<IStudioBoxerResponseEnrichment> ();

         const answer: IStudioBoxerResponseEnrichment = { 
            id: "1",
            url: "",
            summary: passedResponse.answer,
            title: question,            
            iconUrl: makeIconPath ("https://braidapps.io")
         };
         enrichments.push(answer);      

         for (let i = 0; i < passedResponse.chunks.length; i++) {
            const enrichment: IStudioBoxerResponseEnrichment = { 
               id: (i+2).toString(),
               url:  passedResponse.chunks[i].chunk.url,
               summary: passedResponse.chunks[i].chunk.summary,
               title: question +  " - Link#" + (i+1).toString(),
               iconUrl: makeIconPath (passedResponse.chunks[i].chunk.url)
            };
            enrichments.push(enrichment);
         }

         const res: HttpResponseInit = {
            status: 200,
            jsonBody: enrichments
         };

         context.log (res.jsonBody);

         return res;
      }
      else {
         context.error ("No 'question' parameter found.");   
         return invalidRequestResponse ("No 'question' parameter found.");           
      }
   }
   catch(error: any) {

      context.error ("Error calling Boxer:", error);
      return defaultErrorResponse();
   }
};

app.http('StudioForTeams-Boxer', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: boxerQuery
});
****************************************

****************************************
Api\src\functions\Summarize.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally
/**
 * @module Summarize.Azure
 * 
 * This module provides the Azure Functions implementation of the text summarization API.
 * It handles HTTP requests for text summarization, validates sessions, and processes
 * requests through the core summarization functionality.
 * 
 * Key features:
 * - Exposes HTTP endpoint for text summarization requests
 * - Validates session tokens and request parameters
 * - Processes requests through the core Summarize module
 * - Returns summarized text or appropriate error responses
 * 
 * Dependencies:
 * - @azure/functions for Azure Functions runtime
 * - ./Summarize for core summarization logic
 * - ./Utility for session validation and error responses
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

import { isSessionValid, sessionFailResponse, defaultErrorResponse, invalidRequestResponse } from "./Utility.Azure";
import { ISummariseRequest, ISummariseResponse } from "../../../CommonTs/src/SummariseApi.Types";
import { recursiveSummarize } from "./Summarize";


/**
 * Asynchronous function to summarize text based on the requested session key and input text.
 * 
 * @param request - The HTTP request object containing the text to be summarized.
 * @param context - The context object for the function invocation.
 * @returns A promise that resolves to an HTTP response with the summarized text or an error message.
 */
export async function summarize(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   let text: string | undefined = undefined;
   let words: number = 50;
   let overallSummary: string | undefined = undefined;
   let minimumTextLength: number = 64;

   if (isSessionValid(request, context)) {

      try {
         const jsonRequest = await request.json();
         context.log(jsonRequest);

         const summariseSpec = (jsonRequest as any).request as ISummariseRequest;

         text = summariseSpec.text;
         words = summariseSpec.lengthInWords ? Math.floor(Number(summariseSpec.lengthInWords)) : 50;
         const persona = summariseSpec.persona;

         if (text && text.length >= minimumTextLength && words > 0) {
            const definitelyText: string = text;
            overallSummary = await recursiveSummarize(persona, definitelyText, 0, words);

            const summariseResponse: ISummariseResponse = {
               summary: overallSummary
            }

            context.log(summariseResponse);

            return {
               status: 200, // Ok
               body: JSON.stringify(summariseResponse)
            };
         }
         else {
            context.error("Text is below minimum length or invalid length for summary.");
            return invalidRequestResponse("Text is below minimum length or invalid length for summary.")
         }
      }
      catch (e: any) {
         context.error(e);
         return defaultErrorResponse();
      }
   }
   else {
      context.error("Session validation failed.");
      return sessionFailResponse();
   }
};

app.http('Summarize', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: summarize
});
****************************************

****************************************
Api\src\functions\Summarize.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally
/**
 * @module Summarize
 * 
 * This module provides functionality for text summarization using AI models.
 * It handles chunking large texts, processing them through AI models, and
 * generating concise summaries based on different personas (article, code, survey).
 * 
 * Key features:
 * - Splits large texts into processable chunks with configurable overlap
 * - Supports multiple summarization personas for different content types
 * - Handles rate limiting and retries for API calls
 * - Validates input text length and session requirements
 * 
 * Deployment:
 * - 'func azure functionapp publish Braid-Api' to publish to Azure
 * - 'npm start' to run locally
 */

import { getDefaultChatModelDriver, getDefaultModel } from "../../../CommonTs/src/IModelFactory";
import { EPromptPersona } from "../../../CommonTs/src/IPromptPersona";
import { IModelConversationPrompt } from "../../../CommonTs/src/IModelDriver";

const model = getDefaultModel();

/**
 * Splits the input text into chunks of maximum size defined by the model
 * 
 * @param text The text to be chunked.
 * @param overlapwords - how may words to put in overlap of chunks
 * @returns An array of strings, each representing a chunk of the input text.
 */
function chunkText(text: string, overlapWords: number): Array<string> {

   const chunks = model.chunkText(text, undefined, overlapWords);

   return chunks;
}

/**
 * Asynchronously summarizes the given text using an AI assistant.
 * 
 * @param persona - The persona to use for the summarisation
 * @param text The text to be summarized.
 * @param words The number of words to use for the summary.
 * @returns A Promise that resolves to the summarized text.
 */
async function singleShotSummarize(persona: EPromptPersona, text: string, words: number): Promise<string> {

   let modelDriver = getDefaultChatModelDriver();
   let prompt : IModelConversationPrompt = {
      history: [],
      prompt: text
   }

   let response = await modelDriver.generateResponse (persona, prompt, {wordTarget: words});

   return response.content;
}

/**
 * Asynchronously generates a recursive summary of the input text based on the specified level and word limit.
 * 
 * @param persona - The persona to use for the summarisation
 * @param text The text to be summarized.
 * @param level The current level of recursion.
 * @param words The maximum number of words in the summary.
 * @returns A Promise that resolves to the generated summary string.
 */
export async function recursiveSummarize(persona: EPromptPersona, text: string, level: number, words: number): Promise<string> {

   let overallSummary: string | undefined = undefined;
   const chunks = chunkText(text, 0);
   const summaries = new Array<string>();

   const recursizeSummarySize = model.defaultChunkSize / 5 / 10; // 5 tokens per word, and we compress by a factor of 10

   if (chunks.length > 1) {
      // If the text was > threshold, we break it into chunks.
      // Here we look over each chunk to generate a summary for each
      for (let i = 0; i < chunks.length; i++) {

         const summary = await singleShotSummarize(persona, chunks[i], recursizeSummarySize);
         summaries.push(summary);
      }
   }
   else {
      const summary = await singleShotSummarize(persona, chunks[0], words);
      summaries.push(summary);
   }

   // If we made multiple summaries, we join them all up 
   if (chunks.length > 1) {
      const joinedSummaries = summaries.join(" ");
      overallSummary = await recursiveSummarize(persona, joinedSummaries, level + 1, words);
   }
   else {
      overallSummary = summaries[0];
   }

   return overallSummary;
}
****************************************

****************************************
Api\src\functions\TestForSummariseFail.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally
/**
 * @module TestForSummariseFail
 * 
 * This module provides functionality to validate the quality of AI-generated summaries.
 * It uses an AI model to detect cases where the summarization process has failed,
 * such as when the summarizer cannot find the main body of text or produces
 * error messages instead of actual summaries.
 * 
 * Key features:
 * - Validates summary quality using AI analysis
 * - Detects common failure patterns in summarization attempts
 * - Handles rate limiting and retries for API calls
 * - Returns clear pass/fail status for summary validation
 * 
 * Deployment:
 * - 'func azure functionapp publish Braid-Api' to publish to Azure
 * - 'npm start' to run locally
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

import { isSessionValid, sessionFailResponse, defaultErrorResponse } from "./Utility.Azure";
import { ITestForSummariseFailRequest, ITestForSummariseFailResponse, ETestForSummariseFail } from "../../../CommonTs/src/TestForSummariseFailApi.Types";
import { getDefaultChatModelDriver } from "../../../CommonTs/src/IModelFactory";
import { IModelConversationPrompt } from "../../../CommonTs/src/IModelDriver";
import { EPromptPersona } from "../../../CommonTs/src/IPromptPersona";

const minimumTextLength = 64;

/**
 * Asynchronous function to find a common theme from a number of paragraphs of text.
 * Makes a POST request to an Azure endpoint to get the most common theme in the provided text.
 * Utilizes axios for HTTP requests and axiosRetry for up to 5 retries in case of rate limit errors.
 * @param text The text containing paragraphs to analyze for a common theme.
 * @param length The length for the theme text to return.
 * @returns A Promise that resolves to the most common theme found in the text.
 */
async function testForSummariseFailCall(text: string, length: number): Promise<ETestForSummariseFail> {

   let modelDriver = getDefaultChatModelDriver();
   let prompt : IModelConversationPrompt = {
      history: [],
      prompt: text
   }

   let response = await modelDriver.generateResponse (EPromptPersona.kTestForSummariseFail, prompt);

   return (response.content === 'No' ? ETestForSummariseFail.kSummaryFailed : ETestForSummariseFail.kSummarySucceeded);
}

/**
 * Finds a theme from the provided text based on certain criteria.
 * Validates the session key and returns an HTTP response with the theme summary or an authorization error message.
 * @param request - The HTTP request containing the text and session key.
 * @param context - The invocation context for logging and validation.
 * @returns A promise of an HTTP response with the theme summary or an authorization error message.
 */
export async function testForSummariseFail(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {

   let text: string | undefined = undefined;
   let length: number | undefined = undefined;
   let overallSummary: ETestForSummariseFail | undefined = undefined;
   const defaultLength = 15;

   if (isSessionValid(request, context)) {

      try {
         const jsonRequest = await request.json();
         context.log(jsonRequest);

         const summariseSpec = (jsonRequest as any).request as ITestForSummariseFailRequest;   
         text = summariseSpec.text;
         length = summariseSpec.lengthInWords;

         if (!text || text.length < minimumTextLength) {
            overallSummary = ETestForSummariseFail.kSummaryFailed;
         }
         else {

            const definitelyText: string = text;
            const definitelyLength: number = length ? length : defaultLength;
            overallSummary = await testForSummariseFailCall(definitelyText, definitelyLength);
         }

         const summariseResponse : ITestForSummariseFailResponse = {
            isValidSummary: overallSummary
         }

         context.log (summariseResponse);
         return {
            status: 200, // Ok
            body: JSON.stringify (summariseResponse)
         };
      }
      catch (e: any) {
         context.error (e);
         return defaultErrorResponse();          
      }
   }
   else {
      context.error ("Session validation failed.");          
      return sessionFailResponse();
   }
};

app.http('TestForSummariseFail', {
   methods: ['GET', 'POST'],
   authLevel: 'anonymous',
   handler: testForSummariseFail
});
****************************************

****************************************
Api\src\functions\Utility.Azure.ts
****************************************
'use strict';
// Copyright Braid Technologies Ltd, 2024
// 'func azure functionapp publish Braid-Api' to publish to Azure
// 'npm start' to run locally
/**
 * @module Utility
 * 
 * This module provides common utility functions used across the Azure Functions endpoints.
 * It handles session validation, error responses, and standard HTTP response formatting.
 * 
 * Key features:
 * - Session key validation against environment variables
 * - Standard HTTP response generators for common scenarios
 * - Error handling and response formatting utilities
 * 
 * Deployment:
 * - 'func azure functionapp publish Braid-Api' to publish to Azure
 * - 'npm start' to run locally
 */

import { HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";

/**
 * Checks if the session provided in the request is valid based on the session keys stored in the environment variables.
 * @param request - The HTTP request object containing the query parameters.
 * @param context - The invocation context for logging and additional context information.
 * @returns True if the session is valid, false otherwise.
 */
export function isSessionValid(request: HttpRequest, context: InvocationContext): boolean {

   let requestedSession: string | undefined = undefined;

   for (const [key, value] of request.query.entries()) {
      if (key === 'session')
         requestedSession = value;
   }

   if ((requestedSession === process.env.SessionKey) || (requestedSession === process.env.SessionKey2)) {
      context.log("Passed session key validation:" + requestedSession);
      return true;
   }
   else {
      context.log("Failed session key validation:" + requestedSession);
      return false;
   }
};

/**
 * Generates an HTTP response object indicating a session failure.
 * 
 * @returns {HttpResponseInit} The HTTP response object with a status code of 401 (Unauthorised) and a message "Authorization check failed."
 */

export function sessionFailResponse(): HttpResponseInit {

   return {
      status: 401, // Unauthorised
      body: "Authorization check failed."
   };
}

/**
 * Generates a default HTTP response with status code 200 (Ok) and a body of "Ok".
 * 
 * @returns {HttpResponseInit} The default HTTP response object with status code and body.
 */
export function defaultOkResponse(): HttpResponseInit {

   return {
      status: 200, // Ok
      body: "Ok"
   };
}

/**
 * Generates a default HTTP response for server errors.
 * Returns a response with status code 500 (Server error) and a message indicating an unexpected problem.
 * @returns {HttpResponseInit} The default error response object
 */
export function defaultErrorResponse(): HttpResponseInit {

   return {
      status: 500, // Server error
      body: "The server encountered an unexpected problem."
   };
}

export function invalidRequestResponse(str: string): HttpResponseInit {

   return {
      status: 400, // Invalid request
      body: "Invalid request:" + str
   };
}

export function notFoundResponse(): HttpResponseInit {

   return {
      status: 404, // Not Found
      body: ""
   };
}
****************************************

****************************************
ApiTest\test\chunk_test.py
****************************************
'''
Test module for the text chunking API endpoint.
This module contains test cases for the text chunking API endpoint,
covering various scenarios including:
- Valid chunking requests with specified size and overlap
- Invalid requests with missing parameters
- Edge cases with very small or large chunk sizes

This module contains integration tests for the /chunk endpoint, which is responsible
for splitting input text into smaller chunks with configurable size and overlap.
The tests verify the API's response format and basic functionality.

Environment Variables Required:
    - SessionKey: Authentication token for API access
'''

import pytest
import requests
import os

from CommonPy.src.request_utilities import request_timeout


# Configure the base URL for the API.
BASE_URL = 'http://localhost:7071/api'
SESSION_KEY = os.environ['SessionKey']

# Construct the full URL to the /chunk endpoint
chunk_url = f'{BASE_URL}/chunk?session=' + SESSION_KEY

# Example test data based on the provided schema
@pytest.fixture
def chunk_request_data():
    return {
        'text': 'This is a sample text to be chunked.',
        'chunkSize': 5,
        'overlapWords': 2
    }

def test_chunk_endpoint(chunk_request_data):

    wrapped = {
        'request' : chunk_request_data
    }

    # Send a POST request
    response = requests.post(chunk_url, json=wrapped, timeout=request_timeout)

    # Assert that the response status code is 200
    assert response.status_code == 200

    # Parse the response JSON
    response_data = response.json()

    # Assert the presence of expected keys in the response data
    assert 'chunks' in response_data

    assert len(response_data['chunks']) > 0

if __name__ == '__main__':
    pytest.main()
****************************************

****************************************
ApiTest\test\classify_test.py
****************************************
'''
Test module for the classification API endpoint.

This module contains test cases for the /classify endpoint, including:
- Successful classification requests with valid data
- Error handling for invalid classification requests
- Validation of response format and content

The tests require a valid session key in the environment variables
and a running API server at the configured BASE_URL.
'''

import pytest
import requests
import os

from CommonPy.src.request_utilities import request_timeout

# Configure the base URL for the API.
BASE_URL = 'http://localhost:7071/api'
SESSION_KEY = os.environ['SessionKey']

# Sample data based on the definitions
classify_request_data = {
    'text': 'Great, fabulous, magnificent, awesome, brilliant, great, love it, smashed it',
    'classifications': ['Positive', 'Negative', 'Neutral']
}

response_data = {
    'classification': 'Positive'
}

# Construct the full URL to the /classify endpoint
classify_url = f'{BASE_URL}/classify?session=' + SESSION_KEY

def test_classification_request():
    '''Test sending a classification request to the API.'''
    wrapped = {
        'request' : classify_request_data
    }
    response = requests.post(classify_url, json=wrapped, timeout=request_timeout)
    assert response.status_code == 200
    response_json = response.json()
    assert 'classification' in response_json
    assert response_json['classification'] in classify_request_data['classifications']

@pytest.mark.parametrize('invalid_data', [
    {'text': 'Example', 'classifications': None},  # Missing classifications
    {'text': '', 'classifications': ['Positive']},  # Empty text
    {'classifications': ['Positive', 'Negative']},  # Missing text
    {'text': 'Example text', 'classifications': []}  # Empty classifications
])
def test_invalid_classification_request(invalid_data):
    '''Test classification requests with invalid data.'''
    wrapped = {
        'request' : invalid_data
    }
    response = requests.post(classify_url, json=wrapped, timeout=request_timeout)
    assert response.status_code == 400  # Assuming the API returns 400 for bad requests

if __name__ == '__main__':
    pytest.main()
****************************************

****************************************
ApiTest\test\embed_test.py
****************************************
'''
Test module for the embedding API endpoint.

This module contains test cases to verify the functionality of the /embed endpoint,
which generates vector embeddings from text input. Tests cover both valid and invalid
request scenarios, verifying response structures and error handling.

Test cases:
- test_embedding_request_structure: Validates successful embedding generation
- test_invalid_request_structure: Verifies proper handling of malformed requests
'''

import pytest
import requests
import os

from CommonPy.src.request_utilities import request_timeout

# Configure the base URL for the API. 
BASE_URL = 'http://localhost:7071/api'  
SESSION_KEY = os.environ['SessionKey']

# Construct the full URL to the /chunk endpoint
embed_url = f'{BASE_URL}/embed?session=' + SESSION_KEY

def test_embedding_request_structure():

    # Define a valid request payload according to the JSON schema
    valid_request = {
        'text': 'This is a test string for generating embeddings'
    }

    wrapped = {
        'request' : valid_request
    }     

    # Simulate sending the request to the API
    response = requests.post(embed_url, json=wrapped, timeout=request_timeout)

    # Check for successful response
    assert response.status_code == 200, f'Unexpected status code: {response.status_code}'

    # Validate response structure
    response_data = response.json()

    # Check if embedding is a list
    assert isinstance(response_data.get('embedding'), list), 'Response embedding is not a list'

    # Check if all elements in embedding are numbers
    assert all(isinstance(x, (int, float)) for x in response_data['embedding']), 'Embedding contains non-numeric elements'

def test_invalid_request_structure():
    
    # Define an invalid request with missing 'text' field
    invalid_request = {
        'wrong_field': 'This should cause an error'
    }
    wrapped = {
        'request' : invalid_request
    }   
    # Simulate sending the request to the API
    response = requests.post(embed_url, json=wrapped, timeout=request_timeout)

    # Expecting a 400 status code for bad request
    assert response.status_code == 400, f'Expected 400 status for invalid request, got {response.status_code}'


if __name__ == '__main__':
    pytest.main()
****************************************

****************************************
ApiTest\test\enumerate_models_test.py
****************************************
'''
Test module for the enumerate_models API endpoint.

This module contains test cases for validating the schema and functionality of the
enumerate_models endpoint, which provides information about available AI models and
their corresponding embedding models. Tests cover both request/response schema
validation and actual API interaction.

The module validates:
- IEnumerateModelsRequest schema
- IEnumerateModelsResponse schema
- API endpoint functionality
- Error handling for invalid responses
'''

import pytest
import requests
import os
import jsonschema

from CommonPy.src.request_utilities import request_timeout

# Configure the base URL for the API.
BASE_URL = 'http://localhost:7071/api'
SESSION_KEY = os.environ['SessionKey']

# Construct the full URL to the /enumerateModels endpoint
enumerate_models_url = f'{BASE_URL}/enumerateModels?session=' + SESSION_KEY

# Load the API schema from the file
ENUMERATE_MODELS_API_SCHEMA = {
    'definitions': {
        'IEnumerateModelsRequest': {
            'type': 'object',
            'additionalProperties': False,
            'title': 'IEnumerateModelsRequest',
            'description': 'Interface for the EnumerateModels request object.'
        },
        'IEnumerateModelsResponse': {
            'type': 'object',
            'properties': {
                'defaultId': {'type': 'string'},
                'defaultEmbeddingId': {'type': 'string'},
                'largeId': {'type': 'string'},
                'largeEmbeddingId': {'type': 'string'},
                'smallId': {'type': 'string'},
                'smallEmbeddingId': {'type': 'string'}
            },
            'required': ['defaultId', 'defaultEmbeddingId', 'largeId', 'largeEmbeddingId', 'smallId', 'smallEmbeddingId'],
            'additionalProperties': False
        }
    }
}

def validate_enumerate_models_schema(instance, schema_name) -> bool:
    '''Utility function to validate a JSON instance against a schema definition.'''
    schema = {'$ref': f'#/definitions/{schema_name}'}

    jsonschema.validate(instance=instance, schema={'$schema': 'http://json-schema.org/draft-07/schema#', **ENUMERATE_MODELS_API_SCHEMA, **schema})

def test_ienumerate_models_request_valid():
    '''Test for a valid IEnumerateModelsRequest object.'''
    request_instance = {}
    validate_enumerate_models_schema(request_instance, 'IEnumerateModelsRequest')

def test_ienumerate_models_response_valid():
    '''Test for a valid IEnumerateModelsResponse object.'''
    response_instance = {
        'defaultId': 'default-id',
        'defaultEmbeddingId': 'default-embedding-id',
        'largeId': 'large-id',
        'largeEmbeddingId': 'large-embedding-id',
        'smallId': 'small-id',
        'smallEmbeddingId': 'small-embedding-id'
    }
    validate_enumerate_models_schema(response_instance, 'IEnumerateModelsResponse')

def test_ienumerate_models_response_missing_fields():
    '''Test for IEnumerateModelsResponse object missing required fields.'''
    response_instance = {
        'defaultId': 'default-id'
        # Missing other required fields
    }
    with pytest.raises(jsonschema.exceptions.ValidationError):
        validate_enumerate_models_schema(response_instance, 'IEnumerateModelsResponse')

def test_ienumerate_models_response_additional_fields():
    '''Test for IEnumerateModelsResponse object with additional fields that should be disallowed.'''
    response_instance = {
        'defaultId': 'default-id',
        'defaultEmbeddingId': 'default-embedding-id',
        'largeId': 'large-id',
        'largeEmbeddingId': 'large-embedding-id',
        'smallId': 'small-id',
        'smallEmbeddingId': 'small-embedding-id',
        'extraField': 'extra'  # Additional field not defined in schema
    }
    with pytest.raises(jsonschema.exceptions.ValidationError):
        validate_enumerate_models_schema(response_instance, 'IEnumerateModelsResponse')

def test_enumerate_request():
    '''Test sending an enumerate request to the API.'''
    wrapped = {
        'request' : ''
    }       
    response = requests.post(enumerate_models_url, json=wrapped, timeout=request_timeout)
    assert response.status_code == 200
    response_json = response.json()
    validate_enumerate_models_schema(response_json, 'IEnumerateModelsResponse')

if __name__ == '__main__':
    pytest.main()
****************************************

****************************************
ApiTest\test\enumerate_repositories_test.py
****************************************
'''
Test module for the EnumerateRepositories API endpoint.

This module contains test cases to verify the functionality of the EnumerateRepositories
API endpoint, which returns a list of available repository IDs. It includes schema 
validation and basic HTTP response testing.

Environment Requirements:
    - SessionKey: Must be set as an environment variable
'''

import pytest
import requests
import os
import jsonschema

from CommonPy.src.request_utilities import request_timeout

# Configure the base URL for the API.
BASE_URL = 'http://localhost:7071/api'
SESSION_KEY = os.environ['SessionKey']

# Construct the full URL to the /enumerateRepositories endpoint
enumerate_repositories_url = f'{
    BASE_URL}/enumerateRepositories?session=' + SESSION_KEY

# Load the API schema from the file
ENUMERATE_REPOSITORIES_API_SCHEMA = {
    'definitions': {
        'IEnumerateRepositoriesRequest': {
            'type': 'object',
            'additionalProperties': False,
            'title': 'IEnumerateRepositoriesRequest',
            'description': 'Interface for the EnumerateRepositories request object.'
        },
        'IEnumerateRepositoriesResponse': {
            'type': 'object',
            'properties': {
                'repositoryIds': {'type': 'array'}
            },
            'required': ['repositoryIds'],
            'additionalProperties': False
        }
    }
}

# Test helper function to validate a response against a schema definition


def validate_response_vs_schema(schema_definition, response_data):
    try:
        jsonschema.validate(instance=response_data, schema=schema_definition)
    except jsonschema.exceptions.ValidationError as ve:
        pytest.fail(f'Response did not match schema: {ve.message}')

# Test function for the 'EnumeratRepositories' API response.


def test_enumerate_repositories():
    # Load the response schema
    response_schema = ENUMERATE_REPOSITORIES_API_SCHEMA[
        'definitions']['IEnumerateRepositoriesResponse']

    # Prepare a mocked request that matches the IEnumerateModelsRequest schema
    wrapped = {}  # This API doesn't require any specific request properties
    response = requests.post(enumerate_repositories_url, json=wrapped, timeout=request_timeout)
    assert response.status_code == 200
    response_json = response.json()

    # Validate the response against the schema
    validate_response_vs_schema(response_schema, response_json)


if __name__ == '__main__':
    pytest.main()
****************************************

****************************************
ApiTest\test\find_theme_test.py
****************************************
"""
Test module for the /findtheme API endpoint.

This module contains test cases to verify the functionality of the theme finding API,
including validation of request parameters and response formats. Tests cover both
valid requests and error scenarios for missing required fields.

Endpoints tested:
    - POST /findtheme: Analyzes text to identify themes
"""

import pytest
import requests
import os

from CommonPy.src.request_utilities import request_timeout

# Configure the base URL for the API.
BASE_URL = 'http://localhost:7071/api'
SESSION_KEY = os.environ['SessionKey']

# Construct the full URL to the /chunk endpoint
find_theme_url = f"{BASE_URL}/findtheme?session=" + SESSION_KEY

@pytest.fixture
def valid_request_data():
    return {
        "text": "Sample text input about magazines, books, literature, moves, films, records, CDs, vinyl, newspapers.",
        "length": 123
    }

def test_find_theme_with_valid_request(valid_request_data):
    wrapped = {
        'request' : valid_request_data
    }
    response = requests.post(find_theme_url, json=wrapped, timeout=request_timeout)
    assert response.status_code == 200, "Expected status code 200 for a valid request"
    data = response.json()
    assert "theme" in data, "Response should contain 'theme'"

def test_find_theme_with_missing_text():
    request_data = {
        "length": 123
    }
    wrapped = {
        'request' : request_data
    }
    response = requests.post(find_theme_url, json=wrapped, timeout=request_timeout)
    assert response.status_code == 400, "Expected status code 400 for missing 'text'"

def test_find_theme_with_missing_length():
    request_data = {
        "text": "Sample text input"
    }
    wrapped = {
        'request' : request_data
    }
    response = requests.post(find_theme_url, json=wrapped, timeout=request_timeout)
    assert response.status_code == 400, "Expected status code 400 for missing 'length'"    

if __name__ == "__main__":
    pytest.main()
****************************************

****************************************
ApiTest\test\page_repository_test.py
****************************************
"""
Integration tests for the Page Repository API endpoints.

This module contains test cases for the /getpage endpoint, verifying:
- Successful page retrieval with valid parameters
- Error handling for missing parameters
- API authentication using session keys

The tests require a running local API instance on port 7071 and
a valid session key in the environment variables.
"""

import pytest
import requests
import os

from CommonPy.src.request_utilities import request_timeout

# Configure the base URL for the API.
BASE_URL = 'http://localhost:7071/api'
SESSION_KEY = os.environ['SessionKey']

# Construct the full URL to the /chunk endpoint
get_page_url = f"{BASE_URL}/getpage?session=" + SESSION_KEY

# Sample data for testing
sample_successful_html = "<html><body>Sample Page</body></html>"

def test_get_page_success():
    url = get_page_url+ '&id=61d4bef7-31eb-4293-a19c-6e17db8d650a'

    response = requests.get(url, timeout=request_timeout)
    assert response.status_code == 200

def test_get_page_missing_param():
    url = get_page_url

    # Missing required 'id' parameter
    response = requests.get(url, timeout=request_timeout)
    assert response.status_code == 404
****************************************

****************************************
ApiTest\test\studio_test.py
****************************************
'''
Test module for the Studio Boxer API endpoints.

This module contains test cases and helper functions to validate the behavior
of the Studio Boxer API, including:
- Response schema validation
- Enrichment structure validation
- Error handling for invalid requests
- Integration tests for the StudioForTeams-Boxer endpoint

Dependencies:
    - pytest
    - requests
    - jsonschema
'''

import pytest
import requests
import os
import jsonschema

from CommonPy.src.request_utilities import request_timeout

# Configure the base URL for the API.
BASE_URL = 'http://localhost:7071/api'
SESSION_KEY = os.environ['SessionKey']

# Test helper function to validate a response against a schema definition


def validate_response_vs_schema(schema_definition, response_data):
    try:
        jsonschema.validate(instance=response_data, schema=schema_definition)
    except jsonschema.exceptions.ValidationError as ve:
        pytest.fail(f'Response did not match schema: {ve.message}')


@pytest.mark.skip(reason='Helper function, not a test')
def test_IStudioBoxerResponseEnrichment_structure(enrichment_data):

   print(str(enrichment_data))

   # Check for required fields
   assert 'id' in enrichment_data
   assert 'summary' in enrichment_data

   # Check if fields are strings
   assert isinstance(enrichment_data['id'], str)
   assert isinstance(enrichment_data['summary'], str)

   if 'url' in enrichment_data:
      assert isinstance(enrichment_data['url'], str)
   if 'iconUrl' in enrichment_data:
      assert isinstance(enrichment_data['iconUrl'], str)
      print(enrichment_data['iconUrl'])
   if 'title' in enrichment_data:
      assert isinstance(enrichment_data['title'], str)


@pytest.mark.skip(reason='Helper function, not a test')
def test_IStudioBoxerResponse_structure(response_data):

    # Check if 'enrichments' is a list
    assert isinstance(response_data, list)

    # Validate each enrichment
    for enrichment in response_data:
        test_IStudioBoxerResponseEnrichment_structure(enrichment)


# Construct the full URL to the /enumerateRepositories endpoint
studio_boxer_url = f'{BASE_URL}/StudioForTeams-Boxer'

# Load the API schema from the file
STUDIO_FOR_TEAMS_BOXER_API_SCHEMA = {
    'definitions': {
        'IStudioBoxerResponse': {
            'type': 'array'
        }
    }
}

# Test function for the 'StudioBoxer' API .


def test_studio_boxer():
    # Load the response schema
    response_schema = STUDIO_FOR_TEAMS_BOXER_API_SCHEMA['definitions']['IStudioBoxerResponse']

   # Prepare a mocked request that matches the IEnumerateModelsRequest schema
    params = {'question': 'What is the purpose of an LLM?'}

    response = requests.post(studio_boxer_url, params=params, timeout=request_timeout)
    assert response.status_code == 200
    response_json = response.json()

    # Validate the response against the schema
    validate_response_vs_schema(response_schema, response_json)
    test_IStudioBoxerResponse_structure(response_json)


def test_invalid_studio_request():
    # Test how the API handles invalid request data
   invalid_data = {'wrong_field': 'Some value'}
   response = requests.post(studio_boxer_url, params=invalid_data, timeout=request_timeout)
   # Assuming a bad request returns status code 400
   assert response.status_code == 400


if __name__ == '__main__':
    pytest.main()
****************************************

****************************************
ApiTest\test\summarise_test.py
****************************************
"""
Test module for the text summarization API endpoint.

This module contains integration tests for the summarization functionality,
covering various use cases and scenarios including:

- Standard text summarization with specified length
- Survey response summarization using specialized personas
- Code summarization using specialized personas
- Edge cases and error handling:
  - Missing length parameter
  - Missing text parameter
  - Empty requests
  - Invalid requests

The tests verify both successful responses (200) and error conditions (400, 500),
ensuring the API endpoint handles different input scenarios appropriately.

Dependencies:
    - pytest: Testing framework
    - requests: HTTP client for API calls
    - pathlib: File path handling
    - os: Environment variable access

Environment Variables:
    - SessionKey: Required for API authentication
    - BASE_URL: API endpoint (defaults to http://localhost:7071/api)
"""

import os
import pathlib
import pytest
import requests

from CommonPy.src.request_utilities import request_timeout

# Configure the base URL for the API.
BASE_URL = 'http://localhost:7071/api'
SESSION_KEY = os.environ['SessionKey']

SURVEY_TEXT = (
    "The course meets my overall expectations:'Agree'" +
    "The duration and pacing of the course were appropriate:'Agree'" +
    "The 'AI Ethics' session provided valuable insights that I can apply in "
    "real-world scenarios. :'Strongly agree'" +
    "The 'Design Thinking' sessions enhanced my problem-solving and innovation "
    "skills.:'Agree'" +
    "The 'Achieving Personal High Performance' session offered practical techniques "
    "to improve my productivity and focus.:'Strongly agree'" +
    "The Python coursework helped build a strong foundation in programming for AI "
    "applications.:'Neutral'" +
    "The courses on Large Language Models (LLMs) and Generative AI improved my "
    "understanding of these technologies and their potential uses. :'Agree'" +
    "I feel confident the skills I'm building will help my career at "
    "Vodafone :'Agree'" +
    "The practical exercises, examples, and group activities were engaging and "
    "helped reinforce key concepts. :'Strongly agree'" +
    "What was the most valuable part of this course for you, and why:'Personal "
    "Performance was really good for 3 out of the 4 sessions. Last session did "
    "not hit home quite as much a the others. AI Ethics provided great sessions "
    "to enhance thinking around this subject'" +
    "What could be improved to enhance the learning experience for future "
    "participants?:'For a complete novice, the Python and Udacity training could "
    "have been made better with some live support for troubleshooting. '" +
    "What changes would you like to see for the 'Gateway Projects' build phase?:"
    "'Continued support from PO's, SMe's and Braid team during build phase'"
)

def summarise_endpoint_url():
    # Construct the full URL for the summary endpoint
    return f'{BASE_URL}/Summarize?session=' + SESSION_KEY


def test_valid_summarise_request():
    # Test case for a valid summarization request
    payload = {
        'text': 'This is a text that needs to be summarized and in order for this to work it needs to be over the minumum text length.',
        'lengthInWords': 10
    }
    wrapped = {
        'request': payload
    }
    response = requests.post(summarise_endpoint_url(),
                             json=wrapped, timeout=request_timeout)
    assert response.status_code == 200
    data = response.json()
    assert 'summary' in data
    assert isinstance(data['summary'], str)
    # Further checks can be added based on expected summary content


def test_valid_summarise_survey_request():
    # Test case for a valid summarization request
    payload = {
        'promptPersona': 'SurveySummariser',
        'text': SURVEY_TEXT,
        'lengthInWords': 100
    }
    wrapped = {
        'request': payload
    }
    response = requests.post(summarise_endpoint_url(),
                             json=wrapped, timeout=request_timeout)
    assert response.status_code == 200
    data = response.json()
    assert 'summary' in data
    assert isinstance(data['summary'], str)
    print(data['summary'])


def test_valid_summarise_code_request():

    source = get_current_source()

    # Test case for a valid summarization request
    payload = {
        'promptPersona': 'CodeSummariser',
        'text': source,
        'lengthInWords': 100
    }
    wrapped = {
        'request': payload
    }
    response = requests.post(summarise_endpoint_url(),
                             json=wrapped, timeout=request_timeout)
    assert response.status_code == 200
    data = response.json()
    assert 'summary' in data
    assert isinstance(data['summary'], str)
    print(data['summary'])


def test_summarise_request_without_length():
    # Test case with the text but no lengthInWords
    payload = {
        'text': 'This text needs summarization but without specifying the length.'
    }
    wrapped = {
        'request': payload
    }
    response = requests.post(summarise_endpoint_url(),
                             json=wrapped, timeout=request_timeout)
    assert response.status_code == 200
    data = response.json()
    assert 'summary' in data
    assert isinstance(data['summary'], str)


def test_summarise_request_missing_text():
    # This should fail because 'text' is a required field
    payload = {
        'lengthInWords': 10
    }
    wrapped = {
        'request': payload
    }
    response = requests.post(summarise_endpoint_url(),
                             json=wrapped, timeout=request_timeout)
    assert response.status_code == 400  # Assuming the API returns a 400 Bad Request
    # Additional logic to verify error message can be added here


def test_empty_summarise_request():
    # Test case with an empty payload
    payload = {}
    response = requests.post(summarise_endpoint_url(),
                             json=payload, timeout=request_timeout)
    assert response.status_code == 500  # Empty request should fail


def get_current_source():

    # Get the path of the current file
    file_path = pathlib.Path(__file__)
    # Read the contents
    source = file_path.read_text(encoding='utf-8')

    return source


if __name__ == '__main__':
    pytest.main()
****************************************

****************************************
Boxer\core\ActivityRecord.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module ActivityRecord
 * @description Defines interfaces and utilities for storing user activity records in Braid.
 * 
 * This module provides interfaces for different types of activity records that can be stored:
 * - Base activity records (IStoredActivity)
 * - URL-based activities (IStoredUrlActivity) 
 * - URL like/unlike activities (IStoredLikeUrlActivity)
 * - Message-based activities (IStoredMessageActivity)
 * 
 * Each interface extends IStorable for persistence and includes version information via
 * className and schemaNumber constants. The module also provides utility functions for
 * handling dates in UTC format for consistent storage.
 */

import { IStorable } from '../../CommonTs/src/IStorable';

export const activityRecordClassName = "IStoredActivity";
export const activityRecordSchemaNumber = 1;

// ActivityRecord - has several derived classes according to different activity types. 
export interface IStoredActivity extends IStorable {

}

export const urlActivityRecordClassName = "IStoredUrlActivity";
export const urlActivityRecordSchemaNumber = "1";

// ActivityRecord - activity details plus the URL they clicked on 
export interface IStoredUrlActivity extends IStoredActivity {
   
   url: string;
}

export const urlLikeActivityRecordClassName = "IStoredLikeUrlActivity";
export const urlLikeActivityRecordSchemaNumber = "1";

// ActivityRecord - URL activity details plus a flag to say like (unlike if false) 
export interface IStoredLikeUrlActivity extends IStoredUrlActivity {
   
   like: boolean;
}

export const messageActivityRecordClassName = "IStoredMessageActivity";
export const messageActivityRecordSchemaNumber = "1";

// ActivityRecord - activity details plus the URL they clicked on 
export interface IStoredMessageActivity extends IStoredActivity {
   
   message: string;
}

export function makeDateUTC(rhs: Date) : Date {
   let d = new Date (rhs);
   d.setMilliseconds(0); // MSecs are not used in UTC, and Cosmos DB recommends UTC
   return d;
}
****************************************

****************************************
Boxer\core\ActivityRepository.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module ActivityRepository
 * @description Provides repository implementation for storing and retrieving user activities in Braid.
 * 
 * This module implements the IActivityRepository interface to handle persistence of different
 * types of activity records (URLs visited, likes/unlikes, messages) to Cosmos DB. It provides:
 * - Activity saving through the ActivityRepositoryApi
 * - Loading of recent URL-based activities
 * - Loading of recent message activities
 * 
 * The repository requires a session key for authentication and uses the environment configuration
 * to determine the appropriate API endpoints for storage operations.
 */

// 3rd party imports
import axios from "axios";

// Internal imports
import { IStoredActivity, IStoredUrlActivity, IStoredLikeUrlActivity, IStoredMessageActivity, urlActivityRecordClassName, urlLikeActivityRecordClassName, messageActivityRecordClassName } from './ActivityRecord';
import { SessionKey } from "./Keys";
import { IActivityRepository } from "./IActivityRepository";

import { getDefaultEnvironment } from "../../CommonTs/src/IEnvironmentFactory";
import { ActivityRepostoryApi} from '../../CommonTs/src/ActivityRepositoryApi';


// ActivityRepositoryCosmos 
export class ActivityRepositoryCosmos implements IActivityRepository {

   private _sessionKey: string;

   /**
    * Create an ActivityRepository object 
    * @param sessionKey_ - joining key
    */
   public constructor(sessionKey_: SessionKey) {

      this._sessionKey = sessionKey_.toString();
   }


   async save (record : IStoredActivity) : Promise<boolean> {
      
      let environment = getDefaultEnvironment ()  
      
      let api = new ActivityRepostoryApi (environment, this._sessionKey);

      return api.save (record);      
   }

   async loadRecentUrlActivity (count : number) : Promise<Array<IStoredActivity>> {
      
      let clicks = await this.loadRecent (count, urlActivityRecordClassName);
      let likes = await this.loadRecent (count, urlLikeActivityRecordClassName);    
      
      let all = clicks.concat (likes);

      return all;
   }

   async loadRecentMessages (count : number) : Promise<Array<IStoredActivity>> {
      return this.loadRecent (count, messageActivityRecordClassName);
   }

   async loadRecent (limit : number, className: string) : Promise<Array<IStoredActivity>> {
      
      let environment = getDefaultEnvironment ()  
      
      let api = new ActivityRepostoryApi (environment, this._sessionKey);

      // we downcast IStoredActivity bcs we know it is one
      let storedRecords : Array <IStoredActivity> = await api.recent ({ limit: limit, className: className}) as Array <IStoredActivity>; 
   
      return storedRecords;
   }

   async removeMessageRecord (recordId: string) : Promise<boolean> {

      let environment = getDefaultEnvironment ()  
      
      let api = new ActivityRepostoryApi (environment, this._sessionKey);

      return api.remove (recordId);
   }
}
****************************************

****************************************
Boxer\core\AIConnection.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module AIConnection
 * @description Manages communication with AI/LLM services in the Boxer application.
 * 
 * This module provides the AIConnection class which handles:
 * - Making enriched queries to LLM models with context
 * - Streaming responses back to the UI
 * - Managing conversation history and token limits
 * - Tracking active call state
 * - Building enriched queries from message history
 * 
 * The connection requires a session key for authentication and uses the environment 
 * configuration to determine appropriate API endpoints. It works with the QueryModelApi
 * to make actual API calls while providing higher-level conversation management.
 */


// Local
import { SessionKey } from "./Keys";
import { Message } from './Message';
import { Persona } from './Persona';
import { EIcon } from './Icons';
import { EConfigNumbers, EConfigStrings } from './ConfigStrings';
import { throwIfUndefined } from './Asserts';
import { AssertionFailedError } from "./Errors";
import { getDefaultKeyGenerator } from "./IKeyGeneratorFactory";

import { getDefaultEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { EChunkRepository, IRelevantEnrichedChunk} from '../../CommonTs/src/EnrichedChunk';

import { IEnrichedQuery, IEnrichedResponse, IGenerateQuestionQuery, IQuestionGenerationResponse } from '../../CommonTs/src/EnrichedQuery';
import { EModelConversationRole, IModelConversationElement } from "../../CommonTs/src/IModelDriver";
import { QueryModelApi } from '../../CommonTs/src/QueryModelApi';

// We allow for the equivalent of 10 minutes of chat. 10 mins * 60 words = 600 words = 2400 tokens. 
const kMaxTokens : number= 4096;

export class AIConnection {

   private _activeCallCount: number; 
   private _queryModelApi : QueryModelApi;

   /**
    * Create an AIConnection object 
    */
   constructor(sessionKey_: SessionKey) {

      this._activeCallCount = 0;  
      this._queryModelApi = new QueryModelApi (getDefaultEnvironment (), sessionKey_.toString())
   }  

   // Makes an Axios call to call web endpoint
   // Make two queries - one to get the answer to the direct question, another to ask for a reference summary. 
   // The reference summary is then used to look up good articles to add to the response.  
   async makeEnrichedCall  (responseShell: Message, query: IEnrichedQuery) : Promise<Message | undefined> {

      let response = await this._queryModelApi.queryModelWithEnrichment (query);

      if (response) {
         this.streamResponse (responseShell, response);
      }
          
      return responseShell;                                                                            
   }    

   // Asks the LLM for a question that relates to the context  
   async makeFollowUpCall  (summary: string) : Promise<Message | undefined> {
      
      let followUpQuery = AIConnection.buildQueryForQuestionPrompt (summary);

      let response = await this._queryModelApi.generateQuestion (followUpQuery);

      if (response) {
         let keyGenerator = getDefaultKeyGenerator();
         return new Message (keyGenerator.generateKey(), EConfigStrings.kLLMGuid, undefined, 
                             response.question, new Date()); 
      }
      return undefined;                                                                       
   } 

   
   /**
    * Asynchronously streams the enriched response to update the message shell with chunks and live updates.
    * This is a confidence trick - e give the appearance of streaming, not the actuality. 
    * Only reason is that we are going to shutt off dedicated client & move to an API model - so real streaming wont be processsed here. 
    * 
    * @param responseShell - The message shell to be updated with the enriched response.
    * @param response - The enriched response containing answer and relevant enriched chunks.
    * @returns A promise that resolves with the updated message shell after streaming the response.
    */
   private async streamResponse  (responseShell: Message, response: IEnrichedResponse) : Promise<Message> {

      let done = new Promise<Message>(async function(resolve, reject) {

         let responseChunks = response.chunks;

         let shellChunks = new Array<IRelevantEnrichedChunk>();
         shellChunks.length = responseChunks.length;

         for (let i = 0; i < responseChunks.length; i++) {

            let shellEmbed = {chunk: {
                  url: responseChunks[i].chunk.url,
                  summary: responseChunks[i].chunk.summary,
                  text: responseChunks[i].chunk.text
               }, 
               relevance: responseChunks[i].relevance};
            shellChunks[i] = shellEmbed;
         }

         responseShell.chunks = shellChunks;
         let index = 0;
         let maxIndex = 6; 

         let interval = setInterval ( () => {

            switch (index) {
               case 0:
                  let text1 = response.answer.slice (0, response.answer.length / 2);
                  responseShell.liveUpdateText (text1, true);
                  break;  
               case 1:
                  let text2 = response.answer;
                  responseShell.liveUpdateText (text2, true);                     
                  break;                                      
               case 2:
                  if (responseChunks.length > 0) {
                     shellChunks[0].chunk.summary = responseChunks[0].chunk.summary.slice (0, responseChunks[0].chunk.summary.length / 2);
                     responseShell.liveUpdateChunks (shellChunks, true);               
                  }       
                  break;
               case 3:
                  if (responseChunks.length > 1)                  {
                     shellChunks[1].chunk.summary = responseChunks[1].chunk.summary.slice (0, responseChunks[0].chunk.summary.length / 2);  
                     responseShell.liveUpdateChunks (shellChunks, true);                              
                  }             
                  break;  
               case 4:
                  if (responseChunks.length > 0)              { 
                     shellChunks[0].chunk.summary = responseChunks[0].chunk.summary;     
                     responseShell.liveUpdateChunks (shellChunks, true);                              
                  }                                     
                  break;   
               case 5:
                  if (responseChunks.length > 1)          {        
                     shellChunks[1].chunk.summary = responseChunks[1].chunk.summary;    
                     responseShell.liveUpdateChunks (shellChunks, true);            
                  }       
                  break;         
               default:
                  break;                                                 
            }

            index++;
            if (index === maxIndex) {
               responseShell.liveUpdateChunks (shellChunks, false); 
               resolve (responseShell);
               clearInterval(interval);
            }

         }, 100); 
      });

      return done;
   }

   isBusy () {
      return this._activeCallCount !== 0;
   }

   static buildEnrichmentQuery (messages: Array<Message>, authors: Map<string, Persona>): IEnrichedQuery {

      let history = new Array<IModelConversationElement> ();
      let question = "";    

      var start = AIConnection.findEarliestMessageIndexWithinTokenLimit(messages, authors);

      for (let i = start; i < messages.length; i++) {

         let message = messages[i];

         if (AIConnection.isRequestForLLM(message, authors)) {

            // The last message contains the question. 
            if (i === messages.length -1) {
               // Remove the name of our LLM
               let edited = message.text.replace (EConfigStrings.kLLMRequestSignature, "");   
               
               // Expand 'LLM' to Large Language Model (LLM) as that seems to make a big difference to document hits 
               // This includes some common typos
               let lookFor = [EConfigStrings.kPromptLookFor1, EConfigStrings.kPromptLookFor2, ,
                              EConfigStrings.kPromptLookFor4, EConfigStrings.kPromptLookFor5, EConfigStrings.kPromptLookFor6
                             ] as Array<string>;
               
               let replaceWith = [EConfigStrings.kPromptReplaceWith1, EConfigStrings.kPromptReplaceWith2, EConfigStrings.kPromptReplaceWith3,
                                 EConfigStrings.kPromptReplaceWith4, EConfigStrings.kPromptReplaceWith5, EConfigStrings.kPromptReplaceWith6
                                ] as Array<string>;
               
               for (let i = 0; i < lookFor.length; i++) {
                  if (edited.includes (lookFor[i])) 
                     edited = edited.replace (lookFor[i], replaceWith[i]);
               }             
               
               question = edited;      
            } 
            else {
               // else we just remove the name of our LLM
               let edited = message.text.replace (EConfigStrings.kLLMRequestSignature, "");
               let entry = { role: EModelConversationRole.kUser, content: edited };
               history.push (entry);
            }
         }

         if (AIConnection.isFromLLM(message, authors)) {
            
            let entry = { role: EModelConversationRole.kAssistant, content: message.text };
            history.push (entry);     

            for (let j = 0; j < message.chunks.length; j++) {
               let entry = { role: EModelConversationRole.kAssistant, content: message.chunks[j].chunk.summary };
               history.push (entry);
            }                   
         }         

      }

      let query = {
         repositoryId: EChunkRepository.kBoxer,
         question : question,
         history: history,
         maxCount: 2,
         similarityThreshold : 0.4,
         wordTarget: 50
      } 

      return query; 
   }   

   static buildQueryForQuestionPrompt (summary: string): IGenerateQuestionQuery {

      let query = {
         wordTarget: 10,
         summary: summary
      } 

      return query; 
   }   

   static buildTranscript (messages: Array<Message>, authors: Map<string, Persona>): string {

      let builtQuery : string = "";
   

      var start = AIConnection.findEarliestMessageIndexWithinTokenLimit(messages, authors);

      for (let i = start; i < messages.length; i++) {

         let message = messages[i];

         if (AIConnection.isFromLLM(message, authors)) {
            
            builtQuery = builtQuery + EConfigStrings.kLLMName + ":" + message.text + "\n";
         }            
         else {
            let author = authors.get (message.authorId);
            if (!author)
               author = Persona.unknown();

            builtQuery = builtQuery + author.name + ":" + message.text + "\n";
         }      
      }

      return builtQuery; 
   }  
    

   private static findEarliestMessageIndexWithinTokenLimit (messages: Array<Message>, authors: Map<string, Persona>) : number {

      if (messages.length == 0)      
         throw new AssertionFailedError ("Message array is zero length.");
      if (messages.length == 1)
         return 0;

      let tokenAccumulator = 0;
      let iLowest = 0;
      let lowestIndex = Math.max (0, messages.length - EConfigNumbers.kMaxMessagesBack)

      for (let i = messages.length - 1; i >= lowestIndex && tokenAccumulator < kMaxTokens; i--) {

         tokenAccumulator += messages[i].tokens;

         if (tokenAccumulator < kMaxTokens)
            iLowest = i;
      }      
      return iLowest;
   }

   /**
    * is a message from the LLM - look at the author ID
    */
   static isFromLLM (message: Message, authors: Map<string, Persona>) : boolean {

      let author = Persona.safeAuthorLookup (authors, message.authorId);
      throwIfUndefined (author);

      return (author.icon === EIcon.kLLMPersona);
   }


   /**
    * is a message invoking the LLM - look at the author, and if the message contains the LLM name 
    */
   static isRequestForLLM (message: Message, authors: Map<string, Persona>) : boolean {

      let author = Persona.safeAuthorLookup (authors, message.authorId);
      throwIfUndefined (author);

      return (author.icon === EIcon.kPersonPersona) && 
      (message.text.includes (EConfigStrings.kLLMRequestSignature) || message.text.includes (EConfigStrings.kLLMRequestSignatureLowerCase));
   }

  /**
    * is a message an attempt to invoke the LLM - look at the author, and if the message contains miss-spellings of LLM name 
    */
   static mightBeMissTypedRequestForLLM (message: Message, authors: Map<string, Persona>) : boolean {

      if (this.isRequestForLLM (message, authors))
         return false;

      let author = Persona.safeAuthorLookup (authors, message.authorId);
      throwIfUndefined (author);

      return (author.icon === EIcon.kPersonPersona) && 
         (message.text.includes (EConfigStrings.kLLMNearRequestSignature) || message.text.includes (EConfigStrings.kLLMNearRequestSignatureLowerCase));
   }   
}
****************************************

****************************************
Boxer\core\ApiCalls.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module ApiCalls
 * @description Provides functions for making API calls to the Braid backend.
 * 
 * This module includes functions for making summarization requests to the Summarise API,
 * as well as other utility functions for making API calls to other services.
 */

import axios from "axios";

// Local
import { SessionKey } from "./Keys";
import { logApiError } from "./Logging";
import { EConfigStrings } from "./ConfigStrings";
import { EConfigNumbers } from "./ConfigStrings";
import { getDefaultEnvironment } from "../../CommonTs/src/IEnvironmentFactory";
import { ISummariseRequest, ISummariseResponse} from "../../CommonTs/src/SummariseApi.Types"
import { EPromptPersona } from "../../CommonTs/src/IPromptPersona";


export async function makeSummaryCall (session: SessionKey, text: string) : Promise<string | undefined> {

   let summary: string | undefined = undefined;
   let env =  getDefaultEnvironment();
   let apiUrl = env.summariseApi() + '?session=' + session.toString();
   
   let request: ISummariseRequest = {
      persona: EPromptPersona.kDeveloperAssistant,
      text: text,
      lengthInWords: EConfigNumbers.kSummaryLengthWords
   };

   try {
      let response = await axios.post(apiUrl, {
        request: request,
        headers: {
           'Content-Type': 'application/json'
        }
      });

      summary = (response.data as ISummariseResponse).summary;

   } catch (e: any) {       

      logApiError ("Error calling Summarize API:", e);           
   }   
   
   return summary;
}
****************************************

****************************************
Boxer\core\Asserts.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Asserts
 * @description Provides utility functions for asserting the validity of objects.
 * 
 * This module includes functions for checking if an object is undefined or null,
 * and throwing an error if it is. It is used to enforce type safety and prevent
 * runtime errors in the application.
 */

import { AssertionFailedError} from './Errors';

export const throwIfUndefined: <T, >(x: T | undefined) => asserts x is T = x => {
   if (typeof x === "undefined") throw new AssertionFailedError ("Object is undefined.");
}

export const throwIfNull: <T, >(x: T | null) => asserts x is T = x => {
   if (x === null) throw new AssertionFailedError ("Object is null.");
}
****************************************

****************************************
Boxer\core\BoxerFluidConnection.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module BoxerFluidConnection
 * @description Manages the Fluid connection for the Boxer application.
 * 
 * This module provides the BraidFluidConnection class which handles:
 * - Setting up and managing local caucuses for participants and messages
 * - Adding the Boxer persona to the participant caucus
 * - Tracking active call state
 * - Building enriched queries from message history
 * 
 * The connection requires a session key for authentication and uses the environment 
 * configuration to determine appropriate API endpoints. It works with the QueryModelApi
 * to make actual API calls while providing higher-level conversation management.
 */

import { SharedMap } from "fluid-framework/legacy";
import { Persona } from './Persona';
import { Message } from './Message';
import { SharedEmbedding } from "./SharedEmbedding";
import { FluidConnection } from './FluidConnection';
import { CaucusOf } from './CaucusFramework';
import { throwIfUndefined } from './Asserts'; 
import { EConfigStrings } from "./ConfigStrings";
import { EIcon } from "./Icons";

const containerSchema = {
   initialObjects: {
      participantMap: SharedMap,
      messageMap: SharedMap,
      sharedEmbeddingMap: SharedMap,
      configuration: SharedMap
   }
};

// MessageBotFluidConnection - concrete derived class of FluidConnection
// connects the fluid connection to two local caucuses - one for participants, another for messages
export class BraidFluidConnection extends FluidConnection {

   _initialObjects: any;
   _localUser: Persona;
   _participantCaucus: CaucusOf<Persona> | undefined;
   _messageCaucus: CaucusOf<Message> | undefined;
   _sharedEmbeddingCaucus: CaucusOf<SharedEmbedding> | undefined;
   _interval: NodeJS.Timeout | undefined;

   constructor(localUser_: Persona) {

      super();

      this._initialObjects = undefined;
      this._participantCaucus = undefined;
      this._messageCaucus = undefined;   
      this._sharedEmbeddingCaucus = undefined;
      this._localUser = localUser_; 
      this._interval = undefined;
   }

   schema() : any {
      return containerSchema;
   }

   // This menas the list of Messages is ordered by send time ascending
   compareFn (a: Message, b: Message) : number {
      return a.sentAt.getTime() - b.sentAt.getTime();
   }

   setupLocalCaucuses (initialObjects_: any) : void {

      this._initialObjects = initialObjects_;

      // Create caucuses so they exist when observers are notified of connection
      this._participantCaucus = new CaucusOf<Persona>(initialObjects_.participantMap as SharedMap);
      this._messageCaucus = new CaucusOf<Message>(initialObjects_.messageMap as SharedMap, this.compareFn);  
      this._sharedEmbeddingCaucus = new CaucusOf<SharedEmbedding> (initialObjects_.sharedEmbeddingMap as SharedMap)
      
      this.setInitialValues(this._participantCaucus, this._messageCaucus);

      let self = this;

      this._interval = setInterval(() => {
         throwIfUndefined(self._participantCaucus);
         throwIfUndefined(self._messageCaucus);         
         checkAddAddSelfToAudience(self._participantCaucus, self._messageCaucus, self._localUser);
       }, 10000);
   }

   disconnectLocalCaucuses () : void {
      clearInterval (this._interval);
   }

   participantCaucus(): CaucusOf<Persona> {
      throwIfUndefined (this._participantCaucus);
      return this._participantCaucus;
   }

   messageCaucus(): CaucusOf<Message> {
      throwIfUndefined (this._messageCaucus);
      return this._messageCaucus;
   }    

   sharedEmbeddingCaucus(): CaucusOf<SharedEmbedding> {
      throwIfUndefined (this._sharedEmbeddingCaucus);
      return this._sharedEmbeddingCaucus;
   } 

   resetMessages () : void {

      throwIfUndefined (this._messageCaucus);      
      this._messageCaucus.removeAll ();    
      
      throwIfUndefined (this._participantCaucus);  
      this._participantCaucus.removeAll ();

      throwIfUndefined (this._sharedEmbeddingCaucus);  
      this._sharedEmbeddingCaucus.removeAll ();      

      this.setInitialValues (this._participantCaucus, 
                             this._messageCaucus);
   }

   private setInitialValues (participantCaucus: CaucusOf<Persona>,  
                             messageCaucus: CaucusOf<Message>): void {
    
      checkAddAddSelfToAudience (participantCaucus, messageCaucus, this._localUser);

      // Add the Bot persona if its not already there
      let isStored = participantCaucus.has(EConfigStrings.kLLMGuid);

      if (! isStored ) {

         let botPersona = new Persona (EConfigStrings.kLLMGuid, EConfigStrings.kLLMName, EConfigStrings.kLLMName, EIcon.kLLMPersona, undefined, new Date());
         participantCaucus.add (botPersona.id, botPersona);            
      }
   } 
}

function checkAddAddSelfToAudience (participantCaucus: CaucusOf<Persona>, 
   messageCaucus: CaucusOf<Message>,
   localUser: Persona): void {

   let isStored = participantCaucus.has(localUser.id);

   if (! isStored ) {      
      
      // We look at all participants looking for someine with the same email as us. 
      // If we find one, we do a 'glare' comparison to consistently pick a winner, and the loser of the
      // 'glare' comparison sets their details to those of the winner. 
      let currentParticipants = participantCaucus.currentAsArray();
      let found = false;

      for (let i = 0; i < currentParticipants.length && !found; i++) {        
         if ((localUser.email === currentParticipants[i].email ) && 
             (localUser.name === currentParticipants[i].name )) { 
            
            found = true;
            localUser.id = currentParticipants[i].id; // Need to push the new ID back into our local copy
         }
      }

      if (!found) {
         // Connect our own user ID to the participant caucus if we are not already in it (or our email is)
         participantCaucus.add (localUser.id, localUser);             
      }
   } 
   else {
      // Check the right name is stored - name changes when the user logs in 
      let stored = participantCaucus.get(localUser.id);         
      if ((stored.name !== localUser.name) || (stored.email !== localUser.email)) {
         participantCaucus.add (localUser.id, localUser);                 
      }        
   }
}
****************************************

****************************************
Boxer\core\CaucusFramework.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module CaucusFramework
 * @description Provides a framework for managing caucuses in the Boxer application.
 * 
 * This module includes the CaucusOf class which manages a shared map and provides
 * methods for adding, removing, and updating elements in the map. It also includes
 * static interests for notifications when elements are added, changed, or removed.
 * 
 * The CaucusOf class extends the Notifier class from the NotificationFramework module,
 * which provides a mechanism for notifying observers of events.
 */

import { SharedMap, IValueChanged } from "fluid-framework/legacy";
import { debounce } from './Debounce';
import { MDynamicStreamable } from './StreamingFramework';
import { Interest, NotificationFor, Notifier } from './NotificationFramework';
import { throwIfUndefined } from "./Asserts";

export type compareFn<T> = (left: T, right: T) => number;

export class CaucusOf<AType extends MDynamicStreamable> extends Notifier {

   public static caucusMemberAddedNotificationId = "caucusMemberAdded";
   public static caucusMemberAddedInterest = new Interest(CaucusOf.caucusMemberAddedNotificationId);

   public static caucusMemberChangedNotificationId = "caucusMemberChanged";
   public static caucusMemberChangedInterest = new Interest(CaucusOf.caucusMemberChangedNotificationId);

   public static caucusMemberRemovedNotificationId = "caucusMemberRemoved";
   public static caucusMemberRemovedInterest = new Interest(CaucusOf.caucusMemberRemovedNotificationId);

   private _localMap: Map<string, AType>;
   private _localArray: Array<AType>;
   private _shared: SharedMap;
   private _comparator: compareFn<AType> | null;
   private _isCachedArrayDirty: boolean;

   constructor(shared_: SharedMap, comparator_: compareFn<AType> | null = null) {
      super();

      this._shared = shared_;
      this._localMap = new Map<string, AType>();
      this._localArray = new Array<AType>;
      this._comparator = comparator_;
      this._isCachedArrayDirty = true;

      (this._shared as any).on("valueChanged", (changed: IValueChanged, local: boolean, target: SharedMap) => {

         if (local) { 
            return;
         }

         this.doNotification(changed.previousValue !== undefined, target.has(changed.key), changed.key);

      });

      let self = this;
      
      // This functions as a kickstarter for initial load - changes made by other parties before we were connected are not classed as 'remote'
      // so we have to kick the UI
      function kickStart() {
         self.doNotification(false, false, undefined);
      }
      const kickStarted = debounce(() => {kickStart.bind(this)}, 250);
      kickStarted();
   }

   private doNotification(hadPrevious_: boolean, hasTarget_: boolean, key_: string | undefined): void {

      if (hadPrevious_) {

         if (hasTarget_) {

            this.notifyObservers(CaucusOf.caucusMemberChangedInterest, 
               new NotificationFor<string>(CaucusOf.caucusMemberChangedInterest, 
                  key_ as string));

            if (key_) {
               let element = this._shared.get(key_);      
               throwIfUndefined (element);
            
               let object = MDynamicStreamable.resurrect(element) as AType;                  
               this.updateCache (object); 
            }
            else {
               this._isCachedArrayDirty = true;   
            }
         }
         else {

            this.notifyObservers(CaucusOf.caucusMemberRemovedInterest, 
               new NotificationFor<string>(CaucusOf.caucusMemberRemovedInterest, 
                  key_ as string));

            this._isCachedArrayDirty = true;                   
         }
      } else {

         this.notifyObservers(CaucusOf.caucusMemberAddedInterest, 
            new NotificationFor<string>(CaucusOf.caucusMemberAddedInterest, 
               key_ as string));

         this._isCachedArrayDirty = true;                
      }
   }

   has(key_: string): boolean {

      return this._shared.has(key_);
   }

   add(key_: string, element_: AType): void {

      let stream = element_.flatten ();

      this._shared.set(key_, stream);   
      this._isCachedArrayDirty = true;         
   }

   remove (key_: string): boolean {

      let result = this._shared.delete(key_);
      if (result)
         this._isCachedArrayDirty = true;  
      return result;    
   }

   amend(key: string, element: AType) {

      let stream = element.flatten();

      this._shared.set(key, stream);

      this.updateCache (element);    
   }

   get (key_: string) : AType {

      let element = this._shared.get(key_);
      
      throwIfUndefined (element);

      let object = MDynamicStreamable.resurrect(element) as AType;

      return object;
   }

   removeAll (): void {
      
      this._shared.clear();
      this._localMap.clear();
      this._localArray = new Array<AType>();
      this._isCachedArrayDirty = true;      

      this.doNotification(false, false, undefined);   
   }

   current(): Map<string, AType> {

      this._localMap.clear();

      this._shared.forEach((value: any, key: string, map: Map<string, any>) => {

         let object = MDynamicStreamable.resurrect(value) as AType;

         this._localMap.set(key, object);
      }); 

      return this._localMap;
   }

   currentAsArray(): Array<AType> {

      if (this._isCachedArrayDirty) {

         // Truncate the array, then refill from the shared map.
         this._localArray.length = 0;

         this._shared.forEach((value: any, key: string, map: Map<string, any>) => {

            let object = MDynamicStreamable.resurrect(value) as AType;

            this._localArray.push(object);
         }); 

         // Sort it if a comparison function is present
         let comparator = this._comparator;

         this._localArray.sort((a, b) => {
            if (comparator)
               return comparator (a, b);
            else 
               return 0;
         });

         this._isCachedArrayDirty = false;
      }

      return this._localArray;
   }

   synchFrom ( map_: Map<string, AType>) : void {

      var deleteSet: Array<string> = new Array<string>();

      // accumulate a list of things to delete, dont delete as we go bcs it messes up iteration
      this._shared.forEach((value: any, key: string) => {
         if (!map_.get (key)) {
            deleteSet.push(key);
         }
      });

      // delete them once we have completed iteration
      deleteSet.forEach((id: string, index: number) => {
         this._shared.delete(id);
      });

      // Now update items in the shared map that are different in the input map 
      map_.forEach((value: any, key: string) => {

         let elementShared: string | undefined = this._shared.get(key);

         let elementNew: string = value.flatten();

         if (!elementShared) {
            this.add (key, value);
         }
         else
         if (elementShared !== elementNew) {
            this.amend(key, value);
         }
      });

      this._isCachedArrayDirty = true;
   }

   private updateCache (item: AType): Array<AType> {

      let found = false;

      if (this._comparator && this._localArray) {
         let i = this.binarySearch (this._localArray, item, this._comparator);
         if (i !== -1) {
            this._localArray[i] = item;
            found = true;
         }
      }

      if (!found) {
         this._isCachedArrayDirty = true;
      }

      return this.currentAsArray();
   }

   binarySearch(arr: Array<AType>, element: AType, compare_fn: compareFn<AType>) : number {

      let m = 0;
      let n = arr.length - 1;
      
      while (m <= n) {
          let k = (n + m) >> 1;
          let cmp = compare_fn(element, arr[k]);
          if (cmp > 0) {
             m = k + 1;
          } 
          else 
          if (cmp < 0) {
             n = k - 1;
          } 
          else {
             return k;
          }
      }
      return -1;
   }   
}
****************************************

****************************************
Boxer\core\ConfigStrings.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module ConfigStrings
 * @description Provides constants for configuration strings used in the Boxer application.
 * 
 * This module includes strings for logging categories, font names, URLs, Azure settings, and more.
 * It also includes constants for various IDs and keys used in the application, such as session keys,
 * conversation keys, and AI model IDs.
 */

export enum EConfigStrings {

   kCoreLogCategory = "Core",
   kApiLogCategory = "API",
   kDbLogCategory = "DB",   

   kFontNameForTextWrapCalculation = "12pt Segoe UI",

   kHomeRelativeUrl= "/boxer.html",           
   
   kAzureTenantId = "b9576484-5c2e-4613-bfdf-039948cdd521",
   kAzureProductionFluidHost = "https://eu.fluidrelay.azure.com",
   kAzureLocalFluidHost = "http://localhost:7070",

   kLLMName = 'Boxer',
   kLLMNameLowerCase = 'boxer',   
   kLLMGuid = "313aafdb-a05c-4dc7-98d0-4db7f28f122f",
   kLLMRequestSignature = '@Boxer',
   kLLMRequestSignatureLowerCase = '@boxer',
   kLLMNearRequestSignature = 'Boxer',
   kLLMNearRequestSignatureLowerCase = 'boxer',   
   
   // These are applied serially - watch out for adding terms in early edits that then get replaced again later on
   // Spaces are significant
   kPromptLookFor1 = "an LLM",
   kPromptReplaceWith1 = "a Large Language Model (LLM)",
   kPromptLookFor2 = "LLMs",
   kPromptReplaceWith2 = "Large Language Models (LLMs)",   
   kPromptLookFor3 = " LLM ",
   kPromptReplaceWith3 = " Large Language Model (LLM) ",   
   kPromptLookFor4 = " LLm ",
   kPromptReplaceWith4 = " Large Language Model (LLM) ", 
   kPromptLookFor5 = " lLM ",
   kPromptReplaceWith5 = " Large Language Model (LLM) ",
   kPromptLookFor6 = " LlM ",
   kPromptReplaceWith6 = " Large Language Model (LLM) ",

   // Use these to detect questions where we are not relevant
   kResponseNotRelevantMarker = "That doesn't seem to be about AI",
   kResponseDontKnowMarker = "I don't know",   

   kErrorConnectingToKeyAPI = "Error connecting to the Boxer server.",
   kErrorConnectingToAiAPI = "Error connecting to AI server.",

   kSessionParamName = "session",
   kConversationParamName = "conversation",   
   kEmailParamName = "email",
   kNameParamName = "name",
   kSecretParamName = "secret",

   kCohort1ConversationKey = "eb948951-1b53-460e-a023-26e39895dec6",
   kCohort1Team1ConversationKey = "c43edc61-cedc-43f6-9224-db847d1ed0eb",   
   kCohort1Team2ConversationKey = "1eadf3a2-148d-4afd-b69f-c9f72e824486",
   kCohort1Team3ConversationKey = "121ffdef-ced6-45dd-84be-f16171b8b406",   
   kDemoConversationKey = "c70f4a2d-8a56-42d5-b9ce-88bdc50029c8",

   kAdminUserNames = "Jon Verrier" // Comma seperated list of names, at run time we just check if the user name is included in this list. 
};

export enum EConfigNumbers {
   kInitialHelpfulPromptDelayMsecs = 1000,
   kBoxerChattinessMessageCount = 20,
   kMaximumLinkTextlength = 40,
   kMaximumLinkTextlengthMobile = 30,   
   kHelpfulPromptMinimumGapMins = 10, // At least 10 minutes between AI suggestions
   kMessagePrompt2VBorder = 24,       // How much to allow for top + bottom inset
   kMessagePrompt2HBorder = 24,       // How much to allow for left & right inset
   kMessagePromptLineSpace = 8,       // How much to allow between lines
   kMessagePromptMaxCharacters = 2048,
   kMaxDownloadWaitSeconds = 30,
   kMaxMessagesBack = 20,          // Go up to 20 messages back for context to send to the LLM
   kMaxChatLevel = 4, // 0-4 to set how chatty the AI is
   kMinMessagesforRecap = 5 ,// 5 mesages and we offer a recap at the start,
   kSummaryLengthWords = 50
}

// This is used for local running only, as in browser we cannot access environment variables
// NEVER PUT PRODUCTION SECRETS IN HERE
let KStubEnvironmentVariables = {
   SessionKey : "49b65194-26e1-4041-ab11-4078229f478a",
   ConversationKey : "abcde"
};

export {KStubEnvironmentVariables};
****************************************

****************************************
Boxer\core\Debounce.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Debounce
 * @description Provides a utility function for debouncing function calls.
 * 
 * This module includes the debounce function which takes a function and a delay,
 * and returns a new function that will call the original function after the delay,
 * but not more frequently than once per delay period.
 */

import { throwIfNull } from "./Asserts";

export function debounce(fn_ : Function, ms_: number) : Function {

   return () => {

      var timer: NodeJS.Timeout | null = null;
      
      const nested = () => {
         throwIfNull(timer);
         clearTimeout(timer);         
         timer = null;
         fn_();
      };

      timer = setTimeout(nested, ms_);
   };
}
****************************************

****************************************
Boxer\core\Errors.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Errors
 * @description Provides error classes for the Boxer application.
 * 
 * This module includes classes for invalid parameters, invalid operations, invalid states,
 * connection errors, environment errors, and assertion failures. Each class extends the Error
 * class and provides a constructor that logs the error to the console.
 */

import { logApiError, logCoreError } from "./Logging";

export class InvalidParameterError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidParameterError.name; // stack traces display correctly now

      logCoreError ("InvalidParameterError:" + (message ? message : ""), this.cause ? this.cause: "");
   }
}

export class InvalidOperationError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidOperationError.name; // stack traces display correctly now

      logCoreError ("InvalidOperationError:" + (message ? message : ""), this.cause ? this.cause: "");      
   }
}

export class InvalidStateError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidStateError.name; // stack traces display correctly now

      logCoreError ("InvalidStateError:" + (message ? message : ""), this.cause ? this.cause: "");      
   }
}

export class ConnectionError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = ConnectionError.name; // stack traces display correctly now

      logApiError ("ConnectionError:" + (message ? message : ""), this.cause ? this.cause: "");      
   }
}

export class EnvironmentError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = EnvironmentError.name; // stack traces display correctly now

      logCoreError ("EnvironmentError:" + (message ? message : ""), this.cause ? this.cause: "");       
   }
}

export class AssertionFailedError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = AssertionFailedError.name; // stack traces display correctly now

      logCoreError ("AssertionFailedError:" + (message ? message : ""), this.cause ? this.cause: "");       
   }
}

/*
 
export class InvalidUnitError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidUnitError.name; // stack traces display correctly now
   }
}

export class InvalidFormatError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidFormatError.name; // stack traces display correctly now
   }
}

export class InvalidServerResponseError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidServerResponseError.name; // stack traces display correctly now
   }
}

*/
****************************************

****************************************
Boxer\core\FluidConnection.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module FluidConnection
 * @description Provides a base class for managing Fluid connections in the Boxer application.
 * 
 * This module includes the FluidConnection class which handles:
 * - Creating and attaching to Fluid containers
 * - Disconnecting from Fluid containers
 * - Managing local caucuses for participants and messages
 * - Tracking active call state
 * 
 * The connection requires a session key for authentication and uses the environment 
 * configuration to determine appropriate API endpoints. It works with the QueryModelApi
 * to make actual API calls while providing higher-level conversation management.
 */

import { IFluidContainer, ConnectionState } from "fluid-framework";
import { AzureClient } from "@fluidframework/azure-client";

import { FluidClientProps } from "../../CommonTs/src/FluidTokenProvider";
import { IFluidTokenRequest } from "../../CommonTs/src/Fluid";
import { throwIfUndefined } from "./Asserts";
import { logApiError } from "./Logging";
import { ConnectionError, InvalidOperationError, InvalidStateError} from './Errors';
import { Interest } from './NotificationFramework';
import { SessionKey, ConversationKey } from "./Keys";
import { EConfigStrings } from "./ConfigStrings";
import { getDefaultFluidEnvironment } from "../../CommonTs/src/IEnvironmentFactory";
import { EEnvironment } from "../../CommonTs/src/IEnvironment";

let documentUuid = "b03724b3-4be0-4491-b0fa-43b01ab80d50";

export abstract class FluidConnection {

   public static connectedNotificationId = "connected";
   public static connectedInterest = new Interest(FluidConnection.connectedNotificationId);

   _client: AzureClient | undefined;
   _container: IFluidContainer | undefined;

   constructor() {

      this._client = undefined;
      this._container = undefined;
   }

   async createNew(sessionKey_: SessionKey, forceProduction: boolean): Promise<ConversationKey> {

      try {
         this.setupBeforeConnection (sessionKey_, forceProduction);

         throwIfUndefined (this._client);
         const { container, services } = await this._client.createContainer(this.schema(), "2");
         this._container = container;

         let self = this;

         return new Promise<ConversationKey>((resolve, reject) => {
            // Attach container to service and return assigned ID
            const containerIdPromise = container.attach();

            containerIdPromise.then((containerId) => {
               if (this._container) {
                  self.setupAfterConnection(this._container);
               }
               else {
                  logApiError ("FluidConnection is in inconsistent internal state.", null);
                  throw new InvalidStateError("FluidConnection is in inconsistent internal state.");
               }

               resolve (new ConversationKey (containerId));
            }).catch((e: any) => {
               logApiError ("Error connecting to conversation: ", e);               
               reject ();
            });
         });
      }
      catch (e: any) {
         throw new ConnectionError("Error connecting new container to remote data service: " + e ? e.message : "(no details found)");
      }
   }

   async attachToExisting(sessionKey_: SessionKey, conversationKey_: ConversationKey, forceProduction: boolean): Promise<ConversationKey> {

      try {
         this.setupBeforeConnection (sessionKey_, forceProduction);

         throwIfUndefined (this._client);
         const { container, services } = await this._client.getContainer(conversationKey_.toString(), this.schema(), "2");
         this._container = container;

         this.setupAfterConnection(this._container);

         return conversationKey_;
      }
      catch (e: any) {
         throw new ConnectionError("Error attaching existing container to remote data service: " + e ? e.message : "(no details found)")
      }
   }

   canDisconnect(): boolean {

      if (!this._container)
         return false;

      var state = this._container.connectionState;
      if (state !== ConnectionState.Connected)
         return false;

      return true;
   }

   isConnected (): boolean {

      return this.canDisconnect();
   }

   async disconnect(): Promise<boolean> {

      if (this.canDisconnect()) {
         if (this._container) {
            await this._container.disconnect();
            this.disconnectLocalCaucuses();
         }

         return true;
      }
      else {
         throw new InvalidOperationError("The remote data service is not connected.")
      }
   }

   // local function to cut down duplication between createNew() and AttachToExisting())
   private setupBeforeConnection(sessionKey_: SessionKey, forceProduction: boolean): void {

      let local = getDefaultFluidEnvironment().name === EEnvironment.kLocal;

      let request: IFluidTokenRequest = {
         local: local,         
         userId: EConfigStrings.kLLMGuid,
         userName: EConfigStrings.kLLMName,
         documentId: documentUuid         
      }

      var clientProps: FluidClientProps = new FluidClientProps(sessionKey_.toString(), request, forceProduction);
      this._client = new AzureClient(clientProps);
   }

   // local function to cut down duplication between createNew() and AttachToExisting())
   private setupAfterConnection(container: IFluidContainer): void {

      // Create caucuses so they exist when observers are notified of connection
      this.setupLocalCaucuses (container.initialObjects);
   }

   abstract schema() : any;
   abstract setupLocalCaucuses(initialObjects: any) : void;
   abstract disconnectLocalCaucuses () : void;
}
****************************************

****************************************
Boxer\core\IActivityRepository.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

// Internal import
import { IStoredActivity } from './ActivityRecord';

export interface IActivityRepository {

   save (record : IStoredActivity) : Promise<boolean>;
   loadRecentUrlActivity (count : number) : Promise<Array<IStoredActivity>>;
   loadRecentMessages (count : number) : Promise<Array<IStoredActivity>>;  
   removeMessageRecord (messageId: string) : Promise<boolean>;
}
****************************************

****************************************
Boxer\core\IActivityRepositoryFactory.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module IActivityRepositoryFactory
 * @description Provides factory function for creating activity repositories.
 * 
 * This module includes the getRecordRepository function which creates and returns
 * an IActivityRepository implementation based on the provided session key. Currently
 * returns a Cosmos DB-backed implementation of the activity repository.
 */

// Internal imports
import { SessionKey } from "./Keys";
import { IActivityRepository } from "./IActivityRepository";
import { ActivityRepositoryCosmos } from "./ActivityRepository";

export function getRecordRepository (sessionKey_: SessionKey) : IActivityRepository {
   return new ActivityRepositoryCosmos(sessionKey_);   
}
****************************************

****************************************
Boxer\core\IAdminRepository.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module IAdminRepository
 * @description Provides an interface for checking if a user is an admin.
 * 
 * This module includes the IAdminRepository interface and the DefaultAdminRepository
 * class, which is a local implementation of the interface.
 */

import { Persona} from "./Persona";
import { EConfigStrings } from "./ConfigStrings";

export interface IAdminRepository {

   isAdmin (persona : Persona) : Promise<boolean>; 
}

export function getDetaultAdminRepository(): IAdminRepository {
   return new DefaultAdminRepository();
}

// THis is a local implementation of IAdminRepository that just searches strigs for a well know name
// If it is present, user can be an admin. 
export class DefaultAdminRepository implements IAdminRepository {

   isAdmin (persona : Persona) : Promise<boolean> {
      
      let done = new Promise<boolean>(function(resolve, reject) {

         let isAdmin = (EConfigStrings.kAdminUserNames.includes (persona.name));

         resolve (isAdmin);
      });

      return done;
   }
}
****************************************

****************************************
Boxer\core\Icons.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Icons
 * @description Provides an enum for the icons used in the Boxer application.
 * 
 * This module includes the EIcon enum which contains the names of the icons used in the application.
 */

export enum EIcon {

   kPersonPersona = "kPersonPersona", 
   kLLMPersona = "kLLMPersona", 
   kBotPersona = "kBotPersona",   // For backwards compatibility 
   kUnknownPersona = "kUnknownPersona",
   kFromBcd = "kFromBcd"
   
};
****************************************

****************************************
Boxer\core\IKeyGenerator.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module IKeyGenerator
 * @description Provides an interface for a class to generate unique keys.
 * 
 * This module includes the IKeyGenerator interface which defines methods for generating keys and secrets,
 * checking if a key could be a valid key, saving and matching secrets, and managing saved secrets.
 */

/// <summary>
/// IKeyGenerator - interface for a class to generate unique keys
/// </summary>
export interface IKeyGenerator {

   generateKey (): string;
   generateSecret(): string;
   couldBeAKey(key: string): boolean;
   saveSecret(secret: string): void;
   matchesSavedSecret (secret: string): boolean;
   haveSavedSecret  () : boolean;
   savedSecret  () : string;
}
****************************************

****************************************
Boxer\core\IKeyGeneratorFactory.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module IKeyGeneratorFactory
 * @description Provides a factory function for creating key generators.
 * 
 * This module includes the getDefaultKeyGenerator function which returns a new instance of the UuidKeyGenerator class.
 */

import { IKeyGenerator } from './IKeyGenerator';
import { UuidKeyGenerator } from './UuidKeyGenerator';

/// <summary>
/// getDefaultKeyGenerator - returns the key generator
/// </summary>

export function getDefaultKeyGenerator(): IKeyGenerator {
   return new UuidKeyGenerator();
}
****************************************

****************************************
Boxer\core\JoinDetails.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module JoinDetails
 * @description Provides a class for managing join details in the Boxer application.
 * 
 * This module includes the JoinDetails class which handles:
 * - Parsing join details from a string
 * - Validating join details
 * - Creating join details from parts
 * - Converting join details to a string
 */

import { EConfigStrings } from "./ConfigStrings";
import { SessionKey, ConversationKey } from "./Keys";

import { getDefaultFluidEnvironment } from "../../CommonTs/src/IEnvironmentFactory";
import { EEnvironment } from "../../CommonTs/src/IEnvironment";

var qs = require('qs');

function validateEmail(email_: string) : boolean {
   if (!email_)
      return false;

   const res = /^[\w-\.]+@([\w-]+\.)+[\w-]{2,4}$/;
   return res.test(String(email_).toLowerCase());
 }

export class JoinDetails {

   private _email: string;
   private _name: string;
   private _session: SessionKey;
   private _conversation: ConversationKey;  
   private _secret: string; 

   /**
    * Create a JoinDetails object. A join details is in the format 'email=xxx@yyy.com&session=guid&conversation=guid' . The email is used to uniquely identify the joiner, the session 
    * specifies a key to use for basic security, conversation is a Fluid UUID
    * It can be valid with a string that looks like an email address, and a session and conversation keys that look like UUIDs
    */
   constructor(trialInput_: string) {
   
      this._session = new SessionKey("");
      this._conversation = new ConversationKey("");      
      this._email = "";
      this._name = "";
      this._secret = "";

      let parsed = qs.parse (trialInput_); 

      this._email = parsed.email ? parsed.email : "";
      this._name = parsed.name ? parsed.name: "";
      this._session = parsed.session ? new SessionKey (parsed.session) : new SessionKey ("");
      this._conversation = parsed.conversation ? new ConversationKey (parsed.conversation) : new ConversationKey ("");  
      this._secret = parsed.secret ? parsed.secret : "";        
   }   
   
   /**
   * set of 'getters' for private variables
   */
   get email(): string  {
      return this._email;
   }
   get name(): string  {
      return this._name;
   }   
   get session(): SessionKey  {
      return this._session;
   }
   get conversation(): ConversationKey  {
      return this._conversation;
   }   
   get secret(): string  {
      return this._secret;
   }     
   toString(): string  {
      return JoinDetails.toString (this._email, this._name, this._session, this._conversation, this._secret);
   }

   canAttemptJoin(): boolean {
      let environment = getDefaultFluidEnvironment();

      // If we are running locally, allow empty conversation key -> this creates a new conversation
      if ((environment.name === EEnvironment.kLocal) && this._conversation.toString().length === 0)
         return this._session.looksValidSessionKey() && validateEmail (this._email);

      return (this._session.looksValidSessionKey() 
         && this._conversation.looksValidConversationKey() 
         && validateEmail (this._email));          
   } 

   static toString (email_: string, name_: string, session_: SessionKey, conversation_: ConversationKey, secret_: string) : string {
      return '&' + EConfigStrings.kEmailParamName + '=' +  email_ 
         + '&' + EConfigStrings.kNameParamName + '=' +  name_ 
         + '&' + EConfigStrings.kSessionParamName + '=' + session_.toString() 
         + '&' + EConfigStrings.kConversationParamName + '=' + conversation_.toString()
         + '&' + EConfigStrings.kSecretParamName + '=' + secret_.toString();
   }

   static makeFromParts (email_: string, name_: string, session_: SessionKey, conversation_: ConversationKey, secret_: string) {

      return new JoinDetails (JoinDetails.toString (email_, name_, session_, conversation_, secret_));
   }
  
}
****************************************

****************************************
Boxer\core\JoinPageValidator.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module JoinPageValidator
 * @description Provides a class for validating join details in the Boxer application.
 * 
 * This module includes the JoinPageValidator class which handles:
 * - Validating join details
 * - Checking if a user can attempt to join a conversation
 * - Managing saved secrets
 */

import { SessionKey, ConversationKey } from "./Keys";
import { JoinDetails } from "./JoinDetails";
import { getDefaultKeyGenerator } from "./IKeyGeneratorFactory";

export class JoinPageValidator {

   /**
    * Create an empty JoinPageValidator object 
    */
   constructor() {
   }   

   // Looks at the name and keys provided, and returns true if the data looks ready to join a conversation, else false.
   canAttemptJoin  (email_: string, name_: string, session_: SessionKey, conversation_: ConversationKey) : boolean {

      let details = JoinDetails.makeFromParts (email_, name_, session_, conversation_, "");    

      return details.canAttemptJoin();
   }

   // Looks at the secret returns true if the secret matches the one stored, else false.
   matchesSavedSecret  (secret_: string) : boolean {

      let keyGenerator = getDefaultKeyGenerator();

      return keyGenerator.matchesSavedSecret (secret_);
   }   

   haveSavedSecret  () : boolean {

      let keyGenerator = getDefaultKeyGenerator();

      return keyGenerator.haveSavedSecret ();
   }     

   savedSecret  () : string {

      let keyGenerator = getDefaultKeyGenerator();

      return keyGenerator.savedSecret ();
   }     
}
****************************************

****************************************
Boxer\core\KeyRetriever.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module KeyRetriever
 * @description Provides a class for retrieving keys from the Braid backend.
 * 
 * This module includes the KeyRetriever class which handles:
 * - Making API calls to retrieve keys
 * - Tracking active call state
 * - Logging errors
 */

import axios from "axios";

// Local
import { logApiError } from "./Logging";
import { EConfigStrings } from './ConfigStrings';
import { ConnectionError } from "./Errors";
import { SessionKey } from "./Keys";

export class KeyRetriever {

   private activeCallCount: number;

   /**
    * Create an empty KeyRetriever object 
    */
   constructor() {
      this.activeCallCount = 0;
   }   

   // Makes an Axios call to request the key
   // If running locally, looks for an environment variable
   async requestKey  (apiUrl_: string, paramName_: string, sessionKey_: SessionKey) : Promise<string> {
     
      /*  Now we use a localhost server bcs it can access environment variables
      // If we are running locally directly in the browser (not via a web server on localhost:)
      // use the stub values - no Production secrets are really stored locally 
      let environment = Environment.environment();
      if (environment === EEnvironment.kLocal) {
         type KStubEnvironmentVariableKey = keyof typeof KStubEnvironmentVariables;
         let memberKeyAsStr: KStubEnvironmentVariableKey = paramName_ as any;
         let checked = KStubEnvironmentVariables[memberKeyAsStr];
         throwIfUndefined(checked);
         return checked;
      }
      */

      this.activeCallCount++;

      var response;

      try {
         response = await axios.get(apiUrl_, {
            params: {
               [paramName_]: sessionKey_.toString()
            },
            withCredentials: false
         });
         this.activeCallCount--; 

      } catch (e: any) {
         
         this.activeCallCount--;
   
         logApiError (EConfigStrings.kErrorConnectingToKeyAPI + ":" + apiUrl_, e?.response?.data);           
      }

      if (!response || !response.data)
         throw new ConnectionError(EConfigStrings.kErrorConnectingToKeyAPI + ":" + apiUrl_);      
      
      return response.data as string;
   }    

   isBusy () {
      return this.activeCallCount !== 0;
   }
}
****************************************

****************************************
Boxer\core\Keys.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Keys
 * @description Provides classes for managing keys in the Boxer application.
 * 
 * This module includes the SessionKey and ConversationKey classes which handle:
 * - Creating and validating keys
 * - Converting keys to strings
 */

import { IKeyGenerator } from './IKeyGenerator';
import { getDefaultKeyGenerator } from './IKeyGeneratorFactory';

export class SessionKey {

   private _sessionId: string;

   /**
    * Create a SessionKey object. A join key is a GUID - this class just makes a type wrapper round a string. 
    */
   constructor(trialInput_: string) {

      this._sessionId = trialInput_;      
   }   
   
   /**
   * Does this look like a valid UUID
   */
   looksValidSessionKey(): boolean {
      let keyGenerator : IKeyGenerator = getDefaultKeyGenerator();

      return keyGenerator.couldBeAKey (this._sessionId);
   }

   /**
    * Return a string representation
    */
   toString(): string {
      return this._sessionId;
   }   
}

export class ConversationKey {

   private _conversationId: string;

   /**
    * Create a ConversationKey object. A ConversationKey is a GUID - this class just makes a type wrapper round a string. 
    */
   constructor(trialInput_: string) {

      this._conversationId = trialInput_;      
   }   
   
   /**
   * Does this look like a valid UUID
   */
   looksValidConversationKey(): boolean {

      let keyGenerator : IKeyGenerator = getDefaultKeyGenerator();

      return keyGenerator.couldBeAKey (this._conversationId);
   }

   /**
    * Return a string representation
    */
   toString(): string {
      return this._conversationId;
   }    
   
}
****************************************

****************************************
Boxer\core\Like.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Like
 * @description Provides a class for managing likes in the Boxer application.
 * 
 * This module includes the Like class which handles:
 * - Creating and managing like objects with names and timestamps
 * - Supporting multiple constructor patterns for initialization
 * - Copying like objects from JSON or constructed sources
 */

/**
 * Embeddeding object
 * @param url - link to source on the web.
 * @param summary - text summary (50 words)
 * @param ada_v2: embedding value array. Note this is copied by value to avoid duplicating large arrays.
 * @param timeStamp - when the item is dated from - can be undefined if not known
 * @param relevance - cosine relevance score to a query - can be undefined if the source reference has not been compared yet
 */
export class Like  {
   private _name: string;
   private _when: Date;

   /**
    * Create an empty Like object
    */
   public constructor();

   /**
    * Create a Like object
    * @param name_ - link to source on the web.
    * @param when_ - text summary (50 words)
    */
   public constructor(name_: string, when_: Date);

   /**
    * Create a Like object
    * @param source - object to copy from - should work for JSON format and for real constructed objects
    */
   public constructor(source: Like);

   public constructor(...arr: any[])
   {

      if (arr.length === 0) {
         this._name = ""; 
         this._when = new Date();        
         return;
      }

      var localName: string;
      var localwhen: Date;

      if (arr.length === 1) {
         localName = arr[0]._name;
         localwhen = arr[0]._when;        
      }
      else { 
         localName = arr[0];
         localwhen = arr[1];           
      }

      this._name = localName;
      this._when = localwhen;
   }

   streamOut(): string {

      return JSON.stringify({ name: this._name, when: this._when});
   }

   streamIn(stream: string): void {

      const obj = JSON.parse(stream);

      this.assign(new Like (obj.name, obj.when));   
   }

   /**
   * set of 'getters' for private variables
   */
   get name(): string {
      return this._name;
   }
   get when(): Date {
      return this._when;
   }

   /**
   * set of 'setters' for private variables
   */
   set name(name_: string) {

      this._name = name_;
   }

   set when(when_: Date) {

      this._when = when_;
   }


   /**
    * test for equality - checks all fields are the same. 
    * Uses field values, not identity bcs if objects are streamed to/from JSON, field identities will be different. 
    * @param rhs - the object to compare this one to.  
    */
   equals(rhs: Like): boolean {

      return ((this._name === rhs._name) &&   
         (this._when.getTime() === rhs._when.getTime()));
   }

   /**
    * assignment operator 
    * @param rhs - the object to assign this one from.  
    */
   assign(rhs: Like): Like {

      this._name = rhs._name;
      this._when = new Date (rhs._when);

      return this;
   }
}
****************************************

****************************************
Boxer\core\Logging.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Logging
 * @description Provides a logging system for the Boxer application.
 * 
 * This module includes the logCoreError, logDbError, logApiError, and logApiInfo functions which log errors and information to the console.
 */

import { log, LogLevel, tag } from 'missionlog';
import { EConfigStrings } from './ConfigStrings';


 // Logging handler
 const logger = {
   [LogLevel.ERROR]: (tag, msg, params) => console.error(msg, ...params),
   [LogLevel.WARN]: (tag, msg, params) => console.warn(msg, ...params),
   [LogLevel.INFO]: (tag, msg, params) => console.log(msg, ...params),
   [LogLevel.TRACE]: (tag, msg, params) => console.log(msg, ...params),
   [LogLevel.DEBUG]: (tag, msg, params) => console.log(msg, ...params),
} as Record<LogLevel, (tag: string, msg: unknown, params: unknown[]) => void>;

// Initialise logging
log.init({ application: 'DEBUG', notification: 'DEBUG' }, (level, tag, msg, params) => {
   logger[level as keyof typeof logger](tag, msg, params);
});


export function logCoreError (description: string, details: any) : void {

   logger.ERROR (EConfigStrings.kCoreLogCategory, description, [details]);
}

export function logDbError (description: string, details: any) : void {

   logger.ERROR (EConfigStrings.kDbLogCategory, description, [details]);
}

export function logApiError (description: string, details: any) : void {

   logger.ERROR (EConfigStrings.kApiLogCategory, description, [details]);
}

export function logApiInfo (description: string, details: any) : void {

   logger.INFO (EConfigStrings.kApiLogCategory, description, [details]);
}
****************************************

****************************************
Boxer\core\Media.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Media
 * @description Provides a class for managing media queries in the Boxer application.
 * 
 * This module includes the Media class which handles:
 * - Creating and managing media queries
 */


export class Media {  

   listeners: Array<Function>;
   isMobileFormFactorQuery: MediaQueryList;

   /**
    * Initialises repository 
    */
   constructor() {
      this.listeners = new Array();
      this.isMobileFormFactorQuery = window.matchMedia("(max-width: 1023px)");
      this.isMobileFormFactorQuery.addListener(this.onMobileFormFactorChange.bind(this));
   }

   /**
    *
    * isSmallFormFactor - provides a one-time response
    * if the display is at or below mobile form factor boundary.
    */
   isSmallFormFactor(): boolean {

      if (this.isMobileFormFactorQuery.matches) { // If media query matches
         return true;
      } else {
         return false;
      }
   }

  /**
    *
    * onSmallFormFactorChange - local hook on mobile form factor changes. 
    */
   onMobileFormFactorChange(): void {
      var matches: boolean = false;

      if (this.isMobileFormFactorQuery.matches) { // If media query matches
         matches = true;
      } 
      for (var i = 0; i < this.listeners.length; i++) {
         this.listeners[i](matches);
      }
   }

  /**
    *
    * addMobileFormFactorChangeListener - hook on external listeners to be fired if the display transitions across mobile form factor boundary.
    */
   addMobileFormFactorChangeListener(fn: Function) {
      this.listeners.push(fn);
   }
}
****************************************

****************************************
Boxer\core\Message.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Message
 * @description Provides a class for managing messages in the Boxer application.
 * 
 * This module includes the Message class which handles:
 * - Creating and managing message objects with text, author, responseTo, and timestamp
 * - Supporting multiple constructor patterns for initialization
 * - Copying message objects from JSON or constructed sources
 */

import GPT4Tokenizer from 'gpt4-tokenizer';

import { InvalidParameterError } from './Errors';
import { throwIfUndefined } from './Asserts';
import { IKeyGenerator } from './IKeyGenerator';
import { getDefaultKeyGenerator } from './IKeyGeneratorFactory';
import { MDynamicStreamable, DynamicStreamableFactory } from "./StreamingFramework";
import { areSameDate, areSameDeepArray } from './Utilities';
import { IRelevantEnrichedChunk } from '../../CommonTs/src/EnrichedChunk';

const keyGenerator: IKeyGenerator = getDefaultKeyGenerator();
const tokenizer = new GPT4Tokenizer({ type: 'gpt3' });

const className = "Message";

export type MessageStreamingHandler = (message: Message, more: boolean) => void;

// Message - text, plus IDs for the message itself, if its a reply, the person who sent it, and a date-time stamp
export class Message extends MDynamicStreamable {
   private _id: string;
   private _authorId: string;
   private _responseToId: string | undefined;
   private _text: string;
   private _sentAt: Date;
   private _chunks: Array<IRelevantEnrichedChunk>;
   private _tokens: number;
   private _isTokenCacheDirty: boolean;
   private _isStreaming: boolean;
   private _streamHandler: MessageStreamingHandler | undefined;

   /**
    * Create an empty Message object - required for particiation in serialisation framework
    */
   public constructor();

   /**
    * Create a Message object
    * @param id_ - id to use to generate uniqueness 
    * @param authorId_ - Id of the person who sent it
    * @param responseToId_ - id of the message to which it is a response, can be undefined
    * @param text_ - the message body
    * @param sentAt - timestamp for last interaction seen by the framework
    */
   public constructor(id_: string | undefined, authorId_: string | undefined, responseToId_: string | undefined, text_: string, sentAt: Date);

   /**
    * Create a Message object
    * @param id_ - id to use to generate uniqueness 
    * @param authorId_ - Id of the person who sent it
    * @param responseToId_ - id of the message to which it is a response, can be undefined
    * @param text_ - the message body
    * @param sentAt - timestamp for last interaction seen by the framework
    * @param chunks_ - relevent knowledge sources that help understand / provide context for the message. 
    */
   public constructor(id_: string | undefined, authorId_: string | undefined, responseToId_: string | undefined, text_: string, sentAt: Date,
      chunks_: Array<IRelevantEnrichedChunk>);

   /**
    * Create a Message object
    * @param message - object to copy from - should work for JSON format and for real constructed objects
    */
   public constructor(message: Message);

   public constructor(...arr: any[]) {

      super();

      if (arr.length === 0) {
         this._id = keyGenerator.generateKey(); // An new Message has a key
         this._authorId = "";                       // But not an author
         this._responseToId = undefined;
         this._text = "";
         this._sentAt = new Date();
         this._chunks = new Array<IRelevantEnrichedChunk>();
         this._tokens = 0;
         this._isTokenCacheDirty = true;
         this._isStreaming = false;
         this._streamHandler = undefined;
         return;
      }

      var localId: string;
      var localAuthorId: string;
      var localResponseToId: string;
      var localText: string;
      var localSentAt: Date;
      var localChunks: Array<IRelevantEnrichedChunk>;

      if (arr.length === 1) {
         localId = arr[0]._id
         localAuthorId = arr[0]._authorId;
         localResponseToId = arr[0]._responseToId;
         localText = arr[0]._text;
         localSentAt = new Date(arr[0]._sentAt);
         localChunks = arr[0]._chunks;
      }
      else if (arr.length === 5) {
         localId = arr[0];
         localAuthorId = arr[1];
         localResponseToId = arr[2];
         localText = arr[3];
         localSentAt = new Date(arr[4]);
         localChunks = new Array<IRelevantEnrichedChunk>();
      }
      else {
         localId = arr[0];
         localAuthorId = arr[1];
         localResponseToId = arr[2];
         localText = arr[3];
         localSentAt = new Date(arr[4]);
         localChunks = arr[5];
      }

      if (!Message.isValidId(localId)) {
         throw new InvalidParameterError("Id:" + localId + '.');
      }

      this._id = localId;
      this._authorId = localAuthorId;
      this._responseToId = localResponseToId;
      this._text = localText;
      this._sentAt = localSentAt;
      this._chunks = localChunks;
      this._tokens = 0;
      this._isTokenCacheDirty = true;
      this._isStreaming = false;
      this._streamHandler = undefined;
   }

   /**
    * Dynamic creation for Streaming framework
    */
   dynamicClassName(): string {

      return className;
   }

   static createDynamicInstance(): MDynamicStreamable {
      return new Message();
   }

   static _dynamicStreamableFactory: DynamicStreamableFactory = new DynamicStreamableFactory(className, Message.createDynamicInstance);
   streamOut(): string {

      return JSON.stringify({
         id: this._id, authorId: this._authorId,
         responseToId: this._responseToId,
         text: this._text, sentAt: this._sentAt,
         chunks: this._chunks,
         tokens: this._tokens,
         isStreaming: this._isStreaming
      });
   }

   streamIn(stream: string): void {

      const obj = JSON.parse(stream);

      let chunks = new Array<IRelevantEnrichedChunk>();
      let objChunks = obj.chunks;

      if (objChunks) {
         for (let i = 0; i < objChunks.length; i++) {
            let newSource = objChunks[i];
            chunks.push(newSource);
         }
      }
      this.assign(new Message(obj.id, obj.authorId, obj.responseToId, obj.text, new Date(obj.sentAt), chunks));

      this._isTokenCacheDirty = true;

      if (obj.tokens && obj.tokens !== 0) {
         this._tokens = obj.tokens;
         this._isTokenCacheDirty = false;
      }

      // This is for backwards compatibility - the 'streaming' concept was introduced after
      // the set of Fluid containers were set up, so it is not stored on many messages. 
      // So we have to check if the attribute exists
      if (typeof obj.isStreaming === "undefined")
         this._isStreaming = false;
      else
         this._isStreaming = obj.isStreaming;
   }

   /**
   * set of 'getters' for private variables
   */
   get id(): string {
      return this._id;
   }
   get authorId(): string {
      return this._authorId;
   }
   get responseToId(): string | undefined {
      return this._responseToId;
   }
   get text(): string {
      return this._text;
   }
   get sentAt(): Date {
      return this._sentAt;
   }
   get chunks(): Array<IRelevantEnrichedChunk> {
      return this._chunks;
   }
   get isDirty(): boolean {
      return this._isTokenCacheDirty;
   }
   get tokens(): number {
      if (this._isTokenCacheDirty) {
         let estimatedTokens = tokenizer.estimateTokenCount(this._text);

         if (this._chunks) {
            for (let i = 0; i < this._chunks.length; i++) {
               estimatedTokens += tokenizer.estimateTokenCount(this._chunks[i].chunk.summary);
            }
         }
         this._tokens = estimatedTokens;
         this._isTokenCacheDirty = false;
      }
      return this._tokens;
   }
   get checkedResponseToId(): string {
      throwIfUndefined(this._responseToId);
      return this._responseToId;
   }
   get isStreaming(): boolean {
      return this._isStreaming;
   }

   /**
   * set of 'setters' for private variables
   */
   set id(id_: string) {
      if (!Message.isValidId(id_)) {
         throw new InvalidParameterError("Id:" + id_ + '.');
      }

      this._id = id_;
   }

   set authorId(authorId_: string) {

      this._authorId = authorId_;
   }

   set text(text_: string) {

      this._text = text_;
      this._isTokenCacheDirty = true;
   }

   set responseToId(responseToId_: string) {

      this._responseToId = responseToId_;
   }

   set sentAt(sentAt_: Date) {

      this._sentAt = new Date(sentAt_);
   }

   set chunks(chunks_: Array<IRelevantEnrichedChunk>) {
      this._chunks = chunks_;
      this._isTokenCacheDirty = true;
   }
   set isStreaming(isStreaming: boolean) {

      this._isStreaming = isStreaming;
   }

   /**
    * is this message unprompted i.e. not a reply.  
    */
   isUnPrompted(): boolean {
      return (typeof (this._responseToId) === "undefined");
   }

   /**
    * force token calculation
    */
   calculateTokens(): number {

      return this.tokens;
   }

   /**
    * Use this when live streaming text from server into a message
    */
   hookLiveAppend(handler: MessageStreamingHandler): void {

      this._isStreaming = true;
      this._streamHandler = handler;
   }

   /**
    * Use this when live streaming text from server into a message
    */
   unhookLiveAppend(): void {

      this._isStreaming = false;
      this._streamHandler = undefined;
   }

   /**
    * Use this when live streaming text from server into a message
    */
   liveUpdateText(text: string, more: boolean): string {

      this.text = text;

      if (this._streamHandler) {
         this._streamHandler(this, more);
      }

      return this.text;
   }

   /**
     * Use this when live streaming chunks from server into a message
     */
   liveUpdateChunks(chunks: Array<IRelevantEnrichedChunk>, more: boolean): string {

      this._chunks = chunks;

      if (this._streamHandler) {
         this._streamHandler(this, more);
      }

      return this.text;
   }

   /**
    * test for equality - checks all fields are the same. 
    * Uses field values, not identity bcs if objects are streamed to/from JSON, field identities will be different. 
    * @param rhs - the object to compare this one to.  
    */
   equals(rhs: Message): boolean {

      return ((this._id === rhs._id) &&
         (this._authorId === rhs._authorId) &&
         ((this._responseToId === undefined && rhs._responseToId === undefined) || (this._responseToId === rhs._responseToId)) &&
         (this._text === rhs._text) &&
         (areSameDate(this._sentAt, rhs._sentAt)) &&
         areSameDeepArray(this._chunks, rhs._chunks));
   }

   /**
    * assignment operator 
    * @param rhs - the object to assign this one from.  
    */
   assign(rhs: Message): Message {
      this._id = rhs._id;
      this._authorId = rhs._authorId;
      this._responseToId = rhs._responseToId;
      this._text = rhs._text;
      this._sentAt = new Date(rhs._sentAt);
      this._chunks = rhs._chunks;
      this._tokens = 0;
      this._isTokenCacheDirty = true;
      this._isStreaming = false;

      return this;
   }

   /**
    * test for valid id 
    * @param id - the string to test
    */
   static isValidId(id_: string): boolean {
      if (!id_) // undefined keys are allowed if user object has not been originated from or saved anywhere persistent
         return true;

      if (id_ && id_.length > 0) // if the id exists, must be > zero length
         return true;

      return (false);
   }
}
****************************************

****************************************
Boxer\core\NotificationFramework.ts
****************************************
// NotificationFramework
// Copyright (c) 2024 Braid Technologies Ltd
/////////////////////////////////////////
/**
 * @module NotificationFramework
 * @description Provides a framework for managing notifications in the Boxer application.
 * 
 * This module includes the Interest class which handles:
 * - Creating and managing notification interests with unique IDs
 * - Supporting multiple constructor patterns for initialization
 * - Copying interest objects from JSON or constructed sources
 */


/// <summary>
/// Interest -  encapsulates what is being observed - a specific notificationId.
/// </summary>
export class Interest { 

   private _notificationId: string;
   private static noInterest : string  = "nullInterest";

   /**
    * Create a Interest object
    * @param notificationId_ - id of the notification 
    */
   constructor(notificationId_: string);

   /**
    * Create a Interest object
    * @param interest_ - object to copy from - should work for JSON format and for real constructed objects
    */
   public constructor(interest_: Interest);

   /**
    * Create an empty Interest object - required for particiation in serialisation framework
    */
   constructor ();

   constructor(...arr: any[]) { 
      if (arr.length === 0) { // Empty Constructor
         this._notificationId = Interest.noInterest;
         return;
      }
      else {
         if (this.isMyType(arr[0])) { // Copy Constructor
            this._notificationId = arr[0]._notificationId;
         }
         else { // Individual arguments
            this._notificationId = arr[0];
         }
      }
   }

   private isMyType(rhs_: Interest): boolean {
      return rhs_.hasOwnProperty('_notificationId');
   }

   /**
   * set of 'getters' for private variables
   */
   get notificationId(): string  {
      return this._notificationId;
   }

   /**
    * test for equality - checks all fields are the same. 
    * NB must use field values, not identity bcs if objects are streamed to/from JSON, identities will be different. 
    * @param rhs_ - the object to compare this one to.  
    */
   equals(rhs_: Interest): boolean {
      
      return (this._notificationId === rhs_._notificationId);
   }

   /**
    * assignment operator 
    * @param rhs_ - the object to assign this one from.  
    */
   assign(rhs_: Interest): Interest {
      this._notificationId = rhs_._notificationId;

      return this;
   }

   public static createNullInterest () : Interest {
      return new Interest (Interest.noInterest);

   }
}

/// <summary>
/// Notification -  base class for all events. Base carries references to the notifcationId. derived classes add a data package via template class below.
/// Value class - just holds reference to the data, is expected to exist only for the synchronous life of the notification.
/// </summary>
export class Notification {

   private _interest: Interest;

   /**
    * Create a Notification object
    * @param interest_ - the Interest to identify the notification 
    */
   constructor(interest_: Interest);

   /**
    * Create a Notification object
    * @param notification_ - object to copy from - should work for JSON format and for real constructed objects
    */
   public constructor(notification_: Notification);

   /**
    * Create an empty Interest object - required for particiation in serialisation framework
    */
   constructor();

   constructor(...arr: any[]) {
      if (arr.length === 0) { // Empty Contrutructor
         this._interest = Interest.createNullInterest();
         return;
      }
      else {
         if (this.isMyType(arr[0])) { // Copy Contrutructor
            this._interest = new Interest (arr[0]._interest);
         }
         else { // Individual arguments
            this._interest = new Interest (arr[0]);
         }
      }
   }

   private isMyType(rhs_: Notification): boolean {
      return rhs_.hasOwnProperty('_interest');
   }

   /**
   * set of 'getters' for private variables
   */
   get interest (): Interest {
      return this._interest;
   }

   /**
    * test for equality - checks all fields are the same. 
    * Shallow check.
    * @param rhs_ - the object to compare this one to.  
    */
   equals(rhs_: Notification): boolean {

      return (this.interest === rhs_.interest) ||
         (this._interest.equals(rhs_._interest));
   }

   /**
    * assignment operator 
    * @param rhs_ - the object to assign this one from.  
    */
   assign(rhs_: Notification): Notification {
      this._interest = rhs_._interest;

      return this;
   }

}

/// <summary>
/// NotificationFor -  template to specialse Notification by adding an NotificationData class. 
/// Value class - just holds reference to the data, is expected to exist only for the synchronous life of the notification. 
/// If you want data to last longer, add a reference type and the observer will have to save it. 
/// </summary>
export class NotificationFor<EventData> extends Notification
{
   private _eventData: EventData | undefined;


   /**
    * Create an empty NotificationFor<NotificationData>  object - required for particiation in serialisation framework
    */
   constructor();

   /**
    * Create a NotificationFor<NotificationData> object
    * @param notification_ - object to copy from - should work for JSON format and for real constructed objects
    */
   public constructor(notification_: NotificationFor<EventData>);

   /**
    * Create a Notification object
    * @param interest_ - id of the notification 
    * @param eventData_ - the data payload to send with it
    */
   constructor(interest_: Interest, eventData_: EventData) 

   constructor(...arr: any[]) {
      if (arr.length === 0) { // Construct empty
         super();
         this._eventData = undefined;
         return;
      }
      else 
      if (arr.length === 1) { // Copy constructor
         super (arr[0])
         this._eventData = arr[0]._eventData;
      }
      else { // Individual arguments
         super (arr[0])
         this._eventData = arr[1];
      }
   }

   /**
   * set of 'getters' for private variables
   */
   get eventData(): EventData | undefined {
      return this._eventData;
   }

   /**
    * test for equality - checks all fields are the same. 
    * Is a shallow compare if the payload is an object
    * @param rhs_ - the object to compare this one to.  
    */
   equals(rhs_: NotificationFor<EventData>): boolean {

      return (super.equals(rhs_) &&
         (this._eventData === rhs_._eventData));
   }

   /**
    * assignment operator 
    * @param rhs_ - the object to assign this one from.  
    */
   assign(rhs_: NotificationFor<EventData>): NotificationFor<EventData> {
      super.assign(rhs_);
      this._eventData = rhs_._eventData;

      return this;
   }
}

/// <summary>
/// ObserverInterest -  an IObserver plus an Interest . Used by Notifieres to hold a list of things that observers are interested in so it can notify them. 
/// </summary>
export class ObserverInterest {

   private _observer: IObserver | undefined;
   private _interest: Interest;

   /**
    * Create a Interest object
    * @param observer_ - reference to the observer 
    * @param interest_ - the thing it is interested in 
    */
   constructor(observer_: IObserver, interest_: Interest);

   /**
    * Create a ObserverInterest object
    * @param observerInterest_ - object to copy from - should work for JSON format and for real constructed objects
    */
   public constructor(observerInterest_ : ObserverInterest);

   /**
    * Create an empty Interest object - required for particiation in serialisation framework
    */
   constructor();

   constructor(...arr: any[]) {
      if (arr.length === 0) { // Empty constructor
         this._observer = undefined;
         this._interest = Interest.createNullInterest();
         return;
      }
      if (arr.length === 1) { // Copy constructor
         this._observer = arr[0]._observer;
         this._interest = new Interest (arr[0]._interest);
      }
      else { // Indivual arguments
         this._observer = arr[0];
         this._interest = new Interest (arr[1]);
      }
   }

   /**
   * set of 'getters' for private variables
   */
   get observer(): IObserver | undefined {
      return this._observer;
   }
   get interest(): Interest {
      return this._interest;
   }

   /**
    * test for equality - checks all fields are the same. 
    * Shallow compare
    * @param rhs_ - the object to compare this one to.  
    */
   equals(rhs_: ObserverInterest): boolean {

      return ((this._observer === rhs_._observer) && 
         ( (this.interest === rhs_.interest) ||
           (rhs_.interest !== undefined) && (this._interest.equals(rhs_._interest))));
   }

   /**
    * assignment operator 
    * @param rhs_ - the object to assign this one from.  
    */
   assign(rhs_: ObserverInterest): ObserverInterest {
      this._observer = rhs_._observer;
      this._interest = new Interest(rhs_._interest);

      return this;
   }

}

/// <summary>
/// NotificationRouter -  template to act as an intermediary, type-safe router that connects a specific function signature for the method that is called in a notification
/// </summary>
/// 
export type FunctionForNotification = (interest: Interest, data: Notification) => void;

export class NotificationRouter implements IObserver {
   private _function: FunctionForNotification | undefined;

   /**
    * Create empty NotificationRouterFor object
    */
   constructor();

   /**
    * Create a NotificationRouter object
    * @param function_ - function to call on notification 
    */
   constructor(function_: FunctionForNotification);

   /**
    * Create a NotificationRouter  object
    * @param notificationRouter_ - object to copy from - should work for JSON format and for real constructed objects
    */
   public constructor(notificationRouter_: NotificationRouter);

   constructor(...arr: any[]) {
      if (arr.length === 0) { // Construct empty
         this._function = undefined;
         return;
      }
      else {
         if (this.isMyType(arr[0])) { // Copy constructor
            this._function = arr[0]._function;
         }
         else { // Individual arguments
            this._function = arr[0];
         }
      }
   }

   private isMyType(rhs_: FunctionForNotification): boolean {
      return rhs_.hasOwnProperty('_function');
   }

   /**
   * set of 'getters' for private variables
   */
   get function(): FunctionForNotification | undefined {
      return this._function;
   }

   /**
    * test for equality - checks all fields are the same. 
    * Shallow compare
    * @param rhs_ - the object to compare this one to.  
    */
   equals(rhs_: NotificationRouter): boolean {

      return (this._function === rhs_._function);
   }

   /**
    * assignment operator 
    * @param rhs_ - the object to assign this one from.  
    */
   assign(rhs_: NotificationRouter): NotificationRouter {
      this._function = rhs_._function;

      return this;
   }

   notify(interest_: Interest, notification_: Notification): void {

      // pass on to the required method
      if (this._function)
         this._function(interest_, notification_);
   }
}


/// <summary>
/// NotificationRouterFor -  template to act as an intermediary, type-safe router that connects a specific function signature for the method that is called in a notification
/// </summary>
/// 
type FunctionFor<NotificationData> = (interest: Interest, data: NotificationFor<NotificationData>) => void;

export class NotificationRouterFor<NotificationData> implements IObserver
{
   private _function: FunctionFor<NotificationData> | undefined;

   /**
    * Create empty NotificationRouterFor object
    */
   constructor();

   /**
    * Create a NotificationRouterFor object
    * @param function_ - function to call on notification 
    */
   constructor(function_: FunctionFor<NotificationData>);

   /**
    * Create a NotificationRouterFor<NotificationData>  object
    * @param observerRouter - object to copy from - should work for JSON format and for real constructed objects
    */
   public constructor(observerRouter: NotificationRouterFor<NotificationData>);

   constructor(...arr: any[]) {
      if (arr.length === 0) { // Construct empty
         this._function = undefined;
         return;
      }
      else {
         if (this.isMyType (arr[0])) { // Copy constructor
            this._function = arr[0]._function;
         }
         else { // Individual arguments
            this._function = arr[0];
         }
      }
   }

   private isMyType(rhs_: FunctionFor<NotificationData>): boolean {
      return rhs_.hasOwnProperty('_function');
   }

   /**
   * set of 'getters' for private variables
   */
   get function(): FunctionFor<NotificationData> | undefined {
      return this._function;
   }

   /**
    * test for equality - checks all fields are the same. 
    * Shallow compare
    * @param rhs_ - the object to compare this one to.  
    */
   equals(rhs_: NotificationRouterFor<NotificationData>): boolean {

      return (this._function === rhs_._function);
   }

   /**
    * assignment operator 
    * @param rhs_ - the object to assign this one from.  
    */
   assign(rhs_: NotificationRouterFor<NotificationData>): NotificationRouterFor<NotificationData> {
      this._function = rhs_._function;

      return this;
   }

   notify(interest_: Interest, notification_: NotificationFor<NotificationData>): void {

      // pass on to the required method
      if (this._function)
         this._function(interest_, notification_);
   }
}

export interface IObserver {
   notify(interest_: Interest, notification_: Notification): void;
}

export interface INotifier {
   addObserver(observerInterest_: ObserverInterest): void;
   removeObserver(observerInterest_: ObserverInterest): boolean;
   removeAllObservers(): void;
}

/// <summary>
/// Notifier -  class that sends notifications when things change
/// </summary>
export class Notifier implements INotifier {

   private _observerInterests : Array<ObserverInterest>;

   /**
    * Create an empty Notifier object - required for particiation in serialisation framework
    */
   constructor() {
      this._observerInterests = new Array<ObserverInterest>();
   }

   // Operations
   notifyObservers(interest_: Interest, notificationData_: Notification): void {

      //log.debug(tag.notification, "Notification:" + interest_.notificationId + ": " + JSON.stringify (notificationData_));

      for (var i = 0; i < this._observerInterests.length; i++) {

         let interest = this._observerInterests[i].interest;
         let observer = this._observerInterests[i].observer;

         if (interest) {
            if (interest.equals (interest_)) {
               if (observer)
                  observer.notify(interest, notificationData_);
            }
         }
       }
    }

   // Add the supplied observer to the list of observers associated with
   // the supplied interest. 
   addObserver(observerInterest_: ObserverInterest): void {

      const index = this._observerInterests.indexOf(observerInterest_);
      if (index === -1) {
         this._observerInterests.push(observerInterest_);
      }
   }

   // Remove the supplied observer from the list of observers associated
   // with the supplied interest.
   // returns TRUE if it was correctly found
   removeObserver(observerInterest_: ObserverInterest): boolean {

      const index = this._observerInterests.indexOf(observerInterest_);
      if (index > -1) {
         this._observerInterests.splice(index, 1);
         return true;
      }
      return false;
   }

   removeAllObservers(): void {
      this._observerInterests.length = 0
   }

};  //Notifier
****************************************

****************************************
Boxer\core\Persona.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Persona
 * @description Provides a class for managing personas in the Boxer application.
 * 
 * This module includes the Persona class which handles:
 * - Creating and managing persona objects with names, icons, and timestamps
 * - Supporting multiple constructor patterns for initialization
 * - Copying persona objects from JSON or constructed sources
 */

import { InvalidParameterError } from './Errors';
import { EIcon } from './Icons';
import { throwIfUndefined } from './Asserts'; 
import { getDefaultKeyGenerator } from './IKeyGeneratorFactory';
import { MDynamicStreamable, DynamicStreamableFactory } from "./StreamingFramework";

const keyGenerator = getDefaultKeyGenerator();

const unknownUuid: string = "88a77968-2525-4b83-b396-352ca83d1680";

const className = "Persona";

// atob works in a browser, implement a fallback if we are in node. 
function callAtob(data_: string, forceShim: boolean): string {

   if (!atob || forceShim) {
      const atob = (data: string) => { return Buffer.from(data, 'base64').toString('binary'); }
      return atob(data_);
   }
   return atob(data_);
}

// Persona - aggregates name, icon type, & timestamp of last time we saw them
// excludes email and other PII so can be passed to client even when describing an individual.
export class Persona extends MDynamicStreamable {
   private _id: string;
   private _name: string;
   private _email: string;
   private _icon: EIcon;
   private _thumbnailB64: string | undefined;
   private _lastSeenAt: Date;

   /**
    * Create an empty Persona object - required for particiation in serialisation framework
    */
   public constructor();

   /**
    * Create a Persona object
    * @param id_ - id to use to generate uniqueness 
    * @param name_ - plain text user name.
    * @param amail_ - email address (unique)
    * @param icon_ - icon to use, from the enum list
    * @param thumbNailB64_ - encoded thumbnail image, can be undefined
    * @param lastSeenAt_ - timestamp for last interaction seen by the framework
    */
   public constructor(id_: string | undefined, name_: string | undefined, email_: string | undefined, icon: EIcon, thumbNailB64_: string | undefined, lastSeenAt_: Date);

   /**
    * Create a Persona object
    * @param persona - object to copy from - should work for JSON format and for real constructed objects
    */
   public constructor(persona: Persona);

   public constructor(...arr: any[])
   {

      super();

      if (arr.length === 0) {
         this._id = keyGenerator.generateKey(); // An new Person has a key
         this._name = "";                       // But not a name or email address
         this._email = "";
         this._icon = EIcon.kUnknownPersona;
         this._thumbnailB64 = undefined;
         this._lastSeenAt = new Date();
         return;
      }

      var localId: string;
      var localName: string;
      var localEmail: string;      
      var localIcon: EIcon;
      var localThumbNailB64: string;
      var localLastSeenAt: Date;

      if (arr.length === 1) {
         localId = arr[0]._id
         localName = arr[0]._name;
         localEmail = arr[0]._email;         
         localIcon = arr[0]._icon;
         localThumbNailB64 = arr[0]._thumbnailB64;
         localLastSeenAt = new Date(arr[0]._lastSeenAt);
      }
      else { 
         localId = arr[0];
         localName = arr[1];
         localEmail = arr[2]
         localIcon = arr[3];         
         localThumbNailB64 = arr[4];
         localLastSeenAt = new Date (arr[5]);
      }

      if (!Persona.isValidId(localId)) {
         throw new InvalidParameterError("Id:" + localId + '.');
      }
      if (!Persona.isValidName(localName)) {
         throw new InvalidParameterError("Name:" + localName + '.');
      }
      if (!Persona.isValidEmail(localEmail)) {
         throw new InvalidParameterError("Email:" + localEmail + '.');
      }
      if (!Persona.isValidThumbnailB64(localThumbNailB64)) {
         throw new InvalidParameterError("Thumbnail:" + localThumbNailB64 + '.');
      }

      this._id = localId;
      this._name = localName;
      this._email = localEmail;
      this._icon = localIcon;
      this._thumbnailB64 = localThumbNailB64;
      this._lastSeenAt = localLastSeenAt;
   }

   /**
    * Dynamic creation for Streaming framework
    */
   dynamicClassName(): string {

      return className;
   }

   static createDynamicInstance(): MDynamicStreamable {
      return new Persona();
   }

   static _dynamicStreamableFactory: DynamicStreamableFactory = new DynamicStreamableFactory(className, Persona.createDynamicInstance);
   streamOut(): string {

      return JSON.stringify({ id: this._id, name: this._name, email: this._email, icon: this._icon, thumbnailB64: this._thumbnailB64, lastSeenAt: this._lastSeenAt });
   }

   streamIn(stream: string): void {

      const obj = JSON.parse(stream);

      let icon: EIcon = ((EIcon as any)[obj.icon]);

      // Backwards compatibility from when we use the case 'Bot' for the LLM
      if (icon === EIcon.kBotPersona) 
         icon = EIcon.kLLMPersona;

      if (icon === undefined)
         throw new InvalidParameterError("Icon:" + obj.icon + '.');

      let name = obj.name;
      let email = obj.email;

      // Backwards compatibility from when we used the email from LinkedIn in the name attribute
      if (name && ((! email) || (email.length === 0))) { 
         email = name;
         name = "";
      }

      this.assign(new Persona (obj.id, name, email, icon, obj.thumbnailB64, new Date(obj.lastSeenAt)));
   }

   /**
   * set of 'getters' for private variables
   */
   get id(): string {
      return this._id;
   }
   get name(): string {
      return this._name;
   }
   get email(): string {
      return this._email;
   }   
   get icon(): EIcon {
      return this._icon;
   }
   get thumbnailB64(): string | undefined {
      return this._thumbnailB64;
   }
   get lastSeenAt(): Date {
      return this._lastSeenAt;
   }
   get checkedThumbnailB64(): string {
      throwIfUndefined (this._thumbnailB64);        
      return this._thumbnailB64;
   }

   /**
   * set of 'setters' for private variables
   */
   set id(id_: string) {
      if (!Persona.isValidId(id_)) {
         throw new InvalidParameterError("Id:" + id_ + '.');
      }

      this._id = id_;
   }

   set name(name_: string) {
      if (!Persona.isValidName(name_)) {
         throw new InvalidParameterError("Name:" + name_ + '.');
      }

      this._name = name_;
   }

   set email(email_: string) {
      if (!Persona.isValidEmail(email_)) {
         throw new InvalidParameterError("Email:" + email_ + '.');
      }

      this._email = email_;
   }

   set icon (icon_: EIcon) {

      this._icon = icon_;
   }

   set thumbnailB64(thumbNailB64_: string) {

      this.setThumbnailB64(thumbNailB64_);
   }

   set lastSeenAt(lastSeenAt_: Date) {

      this._lastSeenAt = new Date(lastSeenAt_);
   }

   /**
    * test for equality - checks all fields are the same. 
    * Uses field values, not identity bcs if objects are streamed to/from JSON, field identities will be different. 
    * @param rhs - the object to compare this one to.  
    */
   equals(rhs: Persona): boolean {
      Persona
      return ((this._id === rhs._id) &&
         ((this._name === undefined && rhs._name == undefined) || (this._name === rhs._name)) &&
         ((this._email === undefined && rhs._email == undefined) || (this._email === rhs._email)) &&         
         (this._icon === rhs._icon) &&         
         ((this._thumbnailB64 === undefined && rhs._thumbnailB64 == undefined) || (this._thumbnailB64 === rhs._thumbnailB64)) &&
         (this.areSameDate (this._lastSeenAt, rhs._lastSeenAt)));
   }

   areSameDate (lhs: Date, rhs : Date) : boolean {
      if (lhs.getTime() === rhs.getTime()) {
         return true;
      }
      return false;
   }

   /**
    * assignment operator 
    * @param rhs - the object to assign this one from.  
    */
   assign(rhs: Persona): Persona {
      this._id = rhs._id;
      this._name = rhs._name;
      this._email = rhs._email;
      this._icon = rhs._icon;
      this._thumbnailB64 = rhs._thumbnailB64;
      this._lastSeenAt = new Date (rhs._lastSeenAt);

      return this;
   }

   /**
    * Set thumbnail with an option to force use of browser shim for B64 encoding 
    */
   setThumbnailB64(thumbNailB64_: string, forceShim_: boolean = false) : void {

      if (!Persona.isValidThumbnailB64(thumbNailB64_, forceShim_)) {
         throw new InvalidParameterError("Thumbnail:" + thumbNailB64_ + '.');
      }

      this._thumbnailB64 = thumbNailB64_;
   }

   /**
    * test for valid id 
    * @param id - the string to test
    */
   static isValidId(id_: string): boolean {
      if (!id_) // undefined keys are allowed if user object has not been originated from or saved anywhere persistent
         return true;

      if (id_ && id_.length > 0) // if the id exists, must be > zero length
         return true;

      return (false);
   }

   /**
    * test for valid name 
    * @param name - the string to test
    */
   static isValidName(name_: string): boolean {

      if (name_ == undefined)
         return false;

      return true; // Currently allow anything for a name, even empty string. 
   }

   /**
    * test for valid email 
    * @param email - the string to test
    */
      static isValidEmail(email_: string): boolean {

         if (email_ == undefined)
            return false;
   
         return true; // Currently allow anything for email, even empty string. 
      }
   /**
    * test for valid thumbnail string 
    * @param thumbnail - the string to test
    */
   static isValidThumbnailB64(thumbNailB64_: string, forceShim_: boolean = false): boolean {


      if (thumbNailB64_ == undefined) // Thumbnail can be undefined it its a predefined ICON
         return true;

      // else must be a valid encoded string
      if (thumbNailB64_.length > 0) { 

         var decoded : string;

         try {
            decoded = callAtob(thumbNailB64_, forceShim_);
         } catch (e) {
            return false;   
         }

         return true;
      }

      return (false);
   }

   private static _unknown: Persona = new Persona(unknownUuid, "Unknown", "", EIcon.kUnknownPersona, undefined, new Date(0));

   /**
    * return persona details for 'unknown'
    */
   static unknown(): Persona {
      return Persona._unknown;
   }


   /**
    * return unknown if the persona cannot be found in the map
    */
      static safeAuthorLookup (audience: Map<string, Persona>, authorId: string) : Persona {
   
      let initial = audience.get (authorId);
   
      if (initial)
         return initial;
      else
         return Persona.unknown()
   }

   /**
    * test if the persona details are the status 'unknown'
    * @param persona - the persona to test 
    */
   static isUnknown(persona: Persona): boolean {
      return (persona === Persona._unknown) ||
         (persona && persona.equals(Persona._unknown));
   }
}
****************************************

****************************************
Boxer\core\Queue.ts
****************************************
/*! Copyright Braid Technologies 2022 */
/**
 * @module Queue
 * @description Provides a generic queue data structure implementation for the Boxer application.
 * 
 * This module includes the Queue class which handles:
 * - Creating and managing FIFO (First-In-First-Out) queues
 * - Basic queue operations like enqueue, dequeue, isEmpty, and length
 * - Efficient memory management through offset-based dequeuing
 */


//==============================//
// Queue class
//==============================//

export class Queue<T> {

      // initialise the queue and offset
   queue: Array<T>;
   offset: number; 

   /**
    * Creates a Queue
    */
   constructor() {
      this.offset = 0
      this.queue = new Array<T>();
   }

   // Returns the length of the queue.
   getLength () : number {
      return (this.queue.length - this.offset);
   }

   // Returns true if the queue is empty, and false otherwise.
   isEmpty () : boolean {
      return (this.queue.length == 0);
   }

   /* Enqueues the specified item. The parameter is:
    *
    * item - the item to enqueue
    */
   enqueue (item: T) {
      this.queue.push(item);
   }

   /* Dequeues an item and returns it. If the queue is empty, the value
    * 'undefined' is returned.
    */
   dequeue (): T | undefined {

      // if the queue is empty, return immediately
      if (this.queue.length == 0) return undefined;

      // store the item at the front of the queue
      let item = this.queue[this.offset];

      // increment the offset and remove the free space if necessary
      if (++(this.offset) * 2 >= this.queue.length) {
         this.queue = this.queue.slice(this.offset);
         this.offset = 0;
      }

      // return the dequeued item
      return item;

   }

   /* Returns the item at the front of the queue (without dequeuing it). If the
    * queue is empty then undefined is returned.
    */
   peek(): T | undefined {
      return (this.queue.length > 0 ? this.queue[this.offset] : undefined);
   }
}
****************************************

****************************************
Boxer\core\SharedEmbedding.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module SharedEmbedding
 * @description Provides a class for managing shared embeddings in the Boxer application.
 * 
 * This module includes the SharedEmbedding class which handles:
 * - Creating and managing shared embedding objects with URLs, conversation IDs, and like counts
 * - Supporting multiple constructor patterns for initialization
 * - Copying shared embedding objects from JSON or constructed sources
 */

import { InvalidParameterError } from './Errors';
import { throwIfUndefined } from './Asserts'; 
import { IKeyGenerator } from './IKeyGenerator';
import { getDefaultKeyGenerator } from './IKeyGeneratorFactory';
import { MDynamicStreamable, DynamicStreamableFactory } from "./StreamingFramework";
import { areSameShallowArray } from './Utilities';
import { Like } from './Like';

var keyGenerator: IKeyGenerator = getDefaultKeyGenerator();

const className = "SharedEmbedding";

// SharedEmbedding - URL, conversation, net like count, emails of who has liked it, emails of who has disliked it. 
export class SharedEmbedding extends MDynamicStreamable {
   private _id: string; 
   private _url: string | undefined;
   private _conversationId: string | undefined;
   private _likes: Array<Like>;

   /**
    * Create an empty Message object - required for particiation in serialisation framework
    */
   public constructor();

   /**
    * Create a SharedEmbedding object
    * @param id_ - id to use to generate uniqueness 
    * @param url_ - URL
    * @param conversationId_ - in which conversation id the 'like' happen
    * @param likes_ - array of names of people that have liked it. 
    */
   public constructor(id_: string | undefined, url_: string | undefined, conversationId_: string | undefined,  
                      likes_: Array<Like> | undefined);

   /**
    * Create a SharedEmbedding object
    * @param sharedEmbedding_ - object to copy from - should work for JSON format and for real constructed objects
    */
   public constructor(sharedEmbedding_: SharedEmbedding);

   public constructor(...arr: any[])
   {
      super();

      var localId: string = "";
      var localUrl: string | undefined = undefined;
      var localConversationId : string | undefined = undefined;
      var localLikes: Array<Like> = new Array<Like> ();        

      if (arr.length === 0) {

         localId = keyGenerator.generateKey(); // A new SharedEmbedding has a key                                     
      }
      else 
      if (arr.length === 1) {

         localId = arr[0]._id
         localUrl = arr[0]._url;
         localConversationId = arr[0]._conversationId;         
         localLikes = arr[0]._likes.slice(0);         
      }
      else if (arr.length === 4) {
         localId = arr[0];
         localUrl = arr[1]; 
         localConversationId = arr[2];     
         if (arr[3])      
            localLikes = arr[3].slice(0);     
      }

      if (!SharedEmbedding.isValidId(localId)) {
         throw new InvalidParameterError("Id:" + localId + '.');
      }

      this._id = localId;    
      this._url = localUrl;
      this._conversationId = localConversationId;
      this._likes = localLikes;           
   }

   /**
    * Dynamic creation for Streaming framework
    */
   dynamicClassName(): string {

      return className;
   }

   static createDynamicInstance(): MDynamicStreamable {
      return new SharedEmbedding();
   }

   static _dynamicStreamableFactory: DynamicStreamableFactory = new DynamicStreamableFactory(className, SharedEmbedding.createDynamicInstance);

   streamOut(): string {

      return JSON.stringify({ id: this._id, url: this._url, conversationId: this._conversationId,
                            likes: this._likes});
   }

   streamIn(stream: string): void {

      const obj = JSON.parse(stream);

      let likes = new Array<Like> (); 

      let objLikes = obj.likes;

      if (objLikes) {
         for (let i = 0; i < objLikes.length; i++) {
            likes.push (new Like (objLikes[i]));
         }      
      }     


      this.assign(new SharedEmbedding (obj.id, obj.url, obj.conversationId, likes));
   }

   /**
   * set of 'getters' for private variables
   */
   get id(): string {
      return this._id;
   }
   get url(): string | undefined {
      return this._url;
   }
   get conversationId(): string | undefined {
      return this._conversationId;
   }   
   get netLikeCount(): number {
      return this._likes.length;
   }
   get likes(): Array<Like> {
      return this._likes;
   }     

   /**
   * set of 'setters' for private variables
   */
   set id(id_: string) {
      if (!SharedEmbedding.isValidId(id_)) {
         throw new InvalidParameterError("Id:" + id_ + '.');
      }

      this._id = id_;
   }

   set url(url_: string | undefined) {

      this._url = url_;
   }

   set conversationId(conversationId_: string | undefined) {

      this._conversationId = conversationId_;
   }   

   set likes (likedBy_: Array<Like>) {
      this._likes = likedBy_.slice(0);     
   }


   /**
    * add a like 
    * @param name - the name of the person who has liked it.  
    */
   like(name: string): void {

      throwIfUndefined (this._url);

      let foundLike = false;
      let likeIndex = -1;

      for (let i = 0; i < this._likes.length && !foundLike; i++) {

         if (this._likes[i].name === name) {
            foundLike = true;
            likeIndex = i;
         }
      }   

      if (foundLike)
         return;
      
      this._likes.push (new Like (name, new Date()))  
   }

   /**
    * remove a like 
    * @param name - the name of the person who has a like.  
    */
   unlike(name: string): void {

      throwIfUndefined (this._url);

      let foundLike = false;
      let likeIndex = -1;

      for (let i = 0; i < this._likes.length && !foundLike; i++) {

         if (this._likes[i].name === name) {
            foundLike = true;
            likeIndex = i;
         }
      }
      
      if (foundLike)
         this._likes.splice(likeIndex, 1);      
   }   

   /*
    * test for a like 
    * @param name - the name of the person who has liked it.  
    */
   isLikedBy (name: string): boolean {

      throwIfUndefined (this._url);

      let foundLike = false;

      for (let i = 0; i < this._likes.length && !foundLike; i++) {

         if (this._likes[i].name === name) {
            foundLike = true;
         }
      }   

      return foundLike;
   }

   /**
    * test for equality - checks all fields are the same. 
    * Uses field values, not identity bcs if objects are streamed to/from JSON, field identities will be different. 
    * @param rhs - the object to compare this one to.  
    */
   equals(rhs: SharedEmbedding): boolean {

      return ((this._id === rhs._id) &&
         ((this._url === undefined && rhs._url === undefined) || (this._url === rhs._url)) &&    
         ((this._conversationId === undefined && rhs._conversationId === undefined) || (this._conversationId === rhs._conversationId)) &&                        
         areSameShallowArray (this._likes, rhs._likes));
   }

   /**
    * assignment operator 
    * @param rhs - the object to assign this one from.  
    */
   assign(rhs: SharedEmbedding): SharedEmbedding {

      this._id = rhs._id;   
      this._url = rhs._url;
      this._conversationId = rhs._conversationId;
      this._likes = rhs._likes.slice(0);      

      return this;
   }

   /**
    * test for valid id 
    * @param id - the string to test
    */
   static isValidId(id_: string): boolean {
      if (!id_) // undefined keys are allowed if user object has not been originated from or saved anywhere persistent
         return true;

      if (id_ && id_.length > 0) // if the id exists, must be > zero length
         return true;

      return (false);
   }
}

export function findInMap (url: string, map: Map<string, SharedEmbedding>) : SharedEmbedding | undefined {

   for (const [key, value] of map) {
      if (value.url === url)
         return value;
   }
   return undefined;
}
****************************************

****************************************
Boxer\core\StreamingFramework.ts
****************************************
/////////////////////////////////////////
// StreamingFramework
// Copyright (c) 2024 Braid Technologies Ltd
/////////////////////////////////////////

/**
 * @module StreamingFramework
 * @description Provides a framework for streaming data to and from JSON in the Boxer application.
 * 
 * This module includes the MStreamable and MDynamicStreamable classes which handle:
 * - Creating and managing streaming objects with dynamic class names
 * - Streaming data to and from JSON
 * - Managing dynamic streamable objects based on class names stored in the stream
 */

/// <summary>
/// MStreamable - root class for all derived types that can stream to and from JSON 
/// </summary>
export abstract class MStreamable {

   constructor() {
   }

   abstract streamOut(): string;
   abstract streamIn(stream: string): void;
}

/// <summary>
/// MDynamicStreamable - root class for all derived types that can stream to and from JSON with dynamic creation based on className stored in the stream
/// </summary>
export abstract class MDynamicStreamable extends MStreamable {

   constructor() {
      super();
   }

   abstract dynamicClassName(): string;

   flatten (): string {

      return JSON.stringify({ className: this.dynamicClassName(), data: this.streamOut() });
   }

   static resurrect(stream: string): MDynamicStreamable | undefined {

      const parsed = JSON.parse(stream);

      let obj = DynamicStreamableFactory.create(parsed.className);

      if (obj)
         obj.streamIn(parsed.data);

      return obj;
   }
}

// Signature for the factory function 
type FactoryFunctionFor<MDynamicStreamable> = () => MDynamicStreamable;

var firstDynamicStreamableFactory: DynamicStreamableFactory | undefined = undefined;

export class DynamicStreamableFactory {

   _className: string;
   _factoryMethod: FactoryFunctionFor<MDynamicStreamable>;
   _nextFactory: DynamicStreamableFactory | undefined;

   constructor(className_: string, factoryMethod_: FactoryFunctionFor<MDynamicStreamable>) {
      this._className = className_;
      this._factoryMethod = factoryMethod_;
      this._nextFactory = undefined;

      if (firstDynamicStreamableFactory === undefined) {
         firstDynamicStreamableFactory = this;
      } else {
         var nextFactory: DynamicStreamableFactory = firstDynamicStreamableFactory;

         while (nextFactory._nextFactory) {
            nextFactory = nextFactory._nextFactory;
         }
         nextFactory._nextFactory = this;
      }
   }

   static create(className: string): MDynamicStreamable | undefined {
      var nextFactory: DynamicStreamableFactory | undefined = firstDynamicStreamableFactory;

      while (nextFactory) {
         if (nextFactory._className === className) {
            return nextFactory._factoryMethod();
         }
         nextFactory = nextFactory._nextFactory;
      }
      return undefined;
   }
}
****************************************

****************************************
Boxer\core\Utilities.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module Utilities
 * @description Provides utility functions for the Boxer application.
 * 
 * This module includes the areSameDate, areSameShallowArray, and areSameDeepArray functions which handle:
 * - Comparing dates
 * - Comparing shallow arrays
 * - Comparing deep arrays
 */

import { throwIfUndefined } from './Asserts';

export function areSameDate (lhs: Date | undefined, rhs : Date | undefined) : boolean {

   if (typeof lhs === 'undefined' && typeof rhs === 'undefined') {
      return true;
   }
   if (typeof lhs === 'undefined' && typeof rhs !== 'undefined') {
      return false;
   } 
   if (typeof lhs !== 'undefined' && typeof rhs === 'undefined') {
      return false;
   }        
   throwIfUndefined (lhs);
   throwIfUndefined (rhs);
   if (lhs.getTime() === rhs.getTime()) {
      return true;
   }
   return false;
}

export function areSameShallowArray<T> (lhs: Array<T>, rhs : Array<T>) : boolean {

   if (lhs.length !== rhs.length) {
      return false;
   }        

   for (let i = 0; i < lhs.length; i++) {
      if (lhs[i] !== rhs[i])
         return false;
   }

   return true;
}

export function areSameDeepArray<T> (lhs: Array<T>, rhs : Array<T>) : boolean {

   if (lhs.length !== rhs.length) {
      return false;
   }        

   for (let i = 0; i < lhs.length; i++) {
      if (! (JSON.stringify (lhs[i]) === JSON.stringify (rhs[i])))
         return false;
   }

   return true;
}
****************************************

****************************************
Boxer\core\UuidKeyGenerator.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
/**
 * @module UuidKeyGenerator
 * @description Provides a class for generating UUIDs and secrets in the Boxer application.
 * 
 * This module includes the UuidKeyGenerator class which handles:
 * - Generating UUIDs
 * - Generating secrets
 * - Checking if a key could be a valid key
 * - Saving and matching secrets
 * - Managing saved secrets
 */
import { throwIfNull } from './Asserts';
import { EnvironmentError } from './Errors';
import { IKeyGenerator } from './IKeyGenerator';

let mockStoredSecret = "";

function NumberToUint32Array(f: number) :  Uint32Array {
   
   const buf = new ArrayBuffer(8);
   const floatView = new Float64Array(buf);
   const uintView = new Uint32Array(buf);

   floatView[0] = f;
   const randomValues = new Uint32Array(2);
   randomValues[0] = uintView[0];
   randomValues[1] = uintView[1];

   return randomValues;
}

export class UuidKeyGenerator implements IKeyGenerator {

   generateKey (): string {
      return uuid();
   }

   // Function to generate a random state value
   generateSecret(): string {
      
      // Upper and lower bounds
      const min = 1;
      const max = 100;

      // Generate random number within bounds
      let randomValues = new Uint32Array(2);
      if (typeof window === "undefined") {
         randomValues = NumberToUint32Array (Math.random ());         
      }
      else {
         window.crypto.getRandomValues(randomValues);         
      }

      const secureRandom = min + (randomValues[0] % (max - min + 1));   
      const secureRandomArray = new Array<number>();
      secureRandomArray.push (secureRandom);

      // Encode as UTF-8
      const utf8Encoder = new TextEncoder();
      const utf8Array = utf8Encoder.encode(
        String.fromCharCode.apply(null, secureRandomArray)
      );

      let utf8NumberArray = Array.from(utf8Array);

      // Base64 encode the UTF-8 data     
      return btoa(String.fromCharCode.apply(null, utf8NumberArray)
        .replace(/\+/g, '-')
        .replace(/\//g, '_')
        .replace(/=+$/, ''));
   }      

   couldBeAKey(key: string): boolean {
      return looksLikeUuid (key);
   }

   saveSecret(secret: string): void {

      if (typeof localStorage === 'undefined') {
         mockStoredSecret = secret;
      }
      else {
         localStorage.setItem('secret', secret);
      }
   }

   matchesSavedSecret (secret: string): boolean {

      var stored;

      if (typeof localStorage === 'undefined') {
         stored = mockStoredSecret;
      }
      else {      
         stored = localStorage.getItem('secret');
      }

      return (stored === secret);
   }

   haveSavedSecret  () : boolean {
      var stored;

      if (typeof localStorage === 'undefined') {
         stored = mockStoredSecret;
      }
      else {      
         stored = localStorage.getItem('secret');
      }

      return stored !== null;
   }

   savedSecret  () : string {
      var stored : string;

      if (typeof localStorage === 'undefined') {
         stored = mockStoredSecret;
      }
      else {      
         let fromStorage = localStorage.getItem('secret');
         throwIfNull (fromStorage);
         stored = fromStorage;
      }

      return stored;
   } 

}

function generateUUID() { // Public Domain/MIT

    var d = new Date().getTime();//Timestamp
    var d2 = ((typeof performance !== 'undefined') && performance.now && (performance.now()*1000)) || 0;//Time in microseconds since page-load or 0 if unsupported
    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
        var r = Math.random() * 16;//random number between 0 and 16
        if(d > 0){//Use timestamp until depleted
            r = (d + r)%16 | 0;
            d = Math.floor(d/16);
        } else {//Use microseconds since page-load if supported
            r = (d2 + r)%16 | 0;
            d2 = Math.floor(d2/16);
        }
        return (c === 'x' ? r : (r & 0x3 | 0x8)).toString(16);
    });
}

function uuid(): string {

   var newUuid: string = "";
   
   // Check if Blob is supported in Browser as it is not supported in some Safari versions
   if (typeof Blob !== "undefined") {

      let url = URL.createObjectURL(new Blob());
      URL.revokeObjectURL(url);

      if (typeof window === 'undefined') {
         newUuid = url.split(":")[2];
      }
      else {
         switch (window.location.protocol) {
            case 'file:':
               newUuid = url.split("/")[1];
               break;
            case 'http:':
            case 'https:':
            default:
               newUuid = url.split("/")[3];
               break;
         }
      }
   }
   else {

      newUuid = generateUUID();
   }
   
   if (newUuid.length == 0)
      throw new EnvironmentError("Error creating UUID.");

   return newUuid;
}

export function looksLikeUuid(uuid: string): boolean {

   let split = uuid.split('-');

   if ((uuid.length == 36) && (split.length == 5)) {
      return true;
   }

   return false;
}
****************************************

****************************************
Boxer\coverage\base.css
****************************************
body, html {
  margin:0; padding: 0;
  height: 100%;
}
body {
    font-family: Helvetica Neue, Helvetica, Arial;
    font-size: 14px;
    color:#333;
}
.small { font-size: 12px; }
*, *:after, *:before {
  -webkit-box-sizing:border-box;
     -moz-box-sizing:border-box;
          box-sizing:border-box;
  }
h1 { font-size: 20px; margin: 0;}
h2 { font-size: 14px; }
pre {
    font: 12px/1.4 Consolas, "Liberation Mono", Menlo, Courier, monospace;
    margin: 0;
    padding: 0;
    -moz-tab-size: 2;
    -o-tab-size:  2;
    tab-size: 2;
}
a { color:#0074D9; text-decoration:none; }
a:hover { text-decoration:underline; }
.strong { font-weight: bold; }
.space-top1 { padding: 10px 0 0 0; }
.pad2y { padding: 20px 0; }
.pad1y { padding: 10px 0; }
.pad2x { padding: 0 20px; }
.pad2 { padding: 20px; }
.pad1 { padding: 10px; }
.space-left2 { padding-left:55px; }
.space-right2 { padding-right:20px; }
.center { text-align:center; }
.clearfix { display:block; }
.clearfix:after {
  content:'';
  display:block;
  height:0;
  clear:both;
  visibility:hidden;
  }
.fl { float: left; }
@media only screen and (max-width:640px) {
  .col3 { width:100%; max-width:100%; }
  .hide-mobile { display:none!important; }
}

.quiet {
  color: #7f7f7f;
  color: rgba(0,0,0,0.5);
}
.quiet a { opacity: 0.7; }

.fraction {
  font-family: Consolas, 'Liberation Mono', Menlo, Courier, monospace;
  font-size: 10px;
  color: #555;
  background: #E8E8E8;
  padding: 4px 5px;
  border-radius: 3px;
  vertical-align: middle;
}

div.path a:link, div.path a:visited { color: #333; }
table.coverage {
  border-collapse: collapse;
  margin: 10px 0 0 0;
  padding: 0;
}

table.coverage td {
  margin: 0;
  padding: 0;
  vertical-align: top;
}
table.coverage td.line-count {
    text-align: right;
    padding: 0 5px 0 20px;
}
table.coverage td.line-coverage {
    text-align: right;
    padding-right: 10px;
    min-width:20px;
}

table.coverage td span.cline-any {
    display: inline-block;
    padding: 0 5px;
    width: 100%;
}
.missing-if-branch {
    display: inline-block;
    margin-right: 5px;
    border-radius: 3px;
    position: relative;
    padding: 0 4px;
    background: #333;
    color: yellow;
}

.skip-if-branch {
    display: none;
    margin-right: 10px;
    position: relative;
    padding: 0 4px;
    background: #ccc;
    color: white;
}
.missing-if-branch .typ, .skip-if-branch .typ {
    color: inherit !important;
}
.coverage-summary {
  border-collapse: collapse;
  width: 100%;
}
.coverage-summary tr { border-bottom: 1px solid #bbb; }
.keyline-all { border: 1px solid #ddd; }
.coverage-summary td, .coverage-summary th { padding: 10px; }
.coverage-summary tbody { border: 1px solid #bbb; }
.coverage-summary td { border-right: 1px solid #bbb; }
.coverage-summary td:last-child { border-right: none; }
.coverage-summary th {
  text-align: left;
  font-weight: normal;
  white-space: nowrap;
}
.coverage-summary th.file { border-right: none !important; }
.coverage-summary th.pct { }
.coverage-summary th.pic,
.coverage-summary th.abs,
.coverage-summary td.pct,
.coverage-summary td.abs { text-align: right; }
.coverage-summary td.file { white-space: nowrap;  }
.coverage-summary td.pic { min-width: 120px !important;  }
.coverage-summary tfoot td { }

.coverage-summary .sorter {
    height: 10px;
    width: 7px;
    display: inline-block;
    margin-left: 0.5em;
    background: url(sort-arrow-sprite.png) no-repeat scroll 0 0 transparent;
}
.coverage-summary .sorted .sorter {
    background-position: 0 -20px;
}
.coverage-summary .sorted-desc .sorter {
    background-position: 0 -10px;
}
.status-line {  height: 10px; }
/* yellow */
.cbranch-no { background: yellow !important; color: #111; }
/* dark red */
.red.solid, .status-line.low, .low .cover-fill { background:#C21F39 }
.low .chart { border:1px solid #C21F39 }
.highlighted,
.highlighted .cstat-no, .highlighted .fstat-no, .highlighted .cbranch-no{
  background: #C21F39 !important;
}
/* medium red */
.cstat-no, .fstat-no, .cbranch-no, .cbranch-no { background:#F6C6CE }
/* light red */
.low, .cline-no { background:#FCE1E5 }
/* light green */
.high, .cline-yes { background:rgb(230,245,208) }
/* medium green */
.cstat-yes { background:rgb(161,215,106) }
/* dark green */
.status-line.high, .high .cover-fill { background:rgb(77,146,33) }
.high .chart { border:1px solid rgb(77,146,33) }
/* dark yellow (gold) */
.status-line.medium, .medium .cover-fill { background: #f9cd0b; }
.medium .chart { border:1px solid #f9cd0b; }
/* light yellow */
.medium { background: #fff4c2; }

.cstat-skip { background: #ddd; color: #111; }
.fstat-skip { background: #ddd; color: #111 !important; }
.cbranch-skip { background: #ddd !important; color: #111; }

span.cline-neutral { background: #eaeaea; }

.coverage-summary td.empty {
    opacity: .5;
    padding-top: 4px;
    padding-bottom: 4px;
    line-height: 1;
    color: #888;
}

.cover-fill, .cover-empty {
  display:inline-block;
  height: 12px;
}
.chart {
  line-height: 0;
}
.cover-empty {
    background: white;
}
.cover-full {
    border-right: none !important;
}
pre.prettyprint {
    border: none !important;
    padding: 0 !important;
    margin: 0 !important;
}
.com { color: #999 !important; }
.ignore-none { color: #999; font-weight: normal; }

.wrapper {
  min-height: 100%;
  height: auto !important;
  height: 100%;
  margin: 0 auto -48px;
}
.footer, .push {
  height: 48px;
}
****************************************

****************************************
Boxer\coverage\prettify.css
****************************************
.pln{color:#000}@media screen{.str{color:#080}.kwd{color:#008}.com{color:#800}.typ{color:#606}.lit{color:#066}.pun,.opn,.clo{color:#660}.tag{color:#008}.atn{color:#606}.atv{color:#080}.dec,.var{color:#606}.fun{color:red}}@media print,projection{.str{color:#060}.kwd{color:#006;font-weight:bold}.com{color:#600;font-style:italic}.typ{color:#404;font-weight:bold}.lit{color:#044}.pun,.opn,.clo{color:#440}.tag{color:#006;font-weight:bold}.atn{color:#404}.atv{color:#060}}pre.prettyprint{padding:2px;border:1px solid #888}ol.linenums{margin-top:0;margin-bottom:0}li.L0,li.L1,li.L2,li.L3,li.L5,li.L6,li.L7,li.L8{list-style-type:none}li.L1,li.L3,li.L5,li.L7,li.L9{background:#eee}
****************************************

****************************************
Boxer\scripts\eval_pipeline.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Importing Local Modules
from common.ApiConfiguration import ApiConfiguration
from test.test_utility import run_tests

import os

TEST_DESTINATION_DIR = os.path.join("data", "test")
CHUNK_SOURCE_DIR = "data"

config = ApiConfiguration()

off_topic_questions = [
"What is the capital of France?",
"Who wrote 'To Kill a Mockingbird'?",
"What is the largest planet in our solar system?",
"How many continents are there on Earth?",
"What is the chemical symbol for gold?",
"Who painted the Mona Lisa?",
"What year did the Titanic sink?",
"What is the main ingredient in guacamole?",
"How many bones are in the adult human body?",
"What is the hardest natural substance on Earth?",
"Who was the first person to walk on the moon?",
"What is the currency of Japan?",
"Which element has the atomic number 1?",
"What is the longest river in the world?",
"Who directed the movie Jurassic Park?",
"What is the name of the largest ocean on Earth?",
"In what year did World War II end?",
"What is the square root of 64?",
"Who is known as the 'Father of Computers'?",
"What is the fastest land animal?",
"What is the main language spoken in Brazil?",
"Who discovered penicillin?",
"What is the smallest country in the world by area?",
"What sport is known as 'the beautiful game'?",
"How many states are there in the United States?"];

questions = [
"What is a Large Language Model (LLM)?",
"How do Large Language Models (LLMs) work?",
"What are some common use cases for Large Language Models (LLMs) in applications?",
"How are Large Language Models (LLMs) different from traditional AI models?",
"What are the key components of a Large Language Model (LLM)?",
"How do Large Language Models (LLMs) process and generate text?",
"What is natural language processing (NLP)?",
"How does NLP relate to Large Language Models (LLMs)?",
"What is the difference between supervised, unsupervised, and reinforcement learning?",
"How are Large Language Models (LLMs) trained?",

"What factors should I consider when choosing a Large Language Model (LLM) for my application?",
"How do I determine the size of the model I need?"
"What are the trade-offs between smaller and larger models?",
"How do I evaluate the performance of different Large Language Models (LLMs)?",
"What are the most popular Large Language Models (LLMs) available today (eg GPT-4, BERT, T5)?",
"How does OpenAI's GPT-4 compare to other models like Google's BERT?",
"What is transfer learning and how does it apply to Large Language Models (LLMs)?",
"Can I use pre-trained models or do I need to train my own from scratch?",

"How do I integrate a Large Language Model (LLM) into my Python application?",
"What libraries or frameworks are available for working with Large Language Models (LLMs) in Python?",
"How do I use Hugging Face's Transformers library?",
"What is the process for deploying a Large Language Model (LLM)-based application?",
"How do I handle API rate limits when using a hosted Large Language Model (LLM) service?",
"How can I optimize the response time of a Large Language Model (LLM) in my application?",
"What are the best practices for managing API keys and authentication?",

"How can Large Language Models (LLMs) be used for chatbots?",
"What are the steps to create a question-answering system with a Large Language Model (LLM)?",
"How can I use a Large Language Model (LLM) to summarize text?",
"What are the methods for implementing sentiment analysis using Large Language Models (LLMs)?",
"How can Large Language Models (LLMs) be used for content generation, such as blog posts or articles?",
"What are the considerations for using Large Language Models (LLMs) in voice assistants?",
"How can Large Language Models (LLMs) assist in language translation applications?",
"What is the role of Large Language Models (LLMs) in automated code generation?",
"How can Large Language Models (LLMs) be used for data extraction from unstructured text?",

"How do I fine-tune a pre-trained Large Language Model (LLM) on my own dataset?",
"What datasets are commonly used for training Large Language Models (LLMs)?",
"How much data do I need to train or fine-tune a Large Language Model (LLM) effectively?",
"What are the computational requirements for training a Large Language Model (LLM)?",
"How do I handle bias in training data?",
"What techniques can I use to improve the accuracy of my Large Language Model (LLM)?",

"What are the ethical considerations when using Large Language Models (LLMs) in applications?",
"How can I ensure that my Large Language Model (LLM) is not producing biased or harmful content?",
"What are the privacy concerns when using Large Language Models (LLMs)?",
"How do I manage user data responsibly in a Large Language Model (LLM)-based application?",
"What are the legal implications of using Large Language Models (LLMs) in different industries?",

"How can I optimize the performance of a Large Language Model (LLM) in production?",
"What are some common performance bottlenecks when using Large Language Models (LLMs)?",
"How can I reduce the latency of Large Language Model (LLM) responses?",
"What caching strategies can I use to improve Large Language Model (LLM) response times?",
"How do I monitor and maintain a Large Language Model (LLM)-based application in production?",

"How do I estimate the cost of using a Large Language Model (LLM) in my application?",
"What are the cost considerations when choosing between different Large Language Model (LLM) providers?",
"How can I minimize the cost of API usage for Large Language Models (LLMs)?",
"What are the pricing models for popular Large Language Model (LLM) services like OpenAI's GPT?",

"How do I scale a Large Language Model (LLM)-based application to handle increased traffic?",
"What are the best practices for scaling Large Language Model (LLM) infrastructure?",
"How can I use load balancing with Large Language Models (LLMs)?",
"What cloud services are recommended for hosting Large Language Model (LLM)-based applications?",

"What security measures should I implement when using Large Language Models (LLMs)?",
"How do I protect my Large Language Model (LLM) from adversarial attacks?",
"How can I ensure secure communication between my application and the Large Language Model (LLM) API?",
"What are the risks of using Large Language Models (LLMs) and how can I mitigate them?",

"How can I customize the behavior of a Large Language Model (LLM) to better fit my application?",
"What are prompt engineering techniques and how do they work?",
"How can I use Large Language Models (LLMs) for specific domain applications, like medical or legal?",
"How do I implement contextual understanding in my Large Language Model (LLM)-based application?",
"What are the techniques for chaining Large Language Model (LLM) responses for complex tasks?",

"How do I debug issues with Large Language Model (LLM)-generated content?",
"What are the common issues faced when integrating Large Language Models (LLMs)?",
"How can I track and fix inaccuracies in Large Language Model (LLM) responses?",

"What are the latest advancements in Large Language Model (LLM) technology?",
"How do emerging models like GPT-4.5 or GPT-5 compare to GPT-4?",
"What future applications and improvements are expected for Large Language Models (LLMs)?",
"How is the field of Large Language Models (LLMs) expected to evolve over the next 5 years?",

"What online communities and forums are best for learning about Large Language Models (LLMs)?",
"What are the best courses or tutorials for learning to use Large Language Models (LLMs)?",
"How can I contribute to the development of open-source Large Language Model (LLM) projects?",

"How are Large Language Models (LLMs) used in the healthcare industry?",
"What are the applications of Large Language Models (LLMs) in finance?",
"How can Large Language Models (LLMs) benefit the education sector?",
"What are the uses of Large Language Models (LLMs) in customer service?",
"How do Large Language Models (LLMs) apply to the entertainment and media industry?",

"What are some successful case studies of Large Language Model (LLM) integration?",
"How have other developers solved common problems with Large Language Models (LLMs)?",

"What metrics should I use to evaluate the performance of my Large Language Model (LLM)?",
"How do I measure the quality of the generated text?",
"What are the methods to evaluate the relevance of Large Language Model (LLM) responses?",

"How often should I update or retrain my Large Language Model (LLM)?",
"What are the signs that my Large Language Model (LLM) needs retraining?",
"How do I manage version control for my Large Language Model (LLM) models?",

"What are the best tools for annotating and preparing training data?",
"How do I use TensorFlow or PyTorch with Large Language Models (LLMs)?",
"What is the role of the Hugging Face Model Hub in working with Large Language Models (LLMs)?",
"How can I use Docker to deploy Large Language Model (LLM)-based applications?",

"What are the GDPR implications of using Large Language Models (LLMs)?",
"How can I ensure my use of Large Language Models (LLMs) complies with industry regulations?",
"What are the copyright considerations for content generated by Large Language Models (LLMs)?",

"How can I personalize Large Language Model (LLM) interactions for individual users?",
"What strategies can I use to make Large Language Model (LLM) responses more engaging?",
"How do I gather and use user feedback to improve my Large Language Model (LLM)-based application?"]

tech_questions = [
"What are some common use cases for generative AI?",
"How can Python be used to interact with an LLM?",
"What is the purpose of tokenization in LLMs?",
"Explain the difference between static and dynamic tokenization.",
"How do you handle out-of-vocabulary words in tokenization?",
"What are embeddings in the context of NLP?",
"How do you load a pre-trained LLM in Python using Hugging Face Transformers?",
"Describe the process of fine-tuning an LLM.",
"What are the benefits of fine-tuning a pre-trained model?",
"How can you generate text using GPT-3 in Python?",
"What is the role of the `generate` function in text generation?",
"How do you control the length of generated text in an LLM?",
"Explain the concept of 'temperature' in text generation.",
"What is top-k sampling in the context of LLMs?",
"How does nucleus sampling (top-p) work in text generation?",
"Describe beam search as a decoding strategy.",
"What are the trade-offs between beam search and greedy decoding?",
"How can you evaluate the quality of generated text?",
"What are common metrics for evaluating generative models?",
"How do you prevent an LLM from generating inappropriate content?",
"What is the purpose of prompt engineering?",
"How can you improve the coherence of generated text?",
"What is zero-shot learning in LLMs?",
"How does few-shot learning differ from zero-shot learning?",
"Describe the role of context in text generation.",
"How do you manage large-scale LLMs in a production environment?",
"What are the computational challenges of training an LLM?",
"Explain the concept of model parallelism.",
"How can you reduce the inference time of an LLM?",
"What is model distillation in the context of LLMs?",
"Describe how to use the `transformers` library to implement a chatbot.",
"What is the role of an API in interacting with an LLM?",
"How do you secure an API endpoint for an LLM?",
"What ethical considerations should be taken when using generative AI?",
"How can you detect and mitigate biases in LLMs?",
"What is the impact of training data on the performance of an LLM?",
"How do you perform hyperparameter tuning for an LLM?",
"Explain the role of learning rate schedules in training LLMs.",
"How can you use Python to preprocess text data for LLM training?",
"What are some techniques for data augmentation in NLP?",
"How do you implement a feedback loop for improving an LLM?",
"Describe a real-world application of generative AI.",
"What is the significance of multilingual capabilities in LLMs?",
"How can transfer learning benefit the deployment of LLMs in different domains?"
]

if not os.path.exists(TEST_DESTINATION_DIR):
    os.makedirs(TEST_DESTINATION_DIR)

run_tests (config, TEST_DESTINATION_DIR, CHUNK_SOURCE_DIR, off_topic_questions)
****************************************

****************************************
Boxer\scripts\github_pipeline.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd
import os

# Local Modules
from common.ApiConfiguration import ApiConfiguration
from common.Urls import gitHubUrls, countUrlHits
from common.common_functions import ensure_directory_exists
from github.download_markdown import download_markdown
from text.enrich_text_chunks import enrich_text_chunks
from text.enrich_text_summaries import enrich_text_summaries
from text.enrich_text_embeddings import enrich_text_embeddings
from text.enrich_lite import enrich_lite

MARKDOWN_DESTINATION_DIR = os.path.join("data", "github")
ensure_directory_exists(MARKDOWN_DESTINATION_DIR)

config = ApiConfiguration()

for item in gitHubUrls:
   download_markdown (item[2], item[1], MARKDOWN_DESTINATION_DIR)

enrich_text_chunks(config,MARKDOWN_DESTINATION_DIR) 
enrich_text_summaries(config, MARKDOWN_DESTINATION_DIR)
enrich_text_embeddings(config, MARKDOWN_DESTINATION_DIR)
enrich_lite(MARKDOWN_DESTINATION_DIR)

output_dir = os.path.join(MARKDOWN_DESTINATION_DIR, "output") 
countUrlHits (output_dir, gitHubUrls, "master_text.json", "hit_test_results.json")
****************************************

****************************************
Boxer\scripts\make_new_container.ts
****************************************
'use strict';
// Copyright Braid technologies ltd, 2024

import { expect } from 'expect';
import { describe, it } from 'mocha';

import { SessionKey } from '../core/Keys';
import { Persona } from '../core/Persona';
import { BraidFluidConnection } from '../core/BoxerFluidConnection';
import { throwIfUndefined } from '../core/Asserts';

describe("Make new container", function () {
 

   it("Needs to create new container", async function () {
     
      let local = Persona.unknown();

      let fluidMessagesConnection = new BraidFluidConnection(local);

      throwIfUndefined(process.env.SessionKey);
      fluidMessagesConnection.createNew (new SessionKey (process.env.SessionKey), true).then (conversationKey_ => {
        
         console.log ("Created conversation:" + conversationKey_);

      }).catch ((e : any) => {
      
         console.error ("Error creating conversation:" + e.toString());
      })

      expect (true).toBe (true);
   });         
});
****************************************

****************************************
Boxer\scripts\web_pipeline.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os

# Local Modules
from common.ApiConfiguration import ApiConfiguration
from common.Urls import webUrls, countUrlHits
from web.download_html import download_html
from common.common_functions import ensure_directory_exists
from text.enrich_text_chunks import enrich_text_chunks
from text.enrich_text_summaries import enrich_text_summaries
from text.enrich_text_embeddings import enrich_text_embeddings
from text.enrich_lite import enrich_lite


# Set HTML destination directory
HTML_DESTINATION_DIR = os.path.join("data", "web")
ensure_directory_exists(HTML_DESTINATION_DIR)

config = ApiConfiguration()

# For debugging purposes, you might want to comment out the following block
for item in webUrls:
    download_html(item[1], item[2], HTML_DESTINATION_DIR, config.discardIfBelow)

# Keep this comment as example of how to just process one file for debugging
#download_html("https://www.interaction-design.org/literature/topics/design-thinking", 
#              True, HTML_DESTINATION_DIR, 150)

# Enrich the text chunks, summaries, embeddings, and run lite enrichment
enrich_text_chunks(config, HTML_DESTINATION_DIR) 
enrich_text_summaries(config, HTML_DESTINATION_DIR)
enrich_text_embeddings(config, HTML_DESTINATION_DIR)
enrich_lite(HTML_DESTINATION_DIR)

ENRICHMENT_OUTPUT_DIR = os.path.join(HTML_DESTINATION_DIR, "output")

# Count URL hits 
countUrlHits(ENRICHMENT_OUTPUT_DIR, webUrls, "master_text.json", "hit_test_results_web.json")
****************************************

****************************************
Boxer\scripts\youtube_pipeline.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import logging

# Local Modules
from common.ApiConfiguration import ApiConfiguration
from common.Urls import youTubeUrls, countUrlHits
from common.common_functions import ensure_directory_exists
from youtube.download_transcripts import download_transcripts
from youtube.enrich_transcript_chunks import enrich_transcript_chunks
from youtube.enrich_transcript_summaries import enrich_transcript_summaries
from youtube.enrich_transcript_embeddings import enrich_transcript_embeddings
from text.enrich_lite import enrich_lite

# Configure logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

logger = logging.getLogger(__name__)

logger.info("Script started.")

# Set transcript destination directory
TRANSCRIPT_DESTINATION_DIR = os.path.join("data", "youtube")
ensure_directory_exists(TRANSCRIPT_DESTINATION_DIR)

config = ApiConfiguration()

for item in youTubeUrls:
   logger.debug(f"Downloading transcripts for URL: {item[1]}")
   download_transcripts(item[1], TRANSCRIPT_DESTINATION_DIR)

# Keep this comment as example of how to just process one file for debugging   
#download_transcripts ("PL1T8fO7ArWleyIqOy37OVXsP4hFXymdOZ", TRANSCRIPT_DESTINATION_DIR)
#download_transcripts ("PLFnkruiXQop4Robpmim_3FMZbv_1lAwBu", TRANSCRIPT_DESTINATION_DIR)

logger.info("Enriching transcript chunks...")
enrich_transcript_chunks(config, TRANSCRIPT_DESTINATION_DIR)

logger.info("Enriching transcript summaries...")
enrich_transcript_summaries(config, TRANSCRIPT_DESTINATION_DIR)

logger.info("Enriching transcript embeddings...")
enrich_transcript_embeddings(config, TRANSCRIPT_DESTINATION_DIR)

logger.info("Enriching transcripts with lite enrichment...")
enrich_lite(TRANSCRIPT_DESTINATION_DIR)

logger.info("Counting URL hits...")
output_dir = os.path.join(TRANSCRIPT_DESTINATION_DIR, "output") 
countUrlHits(output_dir, youTubeUrls, "master_transcriptions.json","hit_test_results.json")

logger.info("Script finished.")
****************************************

****************************************
Boxer\test\activityrecord.test.ts
****************************************
'use strict';
// Copyright Braid technologies ltd, 2024
import {  IStoredUrlActivity, IStoredLikeUrlActivity, IStoredMessageActivity, 
   urlActivityRecordClassName, urlLikeActivityRecordClassName, messageActivityRecordClassName,
   urlActivityRecordSchemaNumber, urlLikeActivityRecordSchemaNumber, messageActivityRecordSchemaNumber } from '../core/ActivityRecord';
import { EStorableApplicationIds } from '../../CommonTs/src/IStorable';
import { SessionKey } from '../core/Keys';
import { getRecordRepository } from '../core/IActivityRepositoryFactory';
import { getDefaultKeyGenerator } from '../core/IKeyGeneratorFactory';

import { expect } from 'expect';
import { describe, it } from 'mocha';
import { throwIfUndefined } from '../core/Asserts';

const keyGenerator = getDefaultKeyGenerator();

describe("ActivityRepository", function () {

   this.timeout(10000);

   beforeEach(async () => {

      this.timeout(10000);
   });
      
   let sessionKey = process.env.SessionKey;
   throwIfUndefined (sessionKey);
   let repository = getRecordRepository(new SessionKey (sessionKey));

   it("Needs to save a URL record", async function () {

      var activity : IStoredUrlActivity= {
         id : keyGenerator.generateKey(),
         applicationId: EStorableApplicationIds.kBoxer,
         contextId: "madeupconversationKey",
         userId: "madeupname@hotmail.com",
         created: new Date().toUTCString(),
         amended: new Date().toUTCString(),  
         functionalSearchKey: undefined,  
         className: urlActivityRecordClassName,
         schemaVersion: urlActivityRecordSchemaNumber, 
         url: "https://test.cosmos"
      };

      let saved = await repository.save (activity);

      expect(saved).toEqual(true);     
   });

   it("Needs to save a LikeDislike record", async function () {

      var activity : IStoredLikeUrlActivity= {
         id : keyGenerator.generateKey(),
         applicationId: EStorableApplicationIds.kBoxer,
         contextId: "madeupconversationKey",
         userId: "madeupname@hotmail.com",
         created: new Date().toUTCString(),
         amended: new Date().toUTCString(),  
         functionalSearchKey: undefined,  
         className: urlLikeActivityRecordClassName,
         schemaVersion: urlLikeActivityRecordSchemaNumber, 
         url: "https://test.cosmos",
         like: true
      };

      let saved = await repository.save (activity);

      expect(saved).toEqual(true);     
   });   

   it("Needs to save a Message record", async function () {

      let activity : IStoredMessageActivity = {
         id : keyGenerator.generateKey(), 
         applicationId: EStorableApplicationIds.kBoxer,
         contextId: "madeupconversationKey",
         userId: "madeupname@hotmail.com",
         created: new Date().toUTCString(),
         amended: new Date().toUTCString(),  
         functionalSearchKey: undefined,  
         className: messageActivityRecordClassName,
         schemaVersion: messageActivityRecordSchemaNumber, 
         message: "Test message"
      };
      let saved = await repository.save (activity);

      expect(saved).toEqual(true);     
   });   

   it("Needs to load a record", async function () {

      var activity : IStoredLikeUrlActivity= {
         id : keyGenerator.generateKey(),
         applicationId: EStorableApplicationIds.kBoxer,
         contextId: "madeupconversationKey",
         userId: "madeupname@hotmail.com",
         created: new Date().toUTCString(),
         amended: new Date().toUTCString(),  
         functionalSearchKey: undefined,  
         className: urlLikeActivityRecordClassName,
         schemaVersion: urlLikeActivityRecordSchemaNumber, 
         url: "https://test.cosmos",
         like: true
      };

      let saved = await repository.save (activity);      
      let loaded = await repository.loadRecentUrlActivity (3);

      expect(loaded.length > 0).toEqual(true);     
   });  

   it("Needs to remove a Message record", async function () {

      let messageId = keyGenerator.generateKey();
      let activity : IStoredMessageActivity = {
         id : messageId, 
         applicationId: EStorableApplicationIds.kBoxer,
         contextId: "madeupconversationKey",
         userId: "madeupname@hotmail.com",
         created: new Date().toUTCString(),
         amended: new Date().toUTCString(),  
         functionalSearchKey: undefined,  
         className: messageActivityRecordClassName,
         schemaVersion: messageActivityRecordSchemaNumber, 
         message: "Test message"
      };

      let saved = await repository.save (activity);

      let removed = await repository.removeMessageRecord (messageId);

      expect(removed).toEqual(true);     
   }); 
});
****************************************

****************************************
Boxer\test\adminrespository.test.ts
****************************************
'use strict';
// Copyright Braid technologies ltd, 2024
import { expect } from 'expect';
import { describe, it } from 'mocha';

import { DefaultAdminRepository } from '../core/IAdminRepository';
import { Persona } from '../core/Persona';
import { EIcon } from '../core/Icons';

describe("AdminRespository", function () {

   var count: number = 0;

   function doSomethingAsync () {
      count++;
   }

   it("Needs to say JV is an adminstrator", async function () {

      let repository = new DefaultAdminRepository();
      let persona1 = new Persona("1", "Jon Verrier", "whatever", EIcon.kPersonPersona, undefined, new Date());

      let isAdmin = await repository.isAdmin(persona1);

      expect(isAdmin).toEqual(true);
   });

   it("Needs to say names other than JV are not an adminstrator", async function () {

      let repository = new DefaultAdminRepository();
      let persona1 = new Persona("1", "Jon Verrier2", "whatever", EIcon.kPersonPersona, undefined, new Date());

      let isAdmin = await repository.isAdmin(persona1);

      expect(isAdmin).toEqual(false);
   });

});
****************************************

****************************************
Boxer\test\aiconnection.test.ts
****************************************
'use strict';
// Copyright Braid Technologies ltd, 2024
import { throwIfUndefined } from '../core/Asserts';
import { Message} from '../core/Message';
import { Persona} from '../core/Persona';
import { EIcon } from '../core/Icons';
import { SessionKey } from '../core/Keys';
import { KStubEnvironmentVariables} from '../core/ConfigStrings'; 
import { AIConnection } from '../core/AIConnection';
import { makeSummaryCall } from '../core/ApiCalls';

import { IRelevantEnrichedChunk } from '../../CommonTs/src/EnrichedChunk';

import { expect } from 'expect';
import { describe, it } from 'mocha';

let myMessageId: string = "1234";
let myAuthorId: string = "Jon";
let myText = "Boxer What is back propagation?";
let mySentAt = new Date();

let botMessageId: string = "5678";
let botAuthorId: string = "Bot";
let botText = "Back propogation is a technique used to train nueral networks.";
var botSentAt = new Date(0);

let myBotRequestId: string = "12345";
let myBotRequestText = "Hello @Boxer What is back propagation?";

async function sleep(msec: number) {
   return new Promise(resolve => setTimeout(resolve, msec));
}

describe("AIConnection", async function () {

   let authors = new Map<string, Persona> ();
   let person = new Persona (myAuthorId, myAuthorId, "", EIcon.kPersonPersona, undefined, new Date());   
   let bot = new Persona (botAuthorId, botAuthorId, "", EIcon.kLLMPersona, undefined, new Date());
   authors.set (person.id, person);
   authors.set (bot.id, bot);

   let personMessage = new Message(myMessageId, myAuthorId, undefined, myText, mySentAt);
   let botMessage = new Message(botMessageId, botAuthorId, undefined, botText, botSentAt);
   let botRequest = new Message(myBotRequestId, myAuthorId, undefined, myBotRequestText, mySentAt); 
   this.timeout(20000);

   beforeEach(async () => {

      this.timeout(20000);           
   });

   it("Needs to detect Bot message type", function () {

      var messageEmpty = new Message();

      expect(AIConnection.isFromLLM(botMessage, authors)).toEqual(true);
      expect(AIConnection.isFromLLM(personMessage, authors)).toEqual(false); 
      expect(AIConnection.isFromLLM(botRequest, authors)).toEqual(false);           
   });

   it("Needs to detect Bot request type", function () {

      expect(AIConnection.isRequestForLLM(personMessage, authors)).toEqual(false);   
      expect(AIConnection.isRequestForLLM(botMessage, authors)).toEqual(false);     
      expect(AIConnection.isRequestForLLM(botRequest, authors)).toEqual(true);          
   });   

   it("Needs to detect near-miss Bot request type", function () {

      expect(AIConnection.mightBeMissTypedRequestForLLM (personMessage, authors)).toEqual(true);   
      expect(AIConnection.mightBeMissTypedRequestForLLM(botMessage, authors)).toEqual(false);
      expect(AIConnection.mightBeMissTypedRequestForLLM(botRequest, authors)).toEqual(false);                 
   });   

   it("Needs to allow reference errors & return false", function () {

      var newMessage = new Message(personMessage);
      newMessage.authorId = "Banana";
  
      let caught = false;
      let answer = false;

      try {
         answer = AIConnection.isFromLLM(newMessage, authors);
      }
      catch (e) {
         caught = true;
      }
      expect(caught).toEqual(false);      
      expect(answer).toEqual(false);          
   });   

   it("Needs to build request object", async function () {

      let messages = new Array<Message>();
      messages.length = 3;
      messages[0] = personMessage;
      messages[1] = botRequest;
      messages[2] = botMessage;

      throwIfUndefined(process);
      throwIfUndefined(process.env);
      throwIfUndefined(process.env.SessionKey);        

      let query = AIConnection.buildEnrichmentQuery (messages, authors);

      expect(query.history.length).toEqual(2);         
   });       

   it("Needs to generate valid response from Open AI web endpoint using streaming API", async function () {

      let messages = new Array<Message>();
      messages.length = 2;
      messages[0] = personMessage;
      messages[1] = botRequest;

      throwIfUndefined(process);
      throwIfUndefined(process.env);
      throwIfUndefined(process.env.SessionKey);        

      let caller = new AIConnection (new SessionKey (process.env.SessionKey));                
      let fullQuery = AIConnection.buildEnrichmentQuery (messages, authors);
      let message = new Message();

      let called = false;
      function handler (text: Message, more: boolean) {
         called = true;
      }

      message.hookLiveAppend (handler);

      let result = await caller.makeEnrichedCall (message, fullQuery);

      await sleep (10000);

      message.unhookLiveAppend ();

      expect (message.text.length > 0).toBe(true);    
      expect (message.isStreaming).toBe(false);    
      expect (called).toBe(true);    

   }).timeout(20000); 

   it("Needs to generate valid response from Open AI web endpoint using basic API", async function () {

      let messages = new Array<Message>();
      messages.length = 2;
      messages[0] = personMessage;
      messages[1] = botRequest;
     
      throwIfUndefined(process);
      throwIfUndefined(process.env);
      throwIfUndefined(process.env.SessionKey); 

      let caller = new AIConnection (new SessionKey (process.env.SessionKey));             
      let message = new Message();

      let result = await caller.makeFollowUpCall ("This article explains how Transformers work.");

      expect (result && result.text.length > 0).toBe(true);    
      expect (result && result.isStreaming).toBe(false);              
   }).timeout(20000); 

   function makeLongMessage (startingMessage: Message, segmentCount: number) : Message {

      let segments = new Array<IRelevantEnrichedChunk>();      

      // Make a list of knowledge sources, each with > 1000 tokens
      for (var i = 0; i < segmentCount; i++) {
         
         let accumulatedText = "Hi";

         for (var j = 0; j < 500; j++) {
            accumulatedText = accumulatedText.concat (" token");
         }
         let ks1 = {
            chunk: {
               url: "https://test", 
               summary: accumulatedText,
               text: accumulatedText
            },
            relevance: 0.8
         };
         segments.push (ks1);
      }
      
      let newBotRequest = new Message (startingMessage);
      newBotRequest.chunks = segments;

      return newBotRequest;
   }
   it("Needs to detect when token limit is OK", async function () {

      let messages = new Array<Message>();

      messages.length = 4;
      messages[0] = personMessage;
      messages[1] = botRequest;
      messages[2] = makeLongMessage (botMessage, 2); // This ends up as two mesages as we have a long message and a long chunk. 
      messages[3] = botRequest;

      throwIfUndefined(process);
      throwIfUndefined(process.env);
      throwIfUndefined(process.env.SessionKey);        

      let query = AIConnection.buildEnrichmentQuery (messages, authors);

      expect(query.history.length).toEqual(4);         
   });    

   it("Needs to detect when token limit overflows", async function () {

      let messages = new Array<Message>();

      messages.length = 4;
      messages[0] = personMessage;
      messages[1] = botRequest;
      messages[2] = makeLongMessage (botMessage, 20);
      messages[3] = botRequest;      

      throwIfUndefined(process);
      throwIfUndefined(process.env);
      throwIfUndefined(process.env.SessionKey);        

      let query = AIConnection.buildEnrichmentQuery (messages, authors);

      expect(query.history.length).toEqual(0);         
   });      
});


describe("APIs", function () {

   it("Needs to call summariser", async function () {

      let caught = false;
      let session = new SessionKey(KStubEnvironmentVariables.SessionKey);
      let text = "OpenAI have released a new model called OpenAI-O, where the O stands for omni channel. They have also released a small version of this."
      let summary : string | undefined = "";

      try {
         summary = await makeSummaryCall (session, text);
      }
      catch (e) {
         caught = true;
      }
      expect(caught).toEqual(false);      
      expect(summary && summary.length > 0).toEqual(true);              
   }).timeout(20000);       
   
});
****************************************

****************************************
Boxer\test\caucus.test.ts
****************************************
// Copyright Braid technologies ltd, 2024
import { expect } from 'expect';
import { describe, it } from 'mocha';

import { throwIfUndefined } from '../core/Asserts';
import { Persona } from '../core/Persona';
import { Message } from '../core/Message';
import { Interest, NotificationFor } from '../core/NotificationFramework';
import { BraidFluidConnection } from '../core/BoxerFluidConnection';
import { EIcon } from '../core/Icons';
import { SessionKey, ConversationKey } from '../core/Keys';

var myId: string = "1234";
var myName = "";
var myEmail: string = "jon@a.com";
var myThumbnail: string = "abcd";
var myLastSeenAt = new Date();

class MockLocation { // Just create the fields we use in the Mock
   protocol: string;
   host: string;
   hostname: string;
   hash: string;

   constructor() {
      this.protocol = "";
      this.host = "";
      this.hostname = "";
      this.hash = "";
   }   
}

var mockLocation = new MockLocation();

async function wait() {
   await new Promise(resolve => setTimeout(resolve, 500));
}

function onAdd(interest_: Interest, notification_: NotificationFor<string>) : void {

}

function onChange(interest_: Interest, notification_: NotificationFor<string>): void {

}

function onRemove(interest_: Interest, notification_: NotificationFor<string>): void {

}

describe("Caucus", function () {

   this.timeout(10000);

   var newConnection: BraidFluidConnection;
   var persona: Persona;
   var id: ConversationKey; 

   var oldLocation: any = global.location;

   beforeEach(async () => {

      (global.location as any) = mockLocation;

      this.timeout(10000);
      persona = new Persona(myId, myName, myEmail, EIcon.kPersonPersona, myThumbnail, myLastSeenAt);

      newConnection = new BraidFluidConnection(persona);

      let checked = process.env.SessionKey;
      throwIfUndefined(checked);
      id = await newConnection.createNew(new SessionKey (checked), false);

      await wait();
   });

   afterEach(async () => {

      await wait();
      await newConnection.disconnect();
  
      (global.location as any) = oldLocation;
   });

   it("Can create a valid caucus", async function () {

      var workingPersona: Persona = new Persona(persona);

      let caucus = newConnection.participantCaucus();

      caucus.add(workingPersona.id, workingPersona);
      expect(caucus.has(workingPersona.id)).toEqual(true);
      expect(caucus.get(workingPersona.id).equals(workingPersona)).toEqual(true);
      expect(caucus.current().size).toEqual(2); // The Bot persona is added manually - size is alays >= 1

      workingPersona.name = "Joe";
      caucus.amend(workingPersona.id, workingPersona);
      expect(caucus.get(workingPersona.id).equals(workingPersona)).toEqual(true)

      caucus.remove(workingPersona.id);
      expect(caucus.has(workingPersona.id)).toEqual(false);
      expect(caucus.current().size).toEqual(1); // The Bot persona is added manually - size is alays >= 1
    });

    it("Can detect invalid operations", async function () {

      var workingPersona: Persona = new Persona(persona);

      let caucus = newConnection.participantCaucus();

      caucus.add(workingPersona.id, workingPersona);

      let caught = false;
      try {
         caucus.get("banana");
      }
      catch {
         caught = true;            
      }

      expect(caught).toEqual(true);
    });

   it("Can synchronise", async function () {

      var workingPersona: Persona = new Persona(persona);

      let caucus = newConnection.participantCaucus();

      var synchMap: Map<string, Persona> = new Map<string, Persona>();

      // Sync down to no elements
      caucus.synchFrom(synchMap);
      expect(caucus.current().size === 0).toEqual(true);

      // Sync in a new element
      synchMap.set(workingPersona.id, workingPersona);
      caucus.synchFrom(synchMap);
      expect(caucus.current().size === 1).toEqual(true);
      expect(caucus.get(workingPersona.id).equals(workingPersona)).toEqual(true);

      // Sync in a changed element
      workingPersona.name = "Joe 2";
      caucus.synchFrom(synchMap);
      expect(caucus.current().size === 1).toEqual(true);
      expect(caucus.get(workingPersona.id).equals(workingPersona)).toEqual(true);
   });

   it("Can remove all", async function () {

      var workingPersona: Persona = new Persona(persona);

      let caucus = newConnection.participantCaucus();

      var synchMap: Map<string, Persona> = new Map<string, Persona>();

      // Sync down to no elements
      caucus.synchFrom(synchMap);
      expect(caucus.current().size === 0).toEqual(true);

      // Sync in a new element
      synchMap.set(workingPersona.id, workingPersona);
      caucus.synchFrom(synchMap);
      expect(caucus.current().size === 1).toEqual(true);
      expect(caucus.get(workingPersona.id).equals(workingPersona)).toEqual(true);

      // Remove all elements
      caucus.removeAll ();
      expect(caucus.current().size === 0).toEqual(true);
   });

   it("Can return an ordered array", async function () {

      // Create three Message objects
      var workingMessage: Message = new Message();
      var workingMessage2: Message = new Message();    
      var workingMessage3: Message = new Message(); 
      
      // Space them out a second apart
      let now = new Date();
      workingMessage2.sentAt = new Date(now.getTime() + 1000);
      workingMessage3.sentAt = new Date(now.getTime() + 2000);

      let caucus = newConnection.messageCaucus();

      var synchMap: Map<string, Message> = new Map<string, Message>();
      synchMap.set (workingMessage.id, workingMessage);
      synchMap.set (workingMessage2.id, workingMessage2);
      synchMap.set (workingMessage3.id, workingMessage3);

      // Sync in 3 elements     
      caucus.synchFrom(synchMap);
      expect(caucus.current().size === 3).toEqual(true);

      let tempArray = caucus.currentAsArray();

      expect(tempArray.length === 3).toEqual(true);
      expect(tempArray[0].sentAt.getTime() <= tempArray[1].sentAt.getTime()).toEqual(true);
      expect(tempArray[1].sentAt.getTime() <= tempArray[2].sentAt.getTime()).toEqual(true);
   });   

   it("Can manage a large volume of members", async function () {

      let caucus = newConnection.messageCaucus();
      let count = 1000;

      let start = new Date();
      
      for (let i = 0; i < count; i++) {
         var workingMessage: Message = new Message();         
         caucus.add (workingMessage.id, workingMessage);
         let ordered = caucus.currentAsArray();
      }
      
      let middle = new Date();

      for (let i = 0; i < count; i++) {
         let ordered = caucus.currentAsArray();
      }
      
      let end = new Date();

      console.log ('Loading phase:' + (middle.getTime() - start.getTime()).toString() + '\n', 
                   'Reading phase:' + (end.getTime() - middle.getTime()).toString() + '\n');

      expect(caucus.currentAsArray().length).toEqual(1000);
   }).timeout (30000);    
});
****************************************

****************************************
Boxer\test\chunk.test.ts
****************************************
'use strict';
// Copyright Braid Technologies ltd, 2024

import { expect } from 'expect';
import { describe, it } from 'mocha';

import { KStubEnvironmentVariables } from '../core/ConfigStrings';

import { getEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { FindEnrichedChunkApi } from '../../CommonTs/src/FindEnrichedChunkApi';
import { EChunkRepository } from '../../CommonTs/src/EnrichedChunk';


describe("ChunkRepository", function () {

   let api = new FindEnrichedChunkApi(getEnvironment (EEnvironment.kLocal), KStubEnvironmentVariables.SessionKey);

   it("Needs to identify related content given an input URL", async function () {

      let query = {
         repositoryId: EChunkRepository.kBoxer,
         url: "https://www.youtube.com/watch?v=l5mG4z343qg&t=00m",
         maxCount: 1,
         similarityThreshold : 0.4

      }
      let response = await api.findRelevantChunksFromUrl (query);

      expect(response.length).toEqual(1);     
   });

   it("Needs to identify starter content", async function () {

      let query = {
         repositoryId: EChunkRepository.kBoxer,
         maxCount: 1,
         similarityThreshold : 0.4,
         summary: "This article exploure user interface considerations for interacting with LLM based applications."

      }
      let response = await api.findRelevantChunksFromSummary (query);

      expect(response.length).toEqual(1);          
   });

});
****************************************

****************************************
Boxer\test\debounce.test.ts
****************************************
'use strict';
// Copyright Braid technologies ltd, 2024
import { expect } from 'expect';
import { describe, it } from 'mocha';

import { debounce} from '../core/Debounce';

async function wait() {
   await new Promise(resolve => setTimeout(resolve, 1000));
}

describe("Debounce", function () {

   var count: number = 0;

   function doSomethingAsync () {
      count++;
   }

   it("Needs to function asynchronously", async function () {

      const debounced = debounce(doSomethingAsync, 0);

      debounced();

      await wait();

      expect(count > 0).toEqual(true);
   });

   it("Needs to function called > once", async function () {

      const debounced = debounce(doSomethingAsync, 0);

      debounced();
      debounced();

      await wait();

      expect(count > 0).toEqual(true);
   });
});
****************************************

****************************************
Boxer\test\embedding.test.ts
****************************************
'use strict';
// Copyright Braid technologies ltd, 2024

import { expect } from 'expect';
import { describe, it } from 'mocha';

import { KStubEnvironmentVariables } from "../core/ConfigStrings";

import { getEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { EEnvironment } from '../../CommonTs/src/IEnvironment';
import { FindEnrichedChunkApi } from '../../CommonTs/src/FindEnrichedChunkApi';
import { EChunkRepository } from '../../CommonTs/src/EnrichedChunk';

describe("Embedding", async function () {

   let api = new FindEnrichedChunkApi(getEnvironment (EEnvironment.kLocal), KStubEnvironmentVariables.SessionKey);


   it("Needs to find closest match for an existing YouTube document", async function () {

      let query = {
         repositoryId: EChunkRepository.kBoxer,
         url: "https://www.youtube.com/watch?v=l5mG4z343qg&t=00m",
         maxCount: 1,
         similarityThreshold : 0.4

      }
      let response = await api.findRelevantChunksFromUrl (query);

      expect(response.length).toEqual(1);       

   }).timeout (20000);

   it("Needs to find closest match for an existing Html document", async function () {

      let query = {
         repositoryId: EChunkRepository.kBoxer,
         url: "https://karpathy.medium.com/software-2-0-a64152b37c35",
         maxCount: 1,
         similarityThreshold : 0.4
      }
      let response = await api.findRelevantChunksFromUrl (query);
   
      expect(response.length).toEqual(1); 

   }).timeout (20000);

   it("Needs to find closest match for a simple query", async function () {
      
      let query = {
         repositoryId: EChunkRepository.kBoxer,
         summary: "Trolly chicken dilemma chicks",
         maxCount: 1,
         similarityThreshold : 0.1 // set low so we get a match
      }
      let response = await api.findRelevantChunksFromSummary (query);
   
      expect(response.length).toEqual(1);    

   }).timeout (10000);   

   it("Needs to find closest match for an irrelevant query", async function () {
      
      let query = {
         repositoryId: EChunkRepository.kBoxer,
         summary: "Human baby animals cute cats dogs",
         maxCount: 1,
         similarityThreshold : 0.1 // set low so we get a match
      }
      let response = await api.findRelevantChunksFromSummary (query);
   
      expect(response.length).toEqual(1);    

   }).timeout (10000);     

   it("Needs to find closest match for a Markdown query", async function () {
      
      let query = {
         repositoryId: EChunkRepository.kBoxer,
         summary: "User experience is a very important aspect of building apps. Users need to be able to use your app in an efficient way to perform tasks. Being efficient is one thing but you also need to design apps so that they can be used by everyone, to make them accessible. This chapter will focus on this area so you hopefully end up designing an app that people can and want to use. Introduction User experience is how a user interacts with and uses a specific product or service be it a system, tool",
         maxCount: 1,
         similarityThreshold : 0.4 
      }
      let response = await api.findRelevantChunksFromSummary (query);
   
      expect(response.length).toEqual(1);   

   }).timeout (10000);      
});
****************************************

****************************************
Boxer\test\errors.test.ts
****************************************
'use strict';
// Copyright Braid technologies ltd, 2024
import { expect } from 'expect';
import { describe, it } from 'mocha';

import { InvalidParameterError, InvalidOperationError, ConnectionError, EnvironmentError, InvalidStateError } from '../core/Errors';

var message = "What";

describe("Errors", function () {

   it("Needs to create InvalidParameterError", function () {

      var error: InvalidParameterError = new InvalidParameterError(message);
      expect(error.message === message).toEqual(true);
   });

   it("Needs to create InvalidOperationError", function () {

      var error: InvalidOperationError = new InvalidOperationError(message);
      expect(error.message === message).toEqual(true);
   });

   it("Needs to create ConnectionError", function () {

      var error: ConnectionError = new ConnectionError(message);
      expect(error.message === message).toEqual(true);
   });

   it("Needs to create EnvironmentError", function () {

      var error: EnvironmentError = new EnvironmentError(message);
      expect(error.message === message).toEqual(true);
   });

   it("Needs to create InvalidStateerror", function () {

      var error: InvalidStateError = new InvalidStateError(message);
      expect(error.message === message).toEqual(true);
   });   
});
****************************************

****************************************
Boxer\test\joinpagevalidator.test.ts
****************************************
'use strict';
// Copyright Braid Technologies ltd, 2024
import { expect } from 'expect';
import { describe, it } from 'mocha';
import { IKeyGenerator } from '../core/IKeyGenerator';
import { getDefaultKeyGenerator } from '../core/IKeyGeneratorFactory';
import { SessionKey, ConversationKey } from '../core/Keys';
import { JoinDetails } from '../core/JoinDetails';
import { JoinPageValidator } from '../core/JoinPageValidator';

const badUuid = "9a0583f5xca56-421b-8545-aa23032d6c93"

var keyGenerator: IKeyGenerator = getDefaultKeyGenerator();

describe("JoinPageValidator", function () {

   it("Needs to detect invalid name", function () {

      let validator = new JoinPageValidator();
      let session = new SessionKey (keyGenerator.generateKey());
      let conversation = new ConversationKey (keyGenerator.generateKey());

      expect(validator.canAttemptJoin ("", undefined as unknown as string, session, conversation)).toEqual(false);
   });

   it("Needs to detect invalid session key", function () {

      let validator = new JoinPageValidator();
      let session = new SessionKey (badUuid);
      let conversation = new ConversationKey (keyGenerator.generateKey());

      expect(validator.canAttemptJoin ("joe@mail.com", "Joe", session, conversation)).toEqual(false);
   }); 

   it("Needs to detect invalid conversation key", function () {

      let validator = new JoinPageValidator();
      let session = new SessionKey (keyGenerator.generateKey());
      let conversation = new ConversationKey (badUuid);

      expect(validator.canAttemptJoin ("joe@mail.com", "Joe", session, conversation)).toEqual(false);
   }); 
    

   it("Needs to detect valid components", function () {
      let validator = new JoinPageValidator();
      let session = new SessionKey (keyGenerator.generateKey());
      let conversation = new ConversationKey (keyGenerator.generateKey());

      expect(validator.canAttemptJoin ("joe@mail.com", "Joe", session, conversation)).toEqual(true);
   });
   
});


describe("JoinDetails", function () {

   it("Needs to classify empty string", function () {

      let details = new JoinDetails("");

      expect(details.canAttemptJoin()).toEqual(false);
   });

   it("Needs to detect invalid name", function () {

      let name = "";
      let session = new SessionKey (keyGenerator.generateKey());
      let conversation = new ConversationKey (keyGenerator.generateKey());
      let secret = keyGenerator.generateSecret();

      let details = new JoinDetails ("&email=" + name + "&session=" + session.toString() + "&conversation=" + conversation.toString() + '&secret=' + secret);

      expect(details.canAttemptJoin()).toEqual(false);
   });

   it("Needs to detect invalid session key", function () {

      let name = "joe@mail.com";
      let session = new SessionKey (badUuid);
      let conversation = new ConversationKey (keyGenerator.generateKey());
      let secret = keyGenerator.generateSecret();      

      let details = new JoinDetails ("&email=" + name + "&session=" + session.toString() + "&conversation=" + conversation.toString() + '&secret=' + secret);

      expect(details.canAttemptJoin()).toEqual(false);
   }); 

   it("Needs to detect invalid conversation key", function () {

      let name = "joe@mail.com";
      let session = new SessionKey (keyGenerator.generateKey());
      let conversation = new ConversationKey (badUuid);
      let secret = keyGenerator.generateSecret();  

      let details = new JoinDetails ("&email=" + name + "&session=" + session.toString() + "&conversation=" + conversation.toString()+ '&secret=' + secret);

      expect(details.canAttemptJoin()).toEqual(false);
   });  
   
   it("Needs to detect all valid parts", function () {

      let name = "joe@mail.com";
      let session = new SessionKey (keyGenerator.generateKey());
      let conversation = new ConversationKey (keyGenerator.generateKey());
      let secret = keyGenerator.generateSecret();  

      let details = new JoinDetails ("&email=" + name + "&session=" + session.toString() + "&conversation=" + conversation.toString() + '&secret=' + secret);

      expect(details.canAttemptJoin()).toEqual(true);
   });     
});
****************************************

****************************************
Boxer\test\like.test.ts
****************************************
'use strict';
// Copyright Braid technologies ltd, 2024

import { expect } from 'expect';
import { describe, it } from 'mocha';

import { Like } from '../core/Like';

let me = "Jon";
let now = new Date();

let them = "Jon";
let nowThem = new Date("1/1/2024");

describe("Like", async function () {
     

   var l1: Like, l2: Like, lErr:Like;

   l1 = new Like(me, now);

   l2 = new Like(them, nowThem);

   it("Needs to construct an empty object", function () {

      var lEmpty = new Like();

      expect(lEmpty.name).toEqual("");     
   });

   it("Needs to compare for equality and inequality", function () {

      var lNew: Like = new Like(l1.name, l1.when);

      expect(l1.equals(l1)).toEqual(true);
      expect(l1.equals(lNew)).toEqual(true);
      expect(l1.equals(l2)).toEqual(false);
   });
   
   
   it("Needs to detect inequality on date", function () {

      var lNew: Like = new Like(l1.name, new Date());

      expect(l1.equals(lNew)).toEqual(false);
   });

   it("Needs to correctly store attributes", function () {
         
      expect(l1.name === me).toEqual(true);
      expect(l1.when.getTime() === now.getTime()).toEqual(true);
   });

   it("Needs to copy construct", function () {

      let l2: Like = new Like(l1);

      expect(l1.equals(l2) === true).toEqual(true);
   });

   it("Needs to correctly change attributes", function () {

      var lNew: Like = new Like(l1.name, l1.when);

      lNew.name = them;
      lNew.when = nowThem;
     
      expect(l2.equals (lNew)).toEqual(true);
   });

   it("Needs to convert to and from JSON()", function () {

      var stream: string = l1.streamOut();

      var lNew: Like = new Like();
      lNew.streamIn(stream);
    
      expect(l1.equals(lNew)).toEqual(true);
   });   
});
****************************************

****************************************
Boxer\test\message.test.ts
****************************************
'use strict';
// Copyright Braid Technologies ltd, 2024
import { MDynamicStreamable } from '../core/StreamingFramework';
import { Message} from '../core/Message';
import { IKeyGenerator } from '../core/IKeyGenerator';
import { getDefaultKeyGenerator } from '../core/IKeyGeneratorFactory';

import { IRelevantEnrichedChunk } from '../../CommonTs/src/EnrichedChunk';

import { expect } from 'expect';
import { describe, it } from 'mocha';

var keyGenerator: IKeyGenerator = getDefaultKeyGenerator();

var myId: string = "1234";
var myAuthorId: string = "Jon";
var myResponseToId: string = "abcd";
var myText = "Hello";
var mySentAt = new Date();

var someoneElsesId: string = "5678";
var someoneElsesAuthorId: string = "Barry";
var someoneElsesResponseTo: string = "abcdefgh";
var someoneElsesText = "Bye";
var someoneElsesSentAt = new Date(0);

describe("Message", function () {

   var message1: Message, message2: Message, messageErr:Message;

   message1 = new Message(myId, myAuthorId, myResponseToId, myText, mySentAt);

   message2 = new Message(someoneElsesId, someoneElsesAuthorId, someoneElsesResponseTo, someoneElsesText, someoneElsesSentAt);

   it("Needs to construct an empty object", function () {

      var messageEmpty = new Message();

      expect(messageEmpty.text).toEqual("");
      expect(messageEmpty.responseToId).toEqual(undefined);
      expect(messageEmpty.isUnPrompted()).toEqual(true);
      expect(keyGenerator.couldBeAKey (messageEmpty.id)).toEqual(true);      
   });

   it("Needs to allow undefined ID", function () {

      var caught: boolean = false;
      try {
         messageErr = new Message(undefined, myId, myResponseToId, myText, mySentAt);
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(false);
   });

   it("Needs to detect invalid ID", function () {

      var caught: boolean = false;
      try {
         messageErr = new Message(1 as unknown as string, myId, myResponseToId, myText,  mySentAt);
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);
   });


   it("Needs to compare for equality and inequality", function () {

      var messageNew: Message = new Message(message1.id, message1.authorId, message1.responseToId, message1.text, message1.sentAt);

      expect(message1.equals(message1)).toEqual(true);
      expect(message1.equals(messageNew)).toEqual(true);
      expect(message1.equals(message2)).toEqual(false);
   });
   
   
   it("Needs to detect inequality on date", function () {

      var messageNew: Message = new Message(message1.id, message1.authorId, message1.responseToId, message1.text, new Date());

      expect(message1.equals(messageNew)).toEqual(false);
   });

   it("Needs to throw error if checkedResponseToId is not satisfied", function () {

      var messageEmpty = new Message();

      var caught: boolean = false;
      try {
         let thumb = messageEmpty.checkedResponseToId;

      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);
   });

   it("Needs to correctly store attributes", function () {
         
      expect(message1.authorId === myAuthorId).toEqual(true);
      expect(message1.responseToId === myResponseToId).toEqual(true);
      expect(message1.isUnPrompted()).toEqual(false);      
      expect(message1.sentAt.getTime() === mySentAt.getTime()).toEqual(true);
   });

   it("Needs to copy construct", function () {

      let persona2: Message = new Message(message1);

      expect(message1.equals(persona2) === true).toEqual(true);
   });

   it("Needs to correctly change attributes", function () {

      var messageNew: Message = new Message(message1.id, message1.authorId, message1.responseToId, message1.text, message1.sentAt);

      messageNew.id = someoneElsesId;
      messageNew.text = someoneElsesText;
      messageNew.authorId = someoneElsesAuthorId;
      messageNew.responseToId = someoneElsesResponseTo;
      messageNew.sentAt = someoneElsesSentAt;

      expect(message2.equals (messageNew)).toEqual(true);
   });

   it("Needs to catch errors on change id attributes", function () {

      var caught: boolean = false;
      try {
         message1.id = 1 as unknown as string;
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);

   });

   it("Needs to convert to and from JSON()", function () {

      var stream: string = message1.streamOut();

      var messageNew: Message = new Message(message1.id, message1.authorId, message1.responseToId, message1.text, message1.sentAt);
      messageNew.streamIn(stream);

      expect(message1.equals(messageNew)).toEqual(true);
   });

   it("Needs to convert to and from JSON() with KnowledgeSources attached", function () {

      let ks1 = {
         chunk: {
            url: "https://test", 
            summary: message1.text,
            text: message1.text
         },
         relevance: 0.8
      };
      let messageWithSources = new Message (message1);

      let sources = new Array<IRelevantEnrichedChunk> ();
      sources.push (ks1);
      messageWithSources.chunks = sources;      
      var stream: string = messageWithSources.streamOut();

      var messageNew: Message = new Message(message1.id, message1.authorId, message1.responseToId, message1.text, message1.sentAt);

      messageNew.streamIn(stream);

      expect(messageWithSources.equals(messageNew)).toEqual(true);
   });   

   it("Needs to dynamically create Message to and from JSON()", function () {

      var stream: string = message1.flatten();

      var messageNew: Message = new Message();

      expect(message1.equals(messageNew)).toEqual(false);

      messageNew = MDynamicStreamable.resurrect(stream) as Message;

      expect(message1.equals(messageNew)).toEqual(true);
   });

   it("Needs to dynamically create Message to and from JSON() with KnowledgeSources attached", function () {

      let ks1 = {
         chunk: {
            url: "https://test", 
            summary: message1.text,
            text: message1.text
         },
         relevance: 0.8
      };
      let messageWithSources = new Message (message1);

      let sources = new Array<IRelevantEnrichedChunk> ();
      sources.push (ks1);
      messageWithSources.chunks = sources;      
     
      var stream: string = messageWithSources.flatten();

      var messageNew: Message = new Message();

      expect(messageWithSources.equals(messageNew)).toEqual(false);

      messageNew = MDynamicStreamable.resurrect(stream) as Message;

      expect(messageWithSources.equals(messageNew)).toEqual(true);
   });   

   it("Needs to count with tokens KnowledgeSources attached", function () {

      let ks1 = {chunk: {
            url: "https://test", 
            summary: message1.text,
            text: message1.text
         },
         relevance: 0.8
      };

      var messageNew: Message = new Message();  
      expect(messageNew.isDirty).toEqual(true);          
      expect(messageNew.tokens > 1).toEqual(false);
      expect(messageNew.isDirty).toEqual(false);   

      messageNew.text = "Some text and a bit more x y x help this needs to be longer than 2 tokens";

      expect(messageNew.tokens > 1).toEqual(true);
      expect(messageNew.isDirty).toEqual(false); 

      let messageWithSources = new Message (messageNew);
      expect(messageWithSources.isDirty).toEqual(true); 

      let sources = new Array<IRelevantEnrichedChunk> ();
      sources.push (ks1);
      messageWithSources.chunks = sources;      
      expect(messageWithSources.isDirty).toEqual(true);         
      expect(messageWithSources.tokens > 2).toEqual(true);
      expect(messageWithSources.isDirty).toEqual(false);       
   });    

});
****************************************

****************************************
Boxer\test\notification.test.ts
****************************************
'use strict';
// Copyright Braid technologies ltd, 2024
import { describe, it} from 'mocha';
import { expect } from 'expect';

import {
   Interest,
   Notification,
   NotificationFor,
   ObserverInterest,
   Notifier,
   IObserver,
   NotificationRouter,
   NotificationRouterFor,
   FunctionForNotification
} from '../core/NotificationFramework';
import { throwIfUndefined } from '../core/Asserts';

class MockObserver implements IObserver {

   public _lastNotification: Notification | undefined = undefined;

   constructor() {
      this._lastNotification = undefined;
   }

   notify(interest_: Interest, notification_: Notification): void {

      this._lastNotification = notification_;
   };

   notifyInt (interest_: Interest, notification_: NotificationFor<number>): void {

      this._lastNotification = notification_;
   };
};

describe("NotificationFramework", function () {
  
   it("Needs to create, test & assign Interest", function () {

      var notificationId1 : string = "Playing";
      var notificationId2: string = "Paused";

      var interest1: Interest = new Interest(notificationId1);
      var interest2: Interest = new Interest(notificationId2);
      var interest3: Interest = new Interest (interest1);
      var interest4: Interest = new Interest();

      expect(interest1.equals(interest1)).toEqual(true);
      expect(interest1.equals(interest2)).toEqual(false);
      expect(interest1.equals(interest3)).toEqual(true);
      expect(interest1.equals(interest4)).toEqual(false);
      expect(interest1.notificationId === notificationId1).toEqual(true);

      interest2.assign(interest1);
      expect(interest1.equals(interest2)).toEqual(true);
   });

   it("Needs to create, test & assign Notification", function () {

      var notificationId1: string = "Playing";
      var notificationId2: string = "Paused";

      var interest1: Interest = new Interest(notificationId1);
      var interest2: Interest = new Interest(notificationId2);

      var notification1: Notification = new Notification(interest1);
      var notification2: Notification = new Notification(interest2);
      var notification3: Notification = new Notification(notification1);
      var notification4: Notification = new Notification();

      expect(notification1.equals(notification1)).toEqual(true);
      expect(notification1.equals(notification2)).toEqual(false);
      expect(notification1.equals(notification3)).toEqual(true);
      expect(notification1.equals(notification4)).toEqual(false);
      expect(notification1.interest.equals(interest1)).toEqual(true);

      notification2.assign(notification1);
      expect(notification1.equals(notification2)).toEqual(true);
   });

   it("Need to create, test & assign Notification", function () {

      var notificationId1: string = "Playing";
      var notificationId2: string = "Paused";

      var interest1: Interest = new Interest(notificationId1);
      var interest2: Interest = new Interest(notificationId2);

      var notification1: Notification = new Notification(interest1);
      var notification2: Notification = new Notification(interest2);
      var notification3: Notification = new Notification(notification1);
      var notification4: Notification = new Notification();

      expect(notification1.equals(notification1)).toEqual(true);
      expect(notification1.equals(notification2)).toEqual(false);
      expect(notification1.equals(notification3)).toEqual(true);
      expect(notification1.equals(notification4)).toEqual(false);
      expect(notification1.interest.equals(interest1)).toEqual(true);

      notification2.assign(notification1);
      expect(notification1.equals(notification2)).toEqual(true);
   });

   it("Need to create, test & assign NotificationFor<EventData>", function () {

      var notificationId1: string = "Playing";
      var notificationId2: string = "Paused";

      var interest1: Interest = new Interest(notificationId1);
      var interest2: Interest = new Interest(notificationId2);

      var notification1: NotificationFor<number> = new NotificationFor<number>(interest1, 1);
      var notification2: NotificationFor<number> = new NotificationFor<number>(interest2, 2);
      var notification3: NotificationFor<number> = new NotificationFor<number>(notification1);
      var notification4: NotificationFor<number> = new NotificationFor<number>();

      expect(notification1.equals(notification1)).toEqual(true);
      expect(notification1.equals(notification2)).toEqual(false);
      expect(notification1.equals(notification3)).toEqual(true);
      expect(notification1.equals(notification4)).toEqual(false);
      expect(notification1.interest.equals(interest1)).toEqual(true);
      expect(notification1.eventData === 1).toEqual(true);

      notification2.assign(notification1);
      expect(notification1.equals(notification2)).toEqual(true);
   });

   it("Need to create, test & assign ObserverInterest", function () {

      var observer = new MockObserver();
      var notificationId1: string = "Playing";
      var notificationId2: string = "Paused";

      var interest1: Interest = new Interest(notificationId1);
      var interest2: Interest = new Interest(notificationId2);

      var observerInterest1: ObserverInterest = new ObserverInterest (observer, interest1);
      var observerInterest2: ObserverInterest = new ObserverInterest (observer, interest2);
      var observerInterest3: ObserverInterest = new ObserverInterest (observerInterest1);
      var observerInterest4: ObserverInterest = new ObserverInterest();

      expect(observerInterest1.equals(observerInterest1)).toEqual(true);
      expect(observerInterest1.equals(observerInterest2)).toEqual(false);
      expect(observerInterest1.equals(observerInterest3)).toEqual(true);
      expect(observerInterest1.equals(observerInterest4)).toEqual(false);
      expect(observerInterest1.interest.equals(interest1)).toEqual(true);
      expect(observerInterest1.observer === observer).toEqual(true);

      observerInterest4.assign(observerInterest1);
      expect(observerInterest1.equals(observerInterest4)).toEqual(true);
   });
   
   it("Need to create, test & assign NotificationRouter", function () {

      var observer = new MockObserver();
      var observer2 = new MockObserver();

      let observationRouter1 = new NotificationRouter(observer.notifyInt.bind(observer) as FunctionForNotification);
      var observationRouter2: NotificationRouter = new NotificationRouter(observer.notifyInt.bind(observer2) as FunctionForNotification);
      var observationRouter3: NotificationRouter = new NotificationRouter(observationRouter1);
      var observationRouter4: NotificationRouter = new NotificationRouter();

      expect(observationRouter1.equals(observationRouter1)).toEqual(true);
      expect(observationRouter1.equals(observationRouter2)).toEqual(false);
      expect(observationRouter1.equals(observationRouter3)).toEqual(true);
      expect(observationRouter1.function !== undefined).toEqual(true);
      expect(observationRouter4.function === undefined).toEqual(true);

      observationRouter2.assign(observationRouter1);
      expect(observationRouter1.equals(observationRouter2)).toEqual(true);
   });


   it("Need to create, test & assign NotificationRouterFor", function () {

      var observer = new MockObserver();
      var observer2 = new MockObserver();

      var observationRouter1: NotificationRouterFor<number> = new NotificationRouterFor<number>(observer.notifyInt.bind(observer));
      var observationRouter2: NotificationRouterFor<number> = new NotificationRouterFor<number>(observer.notifyInt.bind(observer2));
      var observationRouter3: NotificationRouterFor<number> = new NotificationRouterFor<number>(observationRouter1);
      var observationRouter4: NotificationRouterFor<number> = new NotificationRouterFor<number>();

      expect(observationRouter1.equals(observationRouter1)).toEqual(true);
      expect(observationRouter1.equals(observationRouter2)).toEqual(false);
      expect(observationRouter1.equals(observationRouter3)).toEqual(true);
      expect(observationRouter1.function !== undefined).toEqual(true);
      expect(observationRouter4.function === undefined).toEqual(true);

      observationRouter2.assign(observationRouter1);
      expect(observationRouter1.equals(observationRouter2)).toEqual(true);
   });

   it("Needs to flow notifications from Notifier to Observer", function () {

      var notifier = new Notifier();
      var observerYes = new MockObserver();
      var observerNo = new MockObserver();

      var notificationId1: string = "Playing";
      var notificationId2: string = "Paused";

      var interest1: Interest = new Interest(notificationId1);
      var interest2: Interest = new Interest(notificationId2);

      var observerInterest1: ObserverInterest = new ObserverInterest(observerYes, interest1);
      var observerInterest2: ObserverInterest = new ObserverInterest(observerNo, interest2);

      notifier.addObserver(observerInterest1);
      notifier.addObserver(observerInterest2);

      // Call sequence 1 - simple notification
      var notification: Notification = new Notification(interest1);

      notifier.notifyObservers(interest1, notification);

      throwIfUndefined (observerYes._lastNotification);

      expect(observerYes._lastNotification.equals(notification) === true).toEqual(true);
      expect((observerNo._lastNotification === undefined) === true).toEqual(true);

      // Call sequence 2 - notification with Notification payload
      var notificationForInt: NotificationFor<number> = new NotificationFor<number>(interest1, 1);

      notifier.notifyObservers(interest1, notificationForInt);

      throwIfUndefined (observerYes._lastNotification);

      expect(observerYes._lastNotification.equals(notificationForInt) === true).toEqual(true);
      expect((observerNo._lastNotification === undefined) === true).toEqual(true);

      // Tidy
      expect(notifier.removeObserver(observerInterest2) === true).toEqual(true);
      expect(notifier.removeObserver(observerInterest2) === false).toEqual(true);
      notifier.removeAllObservers();

      // Call sequence 3 - routed 
      var observationRouter3: NotificationRouter = new NotificationRouter (observerYes.notify.bind(observerYes));

      var observerInterest3: ObserverInterest = new ObserverInterest(observationRouter3, interest1);
      notifier.addObserver(observerInterest3);

      var notification3: Notification = new Notification(interest1);
      notifier.notifyObservers(interest1, notification3);
      
      throwIfUndefined (observerYes._lastNotification);

      expect(observerYes._lastNotification.equals(notification3) === true).toEqual(true);
      expect((observerNo._lastNotification === undefined) === true).toEqual(true);

      expect(notifier.removeObserver(observerInterest3) === true).toEqual(true);
      notifier.removeAllObservers();

      // Call sequence 4 - routed & with a payload
      var observationRouter4: NotificationRouterFor<number> = new NotificationRouterFor<number>(observerYes.notifyInt.bind(observerYes));

      var observerInterest4: ObserverInterest = new ObserverInterest(observationRouter4, interest1);
      notifier.addObserver(observerInterest4);

      var notification4: NotificationFor<number> = new NotificationFor<number>(interest1, 2);
      notifier.notifyObservers(interest1, notification4);
      
      throwIfUndefined (observerYes._lastNotification);

      expect(observerYes._lastNotification.equals(notification4) === true).toEqual(true);
      expect((observerNo._lastNotification === undefined) === true).toEqual(true);
      notifier.removeAllObservers();
   });
});
****************************************

****************************************
Boxer\test\persona.test.ts
****************************************
'use strict';
// Copyright Braid technologies ltd, 2024
import { MDynamicStreamable } from '../core/StreamingFramework';
import { Persona} from '../core/Persona';
import { EIcon } from '../core/Icons';
import { IKeyGenerator } from '../core/IKeyGenerator';
import { getDefaultKeyGenerator } from '../core/IKeyGeneratorFactory';

import { expect } from 'expect';
import { describe, it } from 'mocha';

var keyGenerator: IKeyGenerator = getDefaultKeyGenerator();

var myId: string = "1234";
var myName: string = "Jon";
var myEmail: string = "jon@a.com";
var myThumbnail: string = "abcd";
var myLastSeenAt = new Date();

var someoneElsesId: string = "5678";
var someoneElsesName: string = "Barry";
var someoneElsesEmail: string = "barry@b.com";
var someoneElsesThumbnail: string = "abcdefgh";
var someoneElsesLastSeenAt = new Date(0);

describe("Persona", function () {

   var persona1: Persona, persona2: Persona, personaErr:Persona;

   persona1 = new Persona(myId, myName, myEmail, EIcon.kPersonPersona, myThumbnail, myLastSeenAt);

   persona2 = new Persona(someoneElsesId, someoneElsesName, someoneElsesEmail, EIcon.kPersonPersona, someoneElsesThumbnail, someoneElsesLastSeenAt);

   it("Needs to construct an empty object", function () {

      var personaEmpty = new Persona();

      expect(personaEmpty.name).toEqual("");
      expect(keyGenerator.couldBeAKey (personaEmpty.id)).toEqual(true);      
   });

   it("Needs to allow undefined ID", function () {

      var caught: boolean = false;
      try {
         var personaErr: Persona = new Persona(undefined, myId, myEmail, EIcon.kPersonPersona, myThumbnail, myLastSeenAt);
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(false);
   });

   it("Needs to detect invalid ID", function () {

      var caught: boolean = false;
      try {
         var personaErr: Persona = new Persona(1 as unknown as string, myId, myEmail, EIcon.kPersonPersona, myThumbnail, myLastSeenAt);
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);
   });

   it("Needs to detect invalid name", function () {

      var caught: boolean = false;
      try {
         var personaErr: Persona = new Persona(myId, undefined, myEmail, EIcon.kPersonPersona, myThumbnail, myLastSeenAt);
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);
   });

   it("Needs to throw error if checkedThumbnail is not satisfied", function () {

      var personaEmpty = new Persona();

      var caught: boolean = false;
      try {
         let thumb = personaEmpty.checkedThumbnailB64;

      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);
   });

   it("Needs to detect invalid thumbnail", function () {

      var caught: boolean = false;
      try {
         var personaErr: Persona = new Persona(myId, myName, myEmail, EIcon.kFromBcd, "", myLastSeenAt);
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);
   });

   it("Needs to compare for equality and inequality", function () {

      var personaNew: Persona = new Persona(persona1.id, persona1.name, persona1.email, EIcon.kPersonPersona, persona1.thumbnailB64, persona1.lastSeenAt);

      expect(persona1.equals(persona1)).toEqual(true);
      expect(persona1.equals(personaNew)).toEqual(true);
      expect(persona1.equals(persona2)).toEqual(false);
   });
   
   it("Needs to detect inequality on date", function () {

      var personaNew: Persona = new Persona(persona1.id, persona1.name, persona1.email, persona1.icon, persona1.thumbnailB64, new Date());

      expect(persona1.equals(personaNew)).toEqual(false);
   });

   it("Needs to correctly store attributes", function () {
         
      expect(persona1.name === myName).toEqual(true);
      expect(persona1.thumbnailB64 === myThumbnail).toEqual(true);
      expect(persona1.checkedThumbnailB64 === myThumbnail).toEqual(true);
      expect(persona1.lastSeenAt.getTime() === myLastSeenAt.getTime()).toEqual(true);
   });

   it("Needs to copy construct", function () {

      let persona2: Persona = new Persona(persona1);

      expect(persona1.equals(persona2) === true).toEqual(true);
   });

   it("Needs to correctly change attributes", function () {

      var personaNew: Persona = new Persona(persona1.id, persona1.name, persona1.email, EIcon.kPersonPersona, persona1.thumbnailB64, persona1.lastSeenAt);

      personaNew.id = someoneElsesId;
      personaNew.name = someoneElsesName;
      personaNew.email = someoneElsesEmail;
      personaNew.thumbnailB64 = someoneElsesThumbnail;
      personaNew.lastSeenAt = someoneElsesLastSeenAt;

      expect(persona2.equals (personaNew)).toEqual(true);
   });

   it("Needs to catch errors on change id attributes", function () {

      var caught: boolean = false;
      try {
         persona1.id = 1 as unknown as string;
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);

   });

   it("Needs to throw errors on change name attribute", function () {

      var caught: boolean = false;
      try {
         persona1.name = undefined as unknown as string;
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);

   });

   it("Needs to throw errors on change email attribute", function () {

      var caught: boolean = false;
      try {
         persona1.email = undefined as unknown as string;
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);

   });

   it("Needs to throw errors on change thumbnail attribute using empty string", function () {

      var caught: boolean = false;
      try {
         persona1.thumbnailB64 = "";
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);

   });

   it("Needs to throw errors on change thumbnail attribute using invalid B64 string", function () {

      var caught: boolean = false;
      try {
         persona1.thumbnailB64 = "abcde";
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);
   });

   it("Needs to fall back to browser shim thumbnail attribute ", function () {

      var caught: boolean = false;
      try {
         persona1.setThumbnailB64 ("abcdefgh", true);
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(false);

   });

   it("Needs to throw errors when falling back to browser shim thumbnail attribute ", function () {

      var caught: boolean = false;
      try {
         persona1.setThumbnailB64(1 as unknown as string, true);
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);

   });

   it("Needs to test unknown status", function () {

      let unknown: Persona = Persona.unknown();
      let unknown2: Persona = new Persona(unknown.id, unknown.name, unknown.email, unknown.icon, unknown.thumbnailB64, unknown.lastSeenAt);

      expect(Persona.isUnknown(unknown)).toEqual(true);
      expect(Persona.isUnknown(unknown2)).toEqual(true);
   });

   it("Needs to convert to and from JSON()", function () {

      var stream: string = persona1.streamOut();

      var personaNew: Persona = new Persona(persona1.id, persona1.name, persona1.email, persona1.icon, persona1.thumbnailB64, persona1.lastSeenAt);
      personaNew.streamIn(stream);

      expect(persona1.equals(personaNew)).toEqual(true);
   });

   it("Needs to dynamically create Persona to and from JSON()", function () {

      var stream: string = persona1.flatten();

      var personaNew: Persona = new Persona();

      expect(persona1.equals(personaNew)).toEqual(false);

      personaNew = MDynamicStreamable.resurrect(stream) as Persona;

      expect(persona1.equals(personaNew)).toEqual(true);
   });

});
****************************************

****************************************
Boxer\test\queue.test.ts
****************************************
// Copyright Braid technologies ltd, 2024

import { expect } from 'expect';
import { describe, it } from 'mocha';

import { Queue } from '../core/Queue';

describe("Queue", function () {
  
   
   it("returns empty when initialised.", function () {
      
      let queue = new Queue<string>();
      expect(queue.peek()).toEqual(undefined); 
   });
   
   it("Enqueues & dequeues single item.", function () {

      let queue = new Queue<string>();
      queue.enqueue("One");
      expect(queue.peek()).toEqual("One");
      queue.dequeue();
      expect(queue.peek()).toEqual(undefined); 
   });
   
   it("Enqueues & dequeues multiple items.", function () {

      let queue = new Queue<string>();
      queue.enqueue("One");
      queue.enqueue("Two");
      expect(queue.peek()).toEqual("One");
      queue.dequeue();
      expect(queue.peek()).toEqual("Two");
   });
});
****************************************

****************************************
Boxer\test\sharedembedding.test.ts
****************************************
'use strict';
// Copyright Braid Technologies ltd, 2024
import { MDynamicStreamable } from '../core/StreamingFramework';
import { SharedEmbedding } from '../core/SharedEmbedding';
import { IKeyGenerator } from '../core/IKeyGenerator';
import { getDefaultKeyGenerator } from '../core/IKeyGeneratorFactory';

import { expect } from 'expect';
import { describe, it } from 'mocha';

var keyGenerator: IKeyGenerator = getDefaultKeyGenerator();

var myId: string = "1234";
var myUrl: string = "https://www.sample.com";
var myConversationId = "1234";
var myEmail = "jon@mail.com";

var someoneElsesId: string = "5678";
var someoneElsesUrl: string = "https://www.anothersample.com";
var someoneElsesConversationId = "5678";
var someoneElsesEmail = "barry@mail.com";

describe("SharedEmbedding", function () {

   var sharedEmbedding1: SharedEmbedding, sharedEmbedding2: SharedEmbedding, messageErr:SharedEmbedding;

   sharedEmbedding1 = new SharedEmbedding(myId, myUrl, myConversationId, undefined);

   sharedEmbedding2 = new SharedEmbedding(someoneElsesId, someoneElsesUrl, someoneElsesConversationId, undefined);

   it("Needs to construct an empty object", function () {

      var messageEmpty = new SharedEmbedding();

      expect(typeof (messageEmpty.url)).toEqual('undefined');
      expect(keyGenerator.couldBeAKey (messageEmpty.id)).toEqual(true);      
   });

   it("Needs to allow undefined ID", function () {

      var caught: boolean = false;
      try {
         messageErr = new SharedEmbedding(undefined, myUrl, myConversationId, undefined);
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(false);
   });

   it("Needs to detect invalid ID", function () {

      var caught: boolean = false;
      try {
         messageErr = new SharedEmbedding(1 as unknown as string, myUrl, myConversationId, undefined);
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);
   });


   it("Needs to compare for equality and inequality", function () {

      var messageNew: SharedEmbedding = new SharedEmbedding(sharedEmbedding1.id, sharedEmbedding1.url, 
                                                            sharedEmbedding1.conversationId,  
                                                            sharedEmbedding1.likes);

      expect(sharedEmbedding1.equals(sharedEmbedding1)).toEqual(true);
      expect(sharedEmbedding1.equals(messageNew)).toEqual(true);
      expect(sharedEmbedding1.equals(sharedEmbedding2)).toEqual(false);
   });
   

   it("Needs to throw error if like on undefined url", function () {

      var messageEmpty = new SharedEmbedding();

      var caught: boolean = false;
      try {
         let thumb = messageEmpty.like (myEmail);

      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);
   });

   it("Needs to correctly store attributes", function () {
         
      expect(sharedEmbedding1.url === myUrl).toEqual(true);
      expect(sharedEmbedding1.netLikeCount === 0).toEqual(true);
   });

   it("Needs to copy construct", function () {

      let embedding2: SharedEmbedding = new SharedEmbedding(sharedEmbedding1);

      expect(sharedEmbedding1.equals(embedding2) === true).toEqual(true);
   });

   it("Needs to correctly change attributes", function () {

      var messageNew: SharedEmbedding = new SharedEmbedding(sharedEmbedding1.id, sharedEmbedding1.url, 
                                                            sharedEmbedding1.conversationId, 
                                                            sharedEmbedding1.likes);

      messageNew.id = someoneElsesId;
      messageNew.url = someoneElsesUrl;
      messageNew.conversationId = someoneElsesConversationId;

      expect(sharedEmbedding2.equals (messageNew)).toEqual(true);
   });

   it("Needs to catch errors on change id attributes", function () {

      var caught: boolean = false;
      try {
         sharedEmbedding1.id = 1 as unknown as string;
      } catch (e) {
         caught = true;
      }
      expect(caught).toEqual(true);

   });

   it("Needs to convert to and from JSON()", function () {

      var stream: string = sharedEmbedding1.streamOut();

      var messageNew: SharedEmbedding = new SharedEmbedding(sharedEmbedding1.id, sharedEmbedding1.url, 
                                                            sharedEmbedding1.conversationId,
                                                            sharedEmbedding1.likes);

      messageNew.streamIn(stream);

      expect(sharedEmbedding1.equals(messageNew)).toEqual(true);
   });  

   it("Needs to dynamically create SharedEmbedding to and from JSON()", function () {

      var stream: string = sharedEmbedding1.flatten();

      var messageNew: SharedEmbedding = new SharedEmbedding();

      expect(sharedEmbedding1.equals(messageNew)).toEqual(false);

      messageNew = MDynamicStreamable.resurrect(stream) as SharedEmbedding;

      expect(sharedEmbedding1.equals(messageNew)).toEqual(true);
   });
    
   it("Needs to process a single like", function () {

      var messageEmpty = new SharedEmbedding();
      messageEmpty.url = sharedEmbedding1.url;

      messageEmpty.like(myEmail);

      expect(messageEmpty.netLikeCount).toEqual(1);  
      expect(messageEmpty.isLikedBy (myEmail)).toEqual (true);  
      expect(messageEmpty.isLikedBy ("blah")).toEqual (false);      
   });

   it("Needs to process a duplicate like", function () {

      var messageEmpty = new SharedEmbedding();
      messageEmpty.url = sharedEmbedding1.url;

      messageEmpty.like(myEmail);
      messageEmpty.like(myEmail);

      expect(messageEmpty.netLikeCount).toEqual(1);     
   });   

   it("Needs to process a single unslike", function () {

      var messageEmpty = new SharedEmbedding();
      messageEmpty.url = sharedEmbedding1.url;

      messageEmpty.unlike(myEmail);

      expect(messageEmpty.netLikeCount).toEqual(0);     
   });

   it("Needs to process a duplicate unlike", function () {

      var messageEmpty = new SharedEmbedding();
      messageEmpty.url = sharedEmbedding1.url;

      messageEmpty.like(myEmail);      
      messageEmpty.unlike(myEmail);
      messageEmpty.unlike(myEmail);

      expect(messageEmpty.netLikeCount).toEqual(0);     
   });

   it("Needs to process a like then unlike", function () {

      var messageEmpty = new SharedEmbedding();
      messageEmpty.url = sharedEmbedding1.url;

      messageEmpty.like(myEmail);
      messageEmpty.unlike(myEmail);
      
      expect(messageEmpty.netLikeCount).toEqual(0);     
   });    
        
});
****************************************

****************************************
Boxer\test\uuid.test.ts
****************************************
'use strict';
// Copyright Braid technologies ltd, 2024
import { expect } from 'expect';
import { describe, it } from 'mocha';
import { IKeyGenerator } from '../core/IKeyGenerator';
import { getDefaultKeyGenerator } from '../core/IKeyGeneratorFactory';

const badUuid = "9a0583f5xca56-421b-8545-aa23032d6c93"

var keyGenerator: IKeyGenerator = getDefaultKeyGenerator();

describe("Uuid", function () {

   it("Needs to create UUID", function () {

      var newUuid: string = keyGenerator.generateKey();
      expect(newUuid.length == 36).toEqual(true);
   });

   it("Needs to test valid UUID", function () {

      var newUuid: string = keyGenerator.generateKey();
      expect(keyGenerator.couldBeAKey(newUuid)).toEqual(true);

      expect(keyGenerator.couldBeAKey("")).toEqual(false);
      expect(keyGenerator.couldBeAKey(badUuid)).toEqual(false);
   });   

   it("Needs to generate a secret value", function () {

      var newSecret: string = keyGenerator.generateSecret();

      expect(newSecret.length > 0).toEqual(true);
   });    
});

describe("Uuid - without Blob", function () {

   var oldBlob: any = global.Blob;

   beforeEach(() => {
      (global.Blob as any) = undefined;
   });

   afterEach(() => {
      (global.Blob as any) = oldBlob;
   });

   it("Needs to create UUID without Blob", function () {

      var newUuid: string = keyGenerator.generateKey();

      expect(newUuid.length == 36).toEqual(true);
   });

   it("Needs to test valid UUID without Blob", function () {

      var newUuid: string = keyGenerator.generateKey();
      expect(keyGenerator.couldBeAKey(newUuid)).toEqual(true);

      expect(keyGenerator.couldBeAKey("")).toEqual(false);
      expect(keyGenerator.couldBeAKey(badUuid)).toEqual(false);
   });
});
****************************************

****************************************
Boxer\ui\AnimatedIconButton.tsx
****************************************
/*! Copyright Braid Technologies 2024 */

// React
import React, { useState, useEffect } from 'react';

// Fluent
import {
   makeStyles, 
   Menu,
   MenuButton,
   MenuItem,
   MenuDivider,
   MenuList,
   MenuPopover,
   MenuTrigger,   
} from '@fluentui/react-components';

import {
   Lightbulb24Filled
} from '@fluentui/react-icons';
import { EUIStrings } from './UIStrings';

const animatedGlowIcon = makeStyles({
  root: {        
     boxShadow: '0px 0px 0px 0px white;'
  },
});

export enum EAnimatedIconButtonTypes { // Must mirror MessageBarIntent, with addition of 'nothing' if you dont want to display a message. 
   kLightBulb
}

interface IAnimatedIconButtonProps {
   animate: boolean;
   icon: EAnimatedIconButtonTypes;  
   promptAnimated: string;
   promptUnamimated: string; 
   onClick () : void;
   onCancel () : void;
}

let animatedColourSequence = ['#333333', '#444444', '#555555', '#666666', '#777777', '#888888', '#999999', '#AAAAAA', '#BBBBBB', '#CCCCCC', '#DDDDDD', '#EEEEEE', '#FFFFFF', '#FFFFFF', '#FFFFFF', '#FFFFFF'];
let staticColourSeqeunce = ['#333333'];

// create a forceUpdate hook
// https://stackoverflow.com/questions/46240647/how-to-force-a-functional-react-component-to-render
function useForceUpdate() {
   const [value, setValue] = useState(0); // simple integer state
   return () => setValue(value => value + 1); // update state to force render
}

export const AnimatedIconButton = (props: IAnimatedIconButtonProps) => {

   const [seq, setSeq] = useState<number>(0);
   let localSeq = seq;

   // call the force update hook 
   const forceUpdate = useForceUpdate(); 
      
   function animateColours () : void {
      setSeq (localSeq + 1);
      localSeq = localSeq + 1;
      if (localSeq > animatedColourSequence.length) {
         localSeq = 0;
         setSeq (0);
      }     
      forceUpdate ();             
   } 

   useEffect(() => {
      const interval = setInterval(animateColours, 100);
     
      return (() => {
         if (interval)
            clearInterval(interval);
      });
   }, []);

   const animatedGlowIconClasses = animatedGlowIcon();

   const onClick = (ev: React.MouseEvent<HTMLDivElement>) => {
      props.onClick ();
   }
   const onCancel = (ev: React.MouseEvent<HTMLDivElement>) => {
      props.onCancel ();
   }   

   return (
         <Menu>
            <MenuTrigger disableButtonEnhancement>
               <MenuButton  disabled={!props.animate}
                  icon={<Lightbulb24Filled 
                  className={animatedGlowIconClasses.root} 
                  primaryFill={props.animate ? animatedColourSequence[seq] : staticColourSeqeunce[0]}/>} 
                   />
            </MenuTrigger>

            <MenuPopover>
               <MenuList>
                  <MenuItem onClick={onClick}>{props.promptAnimated}</MenuItem>
                  <MenuDivider/>
                  <MenuItem onClick={onCancel}>{EUIStrings.kNoThanks}</MenuItem>
               </MenuList>
            </MenuPopover>
         </Menu>              
  );

         /* 
         <Tooltip content={props.animate ? props.promptAnimated : props.promptUnamimated} relationship="label">
         <Button 
            disabled={!props.animate}
            icon={<Lightbulb24Filled 
               className={animatedGlowIconClasses.root} 
               primaryFill={props.animate ? animatedColourSequence[seq] : staticColourSeqeunce[0]}/>} 
            onClick={onClick}/>       
            </Tooltip> 
            */  
};
****************************************

****************************************
Boxer\ui\AppEntry.tsx
****************************************
/*! Copyright Braid Technologies 2024 */

// React
import React, { useState } from 'react';
import { createRoot } from "react-dom/client";

// Fluent
import {
   FluentProvider, teamsDarkTheme, makeStyles
} from '@fluentui/react-components';

import { getDefaultLoginEnvironment } from '../../CommonTs/src/IEnvironmentFactory';

// Local
import { Persona } from '../core/Persona';
import { EIcon } from '../core/Icons';
import { JoinDetails } from '../core/JoinDetails';
import { EUIStrings } from './UIStrings';
import { innerColumnStyles } from './ColumnStyles';
import { EMainPageMessageTypes, MainPageMessageRow } from './MainPageMessage';
import { JoinPane } from './JoinPane';
import { ConversationControllerRow } from './ConversationController';
import { SessionKey, ConversationKey } from '../core/Keys';
import { getDefaultKeyGenerator } from '../core/IKeyGeneratorFactory';

export interface IAppProps {

}

const fluidFillPageStyles = makeStyles({
   root: {
      minWidth: "512px",  // Ask for enough for at least the error message, plus don't crowd the entry text box - this is a trial value at 512    
   },
});

const pageOuterStyles = makeStyles({
   root: {
      display: 'flex',
      flexDirection: 'row',
      alignItems: 'stretch',  /* for a row, the main axis is vertical, flex-end is items aligned to the bottom of the row */
      justifyContent: 'center', /* for a row, the cross-axis is horizontal, center means vertically centered */
      height: '100vh', /* fill the screen with flex layout */ 
      width: '100%',  /* fill the screen with flex layout */       
      marginLeft: '0px',
      marginRight: '0px',
      marginTop: '0px',
      marginBottom: '0px',
      paddingLeft: '20px',
      paddingRight: '20px',
      paddingTop: '20px',
      paddingBottom: '20px',
      webkitTextSizeAdjust: '100%'
   },
});

export const App = (props: IAppProps) => {

   let localUserPersona = new Persona ();
   localUserPersona.icon = EIcon.kPersonPersona;

   // Environment.override (EEnvironment.kProduction);

   // This little block attempts to pick up a joinpath from the URL after the #value
   // If it looks valid, we pre-populate the joining form
   // *** BE CAREFUL HERE - CAN GENERATE INFINITE RE_RENDERING ***
   var hashValue: string = "";
   if (window.location.hash)
      hashValue = window.location.hash.substring(1);
   
   let joinAttempt = new JoinDetails (hashValue);
   localUserPersona.email = joinAttempt.email; 
   localUserPersona.name = joinAttempt.name;
   const secret = joinAttempt.secret;

   const [lastMessage, setLastMessage] = useState<string>("");
   const [lastMessageType, setLastMessageType] = useState<EMainPageMessageTypes> (EMainPageMessageTypes.kNothing);
   const [lastMessageIsDismissable, setLastMessageIsDismissable] = useState<boolean>(true);   
   
   const [sessionKey, setSessionKey] = useState<SessionKey>(joinAttempt.session);
   const [conversationKey, setConversationKey] = useState<ConversationKey>(joinAttempt.conversation);

   const fluidFillPageClasses = fluidFillPageStyles();
   const pageOuterClasses = pageOuterStyles();
   const innerColumnClasses = innerColumnStyles();
   
   let keyGenerator = getDefaultKeyGenerator();

   if (secret.length > 0 
      && (!keyGenerator.matchesSavedSecret (secret)) 
      && lastMessage !== EUIStrings.kSecretError) {

      setLastMessage (EUIStrings.kSecretError);
      setLastMessageType (EMainPageMessageTypes.kWarning);    
      setLastMessageIsDismissable(false);            
   }

   function onConnect (sessionKey_: SessionKey, conversationKey_: ConversationKey, secret_: string) : void  {
      
      setLastMessage ("");
      setLastMessageType (EMainPageMessageTypes.kNothing);   
      setLastMessageIsDismissable(true);  

      setSessionKey (sessionKey_);
      setConversationKey (conversationKey_);

      keyGenerator.saveSecret (secret_);

      // Start the login process by redirecting to the login API
      // with no email address and no name bcs thats what we get from login
      let query = JoinDetails.toString ("", "", sessionKey_, conversationKey_, secret_);

      let environment = getDefaultLoginEnvironment ();
      let loginUrl = environment.loginWithLinkedInApi();

      location.replace (loginUrl + '?' + query);
   }

   function onConnectError (hint_: string) : void  {

      setLastMessage (EUIStrings.kJoinApiError);
      setLastMessageType (EMainPageMessageTypes.kError);
   }

   function onFluidError (hint_: string) : void  {

      setLastMessage (EUIStrings.kJoinApiError);
      setLastMessageType (EMainPageMessageTypes.kError);
      setLastMessageIsDismissable(true);        

      // Clear the coversation key - takes us back to the join page.
      setConversationKey (new ConversationKey (""));      
   }
   
   function onAiError (hint_: string) : void  {

      setLastMessage (EUIStrings.kAiApiError);
      setLastMessageType (EMainPageMessageTypes.kError);
      setLastMessageIsDismissable(true);        
   }

   function onDismissMessage () : void {

      setLastMessage ("");
      setLastMessageType (EMainPageMessageTypes.kNothing);
      setLastMessageIsDismissable(true);        
   }

   return (
         <FluentProvider theme={teamsDarkTheme} className={fluidFillPageClasses.root}>            
            <div className={pageOuterClasses.root}>    
               <div className={innerColumnClasses.root}>             
      
                  <MainPageMessageRow 
                     intent={lastMessageType} 
                     text={lastMessage} 
                     dismissable={lastMessageIsDismissable}
                     onDismiss={onDismissMessage}/>
      
                  <ConversationControllerRow 
                     sessionKey={sessionKey}
                     conversationKey={conversationKey}
                     secret={secret}
                     localPersona={localUserPersona}
                     onFluidError={onFluidError}
                     onAiError={onAiError}>                          
                  </ConversationControllerRow>      

                  <JoinPane 
                     sessionKey={sessionKey} 
                     conversationKey={conversationKey}
                     secret={secret}                     
                     joinPersona={localUserPersona}                     
                     onConnect={onConnect} 
                     onConnectError={onConnectError}>                     
                  </JoinPane>   

               </div>
            </div>
         </FluentProvider>         
      );
}

// This allows code to be loaded in node.js for tests, even if we dont run actual React methods
if (document !== undefined && document.getElementById !== undefined) {
   const root = createRoot(document.getElementById("reactRoot") as HTMLElement);
   root.render(
      <App />
   ); 
}
****************************************

****************************************
Boxer\ui\ColumnStyles.tsx
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

// Fluent
import {
   FluentProvider, teamsDarkTheme, makeStyles, Text
} from '@fluentui/react-components';

import { EUIStrings } from './UIStrings';

export const innerColumnStyles = makeStyles({
   root: {
      display: 'flex',
      flexDirection: 'column',
      justifyContent: 'flex-start',    // start layout at the top       
      alignItems: 'center',
      maxWidth: EUIStrings.kMaxColumnWidth
   },
});

export const innerColumnMidStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'row'
   },
});

export const innerColumnFooterStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'row',
      marginTop: 'auto',
      alignSelf: 'flex-end'      
   },
});

export const textFieldStyles = makeStyles({
   root: {    
      width: '100%'
   },
});
****************************************

****************************************
Boxer\ui\ConversationController.tsx
****************************************
/*! Copyright Braid Technologies 2024 */
// The ConversationController manages the interaction with the shared data structures, and drives a ConversationView
// ConversationPage is largely a passive view, although it does notify the controller if the local users adds a message.

// React
import React, { useState, useReducer } from 'react';

// Local
import { throwIfUndefined } from '../core/Asserts';
import { Persona } from '../core/Persona';
import { Message } from '../core/Message';
import { SharedEmbedding, findInMap } from '../core/SharedEmbedding';
import { CaucusOf } from '../core/CaucusFramework';
import { SessionKey, ConversationKey } from '../core/Keys';
import { JoinDetails } from '../core/JoinDetails';
import { JoinPageValidator } from '../core/JoinPageValidator';
import { ConversationView } from './ConversationPane';
import { BraidFluidConnection } from '../core/BoxerFluidConnection';
import { Interest, NotificationFor, NotificationRouterFor, ObserverInterest } from '../core/NotificationFramework';
import { AIConnection } from '../core/AIConnection';
import { EUIStrings, initialQuestions } from './UIStrings';
import { EConfigNumbers, EConfigStrings } from '../core/ConfigStrings';
import { getRecordRepository } from '../core/IActivityRepositoryFactory';
import { IStoredUrlActivity, IStoredLikeUrlActivity, IStoredMessageActivity, 
         urlActivityRecordClassName, urlLikeActivityRecordClassName, messageActivityRecordClassName,
         urlActivityRecordSchemaNumber, urlLikeActivityRecordSchemaNumber, messageActivityRecordSchemaNumber } from '../core/ActivityRecord';

import { getDefaultKeyGenerator } from '../core/IKeyGeneratorFactory';
import { getDetaultAdminRepository} from '../core/IAdminRepository';
import { makeSummaryCall } from '../core/ApiCalls';

import { FindEnrichedChunkApi } from '../../CommonTs/src/FindEnrichedChunkApi';
import { getDefaultEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { IEnrichedChunkSummary, EChunkRepository, kDefaultSimilarityThreshold } from '../../CommonTs/src/EnrichedChunk';
import { EStorableApplicationIds } from '../../CommonTs/src/IStorable';

export interface IConversationControllerProps {

   sessionKey: SessionKey;
   conversationKey: ConversationKey;
   secret: string;
   localPersona: Persona; 
   onFluidError (hint_: string) : void;   
   onAiError (hint_: string) : void;     
}

let firstLoad = true;

export const ConversationControllerRow = (props: IConversationControllerProps) => {

   const [conversation, setConversation] = useState<Array<Message>>(new Array<Message>());
   const [audience, setAudience] = useState<Map<string, Persona>>(new Map<string, Persona>());
   const [sharedEmbeddings, setSharedEmbeddings] = useState<Map<string, SharedEmbedding>>(new Map<string, SharedEmbedding>());   
   const [fluidConnection, setFluidConnection] = useState<BraidFluidConnection | undefined>(undefined);
   const [joining, setJoining] = useState<boolean> (false);
   const [conversationKey, setConversationKey] = useState<ConversationKey> (props.conversationKey);   
   const [isBusy, setIsBusy] = useState<boolean>(false);
   const [suggested, setSuggested] = useState<Message|undefined>(undefined);  
   const [key, setKey] = useState<number> (0);
   const [suppressScroll, setSuppressScroll] = useState<boolean> (false);
   const [chatLevel, setChatLevel] = useState<number>(2);   
   const [userIsAdmin, setUserIsAdmin] = useState<boolean> (false);

   // async call to see if the local user is an administrator
   let repository = getDetaultAdminRepository();
   repository.isAdmin (props.localPersona).then ((result) => {
      if (userIsAdmin != result) {
         setUserIsAdmin (result)
      }
   });

   const [, updateState] = React.useState<object>();
   const forceUpdate = React.useCallback(() => updateState({}), []);

   function addMessage (fluidMessagesConnection_: BraidFluidConnection, message_: Message) : void {

      fluidMessagesConnection_.messageCaucus().add (message_.id, message_);

      // Save state and force a refresh                  
      let messageArray = fluidMessagesConnection_.messageCaucus().currentAsArray();      
      setConversation (messageArray);                
      forceUpdate ();   
      setSuppressScroll(false);      
   }

   function hasRecentHepfulStart (fluidMessagesConnection_: BraidFluidConnection) : boolean {

      let messageArray = fluidMessagesConnection_.messageCaucus().currentAsArray();  

      let currentTime = new Date();
      
      for (let i = 0; i < messageArray.length; i++) {

         if (messageArray[i].authorId === EConfigStrings.kLLMGuid
            && messageArray[i].isUnPrompted()) {

               let messageTime = messageArray[i].sentAt;

               let difference = currentTime.getTime() - messageTime.getTime();

               if (difference < EConfigNumbers.kHelpfulPromptMinimumGapMins * 1000) {
                  return true;
               }
         }
      }

      return false;
   }

   function makeInitialSuggestion (fluidMessagesConnection_: BraidFluidConnection, isInitial: boolean) : void {

      setIsBusy (true);

      setTimeout(() => {

         let messageArray = fluidMessagesConnection_.messageCaucus().currentAsArray(); 

         if (messageArray.length > EConfigNumbers.kMinMessagesforRecap) {
            let message = new Message();

            message.authorId = EConfigStrings.kLLMGuid;            
            message.text = EUIStrings.kWelcomeWouldYouLikeRecap;
            message.sentAt = new Date();   
            
            setSuggested(message);
         }
         else
         if (! hasRecentHepfulStart (fluidMessagesConnection_)) {
            let message = new Message();

            message.authorId = EConfigStrings.kLLMGuid;
            const randomElement = initialQuestions[Math.floor(Math.random() * initialQuestions.length)];
            message.text = randomElement;
            message.sentAt = new Date();   
            
            setSuggested(message);
         } 
         setIsBusy (false);

      }, EConfigNumbers.kInitialHelpfulPromptDelayMsecs);  
   }

   function initialiseConnectionState (fluidMessagesConnection_: BraidFluidConnection, 
                                       conversationKey_: ConversationKey) : void {

      setFluidConnection (fluidMessagesConnection_);  

      // Notifications function for adds, removes, changes
      // Warning - this function must be declared after the call to setFluidConnection(), else it binds to the original value - which is always undefined. 
      // **************************************
      let remoteChanged = function (interest: Interest, data: NotificationFor<Message>) : void {

         let offlineRefresh = function () {       

            if (typeof fluidMessagesConnection_ !== "undefined") {

               throwIfUndefined(fluidMessagesConnection_);   // This is just to keep the compiler happy with statement below. 
               refreshLocalState (fluidMessagesConnection_);                      
            }
         }

         offlineRefresh();    
         forceUpdate ();            
      }      

      refreshLocalState (fluidMessagesConnection_);       

      let changeObserver = new NotificationRouterFor<Message> (remoteChanged);

      let changeObserverInterest = new ObserverInterest (changeObserver, CaucusOf.caucusMemberChangedInterest);
      let addedObserverInterest = new ObserverInterest (changeObserver, CaucusOf.caucusMemberAddedInterest);      
      let removedObserverInterest = new ObserverInterest (changeObserver, CaucusOf.caucusMemberRemovedInterest);

      // Hook up a notification function for adds, removes, changes in the message list       
      fluidMessagesConnection_.messageCaucus().addObserver (changeObserverInterest);
      fluidMessagesConnection_.messageCaucus().addObserver (addedObserverInterest);   
      fluidMessagesConnection_.messageCaucus().addObserver (removedObserverInterest);  
      
      // Hook up a notification function for adds, removes, changes in the participant list 
      fluidMessagesConnection_.participantCaucus().addObserver (changeObserverInterest);
      fluidMessagesConnection_.participantCaucus().addObserver (addedObserverInterest);   
      fluidMessagesConnection_.participantCaucus().addObserver (removedObserverInterest);     
      
      // Hook up a notification function for adds, removes, changes in the list of shared embeddings 
      fluidMessagesConnection_.sharedEmbeddingCaucus().addObserver (changeObserverInterest);
      fluidMessagesConnection_.sharedEmbeddingCaucus().addObserver (addedObserverInterest);   
      fluidMessagesConnection_.sharedEmbeddingCaucus().addObserver (removedObserverInterest);         
      
      setConversationKey (conversationKey_);  

      makeInitialSuggestion (fluidMessagesConnection_, true);    
      
      /* Volume testing - works fine as of May 30 204 - few seconds to load 1,000 messages, view renders at interactive speed. 
      if (firstLoad && Environment.environment() === EEnvironment.kLocal) {
         
         for (let i = 0; i < 1000; i++) {
            let volumeTestMessage = new Message ();
            volumeTestMessage.authorId = EConfigStrings.kLLMGuid;
            volumeTestMessage.text = i.toString();
            volumeTestMessage.sentAt = new Date();        
            fluidMessagesConnection_.messageCaucus().add (volumeTestMessage.id, volumeTestMessage);              
         }
   
         firstLoad = false;
      }   
      */    
   }

   let validater = new JoinPageValidator();

   if (validater.canAttemptJoin (props.localPersona.email, props.localPersona.name, 
                                     props.sessionKey, props.conversationKey) && 
      fluidConnection === undefined 
      && !joining) {

      setJoining(true);
      let fluidMessagesConnection = new BraidFluidConnection ( props.localPersona);
      
      if (! (props.conversationKey.looksValidConversationKey())) {

         fluidMessagesConnection.createNew (props.sessionKey, false).then (conversationKey_ => {
        
            initialiseConnectionState (fluidMessagesConnection, conversationKey_);
            setJoining (false);

         }).catch ((e : any) => {
         
            props.onFluidError ("Error creating new conversation, session: " + props.sessionKey.toString() + ".");
            setJoining (false);
         })
      }
      else {

         fluidMessagesConnection.attachToExisting (props.sessionKey, conversationKey, false).then (conversationKey_ => {

            initialiseConnectionState (fluidMessagesConnection, conversationKey_);
         
            setJoining (false);

         }).catch ((e: any) => {
         
            props.onFluidError (e? e.toString() : EUIStrings.kJoinApiError + " :" + conversationKey.toString() + ".");
            setJoining (false);
         })
      }
   }

   audience.set (props.localPersona.id, props.localPersona);  
   
   function refreshLocalState (fluidConnection_ : BraidFluidConnection) : void {

      // Save state and force a refresh
      let messageArray = fluidConnection_.messageCaucus().currentAsArray();   
      setConversation (messageArray);           
      let audienceMap = fluidConnection_.participantCaucus().current();  
      setAudience (audienceMap);            
      let sharedEmbeddingMap = fluidConnection_.sharedEmbeddingCaucus().current();
      setSharedEmbeddings (sharedEmbeddingMap);       
   }

   function refreshAndForceUpdate () : void {

      throwIfUndefined (fluidConnection);    
      
      refreshLocalState (fluidConnection);
                    
      forceUpdate ();       
   }

   function onSetBraidChattiness (level: number, max: number) : void {

      setChatLevel (level);         
   }

   function onExitConversation () : void {

      let query = JoinDetails.toString ("", "", props.sessionKey, new ConversationKey(""), "");
      location.replace (EConfigStrings.kHomeRelativeUrl + '#' + query);   
      location.reload();          
   }

   function onTrimConversation () : void {

      throwIfUndefined (fluidConnection);
      let fluidMessagesConnection : BraidFluidConnection = fluidConnection;      
      fluidMessagesConnection.resetMessages ();  
      refreshAndForceUpdate ();        
   }

   function onUnlikeUrl (url_: string) : void {
      
      let map = fluidConnection?.sharedEmbeddingCaucus().current();
      if (map) {
         let item = findInMap (url_, map);
         if (item) {
            item.unlike (props.localPersona.name);
            fluidConnection?.sharedEmbeddingCaucus().amend (item.id, item);           
         }
         else {
            item = new SharedEmbedding ();
            item.url = url_;
            item.unlike (props.localPersona.name);
            fluidConnection?.sharedEmbeddingCaucus().add (item.id, item);                            
         }
         map.set (item.id, item) ;
         setSharedEmbeddings (map);   
         setSuppressScroll(true);             
         forceUpdate();     
      }

      let keyGenerator = getDefaultKeyGenerator();

      let repository = getRecordRepository(props.sessionKey);
      let email = props.localPersona.email;

      let record : IStoredLikeUrlActivity= {
         id : keyGenerator.generateKey(),
         applicationId: EStorableApplicationIds.kBoxer,
         contextId: props.conversationKey.toString(),
         userId: email,
         created: new Date().toUTCString(),
         amended: new Date().toUTCString(),  
         functionalSearchKey: undefined,  
         className: urlLikeActivityRecordClassName,
         schemaVersion: urlLikeActivityRecordSchemaNumber, 
         url: url_,
         like: false  
      };
      repository.save (record);                                                            
   }

   function onLikeUrl (url_: string) : void {
      
      let keyGenerator = getDefaultKeyGenerator();

      let repository = getRecordRepository(props.sessionKey);
      let email = props.localPersona.email;

      let record : IStoredLikeUrlActivity= {
         id : keyGenerator.generateKey(), 
         applicationId: EStorableApplicationIds.kBoxer,
         contextId: props.conversationKey.toString(),
         userId: email,
         created: new Date().toUTCString(),
         amended: new Date().toUTCString(),  
         functionalSearchKey: undefined, 
         className: urlLikeActivityRecordClassName,
         schemaVersion: urlLikeActivityRecordSchemaNumber, 
         url: url_,
         like: true  
      };
      repository.save (record); 

      onPostiveUseOfUrl (url_);                                                            
   }

   function onClickUrl (url_: string) : void {
      
      let keyGenerator = getDefaultKeyGenerator();

      let repository = getRecordRepository(props.sessionKey);
      let email = props.localPersona.email;
      let record : IStoredUrlActivity = {
         id : keyGenerator.generateKey(), 
         applicationId: EStorableApplicationIds.kBoxer,
         contextId: props.conversationKey.toString(),
         userId: email,
         created: new Date().toUTCString(),
         amended: new Date().toUTCString(),  
         functionalSearchKey: undefined,  
         className: urlActivityRecordClassName,
         schemaVersion: urlActivityRecordSchemaNumber, 
         url: url_ 
      };
      repository.save (record); 

      onPostiveUseOfUrl (url_);                                                            
   }

   function onPostiveUseOfUrl (url_: string) : void {
      
      let map = fluidConnection?.sharedEmbeddingCaucus().current();
      if (map) {
         let item = findInMap (url_, map);
         if (item) {
            item.like (props.localPersona.name);
            fluidConnection?.sharedEmbeddingCaucus().amend (item.id, item);              
         }
         else {
            item = new SharedEmbedding ();
            item.url = url_;
            item.like (props.localPersona.name);
            fluidConnection?.sharedEmbeddingCaucus().add (item.id, item);            
         }
         map.set (item.id, item) ;
         setSharedEmbeddings (map);  
         setSuppressScroll(true);          
         forceUpdate();                   
      }

      // Get the summary of the URL the user clicked on      
      let api = new FindEnrichedChunkApi (getDefaultEnvironment(), props.sessionKey.toString());
      let query = {
         repositoryId: EChunkRepository.kBoxer,
         url: url_,
         maxCount: 1,
         similarityThreshold : kDefaultSimilarityThreshold
      }
      let summary = api.findChunkFromUrl (query);
      
      summary.then ((enriched: IEnrichedChunkSummary | undefined) => {

         if (enriched) {
            let summaryText = enriched.summary;
         
            let connection = new AIConnection (props.sessionKey);

            // Ask the LLM for a question based on the summary 
            connection.makeFollowUpCall (summaryText).then ((result_: Message | undefined) => {                                                                               
               if (result_) {
                  result_.authorId = props.localPersona.id;
                  setSuggested (result_);
               }         
            });  
         }
      });                                                                
   }

   function onDeleteMessage (id: string) : void {

      throwIfUndefined (fluidConnection);
      let fluidMessagesConnection : BraidFluidConnection = fluidConnection;      
      fluidMessagesConnection.messageCaucus().remove (id);  
      
      let repository = getRecordRepository(props.sessionKey);
      repository.removeMessageRecord (id); 

      setSuppressScroll(true);        

      refreshAndForceUpdate ();   
   }   

   function onAddSuggestedContent () {

      throwIfUndefined (fluidConnection);

      throwIfUndefined (suggested);      
      suggested.sentAt = new Date(); // Need to reset date so it goes at the end. 

      if (suggested.chunks && suggested.chunks.length > 0) {
         // If we have attached chunks, its a full message that we just replay
         addMessage (fluidConnection, suggested); 
      }
      else
      if (suggested.text === EUIStrings.kWelcomeWouldYouLikeRecap) {

         suggested.text = EUIStrings.kSummarising;
         addMessage (fluidConnection, suggested); 
         suggested.hookLiveAppend (onStreamedUpdate);         
         setIsBusy(true);    
         
         // If it is an offer of a summary, make a transcript then post it for summarisation
         let transcript = AIConnection.buildTranscript (fluidConnection.messageCaucus().currentAsArray(), 
                                                        fluidConnection.participantCaucus().current());  

         makeSummaryCall (props.sessionKey, transcript).then ((summary: string | undefined) => {

            if (summary) {
               suggested.text = summary;
               fluidConnection.messageCaucus().amend (suggested.id, suggested);                                 
            }
            suggested.unhookLiveAppend();    
            setIsBusy(false);                        

         }).catch ((e: any) => {
            suggested.unhookLiveAppend();  
            setIsBusy(false);                
         });
      }
      else {
         // else it is a suggested question, so we play it as a message that makes a request to the LLM, which sends all the context with it to the LLM
         let fullMessage = EConfigStrings.kLLMRequestSignature + " " + suggested.text;
         onSend (fullMessage);
      }

      setSuggested (undefined);
   }

   function onCancelSuggestedContent () {
      setSuggested (undefined);
   }
 
   // Hook the message for updates via streaming
   // When we get an update, push it to shared memory for other clients and then refresh the local UI
   let onStreamedUpdate = function  (message: Message, more: boolean) {

      if (fluidConnection) {

         fluidConnection.messageCaucus().amend (message.id, message); 

         setKey (Math.random());
      }
      if (!more)
         message.unhookLiveAppend(); 
   }     

   function onSend (messageText_: string) : void {

      throwIfUndefined (fluidConnection);
      let fluidMessagesConnection : BraidFluidConnection = fluidConnection;       

      let keyGenerator = getDefaultKeyGenerator();     

      // set up a message to append
      let message = new Message ();
      message.authorId = props.localPersona.id;
      message.text = messageText_;
      message.sentAt = new Date();

      // Push it to shared data
      fluidMessagesConnection.messageCaucus().add (message.id, message);
      setSuppressScroll (false);

      // Update the timestamp of the person who posted it
      let storedPerson = fluidMessagesConnection.participantCaucus().get (props.localPersona.id);
      storedPerson.lastSeenAt = message.sentAt;
      fluidMessagesConnection.participantCaucus().amend (storedPerson.id, storedPerson);    
      
      // Save it to the DB - async 
      let repository = getRecordRepository(props.sessionKey);
      let email = props.localPersona.email;

      let record : IStoredMessageActivity = {
         id : message.id, 
         applicationId: EStorableApplicationIds.kBoxer,
         contextId: props.conversationKey.toString(),
         userId: email,
         created: new Date().toUTCString(),
         amended: new Date().toUTCString(),  
         functionalSearchKey: undefined,         
         className: messageActivityRecordClassName,
         schemaVersion: messageActivityRecordSchemaNumber, 
         message: messageText_
      };
      repository.save (record);       

      // Save state and force a refresh
      // NB we keep local variables this time - dont just call the 'refreshLocalState' else you risk stale state
      let messageArray = fluidMessagesConnection.messageCaucus().currentAsArray();      
      setConversation (messageArray);      
      let audienceMap = fluidMessagesConnection.participantCaucus().current();
      setAudience (audienceMap);     
      let sharedEmbeddingMap = fluidMessagesConnection.sharedEmbeddingCaucus().current();
      setSharedEmbeddings (sharedEmbeddingMap);       

      // If LLM is being invoked we make a call here 
      // ======================================================
      if (AIConnection.isRequestForLLM (message, audienceMap)) {

         setIsBusy(true);         

         let query = AIConnection.buildEnrichmentQuery (messageArray, audienceMap);
         let responseShell = new Message (keyGenerator.generateKey(), EConfigStrings.kLLMGuid, message.id, 
                                          "", new Date()); 

         // Push the shell to shared data
         addMessage (fluidMessagesConnection, responseShell);                                             
            
         responseShell.hookLiveAppend (onStreamedUpdate);

         let connection = new AIConnection (props.sessionKey);

         connection.makeEnrichedCall (responseShell, query).then ((result_: Message | undefined) => {            

            setIsBusy(false);        
            if (result_)
               fluidConnection.messageCaucus().amend (result_.id, result_);                                               

         }).catch ( (e: any) => {
               
            props.onAiError (EUIStrings.kAiApiError);
              setIsBusy(false);      
             responseShell.unhookLiveAppend();                                          
         });            
      }
      else {
         // If the user looks they have miss-typed, we send a reminder.  
         // ======================================================      
         if (AIConnection.mightBeMissTypedRequestForLLM (message, audienceMap)) {

            // set up a message to append
            let response = new Message ();
            response.authorId = EConfigStrings.kLLMGuid;
            response.text = EUIStrings.kLLMNameReminder;
            response.sentAt = new Date();
            response.responseToId = message.id;

            // Push it to shared data
            addMessage (fluidMessagesConnection, response);                         
         }
         forceUpdate ();    
      }  
   } 

   let joinValidator = new JoinPageValidator ();

   // Only display conversation when we have all required details and we also have a secret that matches the last one
   if (!joinValidator.canAttemptJoin(props.localPersona.email, props.localPersona.name, props.sessionKey, props.conversationKey) 
    || !joinValidator.matchesSavedSecret (props.secret)) {
    
      return (<div></div>);
   }
   else {  
      return (
         <ConversationView key = {key}
             userIsAdmin = {userIsAdmin}
             isConnected={props.sessionKey.looksValidSessionKey() && conversationKey.looksValidConversationKey()}
             suppressScroll = {suppressScroll}
             isBusy = {isBusy}
             sessionKey={props.sessionKey}
             localPersonaName={props.localPersona.name}
             conversationKey={conversationKey}
             conversation={conversation}
             audience={audience} 
             sharedEmbeddings={sharedEmbeddings}
             hasSuggestedContent={suggested ? true: false}
             suggestedContent={suggested ? suggested.text: ""}
             braidChattinessLevel={chatLevel}
             onSend={onSend} 
             onAddSuggestedContent={onAddSuggestedContent}
             onCancelSuggestedContent={onCancelSuggestedContent}
             onTrimConversation={onTrimConversation}
             onExitConversation={onExitConversation}             
             onClickUrl={onClickUrl}
             onLikeUrl={onLikeUrl}    
             onUnlikeUrl={onUnlikeUrl}      
             onDeleteMessage={onDeleteMessage}          
             onSetBraidChattiness={onSetBraidChattiness}    
             >
         </ConversationView>
      );
   }
}
****************************************

****************************************
Boxer\ui\ConversationMessagePrompt.tsx
****************************************
/*! Copyright Braid Technologies 2024 */
 
// React
import React, { ChangeEvent, useState, useLayoutEffect } from 'react';

// Fluent
import { InputOnChangeData, makeStyles, Textarea } from '@fluentui/react-components';

import { EUIStrings } from './UIStrings';
import { throwIfUndefined } from '../core/Asserts';
import { EConfigNumbers, EConfigStrings } from '../core/ConfigStrings';

export interface IMessagePromptProps {

   message: string;
   onSend (message_: string) : void;   
   onChange (message_: string) : void;
}

const textFieldStyles = makeStyles({
   root: {
      display: 'flex',
      flexDirection: 'column',
      width: '100%'
   },
   textarea: {
      width: '100%',      
      height: '100%',
      textAlign: 'left',
      verticalAlign: 'top',
   },
   prompt: {
      textAlign: 'center',
      fontSize: '8pt',
      color: 'grey',
      width: '100%',       
   }
});

export function wrapText(context: OffscreenCanvasRenderingContext2D | CanvasRenderingContext2D | null, 
   text: string,
   width: number, 
   defaultHeight: number, defaultWidth: number,
   lineSeparation: number): number {

      let y = 0;
      let hardLines = text.split("\n");


   // Special case if we dont have any text - allow provision for one line
   if (hardLines.length === 0)
      return defaultHeight;

   let dy = 0;
   let lines = 0;

   for (var iHardLines = 0; iHardLines < hardLines.length; iHardLines++) {

      var line = "";
      var words = hardLines[iHardLines].split(" ");
      var lineWidth = 0;
      var lineHeightDelta = defaultHeight;

      for (var iWords = 0; iWords < words.length; iWords++) {
         var testLine = line + words[iWords] + " ";
         var testWidth;

         if (context) {
            let metrics = context.measureText(testLine);
            testWidth = metrics.width;
            lineHeightDelta = metrics.actualBoundingBoxAscent + metrics.actualBoundingBoxDescent;            
         }
         else {
            testWidth = defaultWidth * testLine.length;
            lineHeightDelta = defaultHeight;           
         }

         // Finish if we have incrementally exceeded maxWidth, 
         // or if we only have one word so we have to finish any way. 
         if ((testWidth > width) || ((testWidth > width) && iWords === 0)) {
            line = words[iWords] + " ";
            y += lineHeightDelta;
            dy += lineHeightDelta;
            lineWidth = (testWidth - lineWidth) - defaultWidth / 2;
            lines++;

            if ((iWords + 1) < words.length)
               dy += lineSeparation;
         }
         else {
            line = testLine;
            lineWidth = testWidth - defaultWidth / 2;
         }
      }

      if (context) {
         let metrics = context.measureText(line);
         testWidth = metrics.width;
         lineHeightDelta = metrics.actualBoundingBoxAscent + metrics.actualBoundingBoxDescent;            
      }
      else {
         testWidth = defaultWidth * line.length;
         lineHeightDelta = defaultHeight;       
      }

      y += lineHeightDelta;
      dy += lineHeightDelta;
      lines++;
      if ((iHardLines + 1) < hardLines.length)
         dy += lineSeparation;      
   }

   return dy;
}

// Ref
// https://blog.steveasleep.com/how-to-draw-multi-line-text-on-an-html-canvas-in-2021
export function calculateDyNeeded (width: number, value: string): number {

   const smallestTextForWrap = "A";

   let offScreenCanvas = new OffscreenCanvas(width, width * 10);
   throwIfUndefined (offScreenCanvas);
   let offscreenContext = offScreenCanvas.getContext("2d") as OffscreenCanvasRenderingContext2D; 
   offscreenContext.font = EConfigStrings.kFontNameForTextWrapCalculation;

   let metrics = offscreenContext.measureText(smallestTextForWrap);
   let spaceCharWidth = metrics.width;
   let spaceCharHeight = metrics.fontBoundingBoxAscent + metrics.fontBoundingBoxDescent; 

   let dyNeeded = wrapText(offscreenContext, value.length > 0 ? value: smallestTextForWrap,
         width - EConfigNumbers.kMessagePrompt2HBorder,
         spaceCharHeight,
         spaceCharWidth,
         EConfigNumbers.kMessagePromptLineSpace);

   let dyMin = wrapText(offscreenContext, smallestTextForWrap,
         width,
         spaceCharHeight,
         spaceCharWidth,
         EConfigNumbers.kMessagePromptLineSpace);         

   // Tidy up
   offScreenCanvas = null as any as OffscreenCanvas;
   offscreenContext = null as any as OffscreenCanvasRenderingContext2D;

   return Math.max (dyMin, dyNeeded);
}

export const MessagePrompt = (props: IMessagePromptProps) => {   

   const textFieldClasses = textFieldStyles();
   const [width, setWidth] = useState(0); 
   const textAreaId = "textAreaId;"  
   
   useLayoutEffect(() => {
      
      const textArea = document.getElementById(
         textAreaId
       ) as HTMLTextAreaElement | null;

      if (textArea) {
         let dx = textArea.offsetWidth; 

         if (width !== dx) {
            setWidth(dx);         
         }
      } 
    }, []);

   function onKeyChange(ev: ChangeEvent<HTMLTextAreaElement>, data: InputOnChangeData): void {

      props.onChange (data.value);
   } 

   /*
   * looks to see if the user has Ctrl-enter, and if so processes a Commit
   * @param event - Keyboard Event
   * @param value - current text value
   */
   function onSend(event: React.KeyboardEvent<HTMLElement>, value: string) {

      var processed: boolean = false;

      switch (event.key) {

         case 'Enter':
            if (event.ctrlKey) {
               props.onSend (value);
               processed = true;
            }
            break;

         case 'Escape':
            props.onChange ("");
            processed = true;
            break;            

         default:
            break;
      }
  
      if (processed) {
         event.stopPropagation();
         event.preventDefault();
      }
   };

   let bump = EConfigNumbers.kMessagePrompt2VBorder;
   var dyNeeded = bump;

   if (width !== 0) 
      dyNeeded = calculateDyNeeded (width, props.message) + bump;   

   return (<div className={textFieldClasses.root}> 
      <Textarea
         id={textAreaId}
         appearance="outline"
         placeholder={EUIStrings.kSendMessagePlaceholder}
         maxLength={EConfigNumbers.kMessagePromptMaxCharacters}
         textarea={{ className: textFieldClasses.textarea }}
         resize="none"
         value={props.message}
         onChange={onKeyChange}
         style={{
            height: (dyNeeded).toString() + 'px',
            width: '100%'
         }}
         onKeyDown={(e) => onSend(e, props.message)} 
         disabled={false}      
         autoFocus={true}                 
      /> 
      <div className={textFieldClasses.prompt}>{EUIStrings.kMessageTextPrompt}</div>
      </div>);
}
****************************************

****************************************
Boxer\ui\ConversationPane.tsx
****************************************
/*! Copyright Braid Technologies 2024 */

// React
import React, { useState, useEffect } from 'react';

// Fluent
import {
   makeStyles, shorthands, 
   Button, 
   Toolbar, ToolbarButton, ToolbarDivider,
   Tooltip, 
   Body1,
   Caption1,
   Link,
   Text, 
   Spinner, 
   SpinnerProps,
   partitionAvatarGroupItems,
   AvatarGroup,
   AvatarGroupPopover,
   AvatarGroupItem
} from '@fluentui/react-components';

import {
   Person24Regular,
   Laptop24Regular,
   Send24Regular,
   Copy24Regular,
   Delete24Regular, 
   DoorArrowLeft24Regular,
   ChatMultipleRegular,
   ChatMultipleHeartRegular,
   ChatMultipleHeartFilled,
   DeleteRegular,
   ChatOffRegular,
   ChatAddRegular   
} from '@fluentui/react-icons';

import { EIcon } from '../core/Icons';
import { EConfigNumbers, EConfigStrings }  from '../core/ConfigStrings';
import { Persona } from '../core/Persona';
import { Message } from '../core/Message';
import { EUIStrings } from './UIStrings';
import { innerColumnFooterStyles, textFieldStyles } from './ColumnStyles';
import { SessionKey, ConversationKey } from '../core/Keys';
import { JoinDetails } from '../core/JoinDetails';
import { AnimatedIconButton, EAnimatedIconButtonTypes } from './AnimatedIconButton';
import { MessagePrompt } from './ConversationMessagePrompt';
import { Media } from '../core/Media';
import { SharedEmbedding, findInMap } from '../core/SharedEmbedding';

import { IRelevantEnrichedChunk } from '../../CommonTs/src/EnrichedChunk';

export interface IConversationHeaderProps {

   userisAdmin: boolean;
   sessionKey: SessionKey;
   conversationKey: ConversationKey;   
   audience: Map<string, Persona>;
   braidChattinessLevel: number;
   onTrimConversation () : void;  
   onExitConversation () : void;  
   onSetBraidChattiness (level: number, max: number) : void;  
}

export interface IConversationViewProps {

   isConnected: boolean;
   userIsAdmin: boolean;
   sessionKey: SessionKey;
   conversationKey: ConversationKey;    
   audience: Map<string, Persona>;
   conversation: Array<Message>;
   localPersonaName: string;
   sharedEmbeddings: Map<string, SharedEmbedding>;
   isBusy: boolean;   
   hasSuggestedContent: boolean;
   suggestedContent: string;
   suppressScroll: boolean;
   braidChattinessLevel: number;
   onSend (message_: string) : void;   
   onTrimConversation () : void;   
   onExitConversation () : void;
   onAddSuggestedContent (): void;
   onCancelSuggestedContent (): void;
   onClickUrl (url_: string): void;   
   onLikeUrl (url_: string): void;   
   onUnlikeUrl (url_: string): void;     
   onDeleteMessage (id: string) : void;   
   onSetBraidChattiness (level: number, max: number) : void;
}

const headerRowStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'row',
      alignItems: 'center',
      width: '100%' 
   },
});

export const ConversationHeaderRow = (props: IConversationHeaderProps) => {

   let chatLevelForPrompt = props.braidChattinessLevel + 1;
   let maxChatLevelForPrompt = EConfigNumbers.kMaxChatLevel + 1; 

   let lessChatPrompt = EUIStrings.kBoxerLessChatButtonPrompt.replace ("%%1", chatLevelForPrompt.toString())
                                                             .replace ("%%2", maxChatLevelForPrompt.toString());

   let moreChatPrompt = EUIStrings.kBoxerMoreChatButtonPrompt.replace ("%%1", chatLevelForPrompt.toString())
                                                             .replace ("%%2", maxChatLevelForPrompt.toString());

   let canHaveLessChat = props.braidChattinessLevel > 0;
   let canHaveMoreChat = props.braidChattinessLevel < EConfigNumbers.kMaxChatLevel;

   const headerRowClasses = headerRowStyles();

   // Copy audience to an array for consumption by Fluent classes
   let audienceArray = Array.from(props.audience.values());

   const { inlineItems, overflowItems } = partitionAvatarGroupItems({
      items: audienceArray
    });


   function onCopy (ev: React.MouseEvent<HTMLButtonElement>) : void {

      // Make join details with no email address and no name
      let joinDetails = JoinDetails.makeFromParts ("", "", props.sessionKey, props.conversationKey, "");
      
      // https://stackoverflow.com/questions/10783322/window-location-url-javascript

      let newUrl = window.location.protocol + // => "http:"
      '//' +
      window.location.host +                  // => "example.com:3000"
      window.location.pathname +              // => "/pathname/
      '#' + joinDetails.toString();

      navigator.clipboard.writeText (newUrl);
   }       

   function onMoreChat (ev: React.MouseEvent<HTMLButtonElement>) : void {

      if (props.braidChattinessLevel < EConfigNumbers.kMaxChatLevel) {
         let newChatLevel = props.braidChattinessLevel + 1;
         props.onSetBraidChattiness (newChatLevel, EConfigNumbers.kMaxChatLevel);
      }
   } 

   function onLessChat (ev: React.MouseEvent<HTMLButtonElement>) : void {
      if (props.braidChattinessLevel > 0) {     
         let newChatLevel = props.braidChattinessLevel - 1;
         props.onSetBraidChattiness (newChatLevel, EConfigNumbers.kMaxChatLevel);         
      }
   }    

   function onTrimConversation (ev: React.MouseEvent<HTMLButtonElement>) : void {

      props.onTrimConversation();
   } 

   function onExitConversation (ev: React.MouseEvent<HTMLButtonElement>) : void {

      props.onExitConversation();
   }           

   return (
      <div className={headerRowClasses.root}>
         <AvatarGroup>
            {inlineItems.map((persona) => (
               <Tooltip content={persona.name} relationship="label" positioning={'below'} key={persona.id}>
                  <AvatarGroupItem name={persona.name} key={persona.id} />
               </Tooltip>
            ))}
            {overflowItems && (
               <AvatarGroupPopover indicator="icon">
                  {overflowItems.map((persona) => (
                     <AvatarGroupItem name={persona.name} key={persona.id} />
                  ))}
               </AvatarGroupPopover>
            )}
         </AvatarGroup>  
         <ToolbarDivider />
         <Toolbar aria-label="Conversation control toolbar" >                  
            <Tooltip content={EUIStrings.kCopyConversationUrlButtonPrompt} 
               relationship="label" positioning={'below'}>
               <ToolbarButton
                  icon={<Copy24Regular />}
                  aria-label={EUIStrings.kCopyConversationUrlButtonPrompt} 
                  disabled={!(props.sessionKey.looksValidSessionKey() && props.conversationKey.looksValidConversationKey())} 
                  onClick={onCopy}
               />                 
            </Tooltip>           
            <Tooltip content={lessChatPrompt} 
               relationship="label" positioning={'below'}>
               <ToolbarButton
                  icon={<ChatOffRegular />}
                  aria-label={lessChatPrompt} 
                  disabled={!canHaveLessChat} 
                  onClick={onLessChat}
               />  
            </Tooltip>        
            <Tooltip content={moreChatPrompt} 
               relationship="label" positioning={'below'}>
               <ToolbarButton
                  icon={<ChatAddRegular />}
                  aria-label={moreChatPrompt} 
                  disabled={!canHaveMoreChat} 
                  onClick={onMoreChat}
               />  
            </Tooltip>                
            <Tooltip content={EUIStrings.kTrimConversationButtonPrompt} 
               relationship="label" positioning={'below'}>
               <ToolbarButton
                  icon={<Delete24Regular />}
                  aria-label={EUIStrings.kTrimConversationButtonPrompt} 
                  disabled={!(props.userisAdmin && props.sessionKey.looksValidSessionKey() && props.conversationKey.looksValidConversationKey())} 
                  onClick={onTrimConversation}
               />  
            </Tooltip>       
            <Tooltip content={EUIStrings.kExitConversationButtonPrompt} 
               relationship="label" positioning={'below'}>
               <ToolbarButton
                  icon={<DoorArrowLeft24Regular />}
                  aria-label={EUIStrings.kExitConversationButtonPrompt} 
                  disabled={!(props.sessionKey.looksValidSessionKey() && props.conversationKey.looksValidConversationKey())} 
                  onClick={onExitConversation}
               />  
            </Tooltip>                                                   
         </Toolbar>           
      </div>
   );
}

const embeddedRowStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'row',
      width: '100%',
      height: '100%',
      alignItems: 'stretch',   /* for a row, the main axis is vertical, stretch means fill the row with content */
      justifyContent: 'center' /* for a row, the cross-axis is horizontal, center means vertically centered */           
   },
});

const embeddedColumnStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'column',
      justifyContent: 'flex-start'    // start layout at the top                  
   },
});

const conversationContentRowStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'row',         
      width: '100%',           
      alignItems: 'stretch',   /* for a row, the main axis is vertical, stretch means fill the row with content */
      overflowY: 'auto'
   },
});

const conversationContentColumnStyles = makeStyles({
   root: {  
      display: 'flex',
      flexDirection: 'column',                        
      width: '100%',
      overflowY: 'auto'     
   },
});

const DefaultSpinner = (props: Partial<SpinnerProps>) => <Spinner {...props} />;


export const ConversationView = (props: IConversationViewProps) => {

   const embeddedRowClasses = embeddedRowStyles();
   const embeddedColumnClasses = embeddedColumnStyles();   
   const conversationContentRowClasses = conversationContentRowStyles();
   const conversationContentColumnClasses =  conversationContentColumnStyles();
   const footerSectionClasses = innerColumnFooterStyles();   
   const alwaysScrollToBottomId = "AlwaysScrollToBottom";
    
   // Shorthand only
   let conversation = props.conversation;
   let audience = props.audience;

   function onSend (messageText_: string) : void {

      props.onSend (messageText_);
      if (!props.suppressScroll)
         scroll();
   }

   // https://stackoverflow.com/questions/45719909/scroll-to-bottom-of-an-overflowing-div-in-react 
   function scroll (): void {

      const divScroll = document.getElementById(
         alwaysScrollToBottomId
       ) as HTMLDivElement | null;

      if (divScroll) {
         divScroll.scrollIntoView();
      }       
   }
 
   useEffect(() => {
      if (!props.suppressScroll)      
         scroll();
    });     

   if (! props.isConnected) {
      return (<div></div>);
   }
   else {
      return (
         <div className={embeddedRowClasses.root}>      
            <div className={embeddedColumnClasses.root}>                     

               <ConversationHeaderRow 
                  userisAdmin={props.userIsAdmin}
                  sessionKey={props.sessionKey} 
                  conversationKey={props.conversationKey}
                  audience={props.audience} 
                  onTrimConversation={props.onTrimConversation}      
                  onExitConversation={props.onExitConversation}
                  onSetBraidChattiness={props.onSetBraidChattiness}
                  braidChattinessLevel={props.braidChattinessLevel}
                  >                                                                       
               </ConversationHeaderRow>
               
               &nbsp;

               <div className={conversationContentRowClasses.root}>                
                  <div className={conversationContentColumnClasses.root}>             
                     {conversation.map (message => { 
                        return (         
                           <SingleMessageView 
                              sessionKey={props.sessionKey}
                              message={message} 
                              localPersonaName={props.localPersonaName}                              
                              key={message.id}
                              author={Persona.safeAuthorLookup (audience, message.authorId)}
                              userIsAdmin={props.userIsAdmin}
                              sharedEmbeddings={props.sharedEmbeddings}
                              showAiWarning={message.authorId === EConfigStrings.kLLMGuid}
                              onClickUrl={props.onClickUrl}  
                              onLikeUrl={props.onLikeUrl}   
                              onDislikeUrl={props.onUnlikeUrl}
                              onDeleteMessage={props.onDeleteMessage}
                           />
                        )                     
                     })}                          
                     <div id={alwaysScrollToBottomId}/>  
                  </div>               
               </div>

               &nbsp;  

               <div className={footerSectionClasses.root}>               
                  {props.isBusy ? <DefaultSpinner/> : <div/>}              
                  <InputView 
                     onSend={onSend}
                     suggestedContent={props.suggestedContent} 
                     isBusy={props.isBusy}
                     hasSuggestedContent={props.hasSuggestedContent}
                     onAddSuggestedContent={props.onAddSuggestedContent}
                     onCancelSuggestedContent={props.onCancelSuggestedContent}>
                     </InputView>          
               </div> 
            </div>
         </div>
     );
   }
}

export interface ISingleMessageViewProps {

   sessionKey: SessionKey;
   message: Message;  
   author: Persona;
   showAiWarning: boolean;
   localPersonaName: string;   
   sharedEmbeddings: Map<string, SharedEmbedding>;  
   userIsAdmin: boolean; 
   onClickUrl (url_: string) : void;    
   onLikeUrl (url_: string) : void;  
   onDislikeUrl (url_: string) : void;     
   onDeleteMessage (id: string) : void;
}

 export interface IAuthorIconProps {
 
   author: Persona; 
}

export interface IRelevantChunkProps {

   sessionKey: SessionKey;
   segment: IRelevantEnrichedChunk;  
   key: string;
   localPersonaName: string;
   sharedEmbeddings: Map<string, SharedEmbedding>;   
   onClickUrl (url_: string) : void;    
   onLikeUrl (url_: string) : void;  
   onUnlikeUrl (url_: string) : void;      
}

const glow = makeStyles({
   root: {    
      marginBottom: '10px' ,      
      boxShadow: '0px 0px 5px 0px white;'
   },
});

const noGlow = makeStyles({
   root: {    
      marginBottom: '10px'       
   },
});

 export const AuthorIcon = (props: IAuthorIconProps) => {

   const glowClasses = glow();    
   const noGlowClasses = noGlow(); 
   var className;

   if (props.author.icon === EIcon.kLLMPersona) {
      className = glowClasses.root;
   }
   else {
      className = noGlowClasses.root;      
   }

   return ((props.author.icon === EIcon.kLLMPersona) ?
            <Laptop24Regular className={className} />
            : <Person24Regular className={className}/>
   );
}

const singleMessageRow = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'row',
      alignItems: 'left'
   },
});

const singleMessageIconColumn = makeStyles({
   root: {    
      ...shorthands.margin("10px"),      
      display: 'flex',
      flexDirection: 'column'
   },
});

const singleMessageTextColumn = makeStyles({
   root: {    
      ...shorthands.margin("10px"),       
      display: 'flex',
      flexDirection: 'column'
   },
});

const sourcesRow = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'column',
      alignItems: 'left'
   },
});

const padAfterMessage = makeStyles({
   root: {    
      marginBottom: '10px'    
   },
});

const linkStyles = makeStyles({
   root: {    
      marginRight: '10px',
      justifySelf: 'centre'      
   },
});

const greenStyles = makeStyles({
   root: {    
      color: 'green',
      justifySelf: 'centre'       
   },
});

const amberStyles = makeStyles({
   root: {    
      color: 'orange',
      justifySelf: 'centre'  
   },
});

const toolbarRowStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'row',
      alignItems: 'center'
   },
});

const toolbarButtonStyles = makeStyles({
   root: {    
      alignSelf: 'centre',
      marginLeft: '5px',
      marginRight: '5px'
   }
});

const buttonStyles = makeStyles({
   root: {
      flexGrow: '0',
      flexShrink: '0'      
   }
});

/**
 * Splits a string into an array of strings using double newlines as the delimiter.
 * Empty strings are filtered out from the result.
 *
 * @param text - The input string to split
 * @returns An array of non-empty strings split by double newlines
 */
function splitByDoubleNewline(text: string): string[] {
   return text.split('\n\n').filter(str => str.trim().length > 0);
}

export const RelevantChunkView = (props: IRelevantChunkProps) => {

   const sourcesClasses = sourcesRow();
   const greenClasses = greenStyles();
   const amberClasses = amberStyles();

   let relevantChunk = props.segment;
   let relevanceText = relevantChunk.relevance ? (relevantChunk.relevance * 100).toPrecision(2) + '%': "";
   
   const onClickLink = (event: React.MouseEvent<HTMLAnchorElement>): void => {
      // NB we call 'prevent default' as we want to control the action i.e. open a  new tab. 
      event.stopPropagation();
      event.preventDefault();

      props.onClickUrl (relevantChunk.chunk.url);  
      (window as any).open(relevantChunk.chunk.url, '_blank');
   };

   const onClickLike = (event: React.MouseEvent<HTMLButtonElement>): void => {
      // NB we call 'prevent default' as we want to control the action  
      event.stopPropagation();
      event.preventDefault();

      props.onLikeUrl (relevantChunk.chunk.url);        
   }   

   const onClickUnlike = (event: React.MouseEvent<HTMLButtonElement>): void => {
      // NB we call 'prevent default' as we want to control the action  
      event.stopPropagation();
      event.preventDefault();

      props.onUnlikeUrl (relevantChunk.chunk.url);       
   }   

   let relevanceClasses = relevantChunk.relevance ? relevantChunk.relevance >= 0.5 ? greenClasses : amberClasses : amberClasses; 
   let linkClasses = linkStyles();
   let toolbarRowClasses = toolbarRowStyles();  
   let toolbarButtonClasses = toolbarButtonStyles();   
   
   let linkText = relevantChunk.chunk.url;
   
   let media = new Media();
   let maxLength = EConfigNumbers.kMaximumLinkTextlength;
   if (media.isSmallFormFactor()) 
      maxLength = EConfigNumbers.kMaximumLinkTextlengthMobile;

   if (linkText.length > maxLength + 3) {
      linkText = linkText.slice (0, maxLength) + '...';
   }

   let likedByMe = false;
   let likedByAnyone = false;
   let likeText = "";
   let shared = findInMap (relevantChunk.chunk.url, props.sharedEmbeddings);
   if (shared) {
      likedByMe = shared.isLikedBy (props.localPersonaName); 
      likedByAnyone = shared.netLikeCount > 0;  
      if (likedByAnyone) {
         let count =  shared.likes.length;

         if (count > 1)
            likeText = count.toString() + " " + EUIStrings.kLikePlural;
         else
            likeText = count.toString() + " " + EUIStrings.kLikeSignular;         
      }   
   }

   let splitSummary = splitByDoubleNewline (relevantChunk.chunk.summary);

   return (<div className={sourcesClasses.root} key={relevantChunk.chunk.url}>
              <div className={toolbarRowClasses.root}>
                 <Link className={linkClasses.root} 
                    href={relevantChunk.chunk.url} onClick={onClickLink} inline>{linkText}                
                  </Link>
                  <Body1 className={relevanceClasses.root}> {relevanceText} </Body1>
                  <Toolbar aria-label="Like/dislike control toolbar" >                        
                     <ToolbarDivider />                  
                     <Tooltip content={likedByMe ? EUIStrings.kDidNotLikeThis : EUIStrings.kLikedThis} relationship="label" positioning={'above'}>                     
                        <ToolbarButton
                           className={toolbarButtonClasses.root}
                           icon={likedByMe? <ChatMultipleHeartFilled/> : likedByAnyone ? <ChatMultipleHeartRegular/> : <ChatMultipleRegular/>} 
                           onClick={likedByMe ? onClickUnlike : onClickLike}/>   
                     </Tooltip> 
                     <Text size={100}>{likeText}</Text>    
                  </Toolbar>                                              
               </div>
               {splitSummary.map((paragraph, index) => (
                  <Body1 key={index} className={toolbarRowClasses.root}> {paragraph} </Body1>
              ))}                              
            </div>      
         );
}

export const SingleMessageView = (props: ISingleMessageViewProps) => {

   const singleMessageRowClasses = singleMessageRow();
   const singleMessageIconColumnClasses = singleMessageIconColumn();
   const singleMessageColumnClasses = singleMessageTextColumn();
   const toolbarButtonClasses = toolbarButtonStyles(); 
   const toolbarRowClasses = toolbarRowStyles();  

   const padAfterMessageClasses = padAfterMessage();  
   const amberClasses = amberStyles();

   // we can omly delete our own messages
   let canDelete = props.userIsAdmin || (props.author.name === props.localPersonaName);

   const onDeleteMessage = (event: React.MouseEvent<HTMLButtonElement>): void => {
      // NB we call 'prevent default' as we want to control the action  
      event.stopPropagation();
      event.preventDefault();

      props.onDeleteMessage (props.message.id);        
   } 

   var aiSources;
   var aiFooter;   

   if (props.showAiWarning) {
      
      if (props.message.chunks.length > 0) { 

         aiSources = props.message.chunks.map ((releventChunk : IRelevantEnrichedChunk) => {
            return <RelevantChunkView sessionKey={props.sessionKey} 
                    localPersonaName={props.localPersonaName}
                    segment={releventChunk} key={releventChunk.chunk.url} 
                    sharedEmbeddings={props.sharedEmbeddings}
                    onClickUrl={props.onClickUrl}
                    onLikeUrl={props.onLikeUrl}
                    onUnlikeUrl={props.onDislikeUrl}/>
         })   
         aiFooter = <Text size={100}> {EUIStrings.kAiContentWarning} </Text>;   
      }
      else {
         aiSources = <Text size={100} className={amberClasses.root}> {EUIStrings.kAiNoGoodSources} </Text>;  
         aiFooter = <div/>;         
      }
   } 
   else {
      aiFooter = <div/>;
      aiSources = <div/>;
   }

   return (
      <div className={singleMessageRowClasses.root}>
         <div className={singleMessageIconColumnClasses.root}>
            <AuthorIcon author={props.author} />            
         </div>   
         <div className={singleMessageColumnClasses.root}>
            <Caption1><b>{props.author.name}</b></Caption1> 
            <div className={toolbarRowClasses.root}>      
               <Body1>{props.message.text}</Body1>                 
               <Toolbar aria-label="Delete control toolbar" >                        
                  <ToolbarDivider />                  
                  <Tooltip content={EUIStrings.kDeleteMessage} relationship="label" positioning={'above'}>                     
                     <ToolbarButton
                        className={toolbarButtonClasses.root}
                        disabled={!canDelete}
                        icon={<DeleteRegular/>} 
                        onClick={onDeleteMessage}/>   
                  </Tooltip>    
               </Toolbar>              
            </div>
            <div className={padAfterMessageClasses.root}></div>              
            {aiSources}  
            <div className={padAfterMessageClasses.root}></div>                     
            {aiFooter}
            <div className={padAfterMessageClasses.root}></div> 
         </div>              
      </div>);    
}

export interface IInputViewProps {
   
   isBusy: boolean;
   hasSuggestedContent: boolean;
   suggestedContent: string;
   onSend (message_: string) : void;
   onAddSuggestedContent(): void;
   onCancelSuggestedContent() : void;
}

 const inputGroupStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'column',      
      textAlign: 'left',
      width: '100%'
   },
});

const inputRowStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'row',      
      textAlign: 'left',
      width: '100%'
   },
});

const textColumnStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'column',      
      width: '100%'
   },
});

const bottonColumnStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'column',      
      width: 'fit-content'   
   },
});

const bottonRowStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'row',      
      justifyContent: 'flex-end'
   },
});

export const InputView = (props: IInputViewProps) => {

   const inputGroupClasses =inputGroupStyles();
   const inputRowClasses = inputRowStyles();
   const textColumnClasses = textColumnStyles();
   const buttonColumnClasses = bottonColumnStyles();   
   const buttonRowClasses = bottonRowStyles();      
   const buttonClasses = buttonStyles();

   const [message, setMessage] = useState<string>("");
   const [canSend, setCanSend] = useState<boolean>(false);

   function onSend (message_: string) : void {

      props.onSend (message);
      setMessage ("");   
      setCanSend (false);        
   }   

   function onChange (message_: string) : void {

      setMessage (message_);   
      setCanSend (message_.length > 0);        
   }  

   function onMessageSend (ev: React.MouseEvent<HTMLButtonElement>) : void {

      onSend(message);       
   }

   return (
      <div className={inputGroupClasses.root}>
         <Text>{EUIStrings.kSendMessagePreamble}</Text>
         &nbsp;
         <div className={inputRowClasses.root}>
            <div className={textColumnClasses.root}>
               <MessagePrompt onSend={onSend} onChange={onChange} message={message} />               
            </div>
            &nbsp;           
            <div className={buttonColumnClasses.root}>
               <div className={buttonRowClasses.root}>                              
                  <Button 
                     className={buttonClasses.root}
                     disabled={(!canSend) || (props.isBusy)}
                     icon={<Send24Regular/>} 
                     onClick={onMessageSend}/>                                               
                  &nbsp;                  
                  <AnimatedIconButton animate={props.hasSuggestedContent} 
                     icon={EAnimatedIconButtonTypes.kLightBulb} 
                     promptAnimated={props.suggestedContent} 
                     promptUnamimated={EUIStrings.kAiHasNoSuggestedDocuments}
                     onClick={props.onAddSuggestedContent}
                     onCancel={props.onCancelSuggestedContent}/>                               
                  </div>
            </div>       
         </div>   
      </div>        
   );
}
****************************************

****************************************
Boxer\ui\JoinPane.tsx
****************************************
/*! Copyright Braid Technologies 2024 */

// React
import React, { ChangeEvent, MouseEvent, useState } from 'react';

// Fluent
import {
   makeStyles, shorthands, 
   Dropdown, Option, Tooltip, Button,
   Text, Input, Image, 
   InputOnChangeData,
   SelectionEvents,
   OptionOnSelectData
} from '@fluentui/react-components';

import {
   Key24Regular
} from '@fluentui/react-icons';

import { getDefaultFluidEnvironment } from '../../CommonTs/src/IEnvironmentFactory';
import { EEnvironment } from '../../CommonTs/src/IEnvironment';

import { Persona } from '../core/Persona';
import { SessionKey, ConversationKey } from '../core/Keys';
import { JoinPageValidator } from '../core/JoinPageValidator';
import { KeyRetriever } from '../core/KeyRetriever';
import { EUIStrings } from './UIStrings';
import { EConfigStrings } from '../core/ConfigStrings';
import { innerColumnFooterStyles, textFieldStyles } from './ColumnStyles';
import { throwIfUndefined } from '../core/Asserts';
import { getDefaultKeyGenerator } from '../core/IKeyGeneratorFactory';

export interface IJoinPageProps {
   sessionKey: SessionKey;  
   conversationKey: ConversationKey;
   secret: string;
   joinPersona: Persona;
   onConnect (sessionKey_: SessionKey, 
              conversationKey_: ConversationKey,
              secret_: string) : void;
   onConnectError (hint_: string) : void;    
}

const joinPageInnerStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'column',  
   },
});

const joinFormRowStyles = makeStyles({
   root: {    
      display: 'flex',
      flexDirection: 'row',    
   },
});

 const buttonDisabledStyles = makeStyles({
   root: {    
      filter: 'grayscale(100%)',
      marginLeft: 'auto', 
      marginRight: '0'
   },
});

const buttonEnabledStyles = makeStyles({
   root: {    
      filter: 'grayscale(0%)',
      marginLeft: 'auto', 
      marginRight: '0'
   },
});

const dropdownStyles = makeStyles({
   root: {
     // Stack the label above the field with a gap
     display: "grid",
     gridTemplateRows: "repeat(1fr)",
     justifyItems: "start",
     ...shorthands.gap("2px"),
     maxWidth: "400px",
   },
 });

 function conversationKeyFromName (name: string) : ConversationKey {
   
   switch (name) {
      case EUIStrings.kTestConversationName:
         return new ConversationKey ("");  
      case EUIStrings.kDemoConversationName:  
         return new ConversationKey (EConfigStrings.kDemoConversationKey);                     
      case EUIStrings.kCohort1Team1ConversationName:
         return new ConversationKey (EConfigStrings.kCohort1Team1ConversationKey);            
      case EUIStrings.kCohort1Team2ConversationName:
         return new ConversationKey (EConfigStrings.kCohort1Team2ConversationKey);              
      case EUIStrings.kCohort1Team3ConversationName:
         return new ConversationKey (EConfigStrings.kCohort1Team3ConversationKey);    
      case EUIStrings.kCohort1ConversationName:
      default:
         return new ConversationKey (EConfigStrings.kCohort1ConversationKey);                   
      }   
 }


export const JoinPane = (props: IJoinPageProps) => {

   const joinPageInnerClasses = joinPageInnerStyles();   
   const joinFormRowClasses = joinFormRowStyles();
   const innerColumnFooterClasses = innerColumnFooterStyles(); 
   const stretchClasses = textFieldStyles();
   const buttonDisabledClasses = buttonDisabledStyles();
   const buttonEnabledClasses = buttonEnabledStyles();
   const dropdownClasses = dropdownStyles();

   const retriever = new KeyRetriever();

   /*
    * @param runningInLocalEnv
    * This logic with runningInLocalEnv is bcs when running against a local fluid framework, we dont know the container ID
    * we have to let the code create a new container then share it manually in the URL#string
    * In production, we have well known container IDs which were created beforehand.
   */
   let runningInLocalEnv: boolean = (getDefaultFluidEnvironment().name === EEnvironment.kLocal);

   let defaultConversationName = EUIStrings.kCohort1ConversationName;
   var conversations: Array<string>;
   
   if (runningInLocalEnv) {
      conversations = [EUIStrings.kTestConversationName];
      defaultConversationName = EUIStrings.kTestConversationName;      
   }
   else {
      conversations = [
         EUIStrings.kCohort1ConversationName,
         EUIStrings.kCohort1Team1ConversationName,
         EUIStrings.kCohort1Team2ConversationName,
         EUIStrings.kCohort1Team3ConversationName,
         EUIStrings.kDemoConversationName
      ];
      defaultConversationName = EUIStrings.kCohort1ConversationName;    
   }

   const [sessionKey, setSessionKey] = useState<SessionKey>(props.sessionKey); 
   const [selectedConversationNames, setSelectedConversationNames] = React.useState<string[]>([
      defaultConversationName
   ]);
   const [conversationName, setConversationName] = React.useState<string>(defaultConversationName);
  
   function onConversationSelect (ev: SelectionEvents, data: OptionOnSelectData) {

      let conversationName = data.optionText;

      setSelectedConversationNames(data.selectedOptions);
      throwIfUndefined (conversationName); // Make compiler happy for next line
      setConversationName(conversationName);     
   };

   function onKeyChange(ev: ChangeEvent<HTMLInputElement>, data: InputOnChangeData): void {

      let newSessionKey = new SessionKey (data.value);

      setSessionKey(newSessionKey);
   }   

   function onTryJoin(ev: MouseEvent<HTMLButtonElement>): void {
      
      ev.preventDefault();

      tryToJoin();
   }

   function tryToJoin () : void {
      
      let conversationKey : ConversationKey;

      if (runningInLocalEnv) {
         conversationKey = props.conversationKey;
      }
      else {
         conversationKey = conversationKeyFromName (conversationName);
      }

      let joinValidator = new JoinPageValidator ();

      let secret = "";

      let keyGenerator = getDefaultKeyGenerator();

      if (! joinValidator.haveSavedSecret ()) {       
         secret = keyGenerator.generateSecret();
         keyGenerator.saveSecret (secret);
      }
      else {
         secret = keyGenerator.savedSecret();
      }

      props.onConnect (sessionKey, conversationKey, secret);
   }

   let joinValidator = new JoinPageValidator ();

   if (joinValidator.matchesSavedSecret (props.secret)) {
      return (<div></div>);
   }
   else {
      return (
         <div className={innerColumnFooterClasses.root} >               
            <div className={joinPageInnerClasses.root}>  
               &nbsp;              
               <div className={joinFormRowClasses.root}>             
                  <Text align="start" className={stretchClasses.root}>{EUIStrings.kJoinPagePreamble}</Text> 
               </div>             
               &nbsp;         
               <div className={joinFormRowClasses.root}>                   
                  <Tooltip withArrow content={EUIStrings.kJoinConversationKeyPrompt} relationship="label">
                     <Input aria-label={EUIStrings.kJoinConversationKeyPrompt}
                        className={stretchClasses.root}                  
                        required={true}                  
                        value={sessionKey.toString()}
                        maxLength={75}
                        contentBefore={<Key24Regular />}
                        placeholder={EUIStrings.kJoinConversationKeyPlaceholder}
                        onChange={onKeyChange}
                        disabled={false}
                        autoFocus={true}
                     />
               </Tooltip>  
               </div>
               &nbsp;
               <div className={joinFormRowClasses.root}>     
                  <div className={dropdownClasses.root}>              
                     <Tooltip withArrow content={EUIStrings.kJoinConversationPicker} relationship="label">
                        <Dropdown
                           defaultValue={defaultConversationName}
                           defaultSelectedOptions={[defaultConversationName]}
                           onOptionSelect={onConversationSelect}
                           {...props}
                        >
                           {conversations.map((conversation) => (
                              <Option key={conversation}>
                                 {conversation}
                              </Option>
                           ))}
                        </Dropdown>
                     </Tooltip>      
                  </div>    
                  &nbsp;          
                  &nbsp;    
                  &nbsp;                                                   
                  <Button onClick={onTryJoin} >        
                     <Tooltip withArrow content={EUIStrings.kJoinConversationWithLinkedInPrompt} relationship="label">
                        <Image className={sessionKey.looksValidSessionKey()? buttonEnabledClasses.root : buttonDisabledClasses.root}
                           alt={EUIStrings.kJoinConversationWithLinkedInPrompt}
                           src="assets/img/SignInWithLinkedIn.png"
                        />
                     </Tooltip>  
                  </Button>              
               </div>               
               &nbsp;                   
               <div className={joinFormRowClasses.root}> 
                  <Text className={stretchClasses.root}>{sessionKey.looksValidSessionKey() ? EUIStrings.kJoinConversationLooksLikeKeyOk : EUIStrings.kJoinConversationDoesNotLookLikeKey}</Text>   
               </div>
               &nbsp;                
            </div>                          
         </div>
      );
   };
}
****************************************

****************************************
Boxer\ui\MainPageMessage.tsx
****************************************
/*! Copyright Braid Technologies 2024 */

// React
import React from 'react';

import { DismissRegular } from "@fluentui/react-icons";
import {
  MessageBar,
  MessageBarActions,
  MessageBarTitle,
  MessageBarBody,
  MessageBarGroup,
  MessageBarIntent,
  Text,
  Button,
  makeStyles,
} from "@fluentui/react-components";

import { EUIStrings } from './UIStrings';

const messageBarStyles = makeStyles({
  messageBarGroup: {
    display: "flex",
    flexDirection: "row",
    alignItems: 'center',    
    maxWidth: EUIStrings.kMaxColumnWidth 
  }
});

export enum EMainPageMessageTypes { // Must mirror MessageBarIntent, with addition of 'nothing' if you dont want to display a message. 
   kInformation = "info", 
   kWarning = "warning", 
   kError = "error", 
   kSuccess = "success",
   kNothing = "nothing"
}

interface IMainPageMessageProps {
   intent: EMainPageMessageTypes;
   text: string;
   dismissable: boolean;
   onDismiss () : void;   
}

export const MainPageMessageRow = (props: IMainPageMessageProps) => {

  const messageClasses = messageBarStyles();
  
  let nullMessage = {intent: EMainPageMessageTypes.kNothing, text:"" };

  let displayMessage = {intent: props.intent, text: props.text };

  const dismissMessage = () =>
    { props.onDismiss() };

  if (displayMessage.intent === EMainPageMessageTypes.kNothing)
     return (<div />);

  if (props.dismissable) {
     return (
        <MessageBarGroup className={messageClasses.messageBarGroup}>
           <MessageBar key={0} intent={displayMessage.intent}>
              <MessageBarBody>
                 <MessageBarTitle>{EUIStrings.kPageErrorCaption}</MessageBarTitle>
                 &nbsp;
                 {displayMessage.text} 
               </MessageBarBody>
               <MessageBarActions
                  containerAction={
                     <Button
                      onClick={() => dismissMessage()}
                      aria-label="dismiss"
                      appearance="transparent"
                      icon={<DismissRegular />}
                     />
                  }
               />
           </MessageBar>
        </MessageBarGroup>
     );
  }
  else
  {
     return (
        <MessageBarGroup className={messageClasses.messageBarGroup}>
           <MessageBar key={0} intent={displayMessage.intent}>
              <MessageBarBody>
                 <MessageBarTitle>{EUIStrings.kPageErrorCaption}</MessageBarTitle>
                 <Text>{displayMessage.text}</Text> 
               </MessageBarBody>
           </MessageBar>
        </MessageBarGroup>);
  }
};
****************************************

****************************************
Boxer\ui\UIStrings.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

export enum EUIStrings {

   kMaxColumnWidth = "896px",
   kJoinPagePreamble = "To join a conversation with @Boxer, you need to enter the key from your contact at Braid, pick a conversation to join, then login with LinkedIn to identify yourself.",
   kJoinConversationKeyPrompt = "Key",
   kJoinConversationKeyPlaceholder = "Key... ",  
   kJoinConversationDoesNotLookLikeKey = "It does not look like the key is valid.",
   kJoinConversationLooksLikeKeyOk = "It looks like the key is valid, you can try to join the conversation via LinkedIn.",
   kJoinConversationWithLinkedInPrompt = "Join with LinkedIn... ",  
   kJoinConversationPicker = "Select a conversation to join.",

   kCohort1ConversationName = "Cohort 1 - Paris Olympics 2024",
   kCohort1Team1ConversationName = "4x100m swim",
   kCohort1Team2ConversationName = "Triathlon",
   kCohort1Team3ConversationName = "Judo",   
   kDemoConversationName = "Demo",
   kTestConversationName = "Test", 

   kPageErrorCaption = "Error",
   
   kJoinApiError = "Sorry, we were not able to connect to the conversation.",
   kAiApiError = "Sorry, we were not able to connect to the AI.", 
   kSecretError = "Sorry, we were not able to validate end-end security in your login. Please try again. If this rekeeps happening, please ask your contact at Braid for support.",  

   kSendMessagePreamble = "Type a message below. If you want @Boxer to reply, put '@Boxer' in the message. Treat your messages as public and do not enter confidential information.",
   kNoThanks = "No thanks.",
   kLikedThis = "Click to like.",
   kDidNotLikeThis = "Click if you don't like it any more.",
   kDeleteMessage = "Delete message.",
   kSendMessagePlaceholder = "Write a message... ",  
   kMessageTextPrompt = "Ctrl+Enter to send or Esc to cancel.",
   kCopyConversationUrlButtonPrompt = "Copy the URL for this conversation to the clipboard.",
   kTrimConversationButtonPrompt = "Delete the conversation history.",
   kExitConversationButtonPrompt = "Leave this conversation.",   
   kBoxerMoreChatButtonPrompt = "Make @Boxer chattier. Currently %%1 out of %%2.",
   kBoxerLessChatButtonPrompt = "Make @Boxer less chatty. Currently %%1 out of %%2.",   
   kAiHasNoSuggestedDocuments = "No suggestions at present. Interacting with @Boxer will generate suggestions.", 
   kPomptToGetStarted = "Where is a good place to start learning about building applications with LLMs? With some examples in Python?",

   kAiNoGoodSources = "@Boxer does not have good backup for this answer. AI can make mistakes. Consider checking important information.",
   kAiContentWarning = "AI can make mistakes. Consider checking important information.",

   kLLMNameReminder = "Just checking...  if you want your request to be sent to @Boxer, include the phrase '@Boxer' in your message. With an '@' sign.",

   kLikeSignular = "like.",
   kLikePlural = "likes.",

   kWelcomeWouldYouLikeRecap = "Welcome, would you like a recap?",
   kSummarising = "Summarising ..."
};

export var initialQuestions: Array<string> = [
      "What are some common use cases for generative AI?",
      "How can Python be used to interact with an LLM?",
      "What is the purpose of tokenization in LLMs?",
      "Explain the difference between static and dynamic tokenization.",
      "How do you handle out-of-vocabulary words in tokenization?",
      "What are embeddings in the context of NLP?",
      "How do you load a pre-trained LLM in Python using Hugging Face Transformers?",
      "Describe the process of fine-tuning an LLM.",
      "What are the benefits of fine-tuning a pre-trained model?",
      "How can you generate text using GPT-3 in Python?",
      "What is the role of the `generate` function in text generation?",
      "How do you control the length of generated text in an LLM?",
      "Explain the concept of 'temperature' in text generation.",
      "What is top-k sampling in the context of LLMs?",
      "How does nucleus sampling (top-p) work in text generation?",
      "Describe beam search as a decoding strategy.",
      "What are the trade-offs between beam search and greedy decoding?",
      "How can you evaluate the quality of generated text?",
      "What are common metrics for evaluating generative models?",
      "How do you prevent an LLM from generating inappropriate content?",
      "What is the purpose of prompt engineering?",
      "How can you improve the coherence of generated text?",
      "What is zero-shot learning in LLMs?",
      "How does few-shot learning differ from zero-shot learning?",
      "Describe the role of context in text generation.",
      "How do you manage large-scale LLMs in a production environment?",
      "What are the computational challenges of training an LLM?",
      "Explain the concept of model parallelism.",
      "How can you reduce the inference time of an LLM?",
      "What is model distillation in the context of LLMs?",
      "Describe how to use the `transformers` library to implement a chatbot.",
      "What is the role of an API in interacting with an LLM?",
      "How do you secure an API endpoint for an LLM?",
      "What ethical considerations should be taken when using generative AI?",
      "How can you detect and mitigate biases in LLMs?",
      "What is the impact of training data on the performance of an LLM?",
      "How do you perform hyperparameter tuning for an LLM?",
      "Explain the role of learning rate schedules in training LLMs.",
      "How can you use Python to preprocess text data for LLM training?",
      "What are some techniques for data augmentation in NLP?",
      "How do you implement a feedback loop for improving an LLM?",
      "Describe a real-world application of generative AI.",
      "What is the significance of multilingual capabilities in LLMs?",
      "How can transfer learning benefit the deployment of LLMs in different domains?"
];
****************************************

****************************************
Boxer\scripts\common\ApiConfiguration.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard library imports
import os

azure = True                  

if azure:
   API_TYPE = "Azure" #AZURE VERSION WAS "Azure"
   # API_KEY = os.environ["AZURE_OPENAI_API_KEY"] #AZURE VERSION WAS os.environ["AZURE_OPENAI_API_KEY"]           #uncomment if code breaks - changes for script to exectable on both Windows and Unix machines.  
   API_KEY = os.getenv("AZURE_OPENAI_API_KEY")  # Use os.getenv() to safely retrieve environment variables       #comment if code breaks  - changes for script to exectable on both Windows and Unix machines. 
   API_VERSION = "2024-06-01" #AZURE VERSION WAS "2023-07-01-preview"
   RESOURCE_ENDPOINT = "https://studiomodels.openai.azure.com:443" #AZURE VERSION WAS os.environ["AZURE_OPENAI_ENDPOINT"] 
else:
   API_TYPE = "open_ai" #AZURE VERSION WAS "Azure"
   API_KEY = os.environ["OPENAI_API_KEY"] #AZURE VERSION WAS os.environ["AZURE_OPENAI_API_KEY"] 
   API_VERSION = "2020-11-07" #AZURE VERSION WAS "2023-07-01-preview"
   RESOURCE_ENDPOINT = "https://api.openai.com/v1" #AZURE VERSION WAS os.environ["AZURE_OPENAI_ENDPOINT"] 



class ApiConfiguration:
    def __init__(self) -> None:
        self.apiKey = API_KEY
        self.apiVersion = API_VERSION
        self.resourceEndpoint = RESOURCE_ENDPOINT
        self.azureDeploymentName = "StudioLarge"
        self.azureEmbedDeploymentName="StudioEmbeddingLarge"
        self.modelName="gpt-35-turbo-16k"
        self.embedModelName="text-embedding-ada-002"
        self.processingThreads = 1
        self.openAiRequestTimeout = 60
        self.summaryWordCount = 50      # 50 word summary
        self.chunkDurationMins = 10     # 10 minute long video clips
        self.maxTokens = 4096           # Upper limit on total tokens in an API call. 10 minutes of video = 600 words = 2400 tokens, plus approx 2x headroom
        self.discardIfBelow = 100       # Dont index if less than 100 tokens in an article

    apiType: str
    apiKey: str
    apiVersion: str
    resourceEndpoint: str
    azureDeploymentName: str
    azureEmbedDeploymentName: str
    modelName: str
    embedModelName: str
    processingThreads: int
    openAiRequestTimeout: int
    summaryWordCount: int
    chunkDurationMins: int
    maxTokens: int
    discardIfBelow: int
****************************************

****************************************
Boxer\scripts\common\common_functions.py
****************************************
# Standard library imports
import os
from openai import AzureOpenAI

from common.ApiConfiguration import ApiConfiguration

config = ApiConfiguration()

def ensure_directory_exists(directory):
    """
    Checks if the directory at the given destination exists.
    If it does not exist, creates the directory.

    Parameters:
    directory (str): The path to the directory.
    """
    # Use os.path.join() to handle path construction across different platforms
    if not os.path.exists(directory):
        os.makedirs(directory)
        #print(f"Directory '{directory}' created.")  #  can remove or comment out this print statement for production
    else:
        # print(f"Directory '{directory}' already exists.")
        pass

# Construct the path using os.path.join() for cross-platform compatibility
HTML_DESTINATION_DIR = os.path.join("data", "web")
ensure_directory_exists(HTML_DESTINATION_DIR)

def get_embedding(text : str, client : AzureOpenAI, config : ApiConfiguration):

   text = text.replace("\n", " ")
   response = client.embeddings.create(input = [text], 
                                   model=config.azureEmbedDeploymentName,
                                   timeout=config.openAiRequestTimeout)
   
   return response.data[0].embedding
****************************************

****************************************
Boxer\scripts\common\Urls.py
****************************************
# Standard library imports
import os
import json
import logging

logging.basicConfig(level=logging.INFO)

youTubeUrls = [  
["Stanford CS229: Machine Learning Full Course taught by Andrew Ng | Autumn 2018 - YouTube", "PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU"],
["Stanford CS224N: Natural Language Processing with Deep Learning | Winter 2021 - YouTube", "PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ"],
["Braid AI Canon", "PL9LkXkIUrSoxIlFSKcyB21XFFLCCYfPGv"],
["Braid - Additional Content", "PL9LkXkIUrSozgkPNepSMzidqtAGR0b1F_"],
["Augmented Language Models (LLM Bootcamp) (youtube.com)", "PL1T8fO7ArWleyIqOy37OVXsP4hFXymdOZ"]
]

gitHubUrls = [
["Generative AI for Beginners", "microsoft/generative-ai-for-beginners/blob/main", "../msintro"],
["AI Engineering", "swyxio/ai-notes", "../aieng"]
]

webUrls = [
["Software 2.0. by Andrej Karpathy", "https://karpathy.medium.com/software-2-0-a64152b37c35", False],
["Transformers, Explained: Understand the Model Behind GPT-3, BERT, and T5 (daleonai.com)", "https://daleonai.com/transformers-explained", False],
["What Is ChatGPT Doing … and Why Does It Work?—Stephen Wolfram", "https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/", False],
["How Stable Diffusion Works · Chris McCormick (mccormickml.com)", "https://mccormickml.com/2022/12/21/how-stable-diffusion-works/", False],
["Deep Learning in a Nutshell: Core Concepts | NVIDIA Technical Blog", "https://developer.nvidia.com/blog/deep-learning-nutshell-core-concepts/", False],
["Practical Deep Learning for Coders - Practical Deep Learning (fast.ai)", "https://course.fast.ai/", True],
["Word2Vec Explained. Explaining the Intuition of Word2Vec &… | by Vatsal | Towards Data Science", "https://towardsdatascience.com/word2vec-explained-49c52b4ccb71", False],
["Yes you should understand backprop | by Andrej Karpathy", "https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b", False],
["The Illustrated Transformer by Jay Alammar (jalammar.github.io)", "https://jalammar.github.io/illustrated-transformer/", False],
["The Annotated Transformer (harvard.edu)", "https://nlp.seas.harvard.edu/annotated-transformer/", False],
["The Illustrated Stable Diffusion by Jay Alammar Visualizing machine learning one concept at a time. (jalammar.github.io)", "https://jalammar.github.io/illustrated-stable-diffusion/", False],
["Huyen Chip's Blog", "https://huyenchip.com/", True],
["Stamford CS234 - Large Language Models", "https://stanford-cs324.github.io/winter2022/lectures/", True],
["The Scaling Hypothesis · Gwern.net", "https://gwern.net/scaling-hypothesis", False],
["chinchilla's wild implications — LessWrong", "https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications", False],
["The AI Revolution: How Auto-GPT Unleashes a New Era of Automation and Creativity | by Sriram Parthasarathy | Towards AI", "https://pub.towardsai.net/the-ai-revolution-how-auto-gpt-unleashes-a-new-era-of-automation-and-creativity-2008aa2ca6ae", False],
["The Waluigi Effect (mega-post) — LessWrong", "https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post", False],
["Build a GitHub Support Bot with GPT3, LangChain, and Python | Dagster Blog", "https://dagster.io/blog/chatgpt-langchain", False],
["Prompt Engineering Guide | Prompt Engineering Guide (promptingguide.ai)", "https://www.promptingguide.ai/", False],
["Learn | Pinecone", "https://www.pinecone.io/learn/", True],
["Use Cases | Langchain", "https://python.langchain.com/v0.1/docs/use_cases/", True],
["Hugging Face Cookbook", "https://huggingface.co/learn/cookbook", True],
["Open AI Cookbook", "https://cookbook.openai.com/", True],
["State of Open Source AI - 2023 Edition", "https://book.premai.io/state-of-open-source-ai/", True],
["Scaled Agile Framework 6.0", "https://scaledagileframework.com/", True],
["McKinsey on AI", "https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier", True],
["A16Z Market Analysis", "https://a16z.com/for-b2b-generative-ai-apps-is-less-more/", True],
["A16Z Market Analysis", "https://a16z.com/navigating-the-high-cost-of-ai-compute/", True],
["A16Z Market Analysis", "https://a16z.com/financial-services-will-embrace-generative-ai-faster-than-you-think/", True],
["A16Z Market Analysis", "https://a16z.com/who-owns-the-generative-ai-platform/", True],
["Interaction Design Foundation", "https://www.interaction-design.org/literature/topics/design-thinking", True],
["UX for AI", "https://www.uxforai.com/", True],
["Testing Machine Learning Systems: Code, Data and Models ", "https://madewithml.com/courses/mlops/testing/", True],
["Monitoring Machine Learning Systems: Code, Data and Models ", "https://madewithml.com/courses/mlops/monitoring/", True]
]

#class to store information about each URL
class UrlHit:
    def __init__(self) -> None:
        self.path = ""
        self.desc = ""
        self.hits = 0

    path: str
    desc: str
    hits: int


def countUrlHits(destinationDir, urls, input_filename, output_filename):
    # Set up logging
    logging.basicConfig(level=logging.WARNING)
    logger = logging.getLogger(__name__)

    if not destinationDir:
        logger.error("Output folder not provided")
        exit(1)

    chunks = []
    total_chunks = 0

    logger.debug("Starting hit counting")

    # Load the chunks from a JSON file
    input_file = os.path.join(destinationDir, input_filename)  # Adjusted input_file path

    logger.debug("Input file path: %s", input_file)

    try:
        with open(input_file, "r", encoding="utf-8") as f:
            chunks = json.load(f)
    except FileNotFoundError:
        logger.error("Input file '%s' not found", input_file)
        exit(1)
    except Exception as e:
        logger.error("Error loading JSON file: %s", str(e))
        exit(1)

    total_chunks = len(chunks)
    logger.debug("Total chunks to be processed: %s", total_chunks)

    # Build an empty array to accumulate hits
    hits = [None] * len(urls)
    for i, url in enumerate(urls):
        hit = UrlHit()
        hit.desc = url[0]
        hit.path = url[1]
        hit.hits = 0
        hits[i] = hit

    # Iterate through chunks accumulating hit count
    for chunk in chunks:
        haveHit = False
        haveAda = False

        ada = chunk.get('hitTrackingId')
        if (len(ada) > 0):
            haveAda = True

        for hit in hits:
            source = chunk.get('hitTrackingId')
            if source in hit.path:
                hit.hits += 1
                haveHit = True

        #if not haveHit:
            #raise AssertionError('All chunks should have a hit: ' + chunk.get('sourceId'))

        #if not haveAda:
            #raise AssertionError('All chunks should have an ada')

    # Print the results
    for hit in hits:
        print(hit.desc + ', ' + hit.path + ', ' + str(hit.hits))

    # Save the hits to an output file
    output_file = os.path.join(destinationDir, output_filename)
    logger.debug("Output file path: %s", output_file)   

    try:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump([hit.__dict__ for hit in hits], f)
        logger.debug("Output file saved at: %s", output_file)
    except Exception as e:
        logger.error("Error saving output file: %s", str(e))
        exit(1)
****************************************

****************************************
Boxer\scripts\github\download_markdown.py
****************************************
""" This script downloads the transcripts for all the markdown files in a GitHub repo. """
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import json
import logging
import time
import threading
import queue
import pathlib
from pathlib import Path

# Third-Party Packages
from markdown import markdown
from bs4 import BeautifulSoup

class Counter:
    """Thread-safe counter"""

    def __init__(self):
        """Initialize the counter"""
        self.value = 0
        self.lock = threading.Lock()

    def increment(self):
        """Increment the counter"""
        with self.lock:
            self.value += 1


counter = Counter()

def makeSourceId(repoSourceDir, repoName, filePath):
    """Constructs sourceId from repoSourceDir, repoName, and filePath"""
    relPath = os.path.relpath(filePath, repoSourceDir)
    composite = repoName + '/' + relPath
    unix = Path(composite).as_posix()
    return unix

def md_to_plain_text(md):
    """Converts Markdown content into plain text"""
    html = markdown(md)
    soup = BeautifulSoup(html, features='html.parser')
    fullText = soup.get_text()
    nolineFeeds = fullText.replace("\n", " ")
    return nolineFeeds
    
def get_markdown(fileName, counter_id, repoSourceDir, repoName, markdownDestinationDir, logger):
    """Reads Markdown content from a file and writes out as plain text"""

    sourceId = makeSourceId(repoSourceDir, repoName, fileName)
    fakeName = Path(fileName).name.replace("\\", "_")
    contentOutputFileName = os.path.join(markdownDestinationDir, fakeName + ".json.mdd")
    metaOutputFilename = os.path.join(markdownDestinationDir, fakeName + ".json")

    # if markdown file already exists, skip it
    if os.path.exists(contentOutputFileName):
        logger.debug("Skipping file %d, %s", counter_id, fileName)
        return False    
    
    markdown_content = Path(fileName).read_text(encoding="utf-8")
    plainText = md_to_plain_text(markdown_content) 

    jsonSeg = {"text": plainText, "start": "0"}
    jsonArr = [jsonSeg]
         
    # save the plain text content as a .json.mdd file
    with open(contentOutputFileName, "w", encoding="utf-8") as file:
        json.dump(jsonArr, file, indent=4, ensure_ascii=False)

    metadata = {
        "speaker": "",
        "title": Path(fileName).name,
        "sourceId": sourceId,
        "filename": os.path.basename(contentOutputFileName),
        "description": Path(fileName).name,
        "hitTrackingId": repoName
    }

    # save the metadata as a .json file
    with open(metaOutputFilename, "w", encoding="utf-8") as file:
        json.dump(metadata, file, indent=4, ensure_ascii=False)
    
    logger.debug("Markdown download completed: %d, %s", counter_id, fileName)
    return True

def process_queue(q, repoSourceDir, repoName, markdownDestinationDir, logger):
    """Processes the queue"""
    while not q.empty():
        file = q.get()

        counter.increment()
        get_markdown(file, counter.value, repoSourceDir, repoName, markdownDestinationDir, logger)
        q.task_done()

def download_markdown(repoSourceDir, repoName, markdownDestinationDir): 
    """Main function to download Markdown files"""

    logging.basicConfig(level=logging.WARNING)
    logger = logging.getLogger(__name__)

    MAX_RESULTS = 100
    PROCESSING_THREADS = 1

    q = queue.Queue()

    if not markdownDestinationDir:
        logger.error("Markdown folder not provided")
        exit(1)

    if not repoSourceDir:
        logger.error("Repo name not provided")
        exit(1)

    cwd = os.getcwd()
    logger.debug("Current directory: %s", cwd)
    logger.debug("Repo folder: %s", repoSourceDir)
    logger.debug("Markdown folder: %s", markdownDestinationDir)

    directory_path = Path(repoSourceDir)

    # Use rglob() to recursively search for all files
    searchPath = directory_path.rglob("*.md")
    markdown_files = list(searchPath)

    # Build a queue of Markdown filenames
    for file in markdown_files:
        q.put(str(file))

    logger.info("Total markdown files to be downloaded: %s", q.qsize())

    start_time = time.time()

    # Create multiple threads to process the queue
    threads = []
    for i in range(PROCESSING_THREADS):
        t = threading.Thread(target=process_queue, args=(q, repoSourceDir, repoName, markdownDestinationDir, logger))
        t.start()
        threads.append(t)

    # Wait for all threads to finish
    for t in threads:
        t.join()

    finish_time = time.time()
    logger.debug("Total time taken: %s", finish_time - start_time)
****************************************

****************************************
Boxer\scripts\test\README.md
****************************************
# Test Scripts README

This README provides instructions on how to run the test scripts located in the `scripts/test/` folder and explains their expected output.

## Table of Contents

1. [Prerequisites](#prerequisites)
2. [Running the Tests](#running-the-tests)
3. [Test Scripts](#test-scripts)
   - [test_web_pipeline.py](#test_web_pipelinepy)
   - [test_youtube_pipeline.py](#test_youtube_pipelinepy)
4. [Expected Output](#expected-output)
5. [Troubleshooting](#troubleshooting)

## Prerequisites

Before running the tests, ensure you have the following:

- Python 3.12.4 installed
- Virtual environment activated
- All required dependencies installed (run `pip install -r scripts/requirements.txt` from the project root)
- Proper environment variables set in your `.env` file

## Running the Tests

To run the test scripts, follow these steps:

1. Navigate to the `scripts/test/` directory:

   ```
   cd scripts/test/
   ```

2. Run the tests using pytest:
   ```
   pytest test_web_pipeline.py test_youtube_pipeline.py
   ```

You can also run each test script separately:

```
pytest -v "test_web_pipeline.py"
pytest -v "test_youtube_pipeline.py"
```

## Test Scripts

### test_web_pipeline.py

This script tests the web content processing pipeline. It includes tests for:

- Downloading HTML content
- Enriching text chunks
- Generating summaries
- Creating embeddings
- Counting URL hits

### test_youtube_pipeline.py

This script tests the YouTube content processing pipeline. It includes tests for:

- Downloading YouTube transcripts
- Enriching transcript chunks
- Generating summaries
- Creating embeddings
- Counting URL hits
- Handling various YouTube API exceptions

## Expected Output

When running the tests, you should see output similar to the following:

```
============================= test session starts ==============================
platform darwin -- Python 3.12.4, pytest-7.4.0, pluggy-1.2.0
rootdir: /path/to/your/project/scripts/test
collected X items

test_web_pipeline.py ...                                                 [ 33%]
test_youtube_pipeline.py ......                                          [100%]

============================== X passed in Y.YYs ===============================
```

Each dot (.) represents a passed test. If a test fails, you'll see an 'F' instead, followed by detailed error information.

## Troubleshooting

If you encounter any issues while running the tests:

1. Ensure all prerequisites are met and dependencies are installed.
2. Check that your `.env` file contains the necessary API keys.
3. Verify that you're running the tests from the correct directory.
4. If a specific test is failing, review the error message and stack trace for more information.
****************************************

****************************************
Boxer\scripts\test\test_3chunks_web_pipeline.py
****************************************
import pytest
import os
import sys
import json
from unittest.mock import MagicMock, patch, mock_open
from pathlib import Path
from collections import namedtuple

# Add the parent directory of the test file to the Python path for importing modules
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from scripts.text.enrich_text_chunks import (
    append_text_to_previous_chunk,
    add_new_chunk,
    parse_json_mdd_transcript,
    enrich_text_chunks
)
from scripts.web.download_html import download_html

# Constants for testing, used for calculating chunk sizes and overlaps
PERCENTAGE_OVERLAP = 0.05
AVERAGE_WORDS_PER_MINUTE = 100
AVERAGE_CHARACTERS_PER_TOKEN = 4
AVERAGE_TOKENS_PER_WORD = 1.33

# Mock configuration for the chunking process
Config = namedtuple('Config', ['chunkDurationMins', 'discardIfBelow', 'maxTokens'])
mock_config = Config(chunkDurationMins=1, discardIfBelow=10, maxTokens=15)  # Adjust maxTokens to ensure chunking

# Mock metadata for chunks, used in the tests
mock_metadata = {
    "speaker": "",
    "title": "Test Title",
    "sourceId": "test-source",
    "filename": "test_file.json.mdd",
    "description": "Test description",
    "hitTrackingId": "https://test.com",
    "start": "0",
    "seconds": 145,
    "text": "This is a test text content."
}

def calculate_exact_text_length(config):
    """
    Calculate the exact number of characters required to generate a specified number of chunks.

    Args:
        config: The configuration object with chunk duration and max tokens.

    Returns:
        int: The total number of characters required for the desired number of chunks.
    """
    tokens_per_chunk = config.maxTokens - int(config.maxTokens * PERCENTAGE_OVERLAP)
    characters_per_chunk = tokens_per_chunk * AVERAGE_CHARACTERS_PER_TOKEN
    total_characters_required = characters_per_chunk * 3  # For 3 chunks
    return total_characters_required

def generate_mock_mdd_content(total_characters_required):
    """
    Generate mock content for an MDD file with three parts, based on the total required characters.

    Args:
        total_characters_required: The total number of characters required.

    Returns:
        str: The JSON string representing the mock MDD content.
    """
    sample_text = "This is a paragraph of text. " * (total_characters_required // len("This is a paragraph of text. ") + 1)
    sample_text = sample_text[:total_characters_required]

    return json.dumps([
        {"text": sample_text[:total_characters_required // 3], "start": "0", "duration": "60"},
        {"text": sample_text[total_characters_required // 3: 2 * total_characters_required // 3], "start": "60", "duration": "60"},
        {"text": sample_text[2 * total_characters_required // 3:], "start": "120", "duration": "60"}
    ])

def create_tokenizer_mock():
    """
    Create a mock tokenizer that simulates realistic token encoding behavior.

    Returns:
        MagicMock: A mock tokenizer with customized encoding behavior.
    """
    tokenizer = MagicMock()
    tokenizer.encode = MagicMock(side_effect=lambda text, disallowed_special=None: list(range(len(text.split()))))
    return tokenizer

@patch('scripts.web.download_html.requests.Session')
@patch('builtins.open', new_callable=mock_open)
@patch('json.dump')
def test_download_html(mock_json_dump, mock_file, mock_session):
    """
    Test the download_html function for downloading and processing HTML content.

    Args:
        mock_json_dump: Mock for the json.dump function.
        mock_file: Mock for the open function.
        mock_session: Mock for the requests.Session class.
    """
    # Mock HTML content
    mock_html = "<html><body><p>This is a test paragraph.</p></body></html>"
    mock_response = mock_session.return_value.get.return_value
    mock_response.content = mock_html.encode('utf-8')
    mock_response.text = mock_html

    # Mock BeautifulSoup
    with patch('scripts.web.download_html.BeautifulSoup') as mock_bs:
        mock_bs.return_value.get_text.return_value = "This is a test paragraph."

        # Run the download_html function
        download_html('http://example.com', False, '/tmp/html', 1)

    # Adjusted expected file path for content
    expected_content_file_path = os.path.normpath('/tmp/html/example.com.json.mdd')
    expected_metadata_file_path = os.path.normpath('/tmp/html/example.com.json')

    # Normalize the actual file paths called with
    actual_content_file_path = os.path.normpath(mock_file.call_args_list[0][0][0])
    actual_metadata_file_path = os.path.normpath(mock_file.call_args_list[1][0][0])

    # Check that the files were opened with the correct paths
    assert actual_content_file_path == expected_content_file_path
    assert actual_metadata_file_path == expected_metadata_file_path

    # Check if json.dump was called with correct content data
    expected_content = [{"text": "This is a test paragraph.", "start": "0"}]
    mock_json_dump.assert_any_call(expected_content, mock_file(), indent=4, ensure_ascii=False)

def test_append_text_to_previous_chunk():
    """
    Test the append_text_to_previous_chunk function to verify text is correctly appended with overlap.
    """
    chunks = [{"text": "Hello world "}]
    text = "This is a test sentence."

    append_text_to_previous_chunk(text, chunks)

    words = text.split(" ")
    expected_overlap_length = int(len(words) * PERCENTAGE_OVERLAP)
    expected_overlap = " ".join(words[:expected_overlap_length])
    assert chunks[-1]["text"].endswith(expected_overlap)

def test_add_new_chunk():
    """
    Test the add_new_chunk function to ensure new chunks are correctly added.
    """
    metadata = {"title": "Test Title", "description": "Test description", "start": "0"}
    text = "This is a test sentence."
    chunk_begin_tokens = 0
    chunks = []
    minimumSegmentTokenCount = 3

    add_new_chunk(metadata, text, chunk_begin_tokens, chunks, minimumSegmentTokenCount)

    assert len(chunks) == 1
    assert chunks[0]["text"] == text
    assert chunks[0]["start"] == str(chunk_begin_tokens)

    characters_per_minute = AVERAGE_WORDS_PER_MINUTE * AVERAGE_CHARACTERS_PER_TOKEN
    expected_seconds = int(len(text) / (characters_per_minute / 60))
    assert chunks[0]["seconds"] == expected_seconds

def test_parse_json_mdd_transcript(tmp_path):
    """
    Test the parse_json_mdd_transcript function with a manually created MDD file.

    Args:
        tmp_path: A pytest fixture providing a temporary directory.
    """
    config = MagicMock()
    config.chunkDurationMins = 1
    config.discardIfBelow = 1
    config.maxTokens = 15  # Adjust maxTokens to force chunking

    metadata = {
        "title": "Test Title",
        "description": "Test description",
        "filename": "test_mdd.json.mdd",
        "start": "0",
        "seconds": 180
    }

    total_characters_required = calculate_exact_text_length(config)
    tokenizer = create_tokenizer_mock()

    # Write the mock MDD content to a temporary file
    mock_mdd_content = generate_mock_mdd_content(total_characters_required)
    mdd_path = tmp_path / "test_mdd.json.mdd"
    mdd_path.write_text(mock_mdd_content)

    chunks = []
    parse_json_mdd_transcript(config, str(mdd_path), metadata, tokenizer, chunks)

    assert len(chunks) == 3

@pytest.fixture
def mock_file_system(tmp_path):
    """
    A pytest fixture to create a mock file system structure for testing.

    Args:
        tmp_path: A pytest fixture providing a temporary directory.

    Returns:
        str: The path to the mock file system.
    """
    # Create a temporary directory structure
    markdown_dir = tmp_path / "markdown"
    markdown_dir.mkdir()

    total_characters_required = calculate_exact_text_length(mock_config)
    sample_text = "This is a paragraph of text. " * (total_characters_required // len("This is a paragraph of text. ") + 1)
    sample_text = sample_text[:total_characters_required]

    # Ensure the mock MDD content has the exact length for 3 chunks
    sample_mdd_content = json.dumps([
        {"text": sample_text[:total_characters_required // 3], "start": "0", "duration": "60"},
        {"text": sample_text[total_characters_required // 3: 2 * total_characters_required // 3], "start": "60", "duration": "60"},
        {"text": sample_text[2 * total_characters_required // 3:], "start": "120", "duration": "60"}
    ])

    (markdown_dir / "test_file.json").write_text(json.dumps(mock_metadata))
    (markdown_dir / "test_file.json.mdd").write_text(sample_mdd_content)
    return str(markdown_dir)

@patch('tiktoken.encoding_for_model')
def test_enrich_text_chunks(mock_tokenizer, mock_file_system):
    """
    Test the enrich_text_chunks function to ensure text chunking and file output are correctly handled.

    Args:
        mock_tokenizer: Mock for the tokenizer.
        mock_file_system: Mock file system structure provided by the fixture.
    """
    # Mock the tokenizer
    mock_tokenizer.return_value.encode.side_effect = lambda text, **kwargs: list(range(len(text.split())))

    # Adjust config to force multiple chunks
    mock_config = Config(chunkDurationMins=1, discardIfBelow=1, maxTokens=15)  # Adjust maxTokens to a small number

    # Run the function
    enrich_text_chunks(mock_config, mock_file_system)

    # Check if the output file was created
    output_file = Path(mock_file_system) / "output" / "master_text.json"
    assert output_file.exists()

    # Read the output file and check its content
    with open(output_file, 'r') as f:
        output_content = json.load(f)

    # Assert the structure and content of the output
    assert isinstance(output_content, list)
    assert len(output_content) == 3
    print(output_content )
if __name__ == "__main__":
    pytest.main()
****************************************

****************************************
Boxer\scripts\test\test_utility.py
****************************************
""" This script will take a list of questions and run them through the test pipeline."""
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
from logging import Logger
import os
import json

# Third-Party Packages
import openai
from openai import AzureOpenAI
from openai import BadRequestError

from tenacity import (
    retry,
    wait_random_exponential,
    stop_after_attempt,
    retry_if_not_exception_type,
)
from rich.progress import Progress
import numpy as np
from numpy.linalg import norm

# Local Modules
from common.ApiConfiguration import ApiConfiguration
from common.common_functions import get_embedding

kOpenAiPersonaPrompt = "You are an AI assistant helping an application developer understand generative AI. You explain complex concepts in simple language, using Python examples if it helps. You limit replies to 50 words or less. If you don't know the answer, say 'I don't know'. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'."
kInitialQuestionPrompt = "You are an AI assistant helping an application developer understand generative AI. You will be presented with a question. Answer the question in a few sentences, using language a suitable for a technical graduate student will understand. Limit your reply to 50 words or less. If you don't know the answer, say 'I don't know'. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'.\n"
kEnrichmentPrompt = "You will be provided with a question about building applications that use generative AI technology. Write a 50 word summary of an article that would be a great answer to the question. Consider enriching the question with additional topics that the question asker might want to understand. Write the summary in the present tense, as though the article exists. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'.\n"
kFollowUpPrompt = "You will be provided with a summary of an article about building applications that use generative AI technology. Write a question of no more than 10 words that a reader might ask as a follow up to reading the article."
kEnrichmentQuestionPrefix = "Question:"
kFollowUpPrefix = "Article summary: "

class test_result:
    def __init__(self) -> None:
        self.question = ""
        self.enriched_question = ""        
        self.hit = False 
        self.hitRelevance = 0
        self.hitSummary = ""
        self.followUp = ""
        self.followUpOnTopic = ""

    question: str
    enriched_question: str    
    hit: bool
    hitRelevance: float
    hitSummary: str
    followUp: str
    followUpOnTopic: str  # Corrected typo here

@retry(
    wait=wait_random_exponential(min=5, max=15),
    stop=stop_after_attempt(5),
    retry=retry_if_not_exception_type(openai.BadRequestError),
)
def get_enriched_question(client: AzureOpenAI, config: ApiConfiguration, text: str, logger):
    """Generate a summary using chatgpt"""

    messages = [
        {
            "role": "system",
            "content": kOpenAiPersonaPrompt,
        },
        {
           "role": "user", 
           "content": kEnrichmentPrompt + kEnrichmentQuestionPrefix + text
        },
    ]

    response = client.chat.completions.create(
        model=config.azureDeploymentName,
        messages=messages,
        temperature=0.7,
        max_tokens=config.maxTokens,
        top_p=0.0,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None,
        timeout=config.openAiRequestTimeout
    )

    text = response.choices[0].message.content
    finish_reason = response.choices[0].finish_reason

    if finish_reason != "stop" and finish_reason != 'length' and finish_reason != "":
        logger.warning("Stop reason: %s", finish_reason)
        logger.warning("Text: %s", text)
        logger.warning("Increase Max Tokens and try again")
        exit(1)

    return text


@retry(
    wait=wait_random_exponential(min=5, max=15),
    stop=stop_after_attempt(5),
    retry=retry_if_not_exception_type(openai.BadRequestError),
)
def get_text_embedding(client: AzureOpenAI, config: ApiConfiguration, text: str, logger: Logger) : 
    """Get the embedding for a text"""

    embedding = get_embedding (text, client, config)
    return embedding


@retry(
    wait=wait_random_exponential(min=5, max=15),
    stop=stop_after_attempt(5),
    retry=retry_if_not_exception_type(openai.BadRequestError),
)
def get_followup_question(client: AzureOpenAI, config: ApiConfiguration, text: str, logger):
    """Generate a summary using chatgpt"""

    messages = [
        {
            "role": "system",
            "content": kFollowUpPrompt,
        },
        {
           "role": "user", 
           "content": text
        },
    ]

    response = client.chat.completions.create(
        model=config.azureDeploymentName,
        messages=messages,
        temperature=0.7,
        max_tokens=config.maxTokens,
        top_p=0.0,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None,
        timeout=config.openAiRequestTimeout
    )

    text = response.choices[0].message.content
    finish_reason = response.choices[0].finish_reason

    if finish_reason != "stop" and finish_reason != 'length' and finish_reason != "":
        logger.warning("Stop reason: %s", finish_reason)
        logger.warning("Text: %s", text)
        logger.warning("Increase Max Tokens and try again")
        exit(1)

    return text

@retry(
    wait=wait_random_exponential(min=5, max=15),
    stop=stop_after_attempt(5),
    retry=retry_if_not_exception_type(openai.BadRequestError),
)
def assess_followup_question(client: AzureOpenAI, config: ApiConfiguration, text: str, logger):
    """Generate a summary using chatgpt"""

    messages = [
        {
            "role": "system",
            "content": "You are an AI assistant helping a team of developers understand AI. You explain complex concepts in simple language. You will be asked a question. Respond 'yes' if the question appears to be about AI, otherwise respond 'no'."
        },
        {
           "role": "user", 
           "content": text
        },
    ]

    response = client.chat.completions.create(
        model=config.azureDeploymentName,
        messages=messages,
        temperature=0.7,
        max_tokens=config.maxTokens,
        top_p=0.0,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None,
        timeout=config.openAiRequestTimeout
    )

    text = response.choices[0].message.content
    finish_reason = response.choices[0].finish_reason

    if finish_reason != "stop" and finish_reason != 'length' and finish_reason != "":
        logger.warning("Stop reason: %s", finish_reason)
        logger.warning("Text: %s", text)
        logger.warning("Increase Max Tokens and try again")
        exit(1)

    return text

def cosine_similarity(a, b): 
   result = np.dot(a, b) / (norm(a) * norm(b))
   return result

def run_tests(config, testDestinationDir, sourceDir, questions): 
   """Run tests with given questions"""

   logging.basicConfig(level=logging.WARNING)
   logger = logging.getLogger(__name__)

   client = AzureOpenAI(
      azure_endpoint = config.resourceEndpoint, 
      api_key=config.apiKey,  
      api_version=config.apiVersion
   )      
   
   if not testDestinationDir:
      logger.error("Test data folder not provided")
      exit(1)

   results = []

   # load the existing chunks from a json file
   cache_file = os.path.join(sourceDir, "embeddings_lite.json")
   if os.path.isfile(cache_file):
      with open(cache_file, "r", encoding="utf-8") as f:
         current = json.load(f)       

   logger.info("Starting test run, total questions to be processed: %s", len(questions))

   for question in questions:
      result = test_result()
      result.question = question

      result.enriched_question = get_enriched_question(client, config, question, logger)

      # Convert the text of the enriched question to a vector embedding
      embedding = get_text_embedding(client, config, result.enriched_question, logger)
   
      # Iterate through the chunks we have stored 
      for chunk in current:
         
         # calculate the similarity between the chunk and the question
         ada = chunk.get("ada_v2")
         similarity = cosine_similarity(ada, embedding)

         # If we pass a reasonableness threshold, count it as a hit
         if similarity > 0.8:
            result.hit = True
         
         # If it is the best hit so far, record the match
         if similarity > result.hitRelevance:
            result.hitRelevance = similarity 
            result.hitSummary = chunk.get("summary")

      # Ask GPT for a follow-up question on the best match
      # Once we have a follow-up, ask GPT if the follow-up looks like it is about AI            
      result.followUp = get_followup_question(client, config, result.hitSummary, logger)
      result.followUpOnTopic = assess_followup_question(client, config, result.followUp, logger)            

      results.append(result)

   logger.debug("Total tests processed: %s", len(results))

   output_results = []
   for result in results:
      output = dict()
      output["question"] = result.question
      output["enriched_question"] = result.enriched_question
      output["hit"] = result.hit   
      output["summary"] = result.hitSummary        
      output["hitRelevance"] = result.hitRelevance      
      output["followUp"] = result.followUp  
      output["followUpOnTopic"] = result.followUpOnTopic             
      output_results.append(output)
      
   # save the test results to a json file
   output_file = os.path.join(testDestinationDir, "test_output.json")
   with open(output_file, "w", encoding="utf-8") as f:
      json.dump(output_results, f)
****************************************

****************************************
Boxer\scripts\test\test_web_pipeline.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import pytest
import os
import json
import shutil
import sys
import logging

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.WARNING)

# Add the project root and scripts directory to the Python path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
scripts_dir = os.path.join(project_root, 'scripts')
sys.path.extend([project_root, scripts_dir])

# Import necessary modules from the project
from common.ApiConfiguration import ApiConfiguration
from common.Urls import webUrls, countUrlHits
from common.common_functions import ensure_directory_exists
from web.download_html import download_html
from text.enrich_text_chunks import enrich_text_chunks
from text.enrich_text_summaries import enrich_text_summaries
from text.enrich_text_embeddings import enrich_text_embeddings
from text.enrich_lite import enrich_lite


'''

def create_mock_html_files(test_output_dir, source_url):
    """Create mock HTML files for testing."""
    html_dir = os.path.join(test_output_dir, "html")
    os.makedirs(html_dir, exist_ok=True)
    
    # Create three mock HTML files
    for i in range(3):
        filename = f"mock_page_{i}.json.mdd"
        filepath = os.path.join(html_dir, filename)
        content = [{"text": f"This is mock content for chunk {i}", "start": str(i * 100)}]
        with open(filepath, "w") as f:
            json.dump(content, f)
        
        # Create corresponding metadata file
        meta_filename = f"mock_page_{i}.json"
        meta_filepath = os.path.join(html_dir, meta_filename)
        metadata = {
            "speaker": "",
            "title": f"Mock Page {i}",
            "sourceId": f"{source_url}/page{i}",
            "filename": filename,
            "description": f"Mock description for page {i}",
            "hitTrackingId": source_url
        }
        with open(meta_filepath, "w") as f:
            json.dump(metadata, f)

def test_chunk_addition(tmp_path, config: ApiConfiguration):
    logger.info("Starting chunk addition test")

    test_output_dir = os.path.join(str(tmp_path), "test_output")
    os.makedirs(test_output_dir, exist_ok=True)
    logger.info(f"Created test output directory: {test_output_dir}")

    source_url = "http://example.com/test"
    create_mock_html_files(test_output_dir, source_url)

    # Mock the download_html function to avoid actual web requests
    with patch('web.download_html.download_html', return_value=None):
        # Run the enrichment process
        enrich_text_chunks(config, test_output_dir)

    # Check the output
    master_text_path = os.path.join(test_output_dir, "output", "master_text.json")
    assert os.path.exists(master_text_path), f"master_text.json not found at {master_text_path}"

    with open(master_text_path, "r") as f:
        chunks = json.load(f)

    # Verify that we have exactly 3 chunks
    assert len(chunks) == 3, f"Expected 3 chunks, but got {len(chunks)}"

    # Verify that each chunk has the correct structure and content
    for i, chunk in enumerate(chunks):
        assert chunk["sourceId"] == f"{source_url}/page{i}", f"Incorrect sourceId for chunk {i}"
        assert chunk["text"].startswith(f"This is mock content for chunk {i}"), f"Incorrect content for chunk {i}"
        assert chunk["start"] == str(i * 100), f"Incorrect start time for chunk {i}"
        assert "seconds" in chunk, f"Missing 'seconds' field in chunk {i}"
        assert chunk["hitTrackingId"] == source_url, f"Incorrect hitTrackingId for chunk {i}"

    logger.info("Chunk addition test completed successfully")

'''
# Fixture to create a temporary directory for test output
@pytest.fixture
def test_output_dir(tmpdir):
    dir_path = tmpdir.mkdir("test_output")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    shutil.rmtree(str(dir_path))

# Fixture to create an instance of ApiConfiguration
@pytest.fixture
def config():
    logger.info("Creating ApiConfiguration instance")
    return ApiConfiguration()

# Function to check if the content from a source URL is present in the specified file
def check_content(file_path, source_url):
    logger.info(f"Checking content for source URL: {source_url}")
    try:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Could not find master_text.json at {file_path}")
        
        with open(file_path, "r", encoding="utf-8") as f:
            content = json.load(f)
        matching_chunks = [chunk for chunk in content if chunk["hitTrackingId"] == source_url]
        logger.info(f"Found {len(matching_chunks)} chunks for source: {source_url}")
        assert matching_chunks, f"Content from source {source_url} not found"
        return matching_chunks
    except Exception as e:
        logger.error(f"Error checking content for {source_url}: {str(e)}")
        raise

# Function to run the entire pipeline of text enrichment processes
def run_pipeline(config, output_dir):
    logger.info(f"Running pipeline for output directory: {output_dir}")
    try:
        enrich_text_chunks(config, output_dir)
        enrich_text_summaries(config, output_dir)
        enrich_text_embeddings(config, output_dir)
        enrich_lite(output_dir)
        logger.info("Pipeline completed successfully")
    except Exception as e:
        logger.error(f"Error running pipeline: {str(e)}")
        raise

# Function to verify the hit counts for the expected number of sources

def verify_hit_counts(output_dir, expected_sources):
    logger.info(f"Verifying hit counts for {expected_sources} expected sources")
    try:
        with open(os.path.join(output_dir, "hit_test_results.json"), "r", encoding="utf-8") as f:
            hit_counts = json.load(f)
        
        assert len(hit_counts) == expected_sources, f"Expected hit counts for {expected_sources} sources, got {len(hit_counts)}"
        
        for i, hit in enumerate(hit_counts):
            logger.info(f"Source {i+1} ({hit['path']}) hit count: {hit['hits']}")
            assert hit['hits'] > 0, f"No hits found for source {hit['path']}. Hit counts: {hit_counts}"
        
        logger.info("Hit count verification completed successfully")
    except Exception as e:
        logger.error(f"Error verifying hit counts: {str(e)}")
        raise

def test_web_pipeline(tmp_path, config: ApiConfiguration):
    logger.info("Starting web pipeline test")

    # Create a new directory for test output
    test_output_dir = os.path.join(str(tmp_path), "test_output")
    os.makedirs(test_output_dir, exist_ok=True)
    logger.info(f"Created test output directory: {test_output_dir}")

    # Clean contents (in case of a failed previous run)
    for item in os.listdir(test_output_dir):
        item_path = os.path.join(test_output_dir, item)
        if os.path.isdir(item_path):
            shutil.rmtree(item_path)
        else:
            os.remove(item_path)
    logger.info("Cleaned test output directory")

    source1 = webUrls[0]  # First source URL
    source2 = webUrls[1]  # Second source URL

    try:
        # Download source 1 and run the whole pipeline
        logger.info(f"Downloading and processing source 1: {source1[1]}")
        download_html(source1[1], source1[2], test_output_dir, config.discardIfBelow)
        run_pipeline(config, test_output_dir)

        # Load JSON output and confirm content from source 1
        master_text_path = os.path.join(test_output_dir, "output", "master_text.json")
        source1_chunks = check_content(master_text_path, source1[1])
        assert source1_chunks, f"No content found for source 1: {source1[1]}"
        logger.info("Confirmed content from source 1")

        # Add source 2 and run the whole pipeline again
        logger.info(f"Downloading and processing source 2: {source2[1]}")
        download_html(source2[1], source2[2], test_output_dir, config.discardIfBelow)
        run_pipeline(config, test_output_dir)

        # Load JSON output and confirm content from both sources
        source1_chunks = check_content(master_text_path, source1[1])
        source2_chunks = check_content(master_text_path, source2[1])
        assert source1_chunks, f"No content found for source 1: {source1[1]}"
        assert source2_chunks, f"No content found for source 2: {source2[1]}"
        logger.info("Confirmed content from both sources")

        # Count URL hits
        test_webUrls = [source1, source2]
        logger.info("Counting URL hits")
        output_dir = os.path.join(test_output_dir, "output")
        countUrlHits(output_dir, test_webUrls, "master_text.json", "hit_test_results.json")

        # Verify the hit counts
        verify_hit_counts(output_dir, 2)  # Expect 2 sources with hits

        logger.info("Web pipeline test completed successfully")

    except Exception as e:
        logger.error(f"Web pipeline test failed: {str(e)}")
        raise

    finally:
        # Clean up by deleting the test output directory and all files
        shutil.rmtree(test_output_dir)
        logger.info(f"Cleaned up test output directory: {test_output_dir}")

    logger.info("Web pipeline test completed")
****************************************

****************************************
Boxer\scripts\test\test_youtube_pipeline.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import pytest
import os
import json
import shutil
import sys
import logging
import re
from unittest.mock import patch, MagicMock
from typing import List, Dict, Any, Optional

# Third-Party Packages
from youtube_transcript_api import NoTranscriptFound, TranscriptsDisabled, VideoUnavailable

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

#Configurations to omit an out of scope log 
logging.getLogger("openai._base_client").setLevel(logging.WARNING)

# Add the project root and scripts directory to the Python path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
scripts_dir = os.path.join(project_root, 'scripts')
sys.path.extend([project_root, scripts_dir])

class IgnoreSpecificWarningsFilter(logging.Filter):
    """
    A custom logging filter to ignore specific warning messages.

    This filter is designed to remove warning logs that match a specific pattern
    related to RetryError and APIConnectionError.
    """

    def __init__(self) -> None:
        """
        Initialize the IgnoreSpecificWarningsFilter.

        Sets up the regex pattern to match the specific warning messages to be filtered.
        """
        super().__init__()
        self.pattern = re.compile(r'Error: RetryError\[<Future at 0x[0-9a-fA-F]+ state=finished raised APIConnectionError>\]')

    def filter(self, record: logging.LogRecord) -> bool:
        """
        Filter log records based on the predefined pattern.

        Args:
            record (logging.LogRecord): The log record to be filtered.

        Returns:
            bool: True if the log should be kept, False if it should be filtered out.
        """
        if record.levelno == logging.WARNING:
            return not self.pattern.search(record.getMessage())
        return True


custom_filter = IgnoreSpecificWarningsFilter()

for name in logging.root.manager.loggerDict:
    logging.getLogger(name).addFilter(custom_filter)

# Import necessary modules from the project
from common.ApiConfiguration import ApiConfiguration
from common.Urls import youTubeUrls, countUrlHits
from common.common_functions import ensure_directory_exists
from youtube.download_transcripts import download_transcripts, get_transcript
from youtube.enrich_transcript_chunks import enrich_transcript_chunks
from youtube.enrich_transcript_summaries import enrich_transcript_summaries
from youtube.enrich_transcript_embeddings import enrich_transcript_embeddings
from text.enrich_lite import enrich_lite

@pytest.fixture
def test_output_dir(tmpdir) -> str:
    """
    Fixture to create a temporary directory for test output.

    Args:
        tmpdir: pytest fixture for temporary directory

    Returns:
        str: Path to the temporary test output directory
    """
    dir_path = tmpdir.mkdir("test_output")
    logger.info(f"Created temporary test output directory: {dir_path}")
    yield str(dir_path)
    # Clean up after the test
    logger.info(f"Cleaning up test output directory: {dir_path}")
    shutil.rmtree(str(dir_path))

@pytest.fixture
def config() -> ApiConfiguration:
    """
    Fixture to create an instance of ApiConfiguration.

    Returns:
        ApiConfiguration: An instance of the ApiConfiguration class
    """
    logger.info("Creating ApiConfiguration instance")
    return ApiConfiguration()

def check_content(file_path: str, source_id: str) -> List[Dict[str, Any]]:
    """
    Check if the content from a source URL is present in the specified file.

    Args:
        file_path (str): Path to the JSON file containing the content
        source_id (str): ID of the source to check for

    Returns:
        List[Dict[str, Any]]: List of chunks matching the source ID

    Raises:
        FileNotFoundError: If the specified file is not found
    """
    logger.info(f"Checking content for source ID: {source_id}")
    try:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Could not find master_enriched.json at {file_path}")
        
        with open(file_path, "r", encoding="utf-8") as f:
            content = json.load(f)
        
        if not content:
            logger.warning(f"File {file_path} is empty")
            return []

        # Log the structure of the first few items for debugging
        logger.info(f"Sample content structure: {json.dumps(content[:2], indent=2)}")
        
        # Check for sourceId or any other potential identifier
        matching_chunks = [
            chunk for chunk in content 
            if chunk.get("sourceId") == source_id or
               chunk.get("playlistId") == source_id or
               chunk.get("hitTrackingId") == source_id
        ]
        
        logger.info(f"Found {len(matching_chunks)} chunks for source: {source_id}")
        
        if not matching_chunks:
            # Log all unique identifiers in the content for debugging
            unique_ids = set(
                chunk.get("sourceId") or chunk.get("playlistId") or chunk.get("hitTrackingId")
                for chunk in content
            )
            logger.warning(f"Available unique identifiers in content: {unique_ids}")
        
        return matching_chunks
    except Exception as e:
        logger.error(f"Error checking content for {source_id}: {str(e)}")
        raise

def run_pipeline(config: ApiConfiguration, output_dir: str) -> None:
    """
    Run the entire pipeline of transcript enrichment processes.

    Args:
        config (ApiConfiguration): Configuration object for API settings
        output_dir (str): Directory to store output files

    Raises:
        Exception: If any step in the pipeline fails
    """
    logger.info(f"Running pipeline for output directory: {output_dir}")
    try:
        logger.info("Starting enrich_transcript_chunks")
        enrich_transcript_chunks(config, output_dir)
        logger.info("Completed enrich_transcript_chunks")

        logger.info("Starting enrich_transcript_summaries")
        enrich_transcript_summaries(config, output_dir)
        logger.info("Completed enrich_transcript_summaries")

        logger.info("Starting enrich_transcript_embeddings")
        enrich_transcript_embeddings(config, output_dir)
        logger.info("Completed enrich_transcript_embeddings")

        logger.info("Starting enrich_lite")
        enrich_lite(output_dir)
        logger.info("Completed enrich_lite")

        logger.info("Pipeline completed successfully")
    except Exception as e:
        logger.error(f"Error running pipeline: {str(e)}", exc_info=True)
        raise

def verify_hit_counts(output_dir: str, expected_sources: int) -> None:
    """
    Verify the hit counts for the expected number of sources.

    Args:
        output_dir (str): Directory containing the hit count results
        expected_sources (int): Expected number of sources

    Raises:
        AssertionError: If the hit counts do not match expectations
    """
    logger.info(f"Verifying hit counts for {expected_sources} expected sources")
    try:
        with open(os.path.join(output_dir, "hit_test_results.json"), "r", encoding="utf-8") as f:
            hit_counts = json.load(f)
        
        assert len(hit_counts) == expected_sources, f"Expected hit counts for {expected_sources} sources, got {len(hit_counts)}"
        
        for i, hit in enumerate(hit_counts):
            logger.info(f"Source {i+1} ({hit['path']}) hit count: {hit['hits']}")
            assert hit['hits'] > 0, f"No hits found for source {hit['path']}. Hit counts: {hit_counts}"
        
        logger.info("Hit count verification completed successfully")
    except Exception as e:
        logger.error(f"Error verifying hit counts: {str(e)}")
        raise

def test_youtube_pipeline(tmp_path: str, config: ApiConfiguration) -> None:
    """
    Test the entire YouTube pipeline process.

    Args:
        tmp_path (str): Temporary path for test output
        config (ApiConfiguration): Configuration object for API settings

    Raises:
        Exception: If any step in the pipeline test fails
    """
    logger.info("Starting YouTube pipeline test")

    # Create a new directory for test output
    test_output_dir = os.path.join(str(tmp_path), "test_output")
    os.makedirs(test_output_dir, exist_ok=True)
    logger.info(f"Created test output directory: {test_output_dir}")

    # Clean contents (in case of a failed previous run)
    for item in os.listdir(test_output_dir):
        item_path = os.path.join(test_output_dir, item)
        if os.path.isdir(item_path):
            shutil.rmtree(item_path)
        else:
            os.remove(item_path)
    logger.info("Cleaned test output directory")

    source1 = youTubeUrls[0]  # First source URL
    source2 = youTubeUrls[1]  # Second source URL

    logger.info(f"Source 1: {source1}")
    logger.info(f"Source 2: {source2}")

    try:
        # Download source 1 and run the whole pipeline
        logger.info(f"Downloading and processing source 1: {source1[1]}")
        logger.info(f"Transcript destination directory: {test_output_dir}")
        download_transcripts(source1[1], test_output_dir)
        run_pipeline(config, test_output_dir)

        # Load JSON output and confirm content from source 1
        master_enriched_path = os.path.join(test_output_dir, "output", "master_enriched.json")
        source1_chunks = check_content(master_enriched_path, source1[1])
        assert source1_chunks, f"No content found for source 1: {source1[1]}"
        logger.info("Confirmed content from source 1")

        # Add source 2 and run the whole pipeline again
        logger.info(f"Downloading and processing source 2: {source2[1]}")
        logger.info(f"Transcript destination directory: {test_output_dir}")
        download_transcripts(source2[1], test_output_dir)
        run_pipeline(config, test_output_dir)

        # Load JSON output and confirm content from both sources
        source1_chunks = check_content(master_enriched_path, source1[1])
        source2_chunks = check_content(master_enriched_path, source2[1])
        assert source1_chunks, f"No content found for source 1: {source1[1]}"
        assert source2_chunks, f"No content found for source 2: {source2[1]}"
        logger.info("Confirmed content from both sources")

        # Count URL hits
        test_youTubeUrls = [source1, source2]
        logger.info("Counting URL hits")
        output_dir = os.path.join(test_output_dir, "output")
        countUrlHits(output_dir, test_youTubeUrls, "master_enriched.json", "hit_test_results.json")

        # Verify the hit counts
        verify_hit_counts(output_dir, 2)  # Expect 2 sources with hits

        logger.info("YouTube pipeline test completed successfully")

    except Exception as e:
        logger.error(f"YouTube pipeline test failed: {str(e)}")
        raise

    finally:
        # Clean up by deleting the test output directory and all files
        shutil.rmtree(test_output_dir)
        logger.info(f"Cleaned up test output directory: {test_output_dir}")

    logger.info("YouTube pipeline test completed")

@pytest.mark.parametrize("exception_class, expected_result", [
    (TranscriptsDisabled, False),
    (VideoUnavailable, False),
    (Exception, False)
])
def test_get_transcript_exceptions(exception_class: Exception, expected_result: bool) -> None:
    """
    Test get_transcript function for various exception scenarios.

    Args:
        exception_class (Exception): The exception class to be raised
        expected_result (bool): The expected return value of get_transcript

    This test ensures that get_transcript handles different exceptions correctly.
    """
    mock_playlist_item = {
        "snippet": {
            "resourceId": {
                "videoId": "test_video_id"
            }
        }
    }
    mock_logger = MagicMock()
    
    with patch('youtube.download_transcripts.YouTubeTranscriptApi.get_transcript') as mock_get_transcript:
        mock_get_transcript.side_effect = exception_class("Test exception")
        
        result = get_transcript(mock_playlist_item, 1, "/tmp/test_dir", mock_logger)
        
        assert result == expected_result
        mock_logger.debug.assert_called()

def test_get_transcript_success() -> None:
    """
    Test successful scenario of get_transcript function.

    This test ensures that get_transcript works correctly when transcript retrieval is successful.
    """
    mock_playlist_item = {
        "snippet": {
            "resourceId": {
                "videoId": "test_video_id"
            }
        }
    }
    mock_logger = MagicMock()
    mock_transcript = [{"text": "Test transcript"}]
    
    with patch('youtube.download_transcripts.YouTubeTranscriptApi.get_transcript') as mock_get_transcript, \
         patch('builtins.open', MagicMock()) as mock_open, \
         patch('os.makedirs') as mock_makedirs:
        mock_get_transcript.return_value = mock_transcript
        
        result = get_transcript(mock_playlist_item, 1, "/tmp/test_dir", mock_logger)
        
        assert result == True
        mock_logger.debug.assert_called_with("Transcription download completed: %d, %s", 1, "test_video_id")
        mock_open.assert_called_once()
        mock_makedirs.assert_called_once()

def test_get_transcript_file_exists() -> None:
    """
    Test get_transcript function when the transcript file already exists.

    This test ensures that get_transcript skips downloading when the transcript file is already present.
    """
    mock_playlist_item = {
        "snippet": {
            "resourceId": {
                "videoId": "test_video_id"
            }
        }
    }
    mock_logger = MagicMock()
    
    with patch('os.path.exists', return_value=True):
        result = get_transcript(mock_playlist_item, 1, "/tmp/test_dir", mock_logger)
        
        assert result == False
        mock_logger.debug.assert_called_with("Skipping video %d, %s", 1, "test_video_id")

if __name__ == "__main__":
    pytest.main([__file__])
****************************************

****************************************
Boxer\scripts\text\enrich_lite.py
****************************************
""" This script removes the text from the enriched transcript and saves it as a new json file."""
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import json
import os
import logging

def remove_text(segments):
    """This function removes the text from each dictionary in the list."""
    return [
        {k: v for k, v in seg.items() if k != "text" and k != "description"}
        for seg in segments
    ]

def enrich_lite(destinationDir): 
    """Remove text from enriched transcript and save as a new JSON file."""
    
    logging.basicConfig(level=logging.WARNING)
    logger = logging.getLogger(__name__)

    if not destinationDir:
        logger.error("Output folder not provided")
        exit(1)

    # Load source list from JSON file
    input_file = os.path.join(destinationDir, "output", "master_enriched.json")
    with open(input_file, "r", encoding="utf-8") as f:
        segments = json.load(f)

    total_segments = len(segments)

    # Create a lambda function to remove the text from each dictionary in the list
    lite = remove_text(segments)

    # Save the embeddings to a JSON file
    output_file = os.path.join(destinationDir, "output", "master_enriched_lite.json")
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(lite, f)

    logger.debug("Total segments processed: %s", total_segments)
****************************************

****************************************
Boxer\scripts\text\enrich_text_chunks.py
****************************************
""" This script generates a master csv file from the transcript files."""
# Copyright (c) 2024 Braid Technologies Ltd

# from the markdown files, generate a master json file
# from the makdown folder read all the .json files then load the associated .mdd file

# Standard Library Imports
import os
import json
import logging
from pathlib import Path
import math

# Third-Party Packages
import tiktoken
from rich.progress import Progress

# Local Modules
from common.common_functions import ensure_directory_exists

PERCENTAGE_OVERLAP = 0.05
AVERAGE_CHARACTERS_PER_TOKEN = 4
AVERAGE_WORDS_PER_MINUTE = 100
AVERAGE_TOKENS_PER_WORD=1.33

total_files = 0

class MddSegment:
    def __init__(self, chunk: dict) -> None:
        self.text = chunk.get("text")
        self.start = chunk.get("start")
        self.duration = chunk.get("duration")

def gen_metadata_master(metadata):
    """generate the metadata master csv file"""
    text = metadata["title"] + " " + metadata["description"]
    metadata["start"] = "0"

    text = text.strip()

    if not text:
        metadata["text"] = "No description available."
    else:
        # clean the text
        text = clean_text(text)
        metadata["text"] = text.strip()


def clean_text(text):
    """clean the text"""
    text = text.replace("\n", " ")  # remove new lines
    text = text.replace("&#39;", "'")
    text = text.replace(">>", "")  # remove '>>'
    text = text.replace("  ", " ")  # remove double spaces
    text = text.replace("[inaudible]", "")  # [inaudible]

    return text


def append_text_to_previous_chunk(text, chunks):
    """
    append PERCENTAGE_OVERLAP text to the previous chunk to smooth context transition
    """
    if chunks:
        words = text.split(" ")
        word_count = len(words)
        if word_count > 0:
            append_text = " ".join(words[0:int(word_count * PERCENTAGE_OVERLAP)])
            chunks[-1]["text"] += append_text


def add_new_chunk(metadata, text, chunk_begin_tokens, chunks, minimumSegmentTokenCount):
    """add a new chunk to the chunks list"""

    # don't add very short chunks
    if len(text) < minimumSegmentTokenCount * AVERAGE_CHARACTERS_PER_TOKEN:
        return
    
    charactersPerSecond = AVERAGE_WORDS_PER_MINUTE * AVERAGE_CHARACTERS_PER_TOKEN / 60

    metadata["start"] = str(chunk_begin_tokens)
    metadata["seconds"] = int(len(text) / charactersPerSecond)
    metadata["text"] = text
    chunks.append(metadata.copy())


def parse_json_mdd_transcript(config, mdd, metadata, tokenizer, chunks):
    """parse the json mdd file and return the transcript"""
    text = ""
    current_tokens = None
    seg_begin_tokens = None
    seg_finish_tokens = None
    current_token_length = 0
    first_chunk = True
    last_chunk = False

    # add the title to the transcript
    if "title" in metadata and metadata["title"]:
        metadata["title"] = clean_text(metadata.get("title"))
        text += metadata.get("title") + ". "

    current_token_length = len(tokenizer.encode(text))

    # open the mdd file
    with open(mdd, "r", encoding="utf-8") as json_file:
        json_mdd = json.load(json_file)

        if len(json_mdd) == 1:
            last_chunk = True

        for chunk in json_mdd:
            seg = MddSegment(chunk)
            current_tokens = int(seg.start)
            current_text = seg.text            

            if seg_begin_tokens is None:
                seg_begin_tokens = current_tokens
                # calculate the finish time from the chunk_begin_time
                seg_finish_tokens = seg_begin_tokens + config.chunkDurationMins * 60

            # Get the number of tokens in the text.
            # Need to calc to allow for tokens for 
            # summary request in next pipeline step
            total_tokens = len(tokenizer.encode(current_text, disallowed_special=())) + current_token_length

            # Deal with case of a chunk that is already over the limit - in which case we add it
            # in chunks # then return.
            if total_tokens >= seg_finish_tokens:
               
               currentWordCount = 0
               words = current_text.split(" ")
               word_count = len(words)
                  
               while currentWordCount < word_count:
                  maxWords = math.floor (seg_finish_tokens / AVERAGE_TOKENS_PER_WORD)
                  thisTextWordCount = min(maxWords, word_count - currentWordCount);
                  thisText = " ".join(words[currentWordCount : thisTextWordCount])
                  add_new_chunk(metadata, thisText, seg_begin_tokens, chunks, config.discardIfBelow)

                  #if we are not at the end, we overlap chunks by moving back a bit
                  if currentWordCount + thisTextWordCount < word_count:
                     currentWordCount += int (thisTextWordCount * (1- PERCENTAGE_OVERLAP))
                  else:
                     currentWordCount += thisTextWordCount

               return
        
            if current_tokens < seg_finish_tokens and total_tokens < config.maxTokens:
                # add the text to the transcript
                text += current_text + " "
                current_token_length = total_tokens
            else:
                if not first_chunk:
                    # append PERCENTAGE_OVERLAP text to the previous chunk
                    # to smooth context transition
                    append_text_to_previous_chunk(text, chunks)
                first_chunk = False
                add_new_chunk(metadata, text, seg_begin_tokens, chunks, config.discardIfBelow)

                text = current_text + " "

                # reset the chunk_begin_time
                seg_begin_tokens = None
                seg_finish_tokens = None

                current_token_length = len(tokenizer.encode(text))

        # Deal with case where there is only one chunk
        if first_chunk and last_chunk:
           add_new_chunk(metadata, text, seg_begin_tokens, chunks, config.discardIfBelow)
        else:
            # Append the last text chunk to the last chunk in chunks dictionary
            if seg_begin_tokens and text != "":
               previous_chunk_tokens = len(tokenizer.encode(chunks[-1]["text"]))
               current_chunk_tokens = len(tokenizer.encode(text))

               if previous_chunk_tokens + current_chunk_tokens < config.maxTokens:
                   chunks[-1]["text"] += text
               else:
                  if not first_chunk:
                     # append PERCENTAGE_OVERLAP text to the previous chunk
                     # to smooth context transition
                     append_text_to_previous_chunk(text, chunks)
                     first_chunk = False
                     add_new_chunk(metadata, text, seg_begin_tokens, chunks, config.discardIfBelow)


def get_transcript(config, metadata, markdownDestinationDir, logger, tokenizer, chunks):
    """get the transcript from the .mdd file"""

    global total_files
    mdd = os.path.join(markdownDestinationDir, metadata["filename"])

    # check that the .mdd file exists
    if not os.path.exists(mdd):
        logger.info("mdd file does not exist: %s", mdd)
        return None
    else:
        logger.debug("Processing file: %s", mdd)
        total_files += 1

    parse_json_mdd_transcript(config, mdd, metadata, tokenizer, chunks)


def enrich_text_chunks(config, markdownDestinationDir):
    logging.basicConfig(level=logging.WARNING)
    logger = logging.getLogger(__name__)
    chunks = []

    if not markdownDestinationDir:
        logger.error("Markdown folder not provided")
        exit(1)

    # https://stackoverflow.com/questions/75804599/openai-api-how-do-i-count-tokens-before-i-send-an-api-request
    ENCODING_MODEL = "gpt-3.5-turbo"
    tokenizer = tiktoken.encoding_for_model(ENCODING_MODEL)

    cwd = os.getcwd()
    logger.debug("Current directory : %s", cwd)
    logger.debug("Markdown folder: %s", markdownDestinationDir)
    logger.debug("Segment length %d minutes", config.chunkDurationMins)

    folder = os.path.join(markdownDestinationDir, "*.json")
    logger.debug("Search spec: %s", str(folder))

    directory_path = Path(markdownDestinationDir)

    # Use rglob() to recursively search for all files
    searchPath = directory_path.glob("*.json")
    jsonFiles = list(searchPath)

    global total_files
    total_files = len(jsonFiles)  # Initialize total_files with the count of jsonFiles

    with Progress() as progress:
        task1 = progress.add_task("[green]Enriching Buckets...", total=total_files)

        for file in jsonFiles:
            # load the json file
            meta = json.load(open(file, encoding="utf-8"))

            get_transcript(config, meta, markdownDestinationDir, logger, tokenizer, chunks)
            progress.update(task1, advance=1)

    logger.debug("Total files: %s", total_files)
    logger.debug("Total chunks: %s", len(chunks))

    # save chunks to a json file
    output_subdir = "output"
    output_file = os.path.join(markdownDestinationDir, output_subdir, "master_text.json")

    # Ensure the output subdirectory exists
    ensure_directory_exists(os.path.dirname(output_file))

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(chunks, f, ensure_ascii=False, indent=4)
****************************************

****************************************
Boxer\scripts\text\enrich_text_embeddings.py
****************************************
""" This script will take a text and create embeddings for each text using the OpenAI API."""
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import re
import os
import json
import threading
import queue

# Third-Party Packages
from openai import AzureOpenAI
from openai import BadRequestError
from tenacity import (
    retry,
    wait_random_exponential,
    stop_after_attempt,
    retry_if_not_exception_type,
)
from rich.progress import Progress

# Local Modules
from common.common_functions import ensure_directory_exists
from common.common_functions import get_embedding
from common.ApiConfiguration import ApiConfiguration

def normalize_text(s, sep_token=" \n "):
    """Normalize text by removing extra spaces and newlines."""
    s = re.sub(r"\s+", " ", s).strip()
    s = re.sub(r". ,", "", s)  # corrected the regex pattern
    s = s.replace("..", ".")
    s = s.replace(". .", ".")
    s = s.replace("\n", "")
    s = s.strip()

    return s


@retry(
    wait=wait_random_exponential(min=10, max=45),
    stop=stop_after_attempt(5),
    retry=retry_if_not_exception_type(BadRequestError),
)
def get_text_embedding(client : AzureOpenAI, config : ApiConfiguration, text: str):
    """Get the embedding for a text."""
    embedding = get_embedding(text,
                              client,
                              config)
    
    return embedding


def process_queue(client : AzureOpenAI, config : ApiConfiguration, progress, task, q, logger, output_chunks, current_chunks):
    """Process the queue."""
    while not q.empty():
        chunk = q.get()
        found = False

        for i in current_chunks:
            if i.get('sourceId') == chunk.get('sourceId'):
              current_summary = i.get("summary")
              current_ada = i.get("ada_v2")
              if current_summary and current_ada: 
                 chunk["summary"] = current_summary
                 chunk["ada_v2"] = current_ada                
                 found = True  
                 output_chunks.append(chunk.copy())                 
                 break

        if not found:
            if "ada_v2" in chunk:
                output_chunks.append(chunk.copy())
            else:
                # Get embedding using OpenAI API
                try:
                    embedding = get_text_embedding(client, config, chunk["text"])
                    chunk["ada_v2"] = embedding.copy()
                    output_chunks.append(chunk.copy())
                except BadRequestError as request_error:
                    logger.warning("Error processing chunk %s: %s", chunk.get('sourceId'), request_error)
                except Exception as e:
                    logger.warning("Unknown error processing chunk %s: %s", chunk.get('sourceId'), str(e))

        progress.update(task, advance=1)
        q.task_done()


def enrich_text_embeddings(config : ApiConfiguration, destinationDir : str):

    logging.basicConfig(level=logging.WARNING)
    logger = logging.getLogger(__name__)
    for key in logging.Logger.manager.loggerDict:
       logging.getLogger(key).setLevel(logging.WARNING)

    client = AzureOpenAI(
       azure_endpoint = config.resourceEndpoint, 
       api_key=config.apiKey,  
       api_version=config.apiVersion
    )   

    if not destinationDir:
        logger.error("Markdown folder not provided")
        exit(1)

    total_chunks = 0
    output_chunks = []
    current = []

    logger.debug("Starting OpenAI Embeddings")

    # Load chunks from the input JSON file
    input_file = os.path.join(destinationDir, "output", "master_enriched.json")
    with open(input_file, "r", encoding="utf-8") as f:
        chunks = json.load(f)

    total_chunks = len(chunks)
    logger.info("Total chunks to be processed: %s", total_chunks)

    # Prepare a queue with chunks to be processed
    q = queue.Queue()
    for chunk in chunks:
        q.put(chunk)

    # Load existing chunks from cache
    cache_file = os.path.join(destinationDir, "output", "master_enriched.json")
    if os.path.isfile(cache_file):
        with open(cache_file, "r", encoding="utf-8") as f:
            current = json.load(f)

    with Progress() as progress:
        task1 = progress.add_task("[green]Enriching Embeddings...", total=total_chunks)
        # Create multiple threads to process the queue
        threads = []
        for i in range(config.processingThreads):
            t = threading.Thread(target=process_queue, args=(client, config, progress, task1, q, logger, output_chunks, current))
            t.start()
            threads.append(t)

        # Wait for all threads to finish
        for t in threads:
            t.join()

    # Sort the output chunks by sourceId
    output_chunks.sort(key=lambda x: x["sourceId"])

    logger.debug("Total chunks processed: %s", len(output_chunks))

    # Save enriched chunks to a JSON file
    output_subdir = "output"
    output_file = os.path.join(destinationDir, output_subdir, "master_enriched.json")

    # Ensure the output subdirectory exists
    ensure_directory_exists(os.path.dirname(output_file))

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output_chunks, f, ensure_ascii=False, indent=4)
****************************************

****************************************
Boxer\scripts\text\enrich_text_summaries.py
****************************************
""" Summarize a youtube transcript using chatgpt"""
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import json
import os
import threading
import queue
import logging
from logging import Logger

# Third-Party Packages
from openai import AzureOpenAI
from openai import BadRequestError
from tenacity import (
    retry,
    wait_random_exponential,
    stop_after_attempt,
    retry_if_not_exception_type,
)
from rich.progress import Progress

# Local Modules
from common.common_functions import ensure_directory_exists
from common.ApiConfiguration import ApiConfiguration

class Counter:
    """thread safe counter"""

    def __init__(self):
        """initialize the counter"""
        self.value = 0
        self.lock = threading.Lock()

    def increment(self):
        """increment the counter"""
        with self.lock:
            self.value += 1
            return self.value
        

counter = Counter()

@retry(
    wait=wait_random_exponential(min=10, max=45),
    stop=stop_after_attempt(5),
    retry=retry_if_not_exception_type(BadRequestError)
)
def chatgpt_summary(client : AzureOpenAI, config : ApiConfiguration, text : str, logger : Logger):
    """generate a summary using chatgpt"""

    messages = [
        {
            "role": "system",
            "content": "You're an AI Assistant for summarising useful blogs, write an authoritative " 
                       + str(config.summaryWordCount) + 
                       "  word summary. Avoid starting sentences with 'This document' or 'The document'.",
        },
        {"role": "user", "content": text},
    ]

    response = client.chat.completions.create(
        model=config.azureDeploymentName,
        messages=messages,
        temperature=0.7,
        max_tokens=config.maxTokens,
        top_p=0.0,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None,
        timeout=config.openAiRequestTimeout        
    )

    # print(response)
    text = response.choices[0].message.content
    finish_reason = response.choices[0].finish_reason

    # print(finish_reason)
    if finish_reason != "stop" and finish_reason != 'length' and finish_reason != "":
        logger.warning("Stop reason: %s", finish_reason)
        logger.warning("Text: %s", text)
        logger.warning("Increase Max Tokens and try again")
        exit(1)

    return text


def process_queue_for_summaries(client : AzureOpenAI, config : ApiConfiguration, progress, task, q, total_chunks, output_chunks, current_chunks, logger):
    """process the queue"""
    
    while not q.empty():

        chunk = q.get()
        found = False

        for i in current_chunks: 
           if i.get('sourceId') == chunk.get('sourceId'):
              current_summary = i.get("summary")
              current_ada = i.get("ada_v2")
              if current_summary and current_ada: 
                 chunk["summary"] = current_summary
                 chunk["ada_v2"] = current_ada                
                 found = True  
                 output_chunks.append(chunk.copy())                 
                 break

        if not found:
           text = chunk.get("text")

           try:
              summary = chatgpt_summary(client, config, text, logger)
              # add the summary to the chunk dictionary
              chunk["summary"] = summary
              output_chunks.append(chunk.copy())
           except BadRequestError as request_error:
              logger.warning("Error: %s", request_error)
           except Exception as e:
              logger.warning("Error: %s", e)

        count = counter.increment()
        progress.update(task, advance=1)
        logger.debug("Processed %d chunks of %d", count, total_chunks)


        q.task_done()


def enrich_text_summaries(config, destinationDir): 

   client = AzureOpenAI(
      azure_endpoint = config.resourceEndpoint, 
      api_key=config.apiKey,  
      api_version=config.apiVersion
   )   

   logging.basicConfig(level=logging.WARNING)
   logger = logging.getLogger(__name__)
   for key in logging.Logger.manager.loggerDict:
      logging.getLogger(key).setLevel(logging.WARNING)

   if not destinationDir:
    logger.error("Destination folder not provided")
    exit(1)

   chunks = []
   output_chunks = []
   current = []
   total_chunks = 0

   logger.debug("Starting OpenAI summarization")

   # load the chunks from a json file
   input_file = os.path.join(destinationDir, "output", "master_text.json")
   with open(input_file, "r", encoding="utf-8") as f:
      chunks = json.load(f)

   total_chunks = len(chunks)

   logger.debug("Total chunks to be processed: %s", len(chunks))

   # add chunk list to a queue
   q = queue.Queue()
   for chunk in chunks:
      q.put(chunk)

   # load the existing chunks from a json file
   output_subdir = "output"
   cache_file = os.path.join(destinationDir, "output", "master_enriched.json")
   # Ensure the output subdirectory exists
   ensure_directory_exists(os.path.dirname(cache_file))

   if os.path.isfile(cache_file):
      with open(cache_file, "r", encoding="utf-8") as f:
         current = json.load(f)   
   
   with open(cache_file, "w", encoding="utf-8") as f:
      json.dump(chunks, f, ensure_ascii=False, indent=4)

   with Progress() as progress:
      task1 = progress.add_task("[purple]Enriching Summaries...", total=total_chunks)

      # create multiple threads to process the queue
      threads = []
      for i in range(config.processingThreads):
         t = threading.Thread(target=process_queue_for_summaries, args=(client, config, progress, task1, q, total_chunks, output_chunks, current, logger))
         t.start()
         threads.append(t)

      # wait for all threads to finish
      for t in threads:
         t.join()

   # sort the output chunks by sourceId 
   output_chunks.sort(key=lambda x: (x["sourceId"]))

   logger.debug("Total chunks processed: %s", len(output_chunks))

   #print(f"markdownDestinationDir = {markdownDestinationDir}")         #added for debugging 
   output_subdir = "output"
   output_file = os.path.join(destinationDir, "output", "master_enriched.json")

   # Ensure the output subdirectory exists
   ensure_directory_exists(os.path.dirname(output_file))
   # save chunks to a json file
   with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output_chunks, f, ensure_ascii=False, indent=4)
****************************************

****************************************
Boxer\scripts\web\download_html.py
****************************************
""" This script downloads the text content for all sub pages of a URL. """
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import os
import json
import logging
import time
import threading
import queue
from pathlib import Path
from urllib.parse import urlsplit, urljoin

# Third-Party Packages
from bs4 import BeautifulSoup
import requests


MAX_LINKS_PERPAGE=256 #Max number of links we keep from a single page
MAX_PAGE_DEPTH=1     #Max depth we search in a website
AVERAGE_CHARACTERS_PER_TOKEN=6

headers = {
   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
   'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
   'Accept-Encoding': 'none',
   'Accept-Language': 'en-US,en;q=0.8',
   'Connection': 'keep-alive'       
}  

class Counter:
    """thread safe counter"""

    def __init__(self):
        """initialize the counter"""
        self.value = 0
        self.lock = threading.Lock()

    def increment(self):
        """increment the counter"""
        with self.lock:
            self.value += 1


counter = Counter()

def makePathOnly (url):
    split_url = urlsplit(url)
    # split_url.scheme   "http"
    # split_url.netloc   "127.0.0.1" 
    # split_url.path     "/asdf/login.php"
    # Use all the path 
    clean_path = str(split_url.netloc) + split_url.path
    return clean_path

def makeFullyQualified (base, rel):
    return urljoin(base,rel)
    
def get_html(url, counter_id, siteUrl, htmlDesitinationDir, logger, minimumPageTokenCount):
    """Read in HTML content and write out as plain text """

    sourceId = makePathOnly (url)
    fakeName = sourceId.replace("//", "_").replace("/", "_")
    contentOutputFileName = os.path.join(htmlDesitinationDir, f"{fakeName}.json.mdd")
    metaOutputFilename = os.path.join(htmlDesitinationDir, f"{fakeName}.json")

    # if markdown file already exists, skip it
    if os.path.exists(contentOutputFileName):
        logger.debug("Skipping : %s", url)
        return False    
    
    # In case the web site expect cookies and/or javascript
    session = requests.Session()     
    page = session.get(url, headers=headers)
    soup = BeautifulSoup(page.content, "html.parser") 
    fullText = soup.get_text()
    nolineFeeds = fullText.replace("\n", " ")
    # dont add very short pages
    if len(nolineFeeds) < minimumPageTokenCount * AVERAGE_CHARACTERS_PER_TOKEN:
       logger.debug("Skipping : %s", url)
       return    

    jsonSeg = dict()
    jsonSeg["text"] = nolineFeeds
    jsonSeg["start"] = "0"
    jsonArr = [""]
    jsonArr[0] = jsonSeg
         
    # save the plain text content as a .json.mdd file
    with open(contentOutputFileName, "w", encoding="utf-8") as file:
        json.dump(jsonArr, file, indent=4, ensure_ascii=False)

    metadata = {}
    metadata["speaker"] = ""
    metadata["title"] = Path(url).name
    metadata["sourceId"] = sourceId
    metadata["filename"] = os.path.basename(contentOutputFileName)   
    metadata["description"] = Path(url).name
    metadata["hitTrackingId"] = siteUrl    

    # save the metadata as a .json file
    json.dump(metadata, open(metaOutputFilename, "w", encoding="utf-8"))
    
    logger.debug("Html download completed: %d, %s", counter_id, url)

    return True


def process_queue(q, sourceUrl, htmlDestinationDir, logger, minimumPageTokenCount):
    """process the queue"""
    while not q.empty():
        file = q.get()

        counter.increment()

        get_html(file, counter.value, sourceUrl, htmlDestinationDir, logger, minimumPageTokenCount)
        q.task_done()


def deduplicate(currentLinks, newLinks): # remove duplicates 

    deduped = []

    for item in newLinks:
        if not item in currentLinks:
           deduped.append(item)
    
    return deduped

def remove_exits(sourceUrl, links): # remove links that point outside the main site being searched
                                    # we also remove links starting with #as they are just the same page
    """ Remove links that point outside the main site being searched """
    trimmed = []

    for item in links:
        match = (item.startswith(sourceUrl) 
                 and (not '#' in item))
        if match :
            trimmed .append(item)        

    return trimmed

def add_prefix(sourceUrl, links):
    """ Add prefixes to relative URLs """

    full = []

    for item in links:
        newUrl = makeFullyQualified(sourceUrl, item)
        full.append(newUrl)

    return full


def recurse_page_list(startUrl, processedLinks, depth, logger, recurse):
    """ Recursively crawl through pages starting from startUrl """

    # Bail if we hit maximum depth
    if depth > MAX_PAGE_DEPTH:
        logger.debug("Depth exceeded: %s", startUrl)
        return

    # In case the website expects cookies and/or JavaScript
    session = requests.Session()
    page = session.get(startUrl, headers=headers)
    soup = BeautifulSoup(page.text, "html.parser")

    logger.debug("Processing: %s", startUrl)
    processedLinks.append(startUrl)

    if not recurse:
        return

    subLinks = soup.find_all('a')
    subUrls = []

    for link in subLinks:
        url = str(link.get('href'))
        subUrls.append(url)

    full = add_prefix(startUrl, subUrls)
    deduped = deduplicate(processedLinks, full)
    trimmed = remove_exits(startUrl, deduped)

    for link in trimmed:
        if link not in processedLinks:
            recurse_page_list(link, processedLinks, depth + 1, logger, recurse)

         
def build_page_list(sourceUrl, q, minimumPageTokenCount, logger, recurse):
    """ Build a list of pages starting from sourceUrl """

    links = []

    recurse_page_list(sourceUrl, links, 0, logger, recurse)

    for url in links:
        q.put(url)
    
def download_html (sourceUrl, recurse, htmlDesitinationDir, minimumPageTokenCount): 
   
   logging.basicConfig(level=logging.WARNING)
   logger = logging.getLogger(__name__)

   PROCESSING_THREADS = 1

   q = queue.Queue()

   if not htmlDesitinationDir:
      logger.error("Html folder not provided")
      exit(1)

   if not sourceUrl:
      logger.error("Source url not provided")
      exit(1)

   logger.debug("Source URL: %s", sourceUrl)
   logger.debug("Html folder: %s", htmlDesitinationDir)

   # Recursively search for all html files  
   build_page_list (sourceUrl, q, minimumPageTokenCount, logger, recurse)
   
   logger.info("Total HTML files to be downloaded: %s", q.qsize())

   start_time = time.time()

   # create multiple threads to process the queue
   threads = []
   for i in range(PROCESSING_THREADS):
      t = threading.Thread(
         target=process_queue,
                args=(q, sourceUrl, htmlDesitinationDir, logger, minimumPageTokenCount),
         )
      t.start()
   threads.append(t)

   # wait for all threads to finish
   for t in threads:
      t.join()

   finish_time = time.time()
   logger.debug("Total time taken: %s", finish_time - start_time)
****************************************

****************************************
Boxer\scripts\youtube\download_transcripts.py
****************************************
""" This script downloads the transcripts for all the videos in a YouTube playlist. """

# Standard Library Imports
import os
import json
import logging
import time
import threading
import queue

# Third-Party Packages
import googleapiclient.discovery
import googleapiclient.errors
from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled, VideoUnavailable
from youtube_transcript_api.formatters import WebVTTFormatter


logger = logging.getLogger(__name__)

GOOGLE_DEVELOPER_API_KEY = os.environ["GOOGLE_DEVELOPER_API_KEY"]

# Initialize the Google developer API client
GOOGLE_API_SERVICE_NAME = "youtube"
GOOGLE_API_VERSION = "v3"

MAX_RESULTS = 50
PROCESSING_THREADS = 1

class Counter:
    """thread safe counter"""

    def __init__(self):
        """initialize the counter"""
        self.value = 0
        self.lock = threading.Lock()

    def increment(self):
        """increment the counter"""
        with self.lock:
            self.value += 1


def gen_metadata(playlist_item, transcriptDestinationDir):
    """Generate metadata for a video"""

    video_id = playlist_item["snippet"]["resourceId"]["videoId"]
    filename = os.path.join(transcriptDestinationDir, video_id + ".json")

    metadata = {}
    metadata["speaker"] = ""
    metadata["title"] = playlist_item["snippet"]["title"]
    metadata["sourceId"] = playlist_item["snippet"]["resourceId"]["videoId"]
    metadata["description"] = playlist_item["snippet"]["description"]
    metadata["hitTrackingId"] = playlist_item["snippet"]["playlistId"]

    # Ensure the directory exists before saving
    os.makedirs(transcriptDestinationDir, exist_ok=True)

    # Save the metadata as a .json file
    with open(filename, "w", encoding="utf-8") as file:
        json.dump(metadata, file, indent=4, ensure_ascii=False)




def get_transcript(playlist_item, counter_id, transcriptDestinationDir, logger):
    """Get the transcript for a video"""

    video_id = playlist_item["snippet"]["resourceId"]["videoId"]
    filename = os.path.join(transcriptDestinationDir, video_id + ".json.vtt")

    # If video transcript already exists, skip it
    if os.path.exists(filename):
        logger.debug("Skipping video %d, %s", counter_id, video_id)
        return False

    try:
        transcript = YouTubeTranscriptApi.get_transcript(video_id)
        # Remove \n from the text
        for item in transcript:
            item["text"] = item["text"].replace("\n", " ")

        logger.debug("Transcription download completed: %d, %s", counter_id, video_id)

        # Ensure the directory exists before saving
        os.makedirs(transcriptDestinationDir, exist_ok=True)

        # Save the transcript as a .vtt file
        with open(filename, "w", encoding="utf-8") as file:
            json.dump(transcript, file, indent=4, ensure_ascii=False)

    except NoTranscriptFound:
        logger.debug("No transcript found for video: %s", video_id)
        return False
    except TranscriptsDisabled:
        logger.debug("Transcripts are disabled for video: %s", video_id)
        return False
    except VideoUnavailable:
        logger.debug("Video unavailable: %s", video_id)
        return False
    except Exception as exception:
        logger.debug("An error occurred: %s", str(exception))
        logger.debug("Transcription not found for video: %s", video_id)
        return False

    return True



def process_queue(q, counter, transcriptDestinationDir, logger):
    """Process the queue"""
    while not q.empty():
        video = q.get()

        counter.increment()

        if get_transcript(video, counter.value, transcriptDestinationDir, logger):
            gen_metadata(video, transcriptDestinationDir)
        q.task_done()

def download_transcripts (playlistId, transcriptDestinationDir): 
   
   logging.basicConfig(level=logging.INFO)
   logger = logging.getLogger(__name__)

   formatter = WebVTTFormatter()
   q = queue.Queue()


   if not transcriptDestinationDir:
      logger.error("Transcript folder not provided")
      exit(1)

   if not playlistId:
      logger.error("Playlist ID not provided")
      exit(1)

   counter = Counter()   

   logger.debug("Transcription folder: %s", transcriptDestinationDir)

   youtube = googleapiclient.discovery.build(
      GOOGLE_API_SERVICE_NAME, GOOGLE_API_VERSION, developerKey=GOOGLE_DEVELOPER_API_KEY
   )

   # Create a request object with the playlist ID and the max results
   request = youtube.playlistItems().list(
      part="snippet", playlistId=playlistId, maxResults=MAX_RESULTS
   )


   # Loop through the pages of results until there is no next page token
   while request:
      # Execute the request and get the response
      response = request.execute()

      # Iterate over the items in the response and append the video IDs to the list
      for item in response["items"]:
        q.put(item)

      # Get the next page token from the response and create a new request object
      next_page_token = response.get("nextPageToken")
      if next_page_token:
         request = youtube.playlistItems().list(
            part="snippet",
            playlistId=playlistId,
            maxResults=MAX_RESULTS,
            pageToken=next_page_token,
      )
      else:
         request = None

   logger.info("Total transcriptions to be download: %s", q.qsize())

   start_time = time.time()

   # create multiple threads to process the queue
   threads = []
   for i in range(PROCESSING_THREADS):
      t = threading.Thread(
             target=process_queue,
             args=(q, counter, transcriptDestinationDir, logger),
             )
      t.start()
      threads.append(t)

   # wait for all threads to finish
   for t in threads:
      t.join()

   finish_time = time.time()
   logger.debug("Total time taken: %s", finish_time - start_time)
****************************************

****************************************
Boxer\scripts\youtube\enrich_transcript_chunks.py
****************************************
""" This script generates a master csv file from the transcript files."""

# from the transcript files, generate a master csv file
# from the transcript folder read all the .json files then load the associated .vtt file

# Standard Library Imports
from datetime import datetime, timedelta
import os
import json
import glob
import logging
from typing import List, Dict

# Third-Party Packages
import tiktoken
from rich.progress import Progress


# Define constants
PERCENTAGE_OVERLAP = 0.05
ENCODING_MODEL = "gpt-3.5-turbo"
tokenizer = tiktoken.encoding_for_model(ENCODING_MODEL)

# Configure logging
logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger(__name__)

class VttChunk:
    def __init__(self, chunk: dict[str, str | float]) -> None:
        self.text = chunk.get("text")
        self.start = chunk.get("start")
        self.duration = chunk.get("duration")

    text: str
    start: float
    duration: float

def gen_metadata_master(metadata):
    """generate the metadata master csv file"""
    text = metadata["title"] + " " + metadata["description"]
    metadata["start"] = "00:00:00"

    text = text.strip()

    if text == "" or text is None:
        metadata["text"] = "No description available."
    else:
        text = text.replace("\n", "")
        metadata["text"] = text.strip()

def clean_text(text):
    """clean the text"""
    text = text.replace("\n", " ")  # remove new lines
    text = text.replace("&#39;", "'")
    text = text.replace(">>", "")  # remove '>>'
    text = text.replace("  ", " ")  # remove double spaces
    text = text.replace("[inaudible]", "")  # [inaudible]

    return text

def append_text_to_previous_chunk(text, chunks):
    """append PERCENTAGE_OVERLAP text to the previous chunk to smooth context transition"""
    if len(chunks) > 0:
        words = text.split(" ")
        word_count = len(words)
        if word_count > 0:
            append_text = " ".join(words[0 : int(word_count * PERCENTAGE_OVERLAP)])
            chunks[-1]["text"] += append_text

def add_new_chunk(metadata, text, chunk_begin_seconds, chunks):
    """add a new chunk to the chunks list"""
    delta = timedelta(seconds=chunk_begin_seconds)
    begin_time = datetime.min + delta
    metadata["start"] = begin_time.strftime("%H:%M:%S")
    metadata["seconds"] = chunk_begin_seconds

    metadata["text"] = text
    chunks.append(metadata.copy())

def parse_json_vtt_transcript(vtt, metadata, chunks, chunkMinutes, maxTokens):
    """parse the json vtt file and return the transcript"""
    text = ""
    current_seconds = None
    seg_begin_seconds = None
    seg_finish_seconds = None
    current_token_length = 0
    first_chunk = True

    logger.debug(f"Processing VTT file: {vtt}")
    logger.debug(f"Initial metadata: {metadata}")

    if "speaker" in metadata and metadata["speaker"] != "":
        metadata["speaker"] = clean_text(metadata.get("speaker"))
        text = "The speaker's name is " + metadata["speaker"] + ". "

    if "title" in metadata and metadata["title"] != "":
        metadata["title"] = clean_text(metadata.get("title"))
        text += metadata.get("title") + ". "

    if "description" in metadata and metadata["description"] != "":
        metadata["description"] = clean_text(metadata.get("description"))
        text += metadata.get("description") + ". "

    current_token_length = len(tokenizer.encode(text))

    try:
        with open(vtt, "r", encoding="utf-8") as json_file:
            json_vtt = json.load(json_file)
    except FileNotFoundError:
        logger.error(f"VTT file not found: {vtt}")
        return chunks
    except json.JSONDecodeError:
        logger.error(f"Invalid JSON in VTT file: {vtt}")
        return chunks

    logger.debug(f"Loaded {len(json_vtt)} segments from VTT file")

    for chunk in json_vtt:
        seg = VttChunk(chunk)
        current_seconds = int(seg.start)
        current_text = seg.text

        if seg_begin_seconds is None:
            seg_begin_seconds = current_seconds
            seg_finish_seconds = seg_begin_seconds + chunkMinutes * 60

        total_tokens = len(tokenizer.encode(current_text)) + current_token_length

        if current_seconds < seg_finish_seconds and total_tokens < maxTokens:
            text += current_text + " "
            current_token_length = total_tokens
        else:
            if not first_chunk:
                append_text_to_previous_chunk(text, chunks)
            first_chunk = False
            add_new_chunk(metadata, text, seg_begin_seconds, chunks)

            text = current_text + " "
            seg_begin_seconds = current_seconds
            seg_finish_seconds = seg_begin_seconds + chunkMinutes * 60
            current_token_length = len(tokenizer.encode(text))

    if seg_begin_seconds is not None and text != "":
        if chunks and not first_chunk:
            previous_chunk_tokens = len(tokenizer.encode(chunks[-1]["text"]))
            current_chunk_tokens = len(tokenizer.encode(text))

            if previous_chunk_tokens + current_chunk_tokens < maxTokens:
                chunks[-1]["text"] += text
            else:
                append_text_to_previous_chunk(text, chunks)
        else:
            add_new_chunk(metadata, text, seg_begin_seconds, chunks)

    logger.debug(f"Processed {len(chunks)} chunks")

    return chunks
    
def get_transcript(metadata, transcriptDestinationDir, chunks, chunkMinutes, maxTokens):
    """get the transcript from the .vtt file"""
    global total_files
    vtt = os.path.join(transcriptDestinationDir, metadata["sourceId"] + ".json.vtt")

    if not os.path.exists(vtt):
        logger.info("vtt file does not exist: %s", vtt)
        return None
    else:
        logger.debug("Processing file: %s", vtt)
        total_files += 1

    parse_json_vtt_transcript(vtt, metadata, chunks, chunkMinutes, maxTokens)

total_files = 0

def enrich_transcript_chunks (config, transcriptDestinationDir): 
    global total_files
    chunks = []
    total_files = 0

    if not transcriptDestinationDir:
        logger.error("Transcript folder not provided")
        exit(1)

    logger.debug("Transcription folder: %s", transcriptDestinationDir)
    logger.debug("Chunk length %d minutes", config.chunkDurationMins)

    folder = os.path.join(transcriptDestinationDir, "*.json")

    with Progress() as progress:
        task1 = progress.add_task("[green]Enriching chunks...", total=total_files)

        for file in glob.glob(folder):
            meta = json.load(open(file, encoding="utf-8"))

            get_transcript(meta, transcriptDestinationDir, chunks, config.chunkDurationMins, (config.maxTokens - config.summaryWordCount * 4))
            progress.update(task1, advance=1)

    logger.debug("Total files: %s", total_files)
    logger.debug("Total chunks: %s", len(chunks))

    output_subdir = "output"
    output_file = os.path.join(transcriptDestinationDir, output_subdir, "master_transcriptions.json")

    ensure_directory_exists(os.path.dirname(output_file))
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(chunks, f, ensure_ascii=False, indent=4)

def ensure_directory_exists(directory):
    """Ensure directory exists; if not, create it."""
    if not os.path.exists(directory):
        os.makedirs(directory)
****************************************

****************************************
Boxer\scripts\youtube\enrich_transcript_embeddings.py
****************************************
# Standard Library Imports
import logging
import re
import os
import json
import threading
import queue

# Third-Party Packages
from openai import AzureOpenAI
from openai import BadRequestError
import tiktoken
from tenacity import (
    retry,
    wait_random_exponential,
    stop_after_attempt,
    retry_if_not_exception_type,
)
from rich.progress import Progress

# Local Modules
from common.ApiConfiguration import ApiConfiguration
from common.common_functions import ensure_directory_exists
from common.common_functions import get_embedding

tokenizer = tiktoken.get_encoding("cl100k_base")

def normalize_text(s, sep_token=" \n "):
    """normalize text by removing extra spaces and newlines"""
    s = re.sub(r"\s+", " ", s).strip()
    s = re.sub(r". ,", "", s)
    s = s.replace("..", ".")
    s = s.replace(". .", ".")
    s = s.replace("\n", "")
    s = s.strip()

    return s

@retry(
    wait=wait_random_exponential(min=10, max=45),
    stop=stop_after_attempt(5),
    retry=retry_if_not_exception_type(BadRequestError),
)
def get_text_embedding(client : AzureOpenAI, config : ApiConfiguration, text: str):
    """get the embedding for a text"""
    embedding = get_embedding(text, 
                              client, 
                              config)
    return embedding

def process_queue(client, config, progress, task, q, logger, output_chunks, current_chunks):
    """process the queue"""
    while not q.empty():
        chunk = q.get()
        found = False

        for i in current_chunks: 
           if i.get('sourceId') == chunk.get('sourceId'):           
              current_summary = i.get("summary")
              current_ada = i.get("ada_v2")
              if current_summary and current_ada: 
                 chunk["summary"] = current_summary
                 chunk["ada_v2"] = current_ada   
                 output_chunks.append(chunk.copy())                                 
                 found = True  
                 break
        
        if not found:
           try:
              embedding = get_text_embedding(client, config, chunk["text"])
              chunk["ada_v2"] = embedding.copy()     
              output_chunks.append(chunk.copy())                          
           except BadRequestError as request_error:
              logger.warning("Error: %s %s", chunk.get('sourceId'), request_error)
           except Exception as e:
              logger.warning("Error: %s %s", chunk.get('sourceId'), 'Unknown error')          

        progress.update(task, advance=1)
        q.task_done()

def convert_time_to_seconds(value):
    """convert time to seconds"""
    time_value = value.split(":")
    if len(time_value) == 3:
        h, m, s = time_value
        return int(h) * 3600 + int(m) * 60 + int(s)
    else:
        return 0

def enrich_transcript_embeddings(config, transcriptDestinationDir): 

   client = AzureOpenAI(
      azure_endpoint = config.resourceEndpoint, 
      api_key=config.apiKey,  
      api_version=config.apiVersion
   )   

   logger = logging.getLogger(__name__)
   logging.basicConfig(level=logging.WARNING)
   for key in logging.Logger.manager.loggerDict:
      logging.getLogger(key).setLevel(logging.WARNING)
   
   if not transcriptDestinationDir:
      logger.error("Transcript folder not provided")
      exit(1)

   total_chunks = 0
   output_chunks = []

   input_file = os.path.join(transcriptDestinationDir, "output", "master_enriched.json")
   with open(input_file, "r", encoding="utf-8") as f:
      chunks = json.load(f)

   total_chunks = len(chunks)

   logger.debug("Starting OpenAI Embeddings")
   logger.debug("Total chunks to be processed: %s", len(chunks))

   q = queue.Queue()
   for chunk in chunks:
      q.put(chunk)

   cache_file = os.path.join(transcriptDestinationDir, "output", "master_enriched.json")
   if os.path.isfile(cache_file):
      with open(cache_file, "r", encoding="utf-8") as f:
         current = json.load(f) 

   with Progress() as progress:
      task1 = progress.add_task("[green]Enriching Embeddings...", total=total_chunks)
      threads = []
      for i in range(config.processingThreads):
         t = threading.Thread(target=process_queue, args=(client, config, progress, task1, q, logger, output_chunks, current))
         t.start()
         threads.append(t)

      for t in threads:
         t.join()

   output_chunks.sort(key=lambda x: (x["sourceId"], convert_time_to_seconds(x["start"])))

   logger.debug("Total chunks processed: %s", len(output_chunks))

   output_subdir = "output"
   output_file = os.path.join(transcriptDestinationDir, output_subdir, "master_enriched.json")

   ensure_directory_exists(os.path.dirname(output_file))

   with open(output_file, "w", encoding="utf-8") as f:
      json.dump(chunks, f, ensure_ascii=False, indent=4)
****************************************

****************************************
Boxer\scripts\youtube\enrich_transcript_summaries.py
****************************************
# Standard Library Imports
import json
import os
import threading
import queue
import logging
from logging import Logger

# Third-Party Packages
from openai import AzureOpenAI
from openai import BadRequestError

from tenacity import (
    retry,
    wait_random_exponential,
    stop_after_attempt,
    retry_if_not_exception_type,
)
from rich.progress import Progress

# Local Modules
from common.common_functions import ensure_directory_exists
from common.ApiConfiguration import ApiConfiguration

class Counter:
    """thread safe counter"""

    def __init__(self):
        """initialize the counter"""
        self.value = 0
        self.lock = threading.Lock()

    def increment(self):
        """increment the counter"""
        with self.lock:
            self.value += 1
            return self.value

@retry(
    wait=wait_random_exponential(min=10, max=45),
    stop=stop_after_attempt(5),
    retry=retry_if_not_exception_type(BadRequestError),
)
def chatgpt_summary(client : AzureOpenAI, config : ApiConfiguration, text : str, logger : Logger):
    """generate a summary using chatgpt"""

    messages = [
        {
            "role": "system",
            "content": "You are an AI Assistant for video summarization, write an authoritative " 
                       + str(config.summaryWordCount) + 
                       " word summary. Avoid starting sentences with 'This document' or 'The document'.",
        },
        {"role": "user", "content": text},
    ]

    response = client.chat.completions.create(
        model=config.azureDeploymentName,
        messages=messages,
        temperature=0.7,
        max_tokens=config.maxTokens,
        top_p=0.0,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None,
        timeout=config.openAiRequestTimeout,
    )

    text = response.choices[0].message.content
    finish_reason = response.choices[0].finish_reason

    if finish_reason != "stop" and finish_reason != 'length' and finish_reason != "":
        logger.warning("Stop reason: %s", finish_reason)
        logger.warning("Text: %s", text)
        logger.warning("Increase Max Tokens and try again")
        exit(1)

    return text

def process_queue(client : AzureOpenAI, config : ApiConfiguration, progress, task, q, counter, logger, output_chunks, current_chunks):
    """process the queue"""
    while not q.empty():

        chunk = q.get()
        found = False

        for i in current_chunks: 
           if i.get('sourceId') == chunk.get('sourceId'):
              current_summary = i.get("summary")
              current_ada = i.get("ada_v2")
              if current_summary and current_ada: 
                 chunk["summary"] = current_summary
                 chunk["ada_v2"] = current_ada   
                 output_chunks.append(chunk.copy())                                 
                 found = True  
                 break

        if not found:           
           text = chunk.get("text")

           # get a summary of the text using chatgpt
           try:
              summary = chatgpt_summary(client, config, text, logger)
              # add the summary to the segment dictionary
              chunk["summary"] = summary
              output_chunks.append(chunk.copy())
           except BadRequestError as request_error:
              logger.warning("Error: %s", request_error)
           except Exception as e:
              logger.warning("Error: %s", e)

        count = counter.increment()
        progress.update(task, advance=1)

        q.task_done()

# convert time '00:01:20' to seconds
def convert_time_to_seconds(value):
    """convert time to seconds"""
    time_value = value.split(":")
    if len(time_value) == 3:
        h, m, s = time_value
        return int(h) * 3600 + int(m) * 60 + int(s)
    else:
        return 0

def enrich_transcript_summaries(config : ApiConfiguration, transcriptDestinationDir: str): 
   
   client = AzureOpenAI(
      azure_endpoint = config.resourceEndpoint, 
      api_key=config.apiKey,  
      api_version=config.apiVersion
   )      

   logging.basicConfig(level=logging.WARNING)
   logger = logging.getLogger(__name__)
   for key in logging.Logger.manager.loggerDict:
      logging.getLogger(key).setLevel(logging.WARNING)

   if not transcriptDestinationDir:
      logger.error("Transcript folder not provided")
      exit(1)

   chunks = []
   output_chunks = []
   current = []
   total_chunks = 0

   counter = Counter()

   logger.debug("Starting OpenAI summarization")

   # load the chunks from a json file
   input_file = os.path.join(transcriptDestinationDir, "output", "master_transcriptions.json")
   with open(input_file, "r", encoding="utf-8") as f:
      chunks = json.load(f)

   total_chunks = len(chunks)

   logger.debug("Total chunks to be processed: %s", len(chunks))

   # add segment list to a queue
   q = queue.Queue()
   for chunk in chunks:
      q.put(chunk)

   # load the existing chunks from a json file
   cache_file = os.path.join(transcriptDestinationDir, "output", "master_enriched.json")
   if os.path.isfile(cache_file):
      with open(cache_file, "r", encoding="utf-8") as f:
         current = json.load(f)  

   with Progress() as progress:
      task1 = progress.add_task("[purple]Enriching Summaries...", total=total_chunks)

      # create multiple threads to process the queue
      threads = []
      for i in range(config.processingThreads):
         t = threading.Thread(target=process_queue, args=(client, config, progress, task1, q, counter, logger, output_chunks, current))
         t.start()
         threads.append(t)

      # wait for all threads to finish
      for t in threads:
         t.join()

   # sort the output chunks by sourceId and start
   output_chunks.sort(key=lambda x: (x["sourceId"], convert_time_to_seconds(x["start"])))

   logger.debug("Total chunks processed: %s", len(output_chunks))

   # save the output chunks to a json file
   output_subdir = "output"
   output_file = os.path.join(transcriptDestinationDir, output_subdir, "master_enriched.json")

   ensure_directory_exists(os.path.dirname(output_file))

   with open(output_file, "w", encoding="utf-8") as f:
        json.dump(chunks, f, ensure_ascii=False, indent=4)
****************************************

****************************************
Boxer\scripts\youtube\not_used_enrich_transcript_speaker.py
****************************************
""" This script will get the speaker name from the YouTube video metadata and the first minute of the transcript using the OpenAI Functions entity extraction."""

# Standard Library Imports
import json
import os
import glob
import threading
import logging
import queue
import time
import argparse

# Third-Party Packages
import openai
from openai.embeddings_utils import get_embedding
from rich.progress import Progress
from tenacity import (
    retry,
    wait_random_exponential,
    stop_after_attempt,
    retry_if_not_exception_type,
)


logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger(__name__)

API_KEY = os.environ["OPENAI_API_KEY"] #AZURE VERSION WAS os.environ["AZURE_OPENAI_API_KEY"] 
RESOURCE_ENDPOINT = "https://api.openai.com/v1" #AZURE VERSION WAS os.environ["AZURE_OPENAI_ENDPOINT"] 
TRANSCRIPT_FOLDER = "../data/transcripts"
PROCESSING_THREADS = 10
SEGMENT_MIN_LENGTH_MINUTES = 3
OPENAI_REQUEST_TIMEOUT = 60

OPENAI_MAX_TOKENS = 512
AZURE_OPENAI_MODEL_DEPLOYMENT_NAME = os.getenv(
    "AZURE_OPENAI_MODEL_DEPLOYMENT_NAME", "gpt-35-turbo"
)


openai.api_type = "open_ai" #AZURE VERSION WAS "Azure"
openai.api_key = API_KEY
openai.api_base = RESOURCE_ENDPOINT
openai.api_version = "2020-11-07" #AZURE VERSION WAS "2023-07-01-preview"

parser = argparse.ArgumentParser()
parser.add_argument("-f", "--folder")
parser.add_argument("--verbose", action="store_true")
args = parser.parse_args()
if args.verbose:
    logger.setLevel(logging.WARNING)

TRANSCRIPT_FOLDER = args.folder if args.folder else None
if not TRANSCRIPT_FOLDER:
    logger.error("Transcript folder not provided")
    exit(1)

get_speaker_name = {
    "name": "get_speaker_name",
    "description": "Get the speaker names for the session.",
    "parameters": {
        "type": "object",
        "properties": {
            "speakers": {
                "type": "string",
                "description": "The speaker names.",
            }
        },
        "required": ["speaker_name"],
    },
}


openai_functions = [get_speaker_name]


# these maps are used to make the function name string to the function call
definition_map = {"get_speaker_name": get_speaker_name}

q = queue.Queue()

errors = 0


class Counter:
    """thread safe counter"""

    def __init__(self):
        """initialize the counter"""
        self.value = 0
        self.lock = threading.Lock()

    def increment(self):
        """increment the counter"""
        with self.lock:
            self.value += 1
            return self.value


counter = Counter()


@retry(
    wait=wait_random_exponential(min=6, max=10),
    stop=stop_after_attempt(5),
    retry=retry_if_not_exception_type(openai.BadRequestError),
)
def get_speaker_info(text, config):
    """Gets the OpenAI functions from the text."""

    function_name = None
    arguments = None

    response_1 = openai.ChatCompletion.create(
        model=config.modelName,
        messages=[
            {
                "role": "system",
                "content": "You are an AI assistant that can extract speaker names from text as a list of comma separated names. Try and extract the speaker names from the title. Speaker names are usually less than 3 words long.",
            },
            {"role": "user", "content": text},
        ],
        functions=openai_functions,
        max_tokens=OPENAI_MAX_TOKENS,
        #AZURE VERSION WAS engine=AZURE_OPENAI_MODEL_DEPLOYMENT_NAME,
        request_timeout=OPENAI_REQUEST_TIMEOUT,
        function_call={"name": "get_speaker_name"},
        temperature=0.0,
    )

    # The assistant's response includes a function call. We extract the arguments from this function call

    result = response_1.get("choices")[0].get("message")

    if result.get("function_call"):
        function_name = result.get("function_call").get("name")
        arguments = json.loads(result.get("function_call").get("arguments"))

    return function_name, arguments


def clean_text(text):
    """clean the text"""
    text = text.replace("\n", " ")  # remove new lines
    text = text.replace("&#39;", "'")
    text = text.replace(">>", "")  # remove '>>'
    text = text.replace("  ", " ")  # remove double spaces
    text = text.replace("[inaudible]", "")  # [inaudible]

    return text


def get_first_segment(file_name):
    """Gets the first segment from the filename"""

    text = ""
    current_seconds = None
    segment_begin_seconds = None
    segment_finish_seconds = None

    vtt = file_name.replace(".json", ".json.vtt")

    with open(vtt, "r", encoding="utf-8") as json_file:
        json_vtt = json.load(json_file)

        for segment in json_vtt:
            current_seconds = segment.get("start")

            if segment_begin_seconds is None:
                segment_begin_seconds = current_seconds
                # calculate the finish time from the segment_begin_time
                segment_finish_seconds = (
                    segment_begin_seconds + SEGMENT_MIN_LENGTH_MINUTES * 60
                )

            if current_seconds < segment_finish_seconds:
                # add the text to the transcript
                text += clean_text(segment.get("text")) + " "

    return text


def process_queue(progress, task):
    """process the queue"""
    while not q.empty():
        filename = q.get()
        progress.update(task, advance=1)
        if errors > 100:
            logger.error("Too many errors. Exiting...")
            exit(1)

        with open(filename, "r", encoding="utf-8") as json_file:
            metadata = json.load(json_file)

            base_text = 'The title is: ' +  metadata['title'] + " " + metadata["description"] + " " + get_first_segment(filename)
            # replace new line with empty string
            base_text = base_text.replace("\n", " ")

            function_name, arguments = get_speaker_info(base_text)
            speakers = arguments.get("speakers", "")
            if speakers == "":
                print(f"From function call: {filename}\t---MISSING SPEAKER---")
                continue
            else:
                print(f"From function call: {filename}\t{speakers}")

            metadata["speaker"] = speakers
            json.dump(metadata, open(filename, "w", encoding="utf-8"))

        q.task_done()
        time.sleep(0.2)


logger.debug("Transcription folder %s", TRANSCRIPT_FOLDER)
logger.debug("Starting Speaker Update")

# load all the transcript json files into the queue
folder = os.path.join(TRANSCRIPT_FOLDER, "*.json")

for filename in glob.glob(folder):
    # load the json file
    q.put(filename)


logger.debug("Starting speaker name update. Files to be processed: %s", q.qsize())
start_time = time.time()
with Progress() as progress:
    task1 = progress.add_task("[blue]Enriching Speaker Data...", total=q.qsize())
    # create multiple threads to process the queue
    threads = []
    for i in range(PROCESSING_THREADS):
        t = threading.Thread(target=process_queue, args=(progress, task1))
        t.start()
        threads.append(t)

    # wait for all threads to finish
    for t in threads:
        t.join()

finish_time = time.time()
logger.debug(
    "Finished speaker name update. Total time taken: %s", finish_time - start_time
)
****************************************

****************************************
BoxerEval\common\ApiConfiguration.py
****************************************
"""
Configuration module for API settings and parameters.

This module manages configuration settings for various API services including Azure OpenAI
and Google's Gemini API. It provides a centralized location for API endpoints, keys,
and other configuration parameters used throughout the application.

The module includes:
- Environment-specific configurations for Azure and OpenAI
- API version management
- Endpoint URLs
- The ApiConfiguration class for structured access to all API-related settings

Note:
    Sensitive information like API keys should be stored in environment variables
    and accessed via os.getenv() for security purposes.

Copyright (c) 2024 Braid Technologies Ltd
"""

# Standard library imports
import os

azure = True                  

if azure:
   API_TYPE = "Azure" #AZURE VERSION WAS "Azure"
   # API_KEY = os.environ["AZURE_OPENAI_API_KEY"] #AZURE VERSION WAS os.environ["AZURE_OPENAI_API_KEY"]           #uncomment if code breaks - changes for script to exectable on both Windows and Unix machines.  
   API_KEY = os.getenv("AZURE_OPENAI_API_KEY")  # Use os.getenv() to safely retrieve environment variables       #comment if code breaks  - changes for script to exectable on both Windows and Unix machines. 
   API_VERSION = "2024-02-01" #AZURE VERSION WAS "2023-07-01-preview"
   RESOURCE_ENDPOINT = "https://braidlms.openai.azure.com/" #AZURE VERSION WAS os.environ["AZURE_OPENAI_ENDPOINT"] 
else:
   API_TYPE = "open_ai" #AZURE VERSION WAS "Azure"
   API_KEY = os.environ["OPENAI_API_KEY"] #AZURE VERSION WAS os.environ["AZURE_OPENAI_API_KEY"] 
   API_VERSION = "2020-11-07" #AZURE VERSION WAS "2023-07-01-preview"
   RESOURCE_ENDPOINT = "https://api.openai.com/v1" #AZURE VERSION WAS os.environ["AZURE_OPENAI_ENDPOINT"] 


# fetch Gemini API key from environment variables
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_SERVICE_ENDPOINT = "https://generativelanguage.googleapis.com"
# API_VERSION = "v1"  # Gemini API version


class ApiConfiguration:
    def __init__(self) -> None:
        """
        Initialises an instance of the ApiConfiguration class, setting default values for Azure OpenAI and Gemini API parameters.

        :param None: No parameters are required to create an instance of this class.

        :return: Nothing is returned by this method.
        """
        self.apiKey = API_KEY
        self.apiVersion = API_VERSION
        self.resourceChatCompletionEndpoint = "https://studiomodels.openai.azure.com/openai/deployments/StudioLarge/chat/completions?api-version=2024-06-01"  # Chat completions endpoint
        self.resourceEmbeddingEndpoint = "https://studiomodels.openai.azure.com/openai/deployments/StudioEmbeddingLarge/embeddings?api-version=2024-06-01"  # Embeddings endpoint
        self.azureDeploymentName = "StudioLarge"
        self.azureEmbedDeploymentName = "StudioEmbeddingLarge"
        self.modelName = "gpt-4"
        self.embedModelName = "text-embedding-3-large"
        self.processingThreads = 4
        self.openAiRequestTimeout = 60
        self.summaryWordCount = 50      # 50 word summary
        self.chunkDurationMins = 10     # 10 minute long video clips
        self.maxTokens = 4096           # Upper limit on total tokens in an API call. 10 minutes of video = 600 words = 2400 tokens, plus approx 2x headroom
        self.discardIfBelow = 100       # Dont index if less than 100 tokens in an article
        self.GeminiApiKey = GEMINI_API_KEY
        self.GeminiServiceEndpoint = GEMINI_SERVICE_ENDPOINT

    apiType: str
    apiKey: str
    apiVersion: str
    resourceEndpoint: str
    azureDeploymentName: str
    azureEmbedDeploymentName: str
    modelName: str
    embedModelName: str
    processingThreads: int
    openAiRequestTimeout: int
    summaryWordCount: int
    chunkDurationMins: int
    maxTokens: int
    discardIfBelow: int 
    GeminiApiKey: str
    GeminiServiceEndpoint: str
****************************************

****************************************
BoxerEval\common\common_functions.py
****************************************
"""
Common functions for the Braid LMS project.

This module provides utility functions for the Braid LMS project, including directory creation,
embedding generation, and API configuration handling.

Copyright (c) 2024 Braid Technologies Ltd
"""

# Standard library imports
import os
from openai import AzureOpenAI

from common.ApiConfiguration import ApiConfiguration

config = ApiConfiguration()

def ensure_directory_exists(directory):
    """
    Checks if the directory at the given destination exists.
    If it does not exist, creates the directory.

    Parameters:
    directory (str): The path to the directory.
    """
    # Use os.path.join() to handle path construction across different platforms
    if not os.path.exists(directory):
        os.makedirs(directory)
        #print(f"Directory '{directory}' created.")  #  can remove or comment out this print statement for production
    else:
        # print(f"Directory '{directory}' already exists.")
        pass

# Construct the path using os.path.join() for cross-platform compatibility
HTML_DESTINATION_DIR = os.path.join("data", "web")
ensure_directory_exists(HTML_DESTINATION_DIR)

def get_embedding(text: str, embedding_client: AzureOpenAI, config: ApiConfiguration, model: str = "text-embedding-3-large"):
    # Replace newlines with spaces 
    text = text.replace("\n", " ")

    # Use the provided model parameter if given, otherwise fall back to config's deployment name
    chosen_model = model if model else config.embedModelName

    # Generate embedding using the chosen model and configuration
    response = embedding_client.embeddings.create(
        input=[text],
        model=chosen_model,
        timeout=config.openAiRequestTimeout
    )
    
    return response.data[0].embedding
****************************************
