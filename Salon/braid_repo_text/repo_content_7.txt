****************************************
CommonPy\test\__init__.py
****************************************

****************************************

****************************************
CommonPy\.pytest_cache\v\cache\lastfailed
****************************************
{}
****************************************

****************************************
CommonPy\.pytest_cache\v\cache\nodeids
****************************************
[
  "test/chunk_repository_test.py::test_basic",
  "test/chunk_repository_test.py::test_does_not_exist",
  "test/chunk_repository_test.py::test_save",
  "test/chunk_repository_test.py::test_save_exists",
  "test/chunk_repository_test.py::test_save_find",
  "test/page_repository_test.py::test_basic",
  "test/page_repository_test.py::test_does_not_exist",
  "test/page_repository_test.py::test_save",
  "test/page_repository_test.py::test_save_load"
]
****************************************

****************************************
CommonPy\.pytest_cache\v\cache\stepwise
****************************************
[]
****************************************

****************************************
CommonTs\dist\tsconfig.tsbuildinfo
****************************************
{"program":{"fileNames":["../node_modules/typescript/lib/lib.es5.d.ts","../node_modules/typescript/lib/lib.es2015.d.ts","../node_modules/typescript/lib/lib.es2016.d.ts","../node_modules/typescript/lib/lib.es2017.d.ts","../node_modules/typescript/lib/lib.es2018.d.ts","../node_modules/typescript/lib/lib.es2019.d.ts","../node_modules/typescript/lib/lib.es2020.d.ts","../node_modules/typescript/lib/lib.es2021.d.ts","../node_modules/typescript/lib/lib.es2022.d.ts","../node_modules/typescript/lib/lib.dom.d.ts","../node_modules/typescript/lib/lib.es2015.core.d.ts","../node_modules/typescript/lib/lib.es2015.collection.d.ts","../node_modules/typescript/lib/lib.es2015.generator.d.ts","../node_modules/typescript/lib/lib.es2015.iterable.d.ts","../node_modules/typescript/lib/lib.es2015.promise.d.ts","../node_modules/typescript/lib/lib.es2015.proxy.d.ts","../node_modules/typescript/lib/lib.es2015.reflect.d.ts","../node_modules/typescript/lib/lib.es2015.symbol.d.ts","../node_modules/typescript/lib/lib.es2015.symbol.wellknown.d.ts","../node_modules/typescript/lib/lib.es2016.array.include.d.ts","../node_modules/typescript/lib/lib.es2016.intl.d.ts","../node_modules/typescript/lib/lib.es2017.date.d.ts","../node_modules/typescript/lib/lib.es2017.object.d.ts","../node_modules/typescript/lib/lib.es2017.sharedmemory.d.ts","../node_modules/typescript/lib/lib.es2017.string.d.ts","../node_modules/typescript/lib/lib.es2017.intl.d.ts","../node_modules/typescript/lib/lib.es2017.typedarrays.d.ts","../node_modules/typescript/lib/lib.es2018.asyncgenerator.d.ts","../node_modules/typescript/lib/lib.es2018.asynciterable.d.ts","../node_modules/typescript/lib/lib.es2018.intl.d.ts","../node_modules/typescript/lib/lib.es2018.promise.d.ts","../node_modules/typescript/lib/lib.es2018.regexp.d.ts","../node_modules/typescript/lib/lib.es2019.array.d.ts","../node_modules/typescript/lib/lib.es2019.object.d.ts","../node_modules/typescript/lib/lib.es2019.string.d.ts","../node_modules/typescript/lib/lib.es2019.symbol.d.ts","../node_modules/typescript/lib/lib.es2019.intl.d.ts","../node_modules/typescript/lib/lib.es2020.bigint.d.ts","../node_modules/typescript/lib/lib.es2020.date.d.ts","../node_modules/typescript/lib/lib.es2020.promise.d.ts","../node_modules/typescript/lib/lib.es2020.sharedmemory.d.ts","../node_modules/typescript/lib/lib.es2020.string.d.ts","../node_modules/typescript/lib/lib.es2020.symbol.wellknown.d.ts","../node_modules/typescript/lib/lib.es2020.intl.d.ts","../node_modules/typescript/lib/lib.es2020.number.d.ts","../node_modules/typescript/lib/lib.es2021.promise.d.ts","../node_modules/typescript/lib/lib.es2021.string.d.ts","../node_modules/typescript/lib/lib.es2021.weakref.d.ts","../node_modules/typescript/lib/lib.es2021.intl.d.ts","../node_modules/typescript/lib/lib.es2022.array.d.ts","../node_modules/typescript/lib/lib.es2022.error.d.ts","../node_modules/typescript/lib/lib.es2022.intl.d.ts","../node_modules/typescript/lib/lib.es2022.object.d.ts","../node_modules/typescript/lib/lib.es2022.sharedmemory.d.ts","../node_modules/typescript/lib/lib.es2022.string.d.ts","../node_modules/typescript/lib/lib.es2022.regexp.d.ts","../node_modules/typescript/lib/lib.decorators.d.ts","../node_modules/typescript/lib/lib.decorators.legacy.d.ts","../node_modules/axios/index.d.ts","../src/ienvironment.ts","../src/api.ts","../src/istorable.ts","../src/storablerepositoryapi.ts","../src/activityrepositoryapi.ts","../src/logging.ts","../src/errors.ts","../src/asserts.ts","../src/chunkapi.types.ts","../src/chunkrepositoryapi.types.ts","../src/chunkrepositoryapi.ts","../src/classifyapi.types.ts","../node_modules/@types/pako/index.d.ts","../src/compress.ts","../src/embedapi.types.ts","../src/enrichedchunk.ts","../src/enrichedquery.ts","../src/enumeratemodelsapi.types.ts","../src/environment.ts","../src/findenrichedchunkapi.ts","../src/findthemeapi.types.ts","../src/fluid.ts","../node_modules/axios-retry/dist/cjs/index.d.ts","../src/fluidapi.ts","../node_modules/@fluidframework/core-interfaces/lib/disposable.d.ts","../node_modules/@fluidframework/core-interfaces/lib/error.d.ts","../node_modules/@fluidframework/core-interfaces/lib/events.d.ts","../node_modules/@fluidframework/core-interfaces/lib/erasedtype.d.ts","../node_modules/@fluidframework/core-interfaces/lib/fluidrouter.d.ts","../node_modules/@fluidframework/core-interfaces/lib/handles.d.ts","../node_modules/@fluidframework/core-interfaces/lib/fluidloadable.d.ts","../node_modules/@fluidframework/core-interfaces/lib/logger.d.ts","../node_modules/@fluidframework/core-interfaces/lib/provider.d.ts","../node_modules/@fluidframework/core-interfaces/lib/config.d.ts","../node_modules/@fluidframework/core-interfaces/lib/messages.d.ts","../node_modules/@fluidframework/core-interfaces/lib/index.d.ts","../node_modules/@fluidframework/core-interfaces/lib/public.d.ts","../node_modules/@fluidframework/driver-definitions/lib/urlresolver.d.ts","../node_modules/@fluidframework/driver-definitions/lib/drivererror.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/users.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/clients.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/config.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/consensus.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/date.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/protocol.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/scopes.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/tokens.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/sockets.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/storage.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/summary.d.ts","../node_modules/@fluidframework/driver-definitions/lib/protocol/index.d.ts","../node_modules/@fluidframework/driver-definitions/lib/storage.d.ts","../node_modules/@fluidframework/driver-definitions/lib/git/resources.d.ts","../node_modules/@fluidframework/driver-definitions/lib/git/index.d.ts","../node_modules/@fluidframework/driver-definitions/lib/index.d.ts","../node_modules/@fluidframework/driver-definitions/lib/public.d.ts","../node_modules/@fluidframework/container-definitions/lib/audience.d.ts","../node_modules/@fluidframework/container-definitions/lib/fluidpackage.d.ts","../node_modules/@fluidframework/container-definitions/lib/browserpackage.d.ts","../node_modules/@fluidframework/driver-definitions/internal.d.ts","../node_modules/@fluidframework/container-definitions/lib/deltas.d.ts","../node_modules/@fluidframework/container-definitions/lib/error.d.ts","../node_modules/@fluidframework/container-definitions/lib/runtime.d.ts","../node_modules/@fluidframework/container-definitions/lib/fluidmodule.d.ts","../node_modules/@fluidframework/container-definitions/lib/loader.d.ts","../node_modules/@fluidframework/core-interfaces/internal.d.ts","../node_modules/@fluidframework/container-definitions/lib/index.d.ts","../node_modules/@fluidframework/container-definitions/lib/public.d.ts","../node_modules/@fluidframework/container-definitions/internal.d.ts","../node_modules/@fluidframework/shared-object-base/lib/serializer.d.ts","../node_modules/@fluid-internal/client-utils/lib/bufferbrowser.d.ts","../node_modules/@fluid-internal/client-utils/lib/hashfilebrowser.d.ts","../node_modules/@fluid-internal/client-utils/lib/performanceisomorphic.d.ts","../node_modules/@fluid-internal/client-utils/lib/base64encodingbrowser.d.ts","../node_modules/@fluid-internal/client-utils/lib/buffershared.d.ts","../node_modules/@types/events_pkg/index.d.ts","../node_modules/@fluid-internal/client-utils/lib/eventemitter.d.cts","../node_modules/@fluid-internal/client-utils/lib/trace.d.ts","../node_modules/@fluid-internal/client-utils/lib/typedeventemitter.d.ts","../node_modules/@fluid-internal/client-utils/lib/indexbrowser.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/attribution.d.ts","../node_modules/@fluidframework/core-utils/lib/assert.d.ts","../node_modules/@fluidframework/core-utils/lib/compare.d.ts","../node_modules/@fluidframework/core-utils/lib/delay.d.ts","../node_modules/@fluidframework/core-utils/lib/heap.d.ts","../node_modules/@fluidframework/core-utils/lib/lazy.d.ts","../node_modules/@fluidframework/core-utils/lib/promisecache.d.ts","../node_modules/@fluidframework/core-utils/lib/promises.d.ts","../node_modules/@fluidframework/core-utils/lib/timer.d.ts","../node_modules/@fluidframework/core-utils/lib/unreachable.d.ts","../node_modules/@fluidframework/core-utils/lib/typesguards.d.ts","../node_modules/@fluidframework/core-utils/lib/oob.d.ts","../node_modules/@fluidframework/core-utils/lib/index.d.ts","../node_modules/@fluidframework/core-utils/internal.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/telemetrytypes.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/logger.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/config.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/fluiderrorbase.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/errorlogging.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/error.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/eventemitterwitherrorhandling.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/events.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/mocklogger.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/thresholdcounter.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/sampledtelemetryhelper.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/utils.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/telemetryeventbatcher.d.ts","../node_modules/@fluidframework/telemetry-utils/lib/index.d.ts","../node_modules/@fluidframework/telemetry-utils/internal.d.ts","../node_modules/@fluidframework/id-compressor/lib/types/identifiers.d.ts","../node_modules/@fluidframework/id-compressor/lib/types/persisted-types/0.0.1.d.ts","../node_modules/@fluidframework/id-compressor/lib/types/persisted-types/index.d.ts","../node_modules/@fluidframework/id-compressor/lib/types/idcompressor.d.ts","../node_modules/@fluidframework/id-compressor/lib/types/index.d.ts","../node_modules/@fluidframework/id-compressor/lib/identifiers.d.ts","../node_modules/@fluidframework/id-compressor/lib/persistanceutilities.d.ts","../node_modules/@fluidframework/id-compressor/lib/sessions.d.ts","../node_modules/@fluidframework/id-compressor/lib/idcompressor.d.ts","../node_modules/@fluidframework/id-compressor/lib/utilities.d.ts","../node_modules/@fluidframework/id-compressor/lib/index.d.ts","../node_modules/@fluidframework/id-compressor/lib/public.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/datastorefactory.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/datastoreregistry.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/garbagecollectiondefinitions.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/protocol.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/summary.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/datastorecontext.d.ts","../node_modules/@fluidframework/runtime-definitions/lib/index.d.ts","../node_modules/@fluidframework/runtime-definitions/internal.d.ts","../node_modules/@fluidframework/datastore-definitions/lib/datastoreruntime.d.ts","../node_modules/@fluidframework/datastore-definitions/lib/storage.d.ts","../node_modules/@fluidframework/datastore-definitions/lib/channel.d.ts","../node_modules/@fluidframework/datastore-definitions/lib/jsonable.d.ts","../node_modules/@fluidframework/datastore-definitions/lib/serializable.d.ts","../node_modules/@fluidframework/datastore-definitions/lib/index.d.ts","../node_modules/@fluidframework/datastore-definitions/internal.d.ts","../node_modules/@fluidframework/shared-object-base/lib/types.d.ts","../node_modules/@fluidframework/shared-object-base/lib/sharedobject.d.ts","../node_modules/@fluidframework/shared-object-base/lib/summaryserializer.d.ts","../node_modules/@fluidframework/shared-object-base/lib/utils.d.ts","../node_modules/@fluidframework/shared-object-base/lib/valuetype.d.ts","../node_modules/@fluidframework/shared-object-base/lib/index.d.ts","../node_modules/@fluidframework/shared-object-base/lib/public.d.ts","../node_modules/@fluidframework/shared-object-base/internal.d.ts","../node_modules/@fluidframework/fluid-static/lib/types.d.ts","../node_modules/@fluidframework/fluid-static/lib/fluidcontainer.d.ts","../node_modules/@fluidframework/fluid-static/lib/rootdataobject.d.ts","../node_modules/@fluidframework/fluid-static/lib/serviceaudience.d.ts","../node_modules/@fluidframework/fluid-static/lib/index.d.ts","../node_modules/@fluidframework/fluid-static/lib/public.d.ts","../node_modules/@fluidframework/driver-utils/lib/buildsnapshottree.d.ts","../node_modules/@fluidframework/driver-utils/lib/blob.d.ts","../node_modules/@fluidframework/driver-utils/lib/documentstorageserviceproxy.d.ts","../node_modules/@fluidframework/driver-utils/lib/error.d.ts","../node_modules/@fluidframework/driver-utils/lib/insecureurlresolver.d.ts","../node_modules/@fluidframework/driver-utils/lib/messagerecognition.d.ts","../node_modules/@fluidframework/driver-utils/lib/network.d.ts","../node_modules/@fluidframework/driver-utils/lib/networkutils.d.ts","../node_modules/@fluidframework/driver-utils/lib/parallelrequests.d.ts","../node_modules/@fluidframework/driver-utils/lib/prefetchdocumentstorageservice.d.ts","../node_modules/@fluidframework/driver-utils/lib/ratelimiter.d.ts","../node_modules/@fluidframework/driver-utils/lib/readandparse.d.ts","../node_modules/@fluidframework/driver-utils/lib/runwithretry.d.ts","../node_modules/@fluidframework/driver-utils/lib/summaryforcreatenew.d.ts","../node_modules/@fluidframework/driver-utils/lib/treeconversions.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/compression/compressiontypes.d.ts","../node_modules/@fluidframework/driver-utils/lib/documentservicefactoryproxy.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/compression/documentservicefactorycompressionadapter.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/compression/summaryblob/documentstorageservicesummaryblobcompressionadapter.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/compression/summaryblob/index.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/compression/index.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/predefinedadapters.d.ts","../node_modules/@fluidframework/driver-utils/lib/adapters/index.d.ts","../node_modules/@fluidframework/driver-utils/lib/storageutils.d.ts","../node_modules/@fluidframework/driver-utils/lib/protocol/githelper.d.ts","../node_modules/@fluidframework/driver-utils/lib/protocol/index.d.ts","../node_modules/@fluidframework/driver-utils/lib/index.d.ts","../node_modules/@fluidframework/driver-utils/lib/public.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/routerliciousresolvedurl.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/tokens.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/defaulttokenprovider.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/errorutils.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/users.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/clients.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/config.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/consensus.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/date.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/protocol.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/scopes.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/tokens.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/sockets.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/storage.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/summary.d.ts","../node_modules/@fluidframework/protocol-definitions/dist/index.d.ts","../node_modules/@fluidframework/server-services-client/dist/auth.d.ts","../node_modules/@fluidframework/server-services-client/dist/array.d.ts","../node_modules/@fluidframework/server-services-client/dist/constants.d.ts","../node_modules/@fluidframework/server-services-client/dist/error.d.ts","../node_modules/@fluidframework/server-services-client/dist/generatenames.d.ts","../node_modules/@fluidframework/gitresources/dist/resources.d.ts","../node_modules/@fluidframework/gitresources/dist/services.d.ts","../node_modules/@fluidframework/gitresources/dist/index.d.ts","../node_modules/@fluidframework/server-services-client/dist/storagecontracts.d.ts","../node_modules/@fluidframework/server-services-client/dist/storage.d.ts","../node_modules/@fluidframework/server-services-client/dist/gitmanager.d.ts","../node_modules/@fluidframework/server-services-client/dist/heap.d.ts","../node_modules/@fluidframework/server-services-client/dist/restwrapper.d.ts","../node_modules/@fluidframework/server-services-client/dist/historian.d.ts","../node_modules/@fluidframework/server-services-client/dist/interfaces.d.ts","../node_modules/@fluidframework/server-services-client/dist/promisetimeout.d.ts","../node_modules/@fluidframework/server-services-client/dist/restlessclient.d.ts","../node_modules/@fluidframework/server-services-client/dist/rollinghash.d.ts","../node_modules/@fluidframework/server-services-client/dist/scopes.d.ts","../node_modules/@fluidframework/protocol-base/dist/githelper.d.ts","../node_modules/@fluidframework/common-utils/dist/assert.d.ts","../node_modules/@fluidframework/common-utils/dist/base64encoding.d.ts","../node_modules/@fluidframework/common-utils/dist/buffershared.d.ts","../node_modules/@fluidframework/common-utils/dist/delay.d.ts","../node_modules/@fluidframework/common-definitions/dist/disposable.d.ts","../node_modules/@fluidframework/common-definitions/dist/events.d.ts","../node_modules/@fluidframework/common-definitions/dist/logger.d.ts","../node_modules/@fluidframework/common-definitions/dist/index.d.ts","../node_modules/@fluidframework/common-utils/dist/disposal.d.ts","../node_modules/@types/events/index.d.ts","../node_modules/@fluidframework/common-utils/dist/typedeventemitter.d.ts","../node_modules/@fluidframework/common-utils/dist/eventforwarder.d.ts","../node_modules/@fluidframework/common-utils/dist/heap.d.ts","../node_modules/@fluidframework/common-utils/dist/buffernode.d.ts","../node_modules/@fluidframework/common-utils/dist/hashfilenode.d.ts","../node_modules/@fluidframework/common-utils/dist/performanceisomorphic.d.ts","../node_modules/@fluidframework/common-utils/dist/indexnode.d.ts","../node_modules/@fluidframework/common-utils/dist/lazy.d.ts","../node_modules/@fluidframework/common-utils/dist/logger.d.ts","../node_modules/@fluidframework/common-utils/dist/promisecache.d.ts","../node_modules/@fluidframework/common-utils/dist/promises.d.ts","../node_modules/@fluidframework/common-utils/dist/rangetracker.d.ts","../node_modules/@fluidframework/common-utils/dist/ratelimiter.d.ts","../node_modules/@fluidframework/common-utils/dist/safeparser.d.ts","../node_modules/@fluidframework/common-utils/dist/timer.d.ts","../node_modules/@fluidframework/common-utils/dist/trace.d.ts","../node_modules/@fluidframework/common-utils/dist/unreachable.d.ts","../node_modules/@fluidframework/common-utils/dist/index.d.ts","../node_modules/@fluidframework/protocol-base/dist/quorum.d.ts","../node_modules/@fluidframework/protocol-base/dist/protocol.d.ts","../node_modules/@fluidframework/protocol-base/dist/index.d.ts","../node_modules/@fluidframework/server-services-client/dist/scribehelper.d.ts","../node_modules/@fluidframework/server-services-client/dist/storageutils.d.ts","../node_modules/@fluidframework/server-services-client/dist/summarytreeuploadmanager.d.ts","../node_modules/@fluidframework/server-services-client/dist/timeoutcontext.d.ts","../node_modules/@fluidframework/server-services-client/dist/utils.d.ts","../node_modules/@fluidframework/server-services-client/dist/wholesummaryuploadmanager.d.ts","../node_modules/@fluidframework/server-services-client/dist/index.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/policies.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/documentservicefactory.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/index.d.ts","../node_modules/@fluidframework/routerlicious-driver/lib/public.d.ts","../node_modules/@fluidframework/azure-client/lib/interfaces.d.ts","../node_modules/@fluidframework/azure-client/lib/azureclient.d.ts","../node_modules/@fluidframework/azure-client/lib/index.d.ts","../node_modules/@fluidframework/azure-client/lib/public.d.ts","../src/ienvironmentfactory.ts","../src/fluidtokenprovider.ts","../src/imodel.ts","../node_modules/gpt4-tokenizer/dist/index.d.ts","../src/model.ts","../src/imodelfactory.ts","../src/loginapi.ts","../src/pagerepositoryapi.types.ts","../src/pagerepositoryapi.ts","../src/querymodelapi.ts","../src/sessionapi.ts","../src/studioapi.types.ts","../src/summariseapi.types.ts","../src/suppresssummarisefailapi.types.ts","../src/themeapi.ts","../node_modules/@types/bintrees/index.d.ts","../node_modules/@types/json-schema/index.d.ts","../node_modules/@types/node/compatibility/disposable.d.ts","../node_modules/@types/node/compatibility/indexable.d.ts","../node_modules/@types/node/compatibility/iterators.d.ts","../node_modules/@types/node/compatibility/index.d.ts","../node_modules/@types/node/ts5.6/globals.typedarray.d.ts","../node_modules/@types/node/ts5.6/buffer.buffer.d.ts","../node_modules/buffer/index.d.ts","../node_modules/undici-types/header.d.ts","../node_modules/undici-types/readable.d.ts","../node_modules/undici-types/file.d.ts","../node_modules/undici-types/fetch.d.ts","../node_modules/undici-types/formdata.d.ts","../node_modules/undici-types/connector.d.ts","../node_modules/undici-types/client.d.ts","../node_modules/undici-types/errors.d.ts","../node_modules/undici-types/dispatcher.d.ts","../node_modules/undici-types/global-dispatcher.d.ts","../node_modules/undici-types/global-origin.d.ts","../node_modules/undici-types/pool-stats.d.ts","../node_modules/undici-types/pool.d.ts","../node_modules/undici-types/handlers.d.ts","../node_modules/undici-types/balanced-pool.d.ts","../node_modules/undici-types/agent.d.ts","../node_modules/undici-types/mock-interceptor.d.ts","../node_modules/undici-types/mock-agent.d.ts","../node_modules/undici-types/mock-client.d.ts","../node_modules/undici-types/mock-pool.d.ts","../node_modules/undici-types/mock-errors.d.ts","../node_modules/undici-types/proxy-agent.d.ts","../node_modules/undici-types/env-http-proxy-agent.d.ts","../node_modules/undici-types/retry-handler.d.ts","../node_modules/undici-types/retry-agent.d.ts","../node_modules/undici-types/api.d.ts","../node_modules/undici-types/interceptors.d.ts","../node_modules/undici-types/util.d.ts","../node_modules/undici-types/cookies.d.ts","../node_modules/undici-types/patch.d.ts","../node_modules/undici-types/websocket.d.ts","../node_modules/undici-types/eventsource.d.ts","../node_modules/undici-types/filereader.d.ts","../node_modules/undici-types/diagnostics-channel.d.ts","../node_modules/undici-types/content-type.d.ts","../node_modules/undici-types/cache.d.ts","../node_modules/undici-types/index.d.ts","../node_modules/@types/node/globals.d.ts","../node_modules/@types/node/assert.d.ts","../node_modules/@types/node/assert/strict.d.ts","../node_modules/@types/node/async_hooks.d.ts","../node_modules/@types/node/buffer.d.ts","../node_modules/@types/node/child_process.d.ts","../node_modules/@types/node/cluster.d.ts","../node_modules/@types/node/console.d.ts","../node_modules/@types/node/constants.d.ts","../node_modules/@types/node/crypto.d.ts","../node_modules/@types/node/dgram.d.ts","../node_modules/@types/node/diagnostics_channel.d.ts","../node_modules/@types/node/dns.d.ts","../node_modules/@types/node/dns/promises.d.ts","../node_modules/@types/node/domain.d.ts","../node_modules/@types/node/dom-events.d.ts","../node_modules/@types/node/events.d.ts","../node_modules/@types/node/fs.d.ts","../node_modules/@types/node/fs/promises.d.ts","../node_modules/@types/node/http.d.ts","../node_modules/@types/node/http2.d.ts","../node_modules/@types/node/https.d.ts","../node_modules/@types/node/inspector.d.ts","../node_modules/@types/node/module.d.ts","../node_modules/@types/node/net.d.ts","../node_modules/@types/node/os.d.ts","../node_modules/@types/node/path.d.ts","../node_modules/@types/node/perf_hooks.d.ts","../node_modules/@types/node/process.d.ts","../node_modules/@types/node/punycode.d.ts","../node_modules/@types/node/querystring.d.ts","../node_modules/@types/node/readline.d.ts","../node_modules/@types/node/readline/promises.d.ts","../node_modules/@types/node/repl.d.ts","../node_modules/@types/node/sea.d.ts","../node_modules/@types/node/sqlite.d.ts","../node_modules/@types/node/stream.d.ts","../node_modules/@types/node/stream/promises.d.ts","../node_modules/@types/node/stream/consumers.d.ts","../node_modules/@types/node/stream/web.d.ts","../node_modules/@types/node/string_decoder.d.ts","../node_modules/@types/node/test.d.ts","../node_modules/@types/node/timers.d.ts","../node_modules/@types/node/timers/promises.d.ts","../node_modules/@types/node/tls.d.ts","../node_modules/@types/node/trace_events.d.ts","../node_modules/@types/node/tty.d.ts","../node_modules/@types/node/url.d.ts","../node_modules/@types/node/util.d.ts","../node_modules/@types/node/v8.d.ts","../node_modules/@types/node/vm.d.ts","../node_modules/@types/node/wasi.d.ts","../node_modules/@types/node/worker_threads.d.ts","../node_modules/@types/node/zlib.d.ts","../node_modules/@types/node/ts5.6/index.d.ts"],"fileInfos":[{"version":"44e584d4f6444f58791784f1d530875970993129442a847597db702a073ca68c","affectsGlobalScope":true},"45b7ab580deca34ae9729e97c13cfd999df04416a79116c3bfb483804f85ded4","3facaf05f0c5fc569c5649dd359892c98a85557e3e0c847964caeb67076f4d75","9a68c0c07ae2fa71b44384a839b7b8d81662a236d4b9ac30916718f7510b1b2d","5e1c4c362065a6b95ff952c0eab010f04dcd2c3494e813b493ecfd4fcb9fc0d8","68d73b4a11549f9c0b7d352d10e91e5dca8faa3322bfb77b661839c42b1ddec7","5efce4fc3c29ea84e8928f97adec086e3dc876365e0982cc8479a07954a3efd4","feecb1be483ed332fad555aff858affd90a48ab19ba7272ee084704eb7167569","5514e54f17d6d74ecefedc73c504eadffdeda79c7ea205cf9febead32d45c4bc",{"version":"4af6b0c727b7a2896463d512fafd23634229adf69ac7c00e2ae15a09cb084fad","affectsGlobalScope":true},{"version":"6920e1448680767498a0b77c6a00a8e77d14d62c3da8967b171f1ddffa3c18e4","affectsGlobalScope":true},{"version":"dc2df20b1bcdc8c2d34af4926e2c3ab15ffe1160a63e58b7e09833f616efff44","affectsGlobalScope":true},{"version":"4443e68b35f3332f753eacc66a04ac1d2053b8b035a0e0ac1d455392b5e243b3","affectsGlobalScope":true},{"version":"bc47685641087c015972a3f072480889f0d6c65515f12bd85222f49a98952ed7","affectsGlobalScope":true},{"version":"0dc1e7ceda9b8b9b455c3a2d67b0412feab00bd2f66656cd8850e8831b08b537","affectsGlobalScope":true},{"version":"ce691fb9e5c64efb9547083e4a34091bcbe5bdb41027e310ebba8f7d96a98671","affectsGlobalScope":true},{"version":"8d697a2a929a5fcb38b7a65594020fcef05ec1630804a33748829c5ff53640d0","affectsGlobalScope":true},{"version":"4ff2a353abf8a80ee399af572debb8faab2d33ad38c4b4474cff7f26e7653b8d","affectsGlobalScope":true},{"version":"93495ff27b8746f55d19fcbcdbaccc99fd95f19d057aed1bd2c0cafe1335fbf0","affectsGlobalScope":true},{"version":"6fc23bb8c3965964be8c597310a2878b53a0306edb71d4b5a4dfe760186bcc01","affectsGlobalScope":true},{"version":"ea011c76963fb15ef1cdd7ce6a6808b46322c527de2077b6cfdf23ae6f5f9ec7","affectsGlobalScope":true},{"version":"38f0219c9e23c915ef9790ab1d680440d95419ad264816fa15009a8851e79119","affectsGlobalScope":true},{"version":"bb42a7797d996412ecdc5b2787720de477103a0b2e53058569069a0e2bae6c7e","affectsGlobalScope":true},{"version":"4738f2420687fd85629c9efb470793bb753709c2379e5f85bc1815d875ceadcd","affectsGlobalScope":true},{"version":"2f11ff796926e0832f9ae148008138ad583bd181899ab7dd768a2666700b1893","affectsGlobalScope":true},{"version":"4de680d5bb41c17f7f68e0419412ca23c98d5749dcaaea1896172f06435891fc","affectsGlobalScope":true},{"version":"9fc46429fbe091ac5ad2608c657201eb68b6f1b8341bd6d670047d32ed0a88fa","affectsGlobalScope":true},{"version":"61c37c1de663cf4171e1192466e52c7a382afa58da01b1dc75058f032ddf0839","affectsGlobalScope":true},{"version":"b541a838a13f9234aba650a825393ffc2292dc0fc87681a5d81ef0c96d281e7a","affectsGlobalScope":true},{"version":"9e9fbd7030c440b33d021da145d3232984c8bb7916f277e8ffd3dc2e3eae2bdb","affectsGlobalScope":true},{"version":"811ec78f7fefcabbda4bfa93b3eb67d9ae166ef95f9bff989d964061cbf81a0c","affectsGlobalScope":true},{"version":"717937616a17072082152a2ef351cb51f98802fb4b2fdabd32399843875974ca","affectsGlobalScope":true},{"version":"d7e7d9b7b50e5f22c915b525acc5a49a7a6584cf8f62d0569e557c5cfc4b2ac2","affectsGlobalScope":true},{"version":"71c37f4c9543f31dfced6c7840e068c5a5aacb7b89111a4364b1d5276b852557","affectsGlobalScope":true},{"version":"576711e016cf4f1804676043e6a0a5414252560eb57de9faceee34d79798c850","affectsGlobalScope":true},{"version":"89c1b1281ba7b8a96efc676b11b264de7a8374c5ea1e6617f11880a13fc56dc6","affectsGlobalScope":true},{"version":"74f7fa2d027d5b33eb0471c8e82a6c87216223181ec31247c357a3e8e2fddc5b","affectsGlobalScope":true},{"version":"ae37d6ccd1560b0203ab88d46987393adaaa78c919e51acf32fb82c86502e98c","affectsGlobalScope":true},{"version":"063600664504610fe3e99b717a1223f8b1900087fab0b4cad1496a114744f8df","affectsGlobalScope":true},{"version":"934019d7e3c81950f9a8426d093458b65d5aff2c7c1511233c0fd5b941e608ab","affectsGlobalScope":true},{"version":"bf14a426dbbf1022d11bd08d6b8e709a2e9d246f0c6c1032f3b2edb9a902adbe","affectsGlobalScope":true},{"version":"5e07ed3809d48205d5b985642a59f2eba47c402374a7cf8006b686f79efadcbd","affectsGlobalScope":true},{"version":"2b72d528b2e2fe3c57889ca7baef5e13a56c957b946906d03767c642f386bbc3","affectsGlobalScope":true},{"version":"479553e3779be7d4f68e9f40cdb82d038e5ef7592010100410723ceced22a0f7","affectsGlobalScope":true},{"version":"368af93f74c9c932edd84c58883e736c9e3d53cec1fe24c0b0ff451f529ceab1","affectsGlobalScope":true},{"version":"af3dd424cf267428f30ccfc376f47a2c0114546b55c44d8c0f1d57d841e28d74","affectsGlobalScope":true},{"version":"995c005ab91a498455ea8dfb63aa9f83fa2ea793c3d8aa344be4a1678d06d399","affectsGlobalScope":true},{"version":"d3d7b04b45033f57351c8434f60b6be1ea71a2dfec2d0a0c3c83badbb0e3e693","affectsGlobalScope":true},{"version":"956d27abdea9652e8368ce029bb1e0b9174e9678a273529f426df4b3d90abd60","affectsGlobalScope":true},{"version":"4fa6ed14e98aa80b91f61b9805c653ee82af3502dc21c9da5268d3857772ca05","affectsGlobalScope":true},{"version":"e6633e05da3ff36e6da2ec170d0d03ccf33de50ca4dc6f5aeecb572cedd162fb","affectsGlobalScope":true},{"version":"d8670852241d4c6e03f2b89d67497a4bbefe29ecaa5a444e2c11a9b05e6fccc6","affectsGlobalScope":true},{"version":"8444af78980e3b20b49324f4a16ba35024fef3ee069a0eb67616ea6ca821c47a","affectsGlobalScope":true},{"version":"caccc56c72713969e1cfe5c3d44e5bab151544d9d2b373d7dbe5a1e4166652be","affectsGlobalScope":true},{"version":"3287d9d085fbd618c3971944b65b4be57859f5415f495b33a6adc994edd2f004","affectsGlobalScope":true},{"version":"b4b67b1a91182421f5df999988c690f14d813b9850b40acd06ed44691f6727ad","affectsGlobalScope":true},{"version":"33358442698bb565130f52ba79bfd3d4d484ac85fe33f3cb1759c54d18201393","affectsGlobalScope":true},{"version":"782dec38049b92d4e85c1585fbea5474a219c6984a35b004963b00beb1aab538","affectsGlobalScope":true},"01ba761ce6d75a4142858a053f45d64d255e057049ab1cc4d9a93e76b8b5c444",{"version":"b262767f0d126e2898a3c19e17a535afd95c716f76ea58d98674263936588c74","signature":"6b5af05e7e92d146304c3f44a4aa754fef6c156e379566516966435d9ec8daab"},{"version":"497a579b0d0c028079128b4c23dc9e29e1a775536a5e8563d2b5f8bd8b55d1f1","signature":"520c382abb839023db1cf06fd36059fc0eb0bee6b77eff5295ad3a7e626f131a"},{"version":"deac99c2a083858fb94f05888005673f667f0af45e1ac010ed12bf81e43f82a5","signature":"951b507746e0f5ed1ff41ddea054b8247c3bfb07c790ba782440b81a87767736"},{"version":"3ff610488ddb4f93e54dc629ec71e547652d4f2e2dcbef2fe10b905e56b4f04a","signature":"5bef187ad53a149312db85462d80db0bcefc8dc2ea9416a1bafd64c4b112bb7f"},{"version":"1961a1b95960de8f7281dcdd1c5c3c21f4c00f6b82954f7b27942d880923a9d4","signature":"da65fa8f5c0fb5099a776111f0b0715897146265fa96358b153472f9e61fd86e"},{"version":"3c79998e3092cdd149e93615d4d700f20bf3b13180e7a9031c390d203d491d89","signature":"19ffc4a69c3446c0fd450bad5df1a2f48cf0baefde1e1814562717de7e93c085"},{"version":"cf2cf6e3f3890c27050b253e68b8d4f4ca27137cca1bd9a252c9954cffa3b965","signature":"0d2cc204d7d78f6d1e8213aa94f13f38a3e5eeae8096b395f6c26b1471449c9d"},{"version":"95f1e169cf99a414e37860ec2bfd16340ee1f16f630ad36f7cbf32d817a400e9","signature":"3eee5ee5b9ce77288d931dfcaee3d95167d0e70a73af698d9249e9d389f875ae"},{"version":"dbe03a68311761f1e436593ca76b1120b8786f0af427a2fe78425513768d31b4","signature":"ff9b5c7800204282f1f2651799e58c02de18e3c573487ed12e0ae75ff0af5617"},{"version":"6dfbc9656385c572c44c9ba1bfb24ac789d6db187b98dafa5aa2c91647087a4c","signature":"fd35c4d2d3112b5126e20f7b1ff7ebc4447e3d417159d005b0c7d7ada33572df"},{"version":"7397fdbca0d6330a4ee4b40514531e206fd25787bd28bf5af2d0e53365cf1ffe","signature":"ccc55c6dcb68bc8182f263de1c074e6d3d65487a9bdddffcf69130f498d3bf34"},{"version":"ed5e5f7a105a20c600468d0551576759194cc7b2909c78e64ca1f9d16a6e7f2a","signature":"942e30f1c90d2fa2e1cc51a010bcc9e4bd7e5350edfd4c48383f6c737a495129"},"c634df3e1b52761b2a219edcc61d0a7f748cdc54b93d73bcb817619452a6388a",{"version":"6db4dfe21975c7513859ba21e36ab02fec813d19414d6df182d0898122b35546","signature":"68c461dd20402dd9777e274c53580934288bd156efe720f9e16daa758d8ab209"},{"version":"33fa200cc812fdb3b3616a60061bea8d777e871a52b49425d5d21534806e7e0f","signature":"095e7bffb71fafaa8916593a4514eb06298ddb11199fe8258ef4f181806c3086"},{"version":"ff3a07cd8b6040f47a798e803035167abba04f91112980009bbdde323c2bc5da","signature":"f1f4d84b3e6c005320086d66a75aeb78c8d29d6751fe2272cd72e4e35f3d23db"},{"version":"64940c4a8d404a9ede996a6a330ab3c4daf9af79e11a8d94177bb5538143fe8a","signature":"adb99845133fa780c37a3b0f98a92bbe683de1c9500708dde193987daaa12c70"},{"version":"0e32a663a8c920010314a0dbb8017a737d400624301418e342a62c325de0e575","signature":"01989b6ec115f36587a8d98c9c560bb4c63b2e5a8b4e0d82e7cb31ea17bb8be8"},{"version":"7e8babbdf4b84b37389bf4b158e64c337afd8ffa0bb84a602a2ddf7f0bb60d10","signature":"9930e1e120243b91a19bae0ff54e6835e217117e0eb98c38b5def487a666c847"},{"version":"54df2b8db3b30ab8f5032a772b9ecad7baf7442f208ec2fe2e889f207b847e09","signature":"30553228a1bef8567756b14cdb82ed091e4cdf7f65736e2dd9670b13c1bd5aba"},{"version":"8c4b92b55a1dfa55555c2e9d70a6fc86f5069a03cf13cd8e2212691736d1db46","signature":"c13cee4943b5433267c74904b9d9c76e90b5cb7cf4d3023cdac0b75fa762847e"},{"version":"e6c5da1b16211a5488343ded23180e6fb96e7efcd8c66f51912ca4067baf10d9","signature":"a914dda30f91f23a07fbc10609d684ea1b8c70e1251f27e3e9e335eed7ab76ae"},"0e61da58d136e579473ea50552c918f8724a924541b7dd5e922e5acb4146a13d",{"version":"e03afaee6b47945a0ec3944b636c9a46a08ed4d1f253e226cac2b864cf82c61f","signature":"b6fd921ab532355c40a32eaadd22c1c47baa6bdc97a99fe06855d0a74360007f"},"76222708e1fd35e13ea7930d141c76811842af42e8200abd3617cdcc800fca9b","b82040a39ffdb225a97fc1a934af30ce65364a1acbeb1900ed06dc305c08419a","acf8e4812e25c86d55725f365c6fd004c099c125351799002077c749d7c32cb5","a4da212ce63d1e8c9937eddc3fa94196a40eec042b0b4a130f18ba909ee10f58","d1d878a1661002034e2dc6a7d40baa2e3d1aec74643c341f7469d604cc245192","b83f2e8e8c6b7f2c761015bd22fa66d0933af1a5396dd706090d1992ab76b508","5d8bc3018458dffe489343207f008e55c693b1d3d734fd1cd1ba13e3540800a4","8c3dc920164192ff835183ea33579ff913cc3f2829682d0250a2180838fa1df3","a64edb16eacf69e9473e5b829d850ac4b526daf673e92a84628c8c492fe06d68","06c8622d8f31b530058177e1ba6e97e3896c369be4b5f0d19e870512787e9e78","905bca74f61f72b7eb9d4d7c5b9020b018e1e125c2b7123f8c62e84921c26198","d1e41a666ead653d3e16fe14afdb0b6bb603e44b20a38cba23614a0ce8f35250","7822697ae97a8d034d4c3e19695952e0f4526133f4ae4cdf2ee51f14dd335da6","d278b1734e9f958b9b9f0705896b3d76c9c73cc74987ea30471b5db8d3eb3f53","f3f1896a7411aa9f3e8fa652f55d07e736333f5d2a93c798aa12b10cfe9bda43","f338a331fc98b7a1f203f27b72934b22157bab6e23102f005b09786dcf383668","af742d95ad117e7e7f97d36c1df19ef68299ee41dc9da1671e7573874b333804","ce990e4091223d3a0b7732e962a4f714382e1329271066e3eca2c9853e941c30","60ed184ec95dc22fc01808907ab2387098f79fd019dfb8a54b3a2220430bcaff","648ec08f15d9e5b13fd7a29b03cbcd4c21ba7bfe47674d3e7ef4c45f93b81016","61aee4092283c67d02e54111c10bc566bc48e470888f3a6719cc1491bd153032","848413d9d679929c63161fb1f28f6df6dc6d2de057cb6e63ca0091ad84f1abf4","ec0860d3af71ec05e7b64a66e00ef3d93a3b7e3a47a5aabb3b5287366c932b7e","9973f2bb033798c44f6723124957466b58a050a47f3327fe5eef48a3a81635e7","ad0dd8d0f68236cb000f06f8d9d8e0282918d5f9208b0ae23fc33c8c2a39c3d3","9a6cac8183a6e52059190a4ff7dc54b038cec6a7c0a27fa02fbf678f2d93ac09","35406f025a591674e32f4144b8c3fd48645042bdcefa5ec987c5114e8c1159a2","f252ef09603db5db7d4701c84a45ab4a00395d41f41f33e16eb01b8d4c648edd","f83fa2051c8c4c23bb4e4fbb8d8dffe498ea23536ed7eaa3d2c6a57e88d39bb2","69367ea67e9d60d2777ad8fcde58467c7e1cd9c07e5cbc49284a92d0398e130f","cd79409534ca0e391e7c4d1df0901069a1a21374141cf49f651439fc1d544b79","3ce35452520daee30c080aa24077564c83a709c612e5756fe2c85236a6c866aa","6ca7039ba41346d5397fd93a62afcac0a2c3970ac39bf2d0bd013eaa647d9ce9","4fc5afde3c92f7237627284d009ac9bc15e6c10d9efa741cd2320c6b3453515b","6a07ba30908ad95dc690755101072babf5dbeffee8f65f2f29ff3ac67ee14034","021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","e8ae2c7b741127c0bf1ac61e259d8616a11c96d45ea9b24994bc06d280a130dc","2cb3ba6b919393c69e0acf8683f6b5dfc831a421fe29c768a263d52961f32384","6037f40d5ddecc221ce1ec233d6872ee98f478be706321abe7ee954ee5ca2d5a","1a3620b673cbda5514238aacf42657fca59232dd8a1e76fd0b530c4092900973","45f83012e25d65dadf39e8242e4fde2c324b3e3e433245f7913593891c1098fe","021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","7ef7ab6398d2e4c5c0a250ea19ea294be0db5b005ed5fa652b3f62c487eb8588","5e1ad0763d3a3b5276301157c8a2d6d246469162a1f777274ac772259614f1d4","021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","be86f4b43f294650b702fa56ec74b80abc8996fe9aa827753de8d1cf557b605d","2af11fa3c25ff650be8197090801e9a657b76eafe4dfc89e916f71d7eb122b2d","85869f1e603b27f51671459a4f98f540f472a2452c337214a023483c4f0ba717","858f82bb3501bc4e3ec08c4d9f8035768a62549d4de42804600e9eb63a475e36","b6e4b2df38794096aba6944a0941accf45da9b97d2da719dd8a95d883b0fc7b1","023683fdc80a7f5c8dc1426427f328373aa309bf28be20bb7ff9b5fe1a3010c3","93d28b4eb12c68fccc1f2fc04a4ef83ea3b2a03b18055d3bf29cab267aa7042e","81dc23d5f6728d5bfc366a79aa017d83c0c180989cceb4faa570555038436200","5fa5ca164fea16db2c611d502b3f5c82c1f02417507de0c4debeaf924f771a7a","09ba4f33b0f77d1d78b10d3acdb6d0e5cdfd50613cf1882e6b7ae6bac6cb366e","ac1609adb8b2d4c4d75de89fb54c703fcbccef08ba12c21097066244b8054660","3df4f4977a0ff52ad829b6cc94ad374c0c0acb935e55abe87063f2b59016f0ee","76363ee0ff4a535c4610ffb2218d3cecd84f480f6be08a4a95a0fdc2f4887e1a","c024d9facf96dc8b416a033b160f30fffea900700f3f2bd238b1a31b67449769","7a2e7c19fbfd3ca11cd3fb90edf4fc3adf379bd31da785bef41f34a5c97d18c0","f4f9db86be98abda0930205133aa386c24ca11f277cfc0d0f1b0fa2de23c6bae","11004bbba9c301e4c60e006ada6adb81b0dc14c648b0c1e01f19439d1f776719","afdc6e7f37a50777eb39afec605955227e931a658ef1fa521faed16973e1deed","afaad0bb62b562a94dcc058825ea7ebf186521024c516f7b0c98bd08a35b1336","b50b9c126725991530c65ef84701450c0e3cca4d7c9d9caeb6a3806b69c0c6c4","568ea0e68446d5ba3c9f511a3a89d2c2c3eb2ec9d71f9c38a692fbb3915339ee","8265e7d6b8b26a3883124f895202fb4b5b65549e1bd6fac4478b1c0914dec628","d13af6c285e514d9a6d136128c277caaf18654a4244f57de4f2a62c8e620782a","10c73797d5742c71db4b536a8ded2319754b0fce698625210ac650e285e2a38e","021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","fd4bdee034d577f19e12e9f14244ecdee787b1040ef23dbbb881b77e5ac071e7","d879775003b6feb704931bda5f4d8767a7c4385487180795e49e39fdedb80bae","b39c4be45e541c41e74a6e1e98bce5f87c81ee0e349a4f443264ac6db68093cf","cd352dca0687583413c65c64fd7d4145c9dbe51206f2c5ada38a6114f3aeff84","ec70a684935852408686d32ee9d351c154a5fd95b3274f887685172b65ba721d","c1022eecdc3f6aae6e93e452a68f46dc7ad45924c9eb47c2a92540fc24520f1f","94e838908103710c131fe491b0ac30143fd6224d86ec526a6d43220b658857e8","f3b721c00165d7fce0ff106c2bf3b4ecf9ca0eebc83db98998a7e8f8a1ccd1db","4cffdeb4fe0cdaed0dff5efbbf1c76b09479f97bb3b70c542174abcf9f4f0c3d","f1409ca7c84b6bb8e4470b6fdaca0701a5a260d8a229d123720333be6edc1bfb","2dad866a6b54b13820fd5d46709ed7b2f11af19414048a1f0ed9c8bb7fdf8afe","3661088f65668cf69edfb1fd5fd7f3563d8a224cd2c35e0b198240622d205865","b8e65d8c2faf5a2b96c51bc92dc75bf0a359528dcc0c6f970f5d5c0f834882a9","3d874e5cdf4fbaebebb05f81c8e4632313f1f659d636be3fcb8735242db3cdd3","021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","03d1384a8eb825f29933e631db99bd1685ee058cc2764d6c8a60db1d02598407","abff08bca8d9c32926713b2f941dddc5309a7fc8f24f741d03b3044f8549888a","d1bf6ff2b40bb2ca030836a8a0f255d4ac0d5027b777a254ec85f0cc1faddf0e","f63bb0b18912e54251237b83754cb5630a8866eedd93ef2e366584b4ab7e62fa","2ec363e2c7fe514d6db7da8a8a6177e5aeefbb619d96650dd242e890aeca2645","d53323b449ff5dd1273219251cf9f4e640747f1ae322d1af861cd8bf536e0c7d","c8d7aca18f8446d801908ab8025dd241aef7ad6cd83843663b6271e07acfec24","7f52f6bbb7e0bee51f540fd37af9c33c420ebc536539adf376a5905f04edf7e0","625001813cf43ab48deddbcab9cf61453ccf6738fbfec0952e38707e42822e3c","ae8073201d5105ed350ae644a0a1951ced542daa51a4fdc75794a37e44d93da2","da713bcf397e56564f24a6173f6c4e001f8302051929ba729dd8eb040ed88a82","78781534bd73651a42c096bd8764e099506278b61b93099936b7d27b4db9d51f","e8a411933c0a7d3a8fcea3630a3a5b87590bd07d3c1f082f15d75da67f9fdecf","ddf406b4f85eef134656521a8ad429fca2cb0521684deef8d34b88f02b667cce","576af7f1374ffe097f26a45785e50fc385755e3abf400871df12908b26c43dfb","101616c5ab3e3e0bacdca873376ee61920201ff692a9d6bbeb379af9ac196afa","55ac7a21b1c472954f6a5327e37f0eea41294eb23360bf2f8d9385c19ff52601","8eaa1d7117a6385028116a705161fb16227d149d09675b11293d1f6869fb9568","80faabea3139f350fee0bfd5898c18241ecfef7c1e76571c28e31da5c886d0dd","021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","433c26f78f3ff2c7adace5737716ac2285c3a05594b011f5a4b4dba41a427360","7da1ca657f036a4da52da123265514f1079bc60f7dfde82ea85aa28f27c63a40","9db52de1e33c471da09684d182d1849cedcf233f1ccdbdf4318fd320c20f740c","24c63dd5d622f149c208c30e72e04dda61db9c47c49c00cb5197c0964d2823fa","7785fa1bf42df640a28e1a5ca7a3f2c4a2b2f72926749e5ea37c6f60ff4ac0cf","759fbc8ddc4fc784f7b9141e2eef7180659c196911d71295d2e8448cb94bc831","09ee43ae7a402f4c062ecdd56652b08adf1a4f58f7fd54b95061aef64d6eb18b","d95ec2c1f87180efd1985f1a23051f8f058ffe051ebfe0b4b71f74caff96f7c0","d2218ef87c038992126dfd83dce7bcf639cd83da17b1bdea6bd92f74c1553be0","5fde1d474cb425206c2bee4a5daad3ea5f3a076ed8321c1978bcfa0c70120c4b","be684eccf9e47a66098aeaf58e3fa0042e3759b43768fedfade3cd6232326861","1ec7cf5145caf91c45a00e641b766cf2657cc48c09220652660737235f7bdf97","e28f754ca99523d5cc4fd71d28ca62706588511eaeabebe4b0de51abce4b3bea","f594ccc1a1fdabf6ab0b875343e827c2a359ad45a5c141c0b5eaf1ea61ffaefa","021154bdf12997a141d0392cc5bb9b917331309ab3d95730412b420d71d15087","94722c0ce2c348208e958b939ff9b898b7bc0607f3c149a146e25447fc98ac80","c1549fd16f2765b4735589fa07bcc12664fd1ddb077ec392f5a2341210fc300d","de463e4e94423b5a3fe6dd5ecdbb956e3d8059dbc7d596cdda5e35cea1f7735c","1c83b27d92088815dcdabb94a0aacb5003cfc817afe0102baa4d37d776b99b6d","58c1d7604faeacf5b0581183077e65ec53bd82e49d09d35506f7073ca0efd129","a19d3b4dc1fd282420c2eb391a16671de2448cee11e2792659ef9ab32e1a68e1","19c8c28ff48cdc8d9f3dad0d59f66205508a35f436be4ad41478d7f3ca142dba","a9b7e861a9d12ed0d2d32072b530920f6c2cdd1678b887dfca918b284bc0e39b","eba603682ab2e7f819bc6562d46d45720b89e70f0e5bba78d3226f423fc9c6c7","a7f07680a8aa67c61dc19ed9a9058be4a1e2b2b11b8bdec1d1057466d08ac1a9","e66955b0b42e7f1f20dc42076569e42eb2c1da7e06468bdfab0a387408881b82","b4069f9aed4198c69b20a8daade43c0c7c5b4a49c06bf2ebe9584cd8aa025f94","3833e686d7df5b4fb1c3fbd8b62bc8986c5a1ba2f63a7f50b92ff9c443aefd15","efd5bede1fde7e0c6ebb1e83d5ccb9d3d6a17e60f132c71f4168678935c58c4b","311e82e0ff986d6401764585f96776ef9a9e2acd0e087e722a5849a731f14682","20b71d238301ca7204568d3d66bd86aed63d091cb16493cd2d072a329eea6f46","a6b9638bfa99955f5aabc8557fb882fe42879e15a38db0a13a0cb3f535d7f547","ae6a13337a9d1e4d2652d702a05bffadfff726e2713ee4388eb6f26b8330b804","caf4ff1b378b920addc5dfc24e4f1c16d68a4f06f00e012732f05eaa9ad2d25f","cfb245c719e0ea0bbcd640d9b65f94e12706b63f0fc950d860770ed46d83264e","7a47653ca382f75c9ffb4497e8c54e0b7ca8f4dcfc7b168c7fd2250eab893da2","0e97456057e413a64f5a103df512abbeebfffa5c69445c5df0471cb89cbf699c","46cd205be3218999d1ec27620895a3ebd2b70000fd11cc29f32f1ff0620e7794","4055718568409184cbb834346d74c6be4b981d399cc52163a60443d0f57d491a","dec7349c2cddaa1793c1179db1bee327a8a138e1def11c2d9cc5461704420ff9","53cdcfb57c6c06401e7656a6bf6a6f31e1f5f975f9d8dff4abcec4ef331ce9f2","21a13cda8bb793012582d06c260c6e81a5574417fa2ad280531f9f9eb0de80c0","7fe63905dd2115a25ede4f6da6a835560edd44a953509037a686a3af1dbb027c","c4235c8d390dc610c1afb57371df39705735318bf47497bcda92fc292f3a819c","8143252207f3e662603fb191a62cfc33e6910b09ff2ecc99a9e6258eae867a8c","6790f423c74646a936e15c7040c674ffeef6c5fda2c690b25607fd25b206b6db","f2181c6ddc831bfdc69e7b08c57340fcdc3c4def65cec00fbe7367c20e2e3cbe","54f200358938db4592ef064cc70575b5b93782b2a1e9a4f3ddb725cb8585c2a2","97c213aa8753e0a40f74c465dacdfa6f0481ef79fc852ec417fed051819e5080","4f6da11b3a981f0f61a3285ee7328fa9fd278cd5d894311eb3d32d3fb851f73c","4c3fe1c1ec258e4a2e00b36be83d69434cbccbe0df278b750ffbb285c019d991","2f0e2bd23bb1ec390a24282ace30b7957ce8fe52a208d753ea9b5fbb07be7cb3","fef2c4394fa651fab2911e10da0095f6e894f118b0da421140802b9572e8d837","f338a331fc98b7a1f203f27b72934b22157bab6e23102f005b09786dcf383668","7336bc25cc72933b720c3bef0cb3087991aa27844c83376fc3fe36a824d7a8ed","cb45b2d61ca2a978551d75614ffb129a4386b4b3b59dc7d05d5c721f6da97684","1070df8aa24c5dd2823080a2882e5d09fb86fcbfc0104ccba13326121233de3f","2f1b2648a9ddeb7af4f497573aa751c99adf6ab11f40b554527f0f65fa5e39a8","8bb104774ea2cd12848b1ecae4c2933f76b876ec4dc21160235f47a25ce9701e","5aa6397b22f8a04f8e5d97b2c08bb7038ca611363da1fe8e1174aa7114022248","c12cfe54ae9534e67fcef5c56efa1af3433b3dab19277866219e150a53db7aa6","63c4a0b4eb97c1f17198ffac8e868c2ade94bed702a93f364fb0de5459244a37","17797f8fd9ef3af7442b58158ce901230538678ff4f776d1bec3396ea9a7db61","b223ca15aac3a161f9f7eb5f7df3c98da26c84ce16866374d7919d196728f054","e197b79669e5e7a62be85bb55a2c4b0a3935c9c21031f16b4801f9c1424fc7de","5c359ff6b9f27ed265bb87736679ba5eb9ef83d356e72f57f207b7b1faaa2be1","244159bc6d99d3f66d2e4233c45fb688f4eb5d753183df4f539bf8f32c8f1330","964cf42a495adc2cc2037613f43522be40fc82012446fbfa4a0c4e3cef2bb97e","b482831de35852ffa394a8070061c4894b171857018d052a9d24d8684a8e99bd","df5ad3e5f00364b3f1beb243a4ce7538b0cead886bfc7c9ef7a6b4084d120bff","7b029c55b78626c3d13bccb4b77dd75047b73d84a7272405a770c3bab61bff15","c7c0b008caa3b7840ac9c52ee5ece3a36b65047ee12210dd2ea5276147a3a2ec","8d69c50f39132a4e9290f41cec755fa8bfa559362fb126f599409bdb6d8a3c7f","ef7263161d377d39bd03f1d6b0b888db7641067a331f92e0b522108e88be9321","a6af53ae0a4603cf6255dbd8bb4209edfad8e952bfa762684033782a28f68272","cbaac46ec418641fcb50afd7d0c8bf9462b6f7ca83af24d1317659a721175e2a","467c234ece0262e142939e2740ce970a71e7dca4adeeed872f0797fd4c3b34ac","508d1d9d7b04b090a99cd0ccf53b7e1e45ec2f96577b34e60fb9847c3d612efb","c6991234729127037d9d3653d89f1c8097caf2e22bf07bd603df5bc324b1c2ee","e1c249a691a5debf16ec5d8127c4b34f2bc12621d626a332cfec3d2592a317f7","6dba67434473193e6248d4db56aa0a23eed8791e861c863b36a4c347c5c9a307","6dcb16b880a06d2dd2912d2ce33c6f5bb09f4e7fa0f94090595caabeeb5454c6","a146e3f554d4f4eeb8fadf905892103cec35a60690c5d0437f65d1a5c85ecac7","65415fad6e906843d03b4f9ffecc427c7264a7b99824d95600f3ba24b0e8c511","ad12999de217ddbea616ff753af3f34217e717ffa9c67b62ca777e35ab3c5874","461f9060dd1fe58a9b79f5fa482fcf82580c47f58418fa3147ae2dd71dede99a","feb85f66b299d0c7379909f145010da50f187b4a87c9d3959d04fbdba4efe2a5","6b0004f4263d883c0428f6bcb6c777a50ea1b898ecb0ad624bf4f2a459d8cf80","32548c99315cdcd18f2d35d4874e86d3a65ab2b5106a6f01282a36a458c90b0e","58ca0005765de377f6af7e4f16e8f6e57a058ea2b7a732f7912807e0ea382ebb","2a6bd474eb954e8c55f890054787bbddd9b2798d298e743ed21758df69b5a303","abf6816f679f726d08e6732d433c94482efcd2a047bfbd7269d4ee8e56bbea13","3db678f64a08de6ed4971ae67dc59f70cbd810c67e15bc907f71ce71e5f61646","95578005d28f8532878f92217ac977b95dd3f61f45a4db882969e90dca98c28f","93d28b4eb12c68fccc1f2fc04a4ef83ea3b2a03b18055d3bf29cab267aa7042e","d8f1ffaf53542b1c5889927060616a3b36495881ece29b8e38b0b17a5bba1e63","d40f28fbc898cd4a152834c3838d26acb6447387958413a3e1a1bacc98e9b03b","3cf26bbbaa0f35f79bc74cc80347663689014af5637e09c07f88ceca8f50a4fc","c846f48f4361e54596493f0e00e6061aa7deeec84fbdcf74c302e1e83035ce6a","c603d9797601ceef13a55f78658c8fa2c4713bc9b7fdee6849115b9c414972ab","c09cc09af6c63564aaf8882cd1ad4522400930bbb3fcb2bdcc99d23c5f8d247b","3946f68bd37bad2765ea915e4aa750d30909a7bdc3012c030e1dafacced4b0a1","29b688cdaf703dfe8727069bcc384c5dbe6658e975152d42a873c8f40d324088","f973eeeb6c6f24a698824ea8b3a104632c82ef985143753d8ed4041ba948fdaa","94cc2d7bc4e0bb60472a4d1339d06072cd06965a58c335b609336c01795a2de9","001050d2385c4dd19b7043ef1b410dc22e1ac015e3e8dc2f312e16d1ad47a13c","c43867a3c095c21039c931980683d74c112f383b45b6a5b8a162564adb10643c","d380a790875c51668a846e69ef594be09715731f18b8e24bf6191ccc5dc96db4","68c6bfbcc44ace7fe4bbcc55810460b7356235624dc15ce7116e312eb8266c1f","0fd5c7cbde56982de70a99695bc4bfd7c6b30d9f3eab4bbd7770cc6442517914","43d3a46ed3aafbce9d061a5bd9acc5bea3b492b9a198092d7c52df51eb4a0865","259aa02b58eebacdc00fb938f402c7228b2f540809a3e4b6cd302defcee4b92a","29accd4fc02fc3278fe31791bb6d42612ca54b1f1541116f78a404941e79cf7b","027a206c5d144c662f6fb51da30a7e50f7dcb7fabc4dc174034c0f0f0858c32d","53869260ad4b0471e55efd292ed86dd522b99f5f1da0a0430709accda8781634","539c78bde44b8b6a595df8e4ddd3a9c5a4952a66aeaaca822515b312ac7ae3d5","1fe8f0c13354c3939901e103ab22444de77b9e4aa6337e6fdaf2e4c3276fff45","2b86ecc37fe743c9cdd7b0f602dde4e82df61e65f8b967ed6d76d4eea337d81d","4030b77e9ae60454573a3719eb115cbf2011e77f3ce3cfb6e3fc5472d760cdf8","d54de56aae4ea724dd68867575ec03773571d1da9021d2a3faf1230ea7f5a833","144e4a91dc7f7037ed34641eadb23bd804d97e2003f6127d396cadd6fe036dd9","0eaa5c5acab4c493c1b6205679fd55a3040f1e64d3104f658c1e34f3de0d9c02","4a1fc61a141cd286d75516879952d8de019e5e8f89ba91dda0ffb20259c7650a","e58401ac759eca62a971022e1c2d4b19c5cc142b3118c402c1de855dcb38d221","526afd4a3d0b0553efcae2d3afd994b803ad2eca6df72d5a871dbfe36909bcdf","4ad360917a549b72b951cdd935b7c692ec6393606573366a1c0af3194881246c","58d79e2ace4d50f42ecddafd1662f94ec0b8aae0f386a29358d9f25282a3789c","477de575189bc1f66bb778cf94b5f97db92e5dd55d76815649aa618e18d7f17e","8a4de9ed3e190e97a429956d8c315cf3d671770632df4b16cd1bfb64af43f9ec","91f0bef0fa97508e4aa610cba632816aea98a2372be7c603a3ec66311c523346","0724b126a8fa0aad75d3c921e2d810e6b1f6c1fd657f31db2634af19361bc9aa",{"version":"6594f3d69d853fbaed585191d664df4799d15592ce2ecf9c8d273c55d2910e97","signature":"52ccb8164274d37193599df1ad1b79633ba3c1a9cc7fcd4354a2c26d10dbf03f"},{"version":"20e2494fd64d211bc419bf884d55989172dbf27d4993db796818a5a106f2c478","signature":"692c60f7d262f95dfcf70bbb97f407df98d8b90742325155e7b5be25588d8742"},{"version":"2a5dace8fa56acbed0d010034accf2567f3c2b4e400c1cdfd811c071de7dcce7","signature":"8fb50cd0de76adbe3e24a86a68c231e2483109e140c9c318fc5d7d8a1bb93c9d"},"14f5893b90b84ec02fad9860e9d3ae7d84a8914fad3241d9c5dddf285b225fd7",{"version":"2354096323c5e2b214aab4e73fd7129f8ec4237b4130987f179ff62f107e1afb","signature":"6ecde31bf8f6a6c2fe98d9678556ebf972f5da4425d26c5487447b54a99a9d25"},{"version":"5ef8bb1958f32e1b5ec085d701da81a406b77f84c8408c6df5c2d4a09a1f29a3","signature":"3802dc06b99697fd943275133c5222c0a1d0d5d87f3e6dd6179f56a77a590107"},{"version":"3364b2a258b0c197795ad0f03e2d6e5d0dc3fcca8a7c1c567fd8e959a96d2e9e","signature":"41b01763ab076abd699e4bae23dd79aa5c693667835b49200eee01a129142393"},{"version":"87104463a40f41b4f2058565f65a2d3e1af1575163923deae0b3cea8960a22a6","signature":"0b5d8c08d76bcccfd0897aebbc17c25c33736d0b4a742707b472793b6a423ed5"},{"version":"0519ecfd18996cfda90176418d99999efa1347c379946fc0463dbda7abe0ed81","signature":"14673e051b65808f6659c9d06f8fce096c19cda62d1f85ffb329bcf9cd428791"},{"version":"2f1af9f805b2109a23cd0c1a36a436638b444b19027b9c218761548e797415a5","signature":"a5d0d79f8a9ee3573519276479bf813bf5f9f04c26807b5db6f646cc16a6d6e6"},{"version":"ffca2717b7ced8a2d5d6f03660a3263444d5120dce461f0c9a131cab2bacc773","signature":"f7e3f5379f1246bdd8de384cf58533a9e6e14a1c2921b9566c2c116f813b5a92"},{"version":"20d505f12b040513de6565891b28d746657dcfbb4bde181f1556f8a3b861fef9","signature":"535dfe1accff1dedcc7b69fe1c5dadc71d9eee7582575cadc6789d6ae242b292"},{"version":"f9450183f08ac346a98b87e79cbbd18848a28ef869acd143fd1e363bf39265f1","signature":"c050d51ab315d84223f2e76cca92b70e97b970bf674ce0eb09a9d52fe1102c52"},{"version":"83ad6cdcc76b9baa8c0b002369e1fd1cc6447d5518bb63da3a2aaf02c015237f","signature":"f9616614db1def366e2bc93b422393b02d4134842931b49ddbc6902beb94e9c8"},{"version":"9713ececdececf937f5018ea7fa8dcb4c279d62970983c3917f31f631a5c6f54","signature":"c6faa4f876e3e4ad0b0ff9d8e92907c025f94ed767f217e9931ba1031363da86"},"85e015a0a95b81409629a30294d1bbe928219c1add01066eb6729b16e2cc2d94","f3d8c757e148ad968f0d98697987db363070abada5f503da3c06aefd9d4248c1",{"version":"70521b6ab0dcba37539e5303104f29b721bfb2940b2776da4cc818c07e1fefc1","affectsGlobalScope":true},{"version":"030e350db2525514580ed054f712ffb22d273e6bc7eddc1bb7eda1e0ba5d395e","affectsGlobalScope":true},{"version":"d153a11543fd884b596587ccd97aebbeed950b26933ee000f94009f1ab142848","affectsGlobalScope":true},"21d819c173c0cf7cc3ce57c3276e77fd9a8a01d35a06ad87158781515c9a438a",{"version":"613b21ccdf3be6329d56e6caa13b258c842edf8377be7bc9f014ed14cdcfc308","affectsGlobalScope":true},{"version":"2d1319e6b5d0efd8c5eae07eb864a00102151e8b9afddd2d45db52e9aae002c4","affectsGlobalScope":true},"4967529644e391115ca5592184d4b63980569adf60ee685f968fd59ab1557188","5929864ce17fba74232584d90cb721a89b7ad277220627cc97054ba15a98ea8f","24bd580b5743dc56402c440dc7f9a4f5d592ad7a419f25414d37a7bfe11e342b","25c8056edf4314820382a5fdb4bb7816999acdcb929c8f75e3f39473b87e85bc","c464d66b20788266e5353b48dc4aa6bc0dc4a707276df1e7152ab0c9ae21fad8","78d0d27c130d35c60b5e5566c9f1e5be77caf39804636bc1a40133919a949f21","c6fd2c5a395f2432786c9cb8deb870b9b0e8ff7e22c029954fabdd692bff6195","1d6e127068ea8e104a912e42fc0a110e2aa5a66a356a917a163e8cf9a65e4a75","5ded6427296cdf3b9542de4471d2aa8d3983671d4cac0f4bf9c637208d1ced43","6bdc71028db658243775263e93a7db2fd2abfce3ca569c3cca5aee6ed5eb186d","cadc8aced301244057c4e7e73fbcae534b0f5b12a37b150d80e5a45aa4bebcbd","385aab901643aa54e1c36f5ef3107913b10d1b5bb8cbcd933d4263b80a0d7f20","9670d44354bab9d9982eca21945686b5c24a3f893db73c0dae0fd74217a4c219","0b8a9268adaf4da35e7fa830c8981cfa22adbbe5b3f6f5ab91f6658899e657a7","11396ed8a44c02ab9798b7dca436009f866e8dae3c9c25e8c1fbc396880bf1bb","ba7bc87d01492633cb5a0e5da8a4a42a1c86270e7b3d2dea5d156828a84e4882","4893a895ea92c85345017a04ed427cbd6a1710453338df26881a6019432febdd","c21dc52e277bcfc75fac0436ccb75c204f9e1b3fa5e12729670910639f27343e","13f6f39e12b1518c6650bbb220c8985999020fe0f21d818e28f512b7771d00f9","9b5369969f6e7175740bf51223112ff209f94ba43ecd3bb09eefff9fd675624a","4fe9e626e7164748e8769bbf74b538e09607f07ed17c2f20af8d680ee49fc1da","24515859bc0b836719105bb6cc3d68255042a9f02a6022b3187948b204946bd2","ea0148f897b45a76544ae179784c95af1bd6721b8610af9ffa467a518a086a43","24c6a117721e606c9984335f71711877293a9651e44f59f3d21c1ea0856f9cc9","dd3273ead9fbde62a72949c97dbec2247ea08e0c6952e701a483d74ef92d6a17","405822be75ad3e4d162e07439bac80c6bcc6dbae1929e179cf467ec0b9ee4e2e","0db18c6e78ea846316c012478888f33c11ffadab9efd1cc8bcc12daded7a60b6","e61be3f894b41b7baa1fbd6a66893f2579bfad01d208b4ff61daef21493ef0a8","bd0532fd6556073727d28da0edfd1736417a3f9f394877b6d5ef6ad88fba1d1a","89167d696a849fce5ca508032aabfe901c0868f833a8625d5a9c6e861ef935d2","615ba88d0128ed16bf83ef8ccbb6aff05c3ee2db1cc0f89ab50a4939bfc1943f","a4d551dbf8746780194d550c88f26cf937caf8d56f102969a110cfaed4b06656","8bd86b8e8f6a6aa6c49b71e14c4ffe1211a0e97c80f08d2c8cc98838006e4b88","317e63deeb21ac07f3992f5b50cdca8338f10acd4fbb7257ebf56735bf52ab00","4732aec92b20fb28c5fe9ad99521fb59974289ed1e45aecb282616202184064f","2e85db9e6fd73cfa3d7f28e0ab6b55417ea18931423bd47b409a96e4a169e8e6","c46e079fe54c76f95c67fb89081b3e399da2c7d109e7dca8e4b58d83e332e605","bf67d53d168abc1298888693338cb82854bdb2e69ef83f8a0092093c2d562107",{"version":"81184fe8e67d78ac4e5374650f0892d547d665d77da2b2f544b5d84729c4a15d","affectsGlobalScope":true},"f52e8dacc97d71dcc96af29e49584353f9c54cb916d132e3e768d8b8129c928d","7394959e5a741b185456e1ef5d64599c36c60a323207450991e7a42e08911419","76103716ba397bbb61f9fa9c9090dca59f39f9047cb1352b2179c5d8e7f4e8d0",{"version":"53eac70430b30089a3a1959d8306b0f9cfaf0de75224b68ef25243e0b5ad1ca3","affectsGlobalScope":true},"4314c7a11517e221f7296b46547dbc4df047115b182f544d072bdccffa57fc72","115971d64632ea4742b5b115fb64ed04bcaae2c3c342f13d9ba7e3f9ee39c4e7",{"version":"c2510f124c0293ab80b1777c44d80f812b75612f297b9857406468c0f4dafe29","affectsGlobalScope":true},"a40826e8476694e90da94aa008283a7de50d1dafd37beada623863f1901cb7fb",{"version":"86956cc2eb9dd371d6fab493d326a574afedebf76eef3fa7833b8e0d9b52d6f1","affectsGlobalScope":true},"24642567d3729bcc545bacb65ee7c0db423400c7f1ef757cab25d05650064f98","e6f5a38687bebe43a4cef426b69d34373ef68be9a6b1538ec0a371e69f309354","a6bf63d17324010ca1fbf0389cab83f93389bb0b9a01dc8a346d092f65b3605f","e009777bef4b023a999b2e5b9a136ff2cde37dc3f77c744a02840f05b18be8ff","1e0d1f8b0adfa0b0330e028c7941b5a98c08b600efe7f14d2d2a00854fb2f393",{"version":"ee1ee365d88c4c6c0c0a5a5701d66ebc27ccd0bcfcfaa482c6e2e7fe7b98edf7","affectsGlobalScope":true},{"version":"875928df2f3e9a3aed4019539a15d04ff6140a06df6cd1b2feb836d22a81eaca","affectsGlobalScope":true},"e9ad08a376ac84948fcca0013d6f1d4ae4f9522e26b91f87945b97c99d7cc30b","eaf9ee1d90a35d56264f0bf39842282c58b9219e112ac7d0c1bce98c6c5da672","c15c4427ae7fd1dcd7f312a8a447ac93581b0d4664ddf151ecd07de4bf2bb9d7","5135bdd72cc05a8192bd2e92f0914d7fc43ee077d1293dc622a049b7035a0afb","4f80de3a11c0d2f1329a72e92c7416b2f7eab14f67e92cac63bb4e8d01c6edc8","6d386bc0d7f3afa1d401afc3e00ed6b09205a354a9795196caed937494a713e6",{"version":"75c3400359d59fae5aed4c4a59fcd8a9760cf451e25dc2174cb5e08b9d4803e2","affectsGlobalScope":true},"94c4187083503a74f4544503b5a30e2bd7af0032dc739b0c9a7ce87f8bddc7b9","b1b6ee0d012aeebe11d776a155d8979730440082797695fc8e2a5c326285678f","45875bcae57270aeb3ebc73a5e3fb4c7b9d91d6b045f107c1d8513c28ece71c0",{"version":"3eb62baae4df08c9173e6903d3ca45942ccec8c3659b0565684a75f3292cffbb","affectsGlobalScope":true},{"version":"a85683ef86875f4ad4c6b7301bbcc63fb379a8d80d3d3fd735ee57f48ef8a47e","affectsGlobalScope":true},"3f16a7e4deafa527ed9995a772bb380eb7d3c2c0fd4ae178c5263ed18394db2c","c6b4e0a02545304935ecbf7de7a8e056a31bb50939b5b321c9d50a405b5a0bba","fab29e6d649aa074a6b91e3bdf2bff484934a46067f6ee97a30fcd9762ae2213","8145e07aad6da5f23f2fcd8c8e4c5c13fb26ee986a79d03b0829b8fce152d8b2","e1120271ebbc9952fdc7b2dd3e145560e52e06956345e6fdf91d70ca4886464f","15c5e91b5f08be34a78e3d976179bf5b7a9cc28dc0ef1ffebffeb3c7812a2dca","a8f06c2382a30b7cb89ad2dfc48fc3b2b490f3dafcd839dadc008e4e5d57031d","553870e516f8c772b89f3820576152ebc70181d7994d96917bb943e37da7f8a7","37ba7b45141a45ce6e80e66f2a96c8a5ab1bcef0fc2d0f56bb58df96ec67e972","93452d394fdd1dc551ec62f5042366f011a00d342d36d50793b3529bfc9bd633",{"version":"745c4240220559bd340c8aeb6e3c5270a709d3565e934dc22a69c304703956bc","affectsGlobalScope":true},"2754d8221d77c7b382096651925eb476f1066b3348da4b73fe71ced7801edada",{"version":"9212c6e9d80cb45441a3614e95afd7235a55a18584c2ed32d6c1aca5a0c53d93","affectsGlobalScope":true},{"version":"bef91efa0baea5d0e0f0f27b574a8bc100ce62a6d7e70220a0d58af6acab5e89","affectsGlobalScope":true},"282fd2a1268a25345b830497b4b7bf5037a5e04f6a9c44c840cb605e19fea841","5360a27d3ebca11b224d7d3e38e3e2c63f8290cb1fcf6c3610401898f8e68bc3","66ba1b2c3e3a3644a1011cd530fb444a96b1b2dfe2f5e837a002d41a1a799e60","7e514f5b852fdbc166b539fdd1f4e9114f29911592a5eb10a94bb3a13ccac3c4",{"version":"7d6ff413e198d25639f9f01f16673e7df4e4bd2875a42455afd4ecc02ef156da","affectsGlobalScope":true},{"version":"6bd91a2a356600dee28eb0438082d0799a18a974a6537c4410a796bab749813c","affectsGlobalScope":true},"a5c09990a37469b0311a92ce8feeb8682e83918723aedbd445bd7a0f510eaaa3","ae25afbbf1ed5df63a177d67b9048bf7481067f1b8dc9c39212e59db94fc9fc6","ac5ed35e649cdd8143131964336ab9076937fa91802ec760b3ea63b59175c10a",{"version":"52a8e7e8a1454b6d1b5ad428efae3870ffc56f2c02d923467f2940c454aa9aec","affectsGlobalScope":true},"78dc0513cc4f1642906b74dda42146bcbd9df7401717d6e89ea6d72d12ecb539","171fd8807643c46a9d17e843959abdf10480d57d60d38d061fb44a4c8d4a8cc4"],"root":[[60,71],[73,81],83,[320,322],[324,334]],"options":{"composite":true,"declaration":true,"declarationMap":true,"esModuleInterop":true,"module":1,"noImplicitAny":true,"outDir":"./","rootDir":"..","sourceMap":true,"strict":true,"target":2},"fileIdsList":[[342,385],[135,342,385],[130,342,385],[130,131,132,133,134,136,137,138,342,385],[96,97,136,342,385],[209,316,342,385],[96,97,115,119,209,315,316,317,342,385],[96,97,115,209,237,315,342,385],[318,342,385],[278,279,280,342,385],[281,342,385],[281,284,342,385,397],[287,342,385],[274,275,276,277,282,284,285,286,289,290,291,292,293,294,295,296,297,298,299,300,342,385],[287,288,289,342,385],[281,342,385,397],[126,342,385],[96,97,115,342,385],[117,342,385],[96,97,115,119,342,385],[96,97,342,385],[96,97,117,122,342,385],[116,117,118,120,121,122,123,124,125,342,385],[96,97,115,116,117,119,120,121,122,123,342,385],[96,97,115,116,119,120,121,124,342,385],[95,342,385],[89,342,385],[87,88,342,385],[84,85,86,87,88,89,90,91,92,93,94,342,385],[152,342,385],[141,142,143,144,145,146,147,148,149,150,151,342,385],[194,342,385],[96,97,119,188,189,190,342,385],[96,97,115,119,125,127,180,188,191,342,385],[189,190,191,192,193,342,385],[96,97,192,342,385],[114,342,385],[97,342,385],[112,342,385],[97,98,110,111,113,342,385],[99,342,385],[100,342,385],[99,100,101,102,103,104,105,106,107,108,109,342,385],[100,101,104,106,342,385],[103,342,385],[96,97,98,110,342,385],[96,97,115,119,225,226,342,385],[225,227,229,342,385],[115,119,212,230,342,385],[228,342,385],[230,231,342,385],[119,230,342,385],[119,342,385],[115,119,342,385],[119,168,342,385],[210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,232,233,235,342,385],[96,97,119,342,385],[96,97,119,168,342,385],[168,342,385],[119,212,342,385],[234,342,385],[236,342,385],[96,97,127,128,202,204,342,385],[204,205,206,207,342,385],[208,342,385],[128,204,342,385],[115,128,204,342,385],[96,97,188,202,203,342,385],[259,260,342,385],[259,342,385],[96,97,168,173,175,176,342,385],[173,342,385],[173,177,178,342,385],[174,342,385],[179,342,385],[173,174,342,385],[169,171,342,385],[169,171,172,342,385],[169,342,385],[170,342,385],[253,261,342,385],[273,302,303,342,385],[253,302,342,385],[253,301,342,385],[242,342,385],[243,342,385],[242,243,244,245,246,247,248,249,250,251,252,342,385],[243,244,247,249,342,385],[246,342,385],[239,342,385],[96,97,115,119,239,311,312,342,385],[238,239,240,241,312,313,342,385],[314,342,385],[187,342,385],[115,342,385],[96,97,115,119,125,127,128,180,181,182,183,184,185,342,385],[186,342,385],[181,342,385],[140,181,182,183,184,185,186,342,385],[96,97,115,119,168,183,342,385],[253,342,385],[253,261,262,263,342,385],[261,262,263,266,342,385],[254,255,256,257,258,262,263,264,265,266,267,268,269,270,271,272,305,306,307,308,309,310,342,385],[59,82,342,385],[253,261,304,342,385],[253,261,262,342,385],[262,342,385],[253,262,263,342,385],[262,263,342,385],[201,342,385],[129,196,197,198,199,200,342,385],[96,97,125,342,385],[96,97,119,125,128,129,139,168,188,195,196,342,385],[125,129,342,385],[96,97,119,188,195,342,385],[96,97,129,188,342,385],[167,342,385],[96,97,153,154,155,342,385],[96,97,119,125,154,157,158,342,385],[96,97,125,154,157,342,385],[96,97,139,342,385],[139,154,342,385],[96,97,154,342,385],[154,155,156,157,158,159,160,161,162,163,164,165,166,342,385],[154,342,385],[342,382,385],[342,384,385],[342,385,390,420],[342,385,386,391,397,398,405,417,428],[342,385,386,387,397,405],[337,338,339,342,385],[342,385,388,429],[342,385,389,390,398,406],[342,385,390,417,425],[342,385,391,393,397,405],[342,384,385,392],[342,385,393,394],[342,385,397],[342,385,395,397],[342,384,385,397],[342,385,397,398,399,417,428],[342,385,397,398,399,412,417,420],[342,380,385,433],[342,380,385,393,397,400,405,417,428],[342,385,397,398,400,401,405,417,425,428],[342,385,400,402,417,425,428],[342,385,397,403],[342,385,404,428,433],[342,385,393,397,405,417],[342,385,406],[342,385,407],[342,384,385,408],[342,382,383,384,385,386,387,388,389,390,391,392,393,394,395,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434],[342,385,410],[342,385,411],[342,385,397,412,413],[342,385,412,414,429,431],[342,385,397,417,418,419,420],[342,385,417,419],[342,385,417,418],[342,385,420],[342,385,421],[342,382,385,417],[342,385,397,423,424],[342,385,423,424],[342,385,390,405,417,425],[342,385,426],[385],[340,341,342,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434],[342,385,405,427],[342,385,400,411,428],[342,385,390,429],[342,385,417,430],[342,385,404,431],[342,385,432],[342,385,390,397,399,408,417,428,431,433],[342,385,417,434],[342,352,356,385,428],[342,352,385,417,428],[342,347,385],[342,349,352,385,425,428],[342,385,405,425],[342,385,435],[342,347,385,435],[342,349,352,385,405,428],[342,344,345,348,351,385,397,417,428],[342,352,359,385],[342,344,350,385],[342,352,373,374,385],[342,348,352,385,420,428,435],[342,373,385,435],[342,346,347,385,435],[342,352,385],[342,346,347,348,349,350,351,352,353,354,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,374,375,376,377,378,379,385],[342,352,367,385],[342,352,359,360,385],[342,350,352,360,361,385],[342,351,385],[342,344,347,352,385],[342,352,356,360,361,385],[342,356,385],[342,350,352,355,385,428],[342,344,349,352,359,385],[342,385,417],[342,347,352,373,385,433,435],[60,61,62,63,342,385],[59,60,82,342,385],[66,342,385],[62,342,385],[72,342,385],[75,342,385],[60,342,385],[65,342,385],[59,60,61,75,82,342,385],[59,60,61,81,82,342,385],[60,66,81,83,319,320,342,385],[60,78,342,385],[322,324,342,385],[59,60,61,82,342,385],[66,322,323,342,385],[60,61,62,63,73,342,385],[59,60,61,76,82,342,385],[59,62,82,342,385]],"referencedMap":[[133,1],[130,1],[134,1],[136,2],[131,3],[139,4],[132,1],[137,1],[138,5],[317,6],[318,7],[316,8],[319,9],[278,1],[279,1],[281,10],[280,1],[274,1],[275,1],[287,1],[276,1],[277,1],[282,11],[285,12],[288,13],[286,1],[301,14],[290,15],[291,1],[292,11],[289,1],[293,1],[294,1],[295,1],[296,1],[297,1],[298,1],[299,1],[284,16],[300,1],[128,17],[116,18],[118,19],[120,20],[121,21],[123,22],[117,1],[126,23],[124,24],[127,17],[122,25],[125,26],[93,1],[84,1],[87,1],[85,26],[86,1],[90,27],[88,1],[89,28],[95,29],[91,1],[94,1],[92,1],[96,26],[153,30],[141,1],[142,1],[143,1],[144,1],[152,31],[145,1],[151,1],[146,1],[147,1],[148,1],[150,1],[149,1],[195,32],[191,33],[189,34],[194,35],[192,1],[193,36],[190,1],[119,37],[98,38],[113,39],[112,1],[114,40],[100,41],[101,1],[102,42],[103,1],[110,43],[104,1],[105,1],[107,44],[108,45],[109,1],[106,41],[99,1],[115,37],[111,46],[97,21],[225,1],[227,47],[230,48],[228,49],[229,50],[232,51],[231,52],[211,53],[210,53],[226,20],[212,54],[213,55],[236,56],[214,57],[215,53],[216,58],[217,59],[218,58],[219,60],[234,53],[235,61],[237,62],[220,1],[221,53],[222,59],[233,53],[223,54],[224,54],[205,63],[208,64],[209,65],[206,66],[207,67],[204,68],[261,69],[259,1],[260,70],[177,71],[174,72],[179,73],[175,74],[180,75],[176,76],[172,77],[169,1],[173,78],[170,79],[171,80],[178,76],[273,81],[304,82],[303,83],[302,84],[243,85],[244,1],[245,86],[246,1],[253,87],[247,1],[248,1],[250,88],[251,89],[252,1],[249,85],[242,1],[240,90],[313,91],[241,55],[314,92],[312,1],[315,93],[238,53],[239,53],[188,94],[140,95],[186,96],[181,97],[182,98],[183,1],[187,99],[184,53],[185,100],[255,1],[254,101],[256,1],[257,1],[258,1],[264,102],[265,1],[267,103],[311,104],[268,1],[269,1],[270,105],[266,105],[271,101],[272,1],[305,106],[263,107],[262,101],[306,108],[307,109],[308,1],[309,105],[310,110],[203,111],[201,112],[202,111],[129,113],[197,114],[198,115],[196,116],[199,117],[200,1],[168,118],[156,119],[159,120],[158,121],[160,122],[161,123],[157,124],[167,125],[155,124],[162,124],[164,124],[166,126],[154,21],[163,126],[165,126],[335,1],[283,1],[135,1],[336,1],[382,127],[383,127],[384,128],[385,129],[386,130],[387,131],[337,1],[340,132],[338,1],[339,1],[388,133],[389,134],[390,135],[391,136],[392,137],[393,138],[394,138],[396,139],[395,140],[397,141],[398,142],[399,143],[381,144],[400,145],[401,146],[402,147],[403,148],[404,149],[405,150],[406,151],[407,152],[408,153],[409,154],[410,155],[411,156],[412,157],[413,157],[414,158],[415,1],[416,1],[417,159],[419,160],[418,161],[420,162],[421,163],[422,164],[423,165],[424,166],[425,167],[426,168],[342,169],[341,1],[435,170],[427,171],[428,172],[429,173],[430,174],[431,175],[432,176],[433,177],[434,178],[72,1],[82,105],[59,1],[343,1],[323,1],[57,1],[58,1],[10,1],[12,1],[11,1],[2,1],[13,1],[14,1],[15,1],[16,1],[17,1],[18,1],[19,1],[20,1],[3,1],[21,1],[4,1],[22,1],[26,1],[23,1],[24,1],[25,1],[27,1],[28,1],[29,1],[5,1],[30,1],[31,1],[32,1],[33,1],[6,1],[37,1],[34,1],[35,1],[36,1],[38,1],[7,1],[39,1],[44,1],[45,1],[40,1],[41,1],[42,1],[43,1],[8,1],[49,1],[46,1],[47,1],[48,1],[50,1],[9,1],[51,1],[52,1],[53,1],[56,1],[54,1],[55,1],[1,1],[359,179],[369,180],[358,179],[379,181],[350,182],[349,183],[378,184],[372,185],[377,186],[352,187],[366,188],[351,189],[375,190],[347,191],[346,184],[376,192],[348,193],[353,194],[354,1],[357,194],[344,1],[380,195],[370,196],[361,197],[362,198],[364,199],[360,200],[363,201],[373,184],[355,202],[356,203],[365,204],[345,205],[368,196],[367,194],[371,1],[374,206],[64,207],[61,208],[67,209],[68,1],[70,207],[69,210],[71,1],[73,211],[74,1],[75,1],[76,212],[77,212],[78,213],[66,214],[79,215],[80,1],[81,1],[83,216],[321,217],[60,1],[320,218],[322,1],[325,219],[62,1],[65,1],[326,220],[324,221],[328,222],[327,210],[329,223],[330,220],[63,224],[331,1],[332,1],[333,1],[334,1]],"latestChangedDtsFile":"./src/ThemeApi.d.ts"},"version":"5.5.4"}
****************************************

****************************************
CommonTs\src\ActivityRepositoryApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

import { Api } from './Api';
import { IStorable, IStorableMultiQuerySpec} from "./IStorable";
import { IEnvironment } from "./IEnvironment";
import { StorableRepostoryApi, IStorableRepostoryApiWrapper } from './StorableRepositoryApi';

/**
 * Represents an API for activities.
 * 
 * @param {EEnvironment} environment_ - The environment to use for saving activities.
 * @param {string} sessionKey_ - The session key for authentication.
 * 
 * @method save - Saves a record to the Activity API.
 * @method remove - removes a record
 * @method load - load an Activity given the key 
 * @method recent - return a list of recent activities
 */
export class ActivityRepostoryApi extends Api implements IStorableRepostoryApiWrapper {

   private storableApi: StorableRepostoryApi;
   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);

      this.storableApi = new StorableRepostoryApi();
   }  

   /**
    * Asynchronously loads a record from the activity repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
    */
   async load (recordId: string) : Promise<IStorable | undefined> {

      let apiUrl = this.environment.getActivityApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.load (recordId, apiUrl);  
   }

   /**
    * Asynchronously finds a record from the activity repository API.
    * 
    * @param functionalSearchKey - The ID of the record to be removed.
    * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
    */
   async find (functionalSearchKey: string) : Promise<IStorable | undefined> {

      let apiUrl = this.environment.findActivityApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.load (functionalSearchKey, apiUrl);  
   }

   /**
    * Asynchronously saves a record to the activity repository API.
    * 
    * @param record - The record to be saved, must implement the IStorable interface.
    * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
    */
   async save (record: IStorable) : Promise<boolean> {

      let apiUrl = this.environment.saveActivityApi() + "?session=" + this.sessionKey.toString();
      
      return this.storableApi.save (record, apiUrl);
   }

   /**
    * Asynchronously removes a record from the activity repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @returns A Promise that resolves to true if the record is successfully removed, false otherwise.
    */
   async remove (recordId: string) : Promise<boolean> {

      let apiUrl = this.environment.removeActivityApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.remove (recordId, apiUrl);  
   }

   /**
    * Asynchronously retrieves recent records from the activity repository API based on the provided query specifications.
    * 
    * @param querySpec - The query specifications including the limit and storeClassName to filter the records.
    * @returns A Promise that resolves to an array of IStorable objects representing the recent records, or an empty array if an error occurs.
    */
   async recent (querySpec: IStorableMultiQuerySpec) : Promise<Array<IStorable>> {

      let apiUrl = this.environment.getActivitiesApi() + "?session=" + this.sessionKey.toString();

      return this.storableApi.recent (querySpec, apiUrl);  
   }
}
****************************************

****************************************
CommonTs\src\Api.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
import axios from 'axios';

import { IEnvironment } from "./IEnvironment";

/**
 * Represents an API class that interacts with the specified environment using the provided session key. 
 * This is a super class of each actual (useful) API. In itself it isn't very useful, it just holds common data. 
 * @param {IEnvironment} environemnt_ - The environment interface to interact with.
 * @param {string} sessionKey_ - The session key for authentication.
 */
export class Api {
   private _environment: IEnvironment;
   private _sessionKey: string;

   public constructor(environemnt_: IEnvironment, sessionKey_: string) {
      this._environment = environemnt_;
      this._sessionKey = sessionKey_;
   }  

   public get environment() : IEnvironment  {
      return this._environment;
   }
   public get sessionKey() : string  {
      return this._sessionKey;
   }   
}
****************************************

****************************************
CommonTs\src\Asserts.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

import { AssertionFailedError} from './Errors';

export const throwIfUndefined: <T, >(x: T | undefined) => asserts x is T = x => {
   if (typeof x === "undefined") throw new AssertionFailedError ("Object is undefined.");
}

export const throwIfNull: <T, >(x: T | null) => asserts x is T = x => {
   if (x === null) throw new AssertionFailedError ("Object is null.");
}
****************************************

****************************************
CommonTs\src\ChunkApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Chunk API

/**
 * Interface for chunk reqiest API.
 * @property {string} text - The text content of the chunk.
 * @property {number | undefined} chunkSize - The size of the chunk in tokens, if specified.
 * @property {number | undefined} overlapWords - The size of the overlap between chunks, in words (=2 * tokens) if specified.
 */
export interface IChunkRequest{

   text: string;
   chunkSize?: number | undefined;
   overlapWords?: number | undefined;
}

/**
 * Return type of chunk reqiest API.
 * @property {Array<string>} chunks - Array of text chunks
 */
export interface IChunkResponse {

   chunks: Array<string>;
}
****************************************

****************************************
CommonTs\src\ChunkApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from ChunkApi.Types.yaml with typeconv
  version: '1'
  x-id: ChunkApi.Types.yaml
  x-comment: >-
    Generated from src\ChunkApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IChunkRequest:
      properties:
        text:
          title: IChunkRequest.text
          type: string
        chunkSize:
          title: IChunkRequest.chunkSize
          type: number
        overlapWords:
          title: IChunkRequest.overlapWords
          type: number
      required:
        - text
      additionalProperties: false
      title: IChunkRequest
      description: >-
        Interface for chunk reqiest API.

        @property {string} text - The text content of the chunk.

        @property {number | undefined} chunkSize - The size of the chunk in
        tokens, if specified.

        @property {number | undefined} overlapWords - The size of the overlap
        between chunks, in words (=2 * tokens) if specified.
      type: object
    IChunkResponse:
      properties:
        chunks:
          items:
            type: string
          title: IChunkResponse.chunks
          type: array
      required:
        - chunks
      additionalProperties: false
      title: IChunkResponse
      description: |-
        Return type of chunk reqiest API.
        @property {Array<string>} chunks - Array of text chunks
      type: object
****************************************

****************************************
CommonTs\src\ChunkRepositoryApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IStorable, IStorableMultiQuerySpec} from "./IStorable";
import { StorableRepostoryApi, IStorableRepostoryApiWrapper} from './StorableRepositoryApi';

/**
 * Represents an API for the Chunk repository
 * 
 * @param {EEnvironment} environment_ - The environment to use for saving Chunks.
 * @param {string} sessionKey_ - The session key for authentication.
 * 
 * @method save - Saves a record to the Chunk API.
 * @method remove - removes a record
 * @method load - load an Chunk given the key 
 */
export class ChunkRepostoryApi extends Api implements IStorableRepostoryApiWrapper {
   
   private storableApi: StorableRepostoryApi;

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);

      this.storableApi = new StorableRepostoryApi();      
   }  

   /**
    * Asynchronously loads a record from the Chunk repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
    */
    async load (recordId: string) : Promise<IStorable | undefined> {

         let apiUrl = this.environment.getChunkApi() + "?session=" + this.sessionKey.toString();
         return this.storableApi.load (recordId, apiUrl);  
      }

   /**
    * Asynchronously finds a record from the Chunk repository API.
    * 
    * @param functionalSearchKey - The ID of the record to be removed.
    * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
    */
    async find (functionalSearchKey: string) : Promise<IStorable | undefined> {

      let apiUrl = this.environment.findChunkApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.find (functionalSearchKey, apiUrl);  
   }

   /**
    * Asynchronously saves a record to the chunk repository API.
    * 
    * @param record - The record to be saved, must implement the IStoredChunk interface.
    * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
    */
   async save (record: IStorable) : Promise<boolean> {

      let apiUrl = this.environment.saveChunkApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.save (record, apiUrl);             
   }  

   /**
    * Asynchronously removes a record from the Chunk repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @returns A Promise that resolves to true if the record is successfully removed, false otherwise.
    */
   async remove (recordId: string) : Promise<boolean> {

      let apiUrl = this.environment.removeChunkApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.remove (recordId, apiUrl);  
   }

   /**
    * Asynchronously retrieves recent records from the activity repository API based on the provided query specifications.
    * 
    * @param querySpec - The query specifications including the limit and storeClassName to filter the records.
    * @returns A Promise that resolves to an array of IStorable objects representing the recent records, or an empty array if an error occurs.
    */
   async recent (querySpec: IStorableMultiQuerySpec) : Promise<Array<IStorable>> {

      let apiUrl = this.environment.getChunksApi() + "?session=" + this.sessionKey.toString();

      return this.storableApi.recent (querySpec, apiUrl);  
   }   
}
****************************************

****************************************
CommonTs\src\ChunkRepositoryApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the ChunkRepository API

import { IStorable} from "./IStorable";

/**
 * Represents an interface for storing embeddings with a model ID and an array of numbers representing the embedding.
 */
export interface IStoredEmbedding {

   modelId: string;
   embedding: Array<number>;
};

/**
 * Defines the structure of a stored text rendering object.
 */
export interface IStoredTextRendering {

   modelId: string;
   text: string;
};

/**
 * Interface representing a chunk of data.
 * 
 * Core data for a chunk:
 * - parentChunkId: Primary key to parent document
 * - originalText: Original text; 0 if undefined, it has been thrown away (as maybe it can be reconstructed)
 * - url: string | undefined;                 // url to external resource, can be null  
 * - storedEmbedding: Embedding of the original text
 * - storedSummary: Summary of the original text - generated with application-specific prompt 
 * - storedTitle: A generated of the original text - generated with application-specific prompt
 * - related: Array of IDs to related chunks
 */
export interface IStoredChunk extends IStorable {

   parentChunkId: string | undefined;       // primary key to parent document
   originalText: string | undefined;        // original text - if undefined, it has been thrown way (as maybe it can be reconstructed)
   url: string | undefined;                 // url to external resource, can be null  
   storedEmbedding: IStoredEmbedding | undefined;   // Embedding of the original text
   storedSummary: IStoredTextRendering | undefined; // Summary of the original text - generated with application specific prompt
   storedTitle: IStoredTextRendering | undefined;   // Title for the original text - generated with application specific prompt   
   relatedChunks: Array <string> | undefined;       // An optional array of related chunks - often the full set that was pulled from a parent document
}
****************************************

****************************************
CommonTs\src\ChunkRepositoryApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from ChunkRepositoryApi.Types.yaml with typeconv
  version: '1'
  x-id: ChunkRepositoryApi.Types.yaml
  x-comment: >-
    Generated from src\ChunkRepositoryApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IStoredEmbedding:
      properties:
        modelId:
          title: IStoredEmbedding.modelId
          type: string
        embedding:
          items:
            type: number
          title: IStoredEmbedding.embedding
          type: array
      required:
        - modelId
        - embedding
      additionalProperties: false
      title: IStoredEmbedding
      description: >-
        Represents an interface for storing embeddings with a model ID and an
        array of numbers representing the embedding.
      type: object
    IStoredTextRendering:
      properties:
        modelId:
          title: IStoredTextRendering.modelId
          type: string
        text:
          title: IStoredTextRendering.text
          type: string
      required:
        - modelId
        - text
      additionalProperties: false
      title: IStoredTextRendering
      description: Defines the structure of a stored text rendering object.
      type: object
    IStoredChunk:
      properties:
        parentChunkId:
          title: IStoredChunk.parentChunkId
          type: string
        originalText:
          title: IStoredChunk.originalText
          type: string
        url:
          title: IStoredChunk.url
          type: string
        storedEmbedding:
          $ref: '#/components/schemas/IStoredEmbedding'
          title: IStoredChunk.storedEmbedding
        storedSummary:
          $ref: '#/components/schemas/IStoredTextRendering'
          title: IStoredChunk.storedSummary
        storedTitle:
          $ref: '#/components/schemas/IStoredTextRendering'
          title: IStoredChunk.storedTitle
        relatedChunks:
          items:
            type: string
          title: IStoredChunk.relatedChunks
          type: array
      required:
        - parentChunkId
        - originalText
        - url
        - storedEmbedding
        - storedSummary
        - storedTitle
        - relatedChunks
      additionalProperties: false
      title: IStoredChunk
      description: "Interface representing a chunk of data.\r\n\r\nCore data for a chunk:\r\n- parentChunkId: Primary key to parent document\r\n- originalText: Original text; 0 if undefined, it has been thrown away (as maybe it can be reconstructed)\r\n- url: string | undefined;                 // url to external resource, can be null  \r\n- storedEmbedding: Embedding of the original text\r\n- storedSummary: Summary of the original text - generated with application-specific prompt \r\n- storedTitle: A generated of the original text - generated with application-specific prompt\r\n- related: Array of IDs to related chunks"
      type: object
****************************************

****************************************
CommonTs\src\ClassifyApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Chunk API

/**
 * Represents a classification request object with text and classifications.
 */
export interface IClassifyRequest{

   text: string;
   classifications: Array<string>;
}

/**
 * Interface for the classification response object.
 */
export interface IClassifyResponse {

   classification: string;
}
****************************************

****************************************
CommonTs\src\ClassifyApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from ClassifyApi.Types.yaml with typeconv
  version: '1'
  x-id: ClassifyApi.Types.yaml
  x-comment: >-
    Generated from src\ClassifyApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IClassifyRequest:
      properties:
        text:
          title: IClassifyRequest.text
          type: string
        classifications:
          items:
            type: string
          title: IClassifyRequest.classifications
          type: array
      required:
        - text
        - classifications
      additionalProperties: false
      title: IClassifyRequest
      description: >-
        Represents a classification request object with text and
        classifications.
      type: object
    IClassifyResponse:
      properties:
        classification:
          title: IClassifyResponse.classification
          type: string
      required:
        - classification
      additionalProperties: false
      title: IClassifyResponse
      description: Interface for the classification response object.
      type: object
****************************************

****************************************
CommonTs\src\Compress.ts
****************************************
import * as pako from 'pako';


/**
 * Compresses a string using deflate algorithm
 * @param input The string to compress
 * @returns Base64 encoded compressed string
 */
export function compressString(input: string): string {
   // Convert string to Uint8Array
   const data = new TextEncoder().encode(input);
   // Compress the data
   const compressed = pako.deflate(data);

   // Universal base64 encoding
   if (typeof window === 'undefined') {
      // Node.js environment
      return Buffer.from(compressed).toString('base64');
   } else {
      // Browser environment
      return btoa(String.fromCharCode.apply(null, Array.from(compressed)));
   }
}

/**
 * Decompresses a string that was compressed using compressString
 * @param input Base64 encoded compressed string
 * @returns Original decompressed string
 */
export function decompressString(input: string): string {
   try {
      // Universal base64 decoding
      let compressedData: Uint8Array;
      if (typeof window === 'undefined') {
         // Node.js environment
         compressedData = Buffer.from(input, 'base64');
      } else {
         // Browser environment
         compressedData = new Uint8Array(
            atob(input).split('').map(char => char.charCodeAt(0))
         );
      }

      // Decompress the data
      const decompressed = pako.inflate(compressedData);
      // Convert back to string
      return new TextDecoder().decode(decompressed);
   } catch (error) {
      throw new Error('Failed to decompress string: Invalid input');
   }
}
****************************************

****************************************
CommonTs\src\EmbedApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Embed API

/**
 * Interface for the embedding request object.
 */
export interface IEmbedRequest{

   text: string;
}

/**
 * Interface for the embedding response object.
 */
export interface IEmbedResponse {

   embedding: Array<number>;
}
****************************************

****************************************
CommonTs\src\EmbedApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from EmbedApi.Types.yaml with typeconv
  version: '1'
  x-id: EmbedApi.Types.yaml
  x-comment: >-
    Generated from src\EmbedApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IEmbedRequest:
      properties:
        text:
          title: IEmbedRequest.text
          type: string
      required:
        - text
      additionalProperties: false
      title: IEmbedRequest
      description: Interface for the embedding request object.
      type: object
    IEmbedResponse:
      properties:
        embedding:
          items:
            type: number
          title: IEmbedResponse.embedding
          type: array
      required:
        - embedding
      additionalProperties: false
      title: IEmbedResponse
      description: Interface for the embedding response object.
      type: object
****************************************

****************************************
CommonTs\src\EnrichedChunk.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Chunk API

// For now there is only one sort of chunk repository. In future there may be new ones so we have an ID to distinguish them. 
export enum EChunkRepository {

   kBoxer = "Boxer"
};

// Default is we only consider >= 50% relevant to present to the user (GPT4 seems to generate low scores ...)
export const kDefaultSimilarityThreshold = 0.5;

/**
 * Represents a Chunk enriched with specific properties.
 * This is a summary class that can be passed between client & server. 
 * @property {string} url - The URL associated with the chunk.
 * @property {string} text - The textual content of the chunk.
 * @property {string} summary - The summary content of the chunk.
 */
export interface IEnrichedChunkSummary {

   url: string;
   text: string;
   summary: string;
}

/**
 * Represents a Chunk enriched with specific properties.
  * This is a server side class only - its for storage. 
 * @property {string} id - The unique identifier of the chunk.
 * @property {Array<number>} embedding - An array of numbers representing the embedding of the chunk.
 */
export interface IEnrichedChunk extends IEnrichedChunkSummary {

   id: string;
   embedding: number[];
}

/**
 * Represents a relevant chunk with its associated relevance score.
 */
export interface IRelevantEnrichedChunk {

   chunk: IEnrichedChunkSummary;
   relevance: number;
}

/**
 * Defines the structure of a chunk query specification object.
 * 
 * @property {EChunkRepository} repositoryId - The ID of the repository to query.
 * @property {number} maxCount - The maximum number of results to retrieve.
 * @property {number} similarityThreshold - The threshold for similarity comparison.
 */
export interface IChunkQuerySpec {

   repositoryId: EChunkRepository;
   maxCount: number;
   similarityThreshold: number;
}

/**
 * Extends the IChunkQuerySpec interface to include a 'url' property of type string.
 */
export interface IChunkQueryRelevantToUrlSpec extends IChunkQuerySpec {

   url: string;
}

/**
 * Extends the IChunkQuerySpec interface to include a 'summary' property of type string.
 */
export interface IChunkQueryRelevantToSummarySpec extends IChunkQuerySpec {

   summary: string;
}
****************************************

****************************************
CommonTs\src\EnrichedQuery.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Query API

import { EChunkRepository, IRelevantEnrichedChunk} from "./EnrichedChunk";


/**
 * Defines the structure of a conversation element.
 */
export enum EConversationRole {

   kSystem = "system",
   kAssistant = "assistant",
   kUser = "user"
};

/**
 * Enum representing standard prompts for an AI assistant helping an application developer understand generative AI.
 * Includes prompts for initial questions, enrichment, follow-up questions, and generating questions.
 * Each prompt provides specific instructions and limitations for the AI assistant's responses.
 */
export enum EStandardPrompts {

   kOpenAiPersonaPrompt = "You are an AI assistant helping an application developer understand generative AI. You explain complex concepts in simple language, using Python examples if it helps. You limit replies to 50 words or less. If you don't know the answer, say 'I don't know'. If the question is not related to building AI applications, Python, or Large Language Models (LLMs),, say 'That doesn't seem to be about AI'.",
   kEnrichmentPrompt = "You will be provided with a question about building applications that use generative AI technology. Write a 50 word summary of an article that would be a great answer to the question. Enrich the summary with additional topics that the question asker might want to understand. Write the summary in the present tense, as though the article exists. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'.\n",
   kFollowUpPrompt = "You will be provided with a summary of an article about building applications that use generative AI technology. Write a question of no more than 10 words that a reader might ask as a follow up to reading the article.",
   kFollowUpPrefix = "Article summary: ",
   kGenerateAQuestionPrompt = "You are an AI assistant helping an application developer understand generative AI. Based on the dialog presented as context, generate a 10 word question that is relevant to the subjects being discussed.\n"   
};


/**
 * Defines the structure of a conversation element.
 */
export interface IConversationElement {
   role: EConversationRole,
   content: string
}

/**
 * Defines the structure of an enriched query object.
 * Contains information about the repository, persona prompt, question prompt,
 * enrichment document prompt, and conversation history.
 */
export interface IEnrichedQuery {

   repositoryId : EChunkRepository;
   personaPrompt: string;
   enrichmentDocumentPrompt: string;
   similarityThreshold: number;
   maxCount: number;
   history: Array<IConversationElement>;
   question: string;
}

/**
 * Defines the structure of an enriched response object.
 * Contains an answer field of type string and a chunks field as an array of Relevant Enriched Chunk objects.
 */
export interface IEnrichedResponse {

   answer: string;
   chunks: Array<IRelevantEnrichedChunk>;
}

/**
 * Interface for generating questions query.
 * Contains persona prompt, question generation prompt, and summary fields.
 */
export interface IGenerateQuestionQuery {

   personaPrompt: string;
   questionGenerationPrompt: string;
   summary: string;
}

/**
 * Defines the structure of a response object for question generation.
 * Contains a property 'question' of type string representing the generated question.
 */
export interface IQuestionGenerationResponse {

   question: string;
}
****************************************

****************************************
CommonTs\src\EnumerateModelsApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the EnumerateModels API

import {EChunkRepository} from './EnrichedChunk';

/**
 * Interface for the EnumerateModels request object.
 */
export interface IEnumerateModelsRequest{

}

/**
 * Interface for the EnumerateModels response object.
 */
export interface IEnumerateModelsResponse {

   defaultId: string;
   defaultEmbeddingId: string;   
   largeId: string;
   largeEmbeddingId: string;
   smallId: string;
   smallEmbeddingId: string;   
}

/**
 * Interface for the EnumerateRepositories request object.
 */
export interface IEnumerateRepositoriesRequest{

}

/**
 * Interface for the EnumerateModels response object.
 */
export interface IEnumerateReposotoriesResponse {

   repositoryIds: Array<EChunkRepository>
}
****************************************

****************************************
CommonTs\src\EnumerateModelsApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from EnumerateModelsApi.Types.yaml with typeconv
  version: '1'
  x-id: EnumerateModelsApi.Types.yaml
  x-comment: >-
    Generated from src\EnumerateModelsApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IEnumerateModelsRequest:
      additionalProperties: false
      title: IEnumerateModelsRequest
      description: Interface for the EnumerateModels request object.
      type: object
    IEnumerateModelsResponse:
      properties:
        defaultId:
          title: IEnumerateModelsResponse.defaultId
          type: string
        defaultEmbeddingId:
          title: IEnumerateModelsResponse.defaultEmbeddingId
          type: string
        largeId:
          title: IEnumerateModelsResponse.largeId
          type: string
        largeEmbeddingId:
          title: IEnumerateModelsResponse.largeEmbeddingId
          type: string
        smallId:
          title: IEnumerateModelsResponse.smallId
          type: string
        smallEmbeddingId:
          title: IEnumerateModelsResponse.smallEmbeddingId
          type: string
      required:
        - defaultId
        - defaultEmbeddingId
        - largeId
        - largeEmbeddingId
        - smallId
        - smallEmbeddingId
      additionalProperties: false
      title: IEnumerateModelsResponse
      description: Interface for the EnumerateModels response object.
      type: object
    IEnumerateRepositoriesRequest:
      additionalProperties: false
      title: IEnumerateRepositoriesRequest
      description: Interface for the EnumerateRepositories request object.
      type: object
    IEnumerateReposotoriesResponse:
      properties:
        repositoryIds:
          items: {}
          title: IEnumerateReposotoriesResponse.repositoryIds
          type: array
      required:
        - repositoryIds
      additionalProperties: false
      title: IEnumerateReposotoriesResponse
      description: Interface for the EnumerateModels response object.
      type: object
****************************************

****************************************
CommonTs\src\Environment.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
import {EEnvironment, IEnvironment} from './IEnvironment';

/**
 * Class representing the Development Environment with methods to retrieve various API endpoints.
 * @class DevelopmentEnvironment
 */
export class DevelopmentEnvironment implements IEnvironment {

   name: string = EEnvironment.kLocal;

   checkSessionApi () : string {
      return "http://localhost:7071/api/CheckSession"; 
   }
   summariseApi () : string {
      return "http://localhost:7071/api/Summarize"; 

   }
   findThemeApi(): string {
      return "http://localhost:7071/api/FindTheme";
   }
   classifyApi () : string {
      return "http://localhost:7071/api/Classify"; 
   }
   chunkApi () : string {
      return "http://localhost:7071/api/Chunk"; 
   }
   embedApi () : string {
      return "http://localhost:7071/api/Embed"; 
   }
   suppressSummariseFail(): string {
      return "http://localhost:7071/api/SuppressSummariseFail";
   }
   saveActivityApi(): string {
      return "http://localhost:7071/api/SaveActivity"
   }
   removeActivityApi(): string {
      return "http://localhost:7071/api/RemoveActivity"
   }   
   getActivitiesApi(): string {
      return "http://localhost:7071/api/GetActivities"      
   }   
   getActivityApi(): string {
      return "http://localhost:7071/api/GetActivity"      
   }  
   findActivityApi(): string {
      return "http://localhost:7071/api/FindActivity"      
   }     
   loginWithLinkedInApi(): string {
      return "http://localhost:7071/api/LoginWithLinkedIn"; 
   }
   authFromLinkedInApi(): string {
      return "http://localhost:7071/api/ProcessAuthFromLinkedIn"; 
   }   
   boxerHome(): string {
      return "http://localhost:1337/aibot.html";
   }
   findRelevantEnrichedChunksFromUrl (): string {
      return "http://localhost:7071/api/FindRelevantEnrichedChunksFromUrl";
   }
   findRelevantEnrichedChunksFromSummary(): string{
      return "http://localhost:7071/api/FindRelevantEnrichedChunksFromSummary";
   }
   findEnrichedChunkFromUrl(): string {
      return "http://localhost:7071/api/FindEnrichedChunkFromUrl";      
   }
   queryModelWithEnrichment(): string {
      return "http://localhost:7071/api/QueryModelWithEnrichment";        
   }
   generateQuestion(): string{
      return "http://localhost:7071/api/GenerateQuestion";       
   }      
   generateFluidTokenApi(): string {
      return "http://localhost:7071/api/GenerateFluidToken";        
   } 
   fluidApi(): string {
      return  "http://localhost:7070";
   }
   fluidTenantId(): string {
      return "b9576484-5c2e-4613-bfdf-039948cdd521";
   }     
   studioForTeamsBoxer(): string {
      return "http://localhost:7071/api/StudioForTeams-Boxer";
   }   
   saveChunkApi() : string {
      return "http://localhost:7071/api/SaveChunk";
   }   
   removeChunkApi(): string{
      return "http://localhost:7071/api/RemoveChunk";
   }   
   getChunkApi(): string{
      return "http://localhost:7071/api/GetChunk";
   }    
   findChunkApi(): string {
      return "http://localhost:7071/api/FindChunk";
   }   
   getChunksApi(): string {
      return "http://localhost:7071/api/GetChunks";
   }         
   savePageApi() : string {
      return "http://localhost:7071/api/SavePage";
   }   
   getPageApi(): string {
      return "http://localhost:7071/api/GetPage";
   }   
   hostProtocolAndName(): string {
      return "http://localhost:7071";
   }
}

/**
 * Class representing the Staging Environment with methods to retrieve various API endpoints.
 * @class StagingEnvironment
 */
export class StagingEnvironment implements IEnvironment {

   name: string = EEnvironment.kStaging;

   checkSessionApi () : string {
      return "https://braid-api.azurewebsites.net/api/CheckSession";
   }
   summariseApi () : string {
      return "https://braid-api.azurewebsites.net/api/Summarize"; 
   }
   findThemeApi(): string {
      return "https://braid-api.azurewebsites.net/api/FindTheme";
   }
   classifyApi () : string {
      return "https://braid-api.azurewebsites.net/api/Classify"; 
   }
   chunkApi () : string {
      return "https://braid-api.azurewebsites.net/api/Chunk"; 
   }
   embedApi () : string {
      return "https://braid-api.azurewebsites.net/api/Embed"; 
   }   
   suppressSummariseFail(): string {
      return "https://braid-api.azurewebsites.net/api/SuppressSummariseFail";
   }   
   saveActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/SaveActivity";
   }  
   removeActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/RemoveActivity";
   }   
   getActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetActivity"      
   }     
   findActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/FindActivity"      
   }    
   getActivitiesApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetActivities";      
   }  
   loginWithLinkedInApi(): string {
      return "https://braid-api.azurewebsites.net/api/LoginWithLinkedIn"; 
   }
   authFromLinkedInApi(): string {
      return "https://braid-api.azurewebsites.net/api/ProcessAuthFromLinkedIn"; 
   }
   boxerHome(): string {
      return "https://braidapps.io/aibot.html";
   }   
   findRelevantEnrichedChunksFromUrl (): string {
      return "https://braid-api.azurewebsites.net/api/FindRelevantEnrichedChunksFromUrl";
   }
   findRelevantEnrichedChunksFromSummary(): string{
      return "https://braid-api.azurewebsites.net/api/FindRelevantEnrichedChunksFromSummary";
   }   
   findEnrichedChunkFromUrl(): string {
      return "https://braid-api.azurewebsites.net/api/FindEnrichedChunkFromUrl";      
   }   
   queryModelWithEnrichment(): string {
      return "https://braid-api.azurewebsites.net/api/QueryModelWithEnrichment";        
   }   
   generateQuestion(): string{
      return "https://braid-api.azurewebsites.net/api/GenerateQuestion";       
   }     
   generateFluidTokenApi(): string {
      return "https://braid-api.azurewebsites.net/api/GenerateFluidToken";        
   }    
   fluidApi(): string {
      return  "https://eu.fluidrelay.azure.com";
   }
   fluidTenantId(): string {
      return "b9576484-5c2e-4613-bfdf-039948cdd521";
   }    
   studioForTeamsBoxer(): string {
      return "https://braid-api.azurewebsites.net/api/StudioForTeams-Boxer";
   }
   saveChunkApi() : string{
      return "https://braid-api.azurewebsites.net/api/SaveChunk";
   }   
   removeChunkApi(): string{
      return "https://braid-api.azurewebsites.net/api/RemoveChunk";
   }   
   getChunkApi(): string{
      return "https://braid-api.azurewebsites.net/api/GetChunk";   
   }
   findChunkApi(): string{
      return "https://braid-api.azurewebsites.net/api/FindChunk";   
   }   
   getChunksApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetChunks";
   }         
   savePageApi() : string {
      return "https://braid-api.azurewebsites.net/api/SavePage";
   }   
   getPageApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetPage";
   }   
   hostProtocolAndName(): string {
      return "https://braid-api.azurewebsites.net";
   }
}

/**
 * Class representing a Production Environment with methods to retrieve various API endpoints.
 * @class ProductionEnvironment
 */
export class ProductionEnvironment implements IEnvironment {

   name: string = EEnvironment.kProduction;
   
   checkSessionApi () : string {
      return "https://braid-api.azurewebsites.net/api/CheckSession";
   }
   summariseApi () : string {
      return "https://braid-api.azurewebsites.net/api/Summarize"; 

   }
   findThemeApi(): string {
      return "https://braid-api.azurewebsites.net/api/FindTheme";
   }
   classifyApi () : string {
      return "https://braid-api.azurewebsites.net/api/Classify"; 
   }
   chunkApi () : string {
      return "https://braid-api.azurewebsites.net/api/Chunk"; 
   }   
   embedApi () : string {
      return "https://braid-api.azurewebsites.net/api/Embed"; 
   }    
   suppressSummariseFail(): string {
      return "https://braid-api.azurewebsites.net/api/SuppressSummariseFail";
   }      
   saveActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/SaveActivity"
   }    
   removeActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/RemoveActivity"
   }    
   getActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetActivity"      
   }     
   findActivityApi(): string {
      return "https://braid-api.azurewebsites.net/api/FindActivity"      
   }       
   getActivitiesApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetActivities"      
   }       
   loginWithLinkedInApi(): string {
      return "https://braid-api.azurewebsites.net/api/LoginWithLinkedIn"; 
   }
   authFromLinkedInApi(): string {
      return "https://braid-api.azurewebsites.net/api/ProcessAuthFromLinkedIn"; 
   }    
   boxerHome(): string {
      return "https://braidapps.io/aibot.html";
   }  
   findRelevantEnrichedChunksFromUrl (): string {
      return "https://braid-api.azurewebsites.net/api/FindRelevantEnrichedChunksFromUrl";
   }
   findRelevantEnrichedChunksFromSummary(): string {
      return "https:/braid-api.azurewebsites.net/api/FindRelevantEnrichedChunksFromSummary";   
   }
   findEnrichedChunkFromUrl(): string {
      return "https://braid-api.azurewebsites.net/api/FindEnrichedChunkFromUrl";      
   }    
   queryModelWithEnrichment(): string {
      return "https://braid-api.azurewebsites.net/api/QueryModelWithEnrichment";        
   } 
   generateQuestion(): string{
      return "https://braid-api.azurewebsites.net/api/GenerateQuestion";       
   }   
   generateFluidTokenApi(): string {
      return "https://braid-api.azurewebsites.net/api/GenerateFluidToken";        
   }
   fluidApi(): string {
      return  "https://eu.fluidrelay.azure.com";
   }
   fluidTenantId(): string {
      return "b9576484-5c2e-4613-bfdf-039948cdd521";
   }  
   studioForTeamsBoxer(): string {
      return "https://braid-api.azurewebsites.net/api/StudioForTeams-Boxer";
   }      
   saveChunkApi() : string{
      return "https://braid-api.azurewebsites.net/api/SaveChunk";
   }   
   removeChunkApi(): string{
      return "https://braid-api.azurewebsites.net/api/RemoveChunk";
   }   
   getChunkApi(): string{
      return "https://braid-api.azurewebsites.net/api/GetChunk";   
   }   
   findChunkApi(): string{
      return "https://braid-api.azurewebsites.net/api/FindChunk";   
   }      
   getChunksApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetChunks";
   }        
   savePageApi() : string {
      return "https://braid-api.azurewebsites.net/api/SavePage";
   }   
   getPageApi(): string {
      return "https://braid-api.azurewebsites.net/api/GetPage";
   }   
   hostProtocolAndName(): string {
      return "https://braid-api.azurewebsites.net";
   }
}
****************************************

****************************************
CommonTs\src\Errors.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

import { logApiError, logCoreError } from "./Logging";

/**
 * Represents an error thrown when an invalid parameter is encountered.
 * @param {string} message - The error message describing the invalid parameter.
 */
export class InvalidParameterError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidParameterError.name; // stack traces display correctly now

      logCoreError ("InvalidParameterError:" + (message ? message : ""), JSON.stringify (this));
   }
}

/**
 * Represents an error that occurs when an invalid operation is attempted.
 * @extends Error
 * @constructor
 * @param {string} [message] - The error message.
 */
export class InvalidOperationError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidOperationError.name; // stack traces display correctly now

      logCoreError ("InvalidOperationError:" + (message ? message : ""), JSON.stringify (this));      
   }
}


/**
 * Represents an error indicating an invalid state.
 * @param message - Optional. A message to describe the error.
 */
export class InvalidStateError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidStateError.name; // stack traces display correctly now

      logCoreError ("InvalidStateError:" + (message ? message : ""), JSON.stringify (this));      
   }
}

/**
 * Represents a custom error class for connection-related errors.
 * @class ConnectionError
 * @extends Error
 * @constructor
 * @param {string} [message] - The error message.
 */
export class ConnectionError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = ConnectionError.name; // stack traces display correctly now

      logApiError ("ConnectionError:" + (message ? message : ""), JSON.stringify (this));      
   }
}

/**
 * Represents an error related to the environment.
 * @param {string} [message] - The error message.
 */
export class EnvironmentError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = EnvironmentError.name; // stack traces display correctly now

      logCoreError ("EnvironmentError:" + (message ? message : ""), JSON.stringify (this));       
   }
}

/**
 * Represents an error that occurs when an assertion fails.
 * @param message - Optional. A message to describe the error.
 */
export class AssertionFailedError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = AssertionFailedError.name; // stack traces display correctly now

      logCoreError ("AssertionFailedError:" + (message ? message : ""), JSON.stringify (this));       
   }
}

/*
 
export class InvalidUnitError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidUnitError.name; // stack traces display correctly now
   }
}

export class InvalidFormatError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidFormatError.name; // stack traces display correctly now
   }
}

export class InvalidServerResponseError extends Error {
   constructor(message?: string) {
      super(message);
      // see: typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html
      Object.setPrototypeOf(this, new.target.prototype); // restore prototype chain
      this.name = InvalidServerResponseError.name; // stack traces display correctly now
   }
}

*/
****************************************

****************************************
CommonTs\src\FindEnrichedChunkApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
import axios from 'axios';

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IChunkQueryRelevantToSummarySpec, IChunkQueryRelevantToUrlSpec, IEnrichedChunkSummary, IRelevantEnrichedChunk } from './EnrichedChunk';


/**
 * Class representing an API for finding enriched chunks.
 */
export class FindEnrichedChunkApi extends Api {

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */   
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);
   }  


   /**
    * Asynchronously finds an enriched chunk summary based on the provided URL query.
    * 
    * @param urlQuery - The URL query specifying the URL to search for the enriched chunk.
    * @returns An IEnrichedChunkSummary objects representing the found enriched chunk summary, or undefined.
    */
   async findChunkFromUrl (urlQuery: IChunkQueryRelevantToUrlSpec) : Promise<IEnrichedChunkSummary | undefined> {

      let apiUrl = this.environment.findEnrichedChunkFromUrl() + "?session=" + this.sessionKey.toString();
      var response: any;
      let empty = undefined;

      try {
         response = await axios.post(apiUrl, {
            data: urlQuery
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return empty;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return empty;      
      }          
   }

   /**
    * Asynchronously finds relevant enriched chunks based on the provided URL query.
    * 
    * @param urlQuery - The URL query specifying the URL to search for relevant enriched chunks.
    * @returns A Promise that resolves to an array of IRelevantEnrichedChunk objects representing the found relevant enriched chunks.
    */
   async findRelevantChunksFromUrl (urlQuery: IChunkQueryRelevantToUrlSpec) : Promise<Array<IRelevantEnrichedChunk>> {

      let apiUrl = this.environment.findRelevantEnrichedChunksFromUrl() + "?session=" + this.sessionKey.toString();
      var response: any;
      let empty = new Array<IRelevantEnrichedChunk> ();

      try {
         response = await axios.post(apiUrl, {
            data: urlQuery
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return empty;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return empty;      
      }          
   }

   /**
    * Asynchronously finds relevant enriched chunks based on the provided summary query.
    * 
    * @param urlQuery - The summary query specifying the summary to search for relevant enriched chunks.
    * @returns A Promise that resolves to an array of IRelevantEnrichedChunk objects representing the found relevant enriched chunks.
    */
   async findRelevantChunksFromSummary (urlQuery: IChunkQueryRelevantToSummarySpec) : Promise<Array<IRelevantEnrichedChunk>> {

      let apiUrl = this.environment.findRelevantEnrichedChunksFromSummary() + "?session=" + this.sessionKey.toString();
      var response: any;
      let empty = new Array<IRelevantEnrichedChunk> ();      

      try {
         response = await axios.post(apiUrl, {
            data: urlQuery
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return empty;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return empty;    
      }          
   }
}
****************************************

****************************************
CommonTs\src\FindThemeApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the FindTheme API

/**
 * Interface for the find theme request object.
 */
export interface IFindThemeRequest{

   text: string;
   length: number;
}

/**
 * Interface for the find theme response object.
 */
export interface IFindThemeResponse {

   theme: string;
}
****************************************

****************************************
CommonTs\src\FindThemeApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from FindThemeApi.Types.yaml with typeconv
  version: '1'
  x-id: FindThemeApi.Types.yaml
  x-comment: >-
    Generated from src\FindThemeApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IFindThemeRequest:
      properties:
        text:
          title: IFindThemeRequest.text
          type: string
        length:
          title: IFindThemeRequest.length
          type: number
      required:
        - text
        - length
      additionalProperties: false
      title: IFindThemeRequest
      description: Interface for the find theme request object.
      type: object
    IFindThemeResponse:
      properties:
        theme:
          title: IFindThemeResponse.theme
          type: string
      required:
        - theme
      additionalProperties: false
      title: IFindThemeResponse
      description: Interface for the find theme response object.
      type: object
****************************************

****************************************
CommonTs\src\Fluid.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Fluid Token API

/**
 * Represents a Fluid user.
 * @interface
 * @property {boolean} local - if true, we are running locally - use local tentantID
 * @property {string} userId - The ID of the user making the request.
 * @property {string} userName - The name of the user making the request.
 
 */
export interface IFluidUser {

   local: boolean;
   userId: string;
   userName: string; 
}

/**
 * Represents a request for a Fluid token.
 * @interface
 * @property {string} documentId - ID of the shared document.
 */
export interface IFluidTokenRequest extends IFluidUser {

   documentId: string;   
}

/**
 * Represents a response to a request for a Fluid token.
 * @interface
 * @property {string} token - the token 
 */
export interface IFluidTokenResponse {

   token: string;   
}
****************************************

****************************************
CommonTs\src\FluidApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
import axios from 'axios';
import axiosRetry from 'axios-retry';

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IFluidTokenRequest } from './Fluid';


export class FluidApi extends Api {

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);
   }  

   /**
    * Asynchronously generates a token using the provided query parameters.
    * 
    * @param query - The request object containing documentId, userId, and userName.
    * @returns A Promise that resolves to a string if successful, otherwise undefined.
    */
   async generateToken (query: IFluidTokenRequest ) : Promise<string | undefined> {

      let apiUrl = this.environment.generateFluidTokenApi() + "?session=" + this.sessionKey;
      var response: any;
      let empty = undefined;

      try {
         // Up to 5 retries - it is a big fail if we cannot get a token for Fluid
         axiosRetry(axios, {
            retries: 5,
            retryDelay: axiosRetry.exponentialDelay,
            retryCondition: (error) => {
               return error?.response?.status === 429 || axiosRetry.isNetworkOrIdempotentRequestError(error);
            }
         });

         response = await axios.post(apiUrl, {
            data: query
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return empty;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return empty;      
      }          
   }
}
****************************************

****************************************
CommonTs\src\FluidTokenProvider.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Implementation of the Fluid connection API

import { AzureRemoteConnectionConfig, AzureClientProps, ITokenProvider, ITokenResponse } from "@fluidframework/azure-client";

import { IEnvironment, EEnvironment } from "./IEnvironment";
import { FluidApi } from "./FluidApi";
import { IFluidUser, IFluidTokenRequest } from "./Fluid";
import { ConnectionError } from "./Errors";
import { getDefaultFluidEnvironment, getEnvironment } from "./IEnvironmentFactory";

/**
 * Token Provider implementation for connecting to an Azure Function endpoint for
 * Azure Fluid Relay token resolution.
 */
export class FluidTokenProvider implements ITokenProvider {
   
   private _api: FluidApi;
   private _user: IFluidUser;

   /**
    * Creates a new instance using configuration parameters.
    * @param environment The environment settings to be used.
    * @param sessionKey The session key for authentication 
    * @param user - User object
    */
   constructor(environment: IEnvironment, sessionKey: string, user: IFluidUser) {

      this._api = new FluidApi(environment, sessionKey);
      this._user = user;
   }

   public async fetchOrdererToken(tenantId: string, documentId?: string): Promise<ITokenResponse> {
      return {
         jwt: await this.getToken(tenantId, documentId),
      };
   }

   public async fetchStorageToken(tenantId: string, documentId: string): Promise<ITokenResponse> {
      return {
         jwt: await this.getToken(tenantId, documentId),
      };
   }

   private async getToken(tenantId: string, documentId: string | undefined): Promise<string> {

      let local = false;
      if (tenantId === "local")
         local = true;

      let request : IFluidTokenRequest = {
         local: local,
         userId: this._user.userId,
         userName: this._user.userName,
         documentId: documentId? documentId : ""
      }

      console.log ("Requesting token for:" + JSON.stringify(request) + " tenantId:" + tenantId);
      
      const response = await this._api.generateToken(request);
      if (!response)
         throw new ConnectionError("Unable to generate Fluid Token");
      return response;
   }
}

export class FluidConnectionConfig implements AzureRemoteConnectionConfig {

   tokenProvider: ITokenProvider; 
   endpoint: string;
   type: any;
   tenantId: string;
   documentId: string = "";

   /**
    * Creates a new instance using configuration parameters.
    * @param sessionKey The session key for authentication 
    * @param tokenRequest - Details to request a token
    * @param forceProduction - boolean, if true then connect to production else default
    */
   constructor(sessionKey: string, tokenRequest: IFluidTokenRequest, forceProduction: boolean) {

      let environment = getDefaultFluidEnvironment();
      if (forceProduction)
         environment = getEnvironment (EEnvironment.kProduction);

      if (environment.name === EEnvironment.kLocal)
         this.type = "local";
      else
         this.type = "remote";

      this.tenantId = environment.fluidTenantId();
      this.endpoint = environment.fluidApi();   
      if (tokenRequest.documentId)   
         this.documentId = tokenRequest.documentId;
      this.tokenProvider = new FluidTokenProvider (environment, sessionKey, tokenRequest);
   }
};

export class FluidClientProps implements AzureClientProps {
   connection: FluidConnectionConfig;

   /**
    * Creates a new instance using configuration parameters.
    * @param sessionKey The session key for authentication 
    * @param tokenRequest - Details to request a token
    * @param forceProduction - boolean, if true then connect to production else default
    */   
   constructor(sessionKey: string, tokenRequest: IFluidTokenRequest, forceProduction: boolean) {
      this.connection = new FluidConnectionConfig(sessionKey, tokenRequest, forceProduction);
   }
};
****************************************

****************************************
CommonTs\src\IEnvironment.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

export const BRAID_ENVIRONMENT_KEY = "BRAID_ENVIRONMENT"

export enum EEnvironment {

   kLocal = "Local", 
   kStaging = "Staging", 
   kProduction = "Production"   
};

export interface IEnvironment {

   name : string;
   hostProtocolAndName(): string;
   checkSessionApi () : string;
   summariseApi () : string;
   findThemeApi(): string;
   chunkApi () : string;   
   classifyApi () : string;
   embedApi() : string;
   suppressSummariseFail(): string;
   saveActivityApi(): string;
   removeActivityApi(): string;
   getActivityApi(): string;   
   findActivityApi(): string;      
   getActivitiesApi(): string;
   boxerHome(): string;
   loginWithLinkedInApi(): string;
   authFromLinkedInApi(): string;
   findRelevantEnrichedChunksFromUrl(): string;
   findRelevantEnrichedChunksFromSummary(): string;   
   findEnrichedChunkFromUrl(): string;   
   queryModelWithEnrichment(): string;
   generateQuestion(): string;   
   generateFluidTokenApi(): string;
   fluidApi(): string;
   fluidTenantId(): string;
   studioForTeamsBoxer() : string;
   saveChunkApi() : string;
   removeChunkApi(): string;
   getChunkApi(): string;
   findChunkApi(): string;   
   getChunksApi(): string;   
   savePageApi() : string;   
   getPageApi(): string;   
}
****************************************

****************************************
CommonTs\src\IEnvironmentFactory.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

// Internal imports
import {EEnvironment, IEnvironment} from './IEnvironment';
import {DevelopmentEnvironment, StagingEnvironment, ProductionEnvironment} from './Environment';

declare var process : any;


/**
 * Returns the default environment based on the current execution context.
 * If running in a browser and on localhost, returns a DevelopmentEnvironment instance.
 * If the process environment variable BRAID_ENVIRONMENT is set to 'Local', returns a DevelopmentEnvironment instance.
 * Otherwise, returns a ProductionEnvironment instance.
 * @returns An instance of IEnvironment representing the default environment.
 */
export function getDefaultEnvironment () : IEnvironment  {

   // Use Development if we are running in Node.js
   if (typeof process !== 'undefined') {
      if (process.env.BRAID_ENVIRONMENT === EEnvironment.kLocal) {
         return new DevelopmentEnvironment();
      }
   }

   return new ProductionEnvironment();   
}

export function getDefaultFluidEnvironment () : IEnvironment  {

   let environment = getDefaultEnvironment();

   // If we are in Browser, and in localhost, use development
   if (typeof window !== 'undefined') {
      if (window.location.hostname === 'localhost') {
         environment = getEnvironment (EEnvironment.kLocal);
      }
   }
   return environment;
}

export function getDefaultLoginEnvironment () : IEnvironment  {

   let environment = getDefaultEnvironment();

   // If we are in Browser, and in localhost, use development
   if (typeof window !== 'undefined') {
      if (window.location.hostname === 'localhost') {
         environment = getEnvironment (EEnvironment.kLocal);
      }
   }
   return environment;
}

/**
 * Returns an instance of IEnvironment based on the provided EEnvironment type.
 * 
 * @param environmentString - The EEnvironment type to determine the environment.
 * @returns An instance of IEnvironment corresponding to the specified EEnvironment type.
 */
export function getEnvironment (environmentString: EEnvironment) : IEnvironment  {

   switch (environmentString) {
      case EEnvironment.kLocal:
         return new DevelopmentEnvironment();   

      case EEnvironment.kStaging:
         return new StagingEnvironment();   

      case EEnvironment.kProduction:
      default:
         return new ProductionEnvironment();
   }
}
****************************************

****************************************
CommonTs\src\IModel.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * Enum representing different sizes of a model.
 * 
 * @enum {string}
 */
export enum EModel {

   kSmall = "Small", 
   kLarge = "Large"  
};

/**
 * Represents an interface for a model with deployment information.
 * @interface
 */
export interface IModel {

   deploymentName : string;
   embeddingDeploymentName: string;
   contextWindowSize : number;
   fitsInContext(text: string): boolean;
   chunkText (text: string, chunkSize: number | undefined, overlapWords: number | undefined): Array<string>;
   estimateTokens (text: string): number;
}
****************************************

****************************************
CommonTs\src\IModelFactory.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

// Internal imports
import {EModel, IModel} from './IModel';
import {GPT4} from './Model';

/**
 * Returns the default model which is an instance of GPT4oMini.
 * @returns {IModel} The default model.
 */
export function getDefaultModel () : IModel  {

   return new GPT4();   
}

/**
 * Returns an instance of IModel based on the provided EModel type.
 * 
 * @param model - The EModel type to determine the model.
 * @returns An instance of IModel corresponding to the specified EModel type.
 */
export function getModel (model: EModel) : IModel  {

   switch (model) {
      default:
         return new GPT4();
   }
}
****************************************

****************************************
CommonTs\src\IStorable.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * Enum representing application names
 * 
 * @enum {string}
 */
export enum EStorableApplicationIds {

   kBoxer = "Boxer", 
   kWaterfall = "Waterfall"  
};

/**
 * Represents an interface for objects that can be stored.
 * 
 * Contains properties:
 * - id: string - the primary key of the stored object
 * - applicationId: string - identifies the application - one of the Enums above. 
 * - contextId: string - identifies the context, e.g., a conversation in Boxer
 * - userId: string | undefined - identifies the user; undefined if no direct user
 * - functionalSearchKey: string | undefined - used if the app needs to searcg by an attribute other than primary key
 * - created: Date - timestamp of creation
 * - amended: Date - timestamp of amendment
 * - className: string - class name; further fields are class-specific
 * - schemaVersion: string - allows versioning on the schema* 
 */
export interface IStorable {
                       
   id : string | undefined;  // id of the object that is stored - primary key. Can be undefined before the object is stored. 
   applicationId: string;    // Name of the application that generated and uses the chunk
   contextId: string | undefined;  // id to identify context - such as a conversation in Boxer. Undefined if application has no multi-tenanting. 
   functionalSearchKey: string | undefined; // Used if the app needs to searcg by an attribute other than primary key
   userId: string | undefined;     // id to identify the user. Undefined if there is no direct user. 
   created: string;      // creation timestamp as ISO date string
   amended: string;      // amend timestamp as ISO date string  
   className: string;  // className - all further fields are specific to the class
   schemaVersion: string;  // Allow versioning on the schema       
}

/**
 * Defines the structure of a query specification for searching for multiple records.
 * Includes the limit of records to return and the class name of the records to be stored / retrieved.
 */
export interface IStorableMultiQuerySpec {

   limit : number;          // limit of records to return
   className: string;       // what sort of records to return
}

/**
 * Defines the structure of a query specification for searching for a single record.
 * Includes the id (primary key) of the record. 
 */
export interface IStorableQuerySpec {

   id : string | undefined;  // id of the object that is stored - primary key.  
   functionalSearchKey: string | undefined; // If the id is unefined, this is used for the search
}

/**
 * Defines the structure of a query specification for searching for a single record.
 * Includes the id (primary key) of the record. 
 */
export interface IStorableOperationResult {

   ok :boolean;  // True if operation succeeeded
}
****************************************

****************************************
CommonTs\src\Logging.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

/**
 * Logs a core error with the provided description and details.
 * 
 * @param description - A brief description of the core error.
 * @param details - Additional details related to the core error.
 * @returns void
 */
export function logCoreError (description: string, details: any) : void {

   console.error ("Core error:" + description + "Details:" + details.toString());
}

/**
 * Logs a database error with the provided description and details.
 * 
 * @param description - A brief description of the error.
 * @param details - Additional details about the error.
 * @returns void
 */
export function logDbError (description: string, details: any) : void {

   console.error ("Database error:" + description + "Details:" + details.toString());
}

/**
 * Logs an API error with the provided description and details.
 * 
 * @param description A brief description of the API error.
 * @param details Additional details related to the API error.
 * @returns void
 */
export function logApiError (description: string, details: any) : void {

   console.error ("Api error:" + description + "Details:" + details.toString());
}

/**
 * Logs API information.
 * 
 * @param description - A brief description of the API information.
 * @param details - Additional details about the API information.
 * @returns void
 */
export function logApiInfo (description: string, details: any) : void {

   console.log ("Api Info:" + description + "Details:" + details.toString());
}
****************************************

****************************************
CommonTs\src\LoginApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
import axios from 'axios';

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";

/**
 * Represents a class for handling login operations.
 * @constructor
 * @param environment_ - The environment settings for the login operations.
 * @param sessionKey_ - The session key for the current login session.
 * @returns A Promise that resolves to a string indicating the login status.
 */
export class LoginApi extends Api {

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);
   }  

   /**
    * Asynchronously logs in using LinkedIn API.
    * 
    * @returns A Promise that resolves to a string indicating the status after attempting to log in.
    */
   async login () : Promise<string> {

      let apiUrl = this.environment.loginWithLinkedInApi() + "?session=" + this.sessionKey.toString();
      var response: any;

      try {
         response = await axios.post(apiUrl, {
         });

         if (response.status === 200) {
            return "Redirecting...";
         }
         else {
            console.error ("Error, status: " + response.status);               
            return "";
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return "";       
      }          
   }
   
}
****************************************

****************************************
CommonTs\src\Model.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
import { InvalidParameterError } from './Errors';
import { IModel } from './IModel';
import GPT4Tokenizer from 'gpt4-tokenizer';

const tokenizer = new GPT4Tokenizer({ type: 'gpt3' });


/**
 * GPTM class implementing IModel interface.
 * Represents a model with specific deployment settings and context window sizes.
 */
export class GPT4 implements IModel {

   deploymentName: string;
   embeddingDeploymentName: string;
   contextWindowSize: number;
   contextWindowSizeWithBuffer: number;

   public constructor() {
      this.deploymentName = "BraidLarge";
      this.embeddingDeploymentName = "BraidLargeEmbedding";
      this.contextWindowSize = 8192;
      this.contextWindowSizeWithBuffer = (8192 - 256)
   }

   /**
    * Checks if the given text fits within the context window size with buffer.
    * 
    * @param text The text to check if it fits within the context window size with buffer.
    * @returns True if the text fits within the context window size with buffer, false otherwise.
    */
   fitsInContext(text: string): boolean {

      let estimatedTokens = tokenizer.estimateTokenCount(text);

      if (estimatedTokens < this.contextWindowSizeWithBuffer)
         return true;
      return false;
   }

   /**
    * Splits the input text into chunks based on the specified overlap of words.
    * 
    * @param text The text to be chunked.
    * @param overlapWords The number of overlapping words between consecutive chunks. If undefined, we chunk with no obverlap. 
    * @returns An array of strings representing the chunked text.
    */
   chunkText(text: string, chunkSize: number | undefined, overlapWords: number | undefined): Array<string> {

      let effectiveChunkSize = chunkSize
         ? Math.min(this.contextWindowSizeWithBuffer, chunkSize)
         : this.contextWindowSizeWithBuffer;

      if (overlapWords) {

         if (overlapWords > effectiveChunkSize)
            throw new InvalidParameterError ("Overlap window size cannot be bigger than chunk size")

         // If the users requests overlapping chunks, we divide the text into pieces the size of the overlap, then glue them back
         // together until we fill a buffer. 
         let chunked = tokenizer.chunkText(text, Math.floor(overlapWords * 2));
         let chunks = new Array<string>();

         let workingBufferText = "";
         let workingBufferTokens = 0;
         let lastChunkText = "";
         let lastChunkTokens = 0;

         for (let i = 0; i < chunked.length; i++) {

            let thisChunkText = chunked[i].text;
            let thisChunkTokens = tokenizer.estimateTokenCount(thisChunkText);

            if (workingBufferTokens + thisChunkTokens < effectiveChunkSize) {
               // If we are within buffer size, we just accumulate
               workingBufferText = workingBufferText + thisChunkText;
               workingBufferTokens = workingBufferTokens + thisChunkTokens;
            }
            else {
               // If we are outside buffer, we save the current chunk and build the start of the next one
               chunks.push(workingBufferText);

               workingBufferText = lastChunkText + thisChunkText
               workingBufferTokens = lastChunkTokens + thisChunkTokens;
            }

            // If we have reached the last chunk, we have to save it. 
            if (i === chunked.length - 1) {
               chunks.push(workingBufferText);
            }

            lastChunkTokens = thisChunkTokens;
            lastChunkText = thisChunkText;
         }
         return chunks;
      }
      else {
         let chunked = tokenizer.chunkText(text, effectiveChunkSize);

         let chunks = new Array<string>();

         for (let i = 0; i < chunked.length; i++) {
            chunks.push(chunked[i].text);
         }
         return chunks;
      }
   }

   /**
    * Estimates the number of tokens in the provided text using the tokenizer.
    * 
    * @param text The text for which to estimate the number of tokens.
    * @returns The estimated number of tokens in the text.
    */
   estimateTokens(text: string): number {

      return tokenizer.estimateTokenCount(text);
   }
}
****************************************

****************************************
CommonTs\src\PageRepositoryApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IStorable} from "./IStorable";
import { StorableRepostoryApi, IStorablePageRepostoryApiWrapper} from './StorableRepositoryApi';
import { compressString, decompressString } from './Compress';
/**
 * Represents an API for the Page repository
 * 
 * @param {EEnvironment} environment_ - The environment to use for saving Pages.
 * @param {string} sessionKey_ - The session key for authentication.
 * 
 * @method save - Saves a record to the Page API.
 * Does not provide a 'load' as Pages are loaded directly into the browser
 */
export class PageRepostoryApi extends Api implements IStorablePageRepostoryApiWrapper {
   
   private storableApi: StorableRepostoryApi;

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);

      this.storableApi = new StorableRepostoryApi();      
   }  

   /**
    * Asynchronously saves a record to the page repository API.
    * 
    * @param record - The record to be saved, must implement the IStoredPage interface.
    * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
    */
   async save (record: IStorable) : Promise<boolean> {

      let apiUrl = this.environment.savePageApi() + "?session=" + this.sessionKey.toString();
      return this.storableApi.save (record, apiUrl);             
   }  

   /**
    * Compresses a string using deflate algorithm
    * @param input The string to compress
    * @returns Base64 encoded compressed string
    */
   public compressString(input: string): string {
      return compressString(input);
   }

   /**
    * Decompresses a string that was compressed using compressString
    * @param input Base64 encoded compressed string
    * @returns Original decompressed string
    */
   public decompressString(input: string): string {
      return decompressString(input);
   }

}
****************************************

****************************************
CommonTs\src\PageRepositoryApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the PageRepository API

import { IStorable, IStorableQuerySpec} from "./IStorable";

/**
 * Interface representing a web page Chunk.
 * 
 * Core data for a Page:
 * - html: HTML content
 */
export interface IStoredPage extends IStorable {

   html: string;       // HTML content
}

// We have an explicit type for the input so code generators can identify it to generate test code
export interface IStoredPageRequest extends IStorableQuerySpec {

}

// We have an explicit type for the output so code generators can identify it to generate test code
export interface IStoredPageResponse extends IStoredPage {

}
****************************************

****************************************
CommonTs\src\PageRepositoryApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from PageRepositoryApi.Types.yaml with typeconv
  version: '1'
  x-id: PageRepositoryApi.Types.yaml
  x-comment: >-
    Generated from src\PageRepositoryApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
components:
  schemas:
    IStoredPage:
      properties:
        html:
          title: IStoredPage.html
          type: string
      required:
        - html
      additionalProperties: false
      title: IStoredPage
      description: "Interface representing a web page Chunk.\r\n\r\nCore data for a Page:\r\n- html: HTML content"
      type: object
    IStoredPageRequest:
      additionalProperties: false
      title: IStoredPageRequest
      type: object
    IStoredPageResponse:
      properties:
        html:
          title: IStoredPage.html
          type: string
      required:
        - html
      additionalProperties: false
      title: IStoredPageResponse, IStoredPage
      description: "Interface representing a web page Chunk.\r\n\r\nCore data for a Page:\r\n- html: HTML content"
      type: object
    StoredPageApi:
      title: StoredPageApi
    paths:
      /functions:
        get:
          operationId: get_page
          summary: Returns a page. 
          description: Returns a page. 
          parameters:
            - request: request
              in: query
              description: A spec for a Page
              schema:
                type: IStoredPageRequest
              required: true
          responses:
            '200':
              description: A Page
              content:
                application/json:
                  schema:
                    type: IStoredPageResponse    
            '400':
              description: An error 
              content:
                application/json:
                  schema:
                    type: string
****************************************

****************************************
CommonTs\src\QueryModelApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
import axios from 'axios';

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IEnrichedQuery, IEnrichedResponse, IGenerateQuestionQuery, IQuestionGenerationResponse } from './EnrichedQuery';

/**
 * Represents a QueryModelApi class that interacts with the specified environment to query models with enrichment and generate questions.
 * @constructor
 * @param environment_ - The environment to interact with.
 * @param sessionKey_ - The session key for authentication.
 */
export class QueryModelApi extends Api {

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);
   }  

   /**
    * Asynchronously queries the model with enrichment data.
    * 
    * @param query - The enriched query data to be sent.
    * @returns A promise that resolves to the enriched response data, or undefined if an error occurs.
    */
   async queryModelWithEnrichment (query: IEnrichedQuery) : Promise<IEnrichedResponse | undefined> {

      let apiUrl = this.environment.queryModelWithEnrichment() + "?session=" + this.sessionKey.toString();
      var response: any;
      let empty = undefined;

      try {
         response = await axios.post(apiUrl, {
            data: query
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return empty;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return empty;      
      }          
   }

   /**
    * Asynchronously generates a question based on the provided query data.
    * 
    * @param query - The data containing persona prompt, question generation prompt, and summary.
    * @returns A promise that resolves to the generated question response, or undefined if an error occurs.
    */
   async generateQuestion (query: IGenerateQuestionQuery) : Promise<IQuestionGenerationResponse | undefined> {

      let apiUrl = this.environment.generateQuestion() + "?session=" + this.sessionKey.toString();
      var response: any;
      let empty = undefined;

      try {
         response = await axios.post(apiUrl, {
            data: query
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return empty;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return empty;      
      }          
   }   
}
****************************************

****************************************
CommonTs\src\SessionApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
import axios from 'axios';

import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";


export class SessionApi extends Api {

   /**
    * Initializes a new instance of the class with the provided environment and session key.
    * 
    * @param environment_ The environment settings to be used.
    * @param sessionKey_ The session key for authentication.
    */
   public constructor(environment_: IEnvironment, sessionKey_: string) {
      super (environment_, sessionKey_);
   }  

   /**
    * Asynchronously checks the validity of a session key by sending a POST request to the session API endpoint.
    * 
    * @returns A Promise that resolves to a boolean value indicating the validity of the session key.
    */
   async checkSessionKey () : Promise<string> {

      let apiUrl = this.environment.checkSessionApi() + "?session=" + this.sessionKey.toString();
      var response: any;

      try {
         response = await axios.post(apiUrl, {
         });

         if (response.status === 200) {
            return response.data;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return "";
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return "";       
      }          
   }
   
}
****************************************

****************************************
CommonTs\src\StorableRepositoryApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
import axios from 'axios';

import { IStorable, IStorableMultiQuerySpec as IStorablesQuerySpec, IStorableQuerySpec} from "./IStorable";

/**
 * Represents a wrapper for interacting with a repository of storable objects.
 * Provides methods to save storable records.
 */
export interface IStorablePageRepostoryApiWrapper {
   
   save (record: IStorable) : Promise<boolean>;  
};

/**
 * Represents a wrapper for interacting with a repository of storable objects.
 * Provides methods to save, remove, and load storable records.
 */
export interface IStorableRepostoryApiWrapper extends IStorablePageRepostoryApiWrapper{
   
   remove (recordId: string) : Promise<boolean>;
   load (recordId: string) : Promise<IStorable | undefined>;
   find (functionalSearchKey: string) : Promise<IStorable | undefined>;  
   recent (querySpec: IStorablesQuerySpec, url: string) : Promise<Array<IStorable>>;
};

/**
 * Represents an API for Storables.
 * 
 * @param {EEnvironment} environment_ - The environment to use for saving Storables.
 * @param {string} sessionKey_ - The session key for authentication.
 * 
 * @method save - Saves a record to the Storables API.
 * @method remove - removes a record
 * @method recent - return a list of recent Storables
 */
export class StorableRepostoryApi {

   /**
    * Initializes a new instance of the class 
    */
   public constructor() {
   }  

   /**
    * Asynchronously saves a record to the Storables repository API.
    * 
    * @param record - The record to be saved, must implement the IStorable interface.
    * @param url - fully factored URL to the API to call
    * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
    */
   async save (record: IStorable, url: string) : Promise<boolean> {

      var response: any;

      try {
         response = await axios.post(url, {request: record});

         if (response && response.status === 200) {
            return true;
         }
         else {
            console.error ("Error, status: " + response?.status);               
            return false;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return false;       
      }          
   }

   /**
    * Asynchronously removes a record from the Storables repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @param url - fully factored URL to the API to call
    * @returns A Promise that resolves to true if the record is successfully removed, false otherwise.
    */
   async remove (recordId: string, url: string) : Promise<boolean> {

      let query: IStorableQuerySpec = {
         id: recordId,
         functionalSearchKey: undefined         
      }
      
      var response: any;

      try {
         response = await axios.post(url, {request: query});

         if (response && response.status === 200) {
            return true;
         }
         else {
            console.error ("Error, status: " + response?.status);               
            return false;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return false;       
      }          
   }

   /**
    * Asynchronously loads a record from the Storable repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @param url - fully factored URL to the API to call
    * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
    */
   async load (recordId: string, url: string) : Promise<IStorable | undefined> {

      let query: IStorableQuerySpec = {
         id: recordId,
         functionalSearchKey: undefined
      }
      var response: any;

      try {
         response = await axios.post(url, {request: query});

         if (response && response.status === 200) {       
            return (response.data as IStorable);
         }
         else {
            console.error ("Error, status: " + response?.status);               
            return undefined;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return undefined;       
      } 
   }

   /**
    * Asynchronously finds a record from the Storable repository API.
    * 
    * @param recordId - The ID of the record to be removed.
    * @param url - fully factored URL to the API to call
    * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
    */
   async find (functionalSearchKey: string, url: string) : Promise<IStorable | undefined> {

      let query: IStorableQuerySpec = {
         id: undefined,
         functionalSearchKey: functionalSearchKey
      }
      var response: any;

      try {
         response = await axios.post(url, {request: query});

         if (response.status === 200) {          
            return (response.data as IStorable);
         }
         else {
            console.error ("Error, status: " + response.status);               
            return undefined;
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return undefined;       
      } 
   }

   /**
    * Asynchronously retrieves recent records from the Storables repository API based on the provided query specifications.
    * 
    * @param querySpec - The query specifications including the limit and storeClassName to filter the records.
    * @param url - fully factored URL to the API to call
    * @returns A Promise that resolves to an array of IStorable objects representing the recent records, or an empty array if an error occurs.
    */
   async recent (querySpec: IStorablesQuerySpec, url: string) : Promise<Array<IStorable>> {

      var response: any;

      try {
         response = await axios.post(url, {request: querySpec});

         if (response.status === 200) {

            let responseRecords = response.data;
            let storedRecords = new Array<IStorable>()

            for (let i = 0; i < responseRecords.length; i++) {
               storedRecords.push (responseRecords[i]);
            }

            return storedRecords;
         }
         else {
            console.error ("Error, status: " + response.status);               
            return new Array<IStorable>();
         }
      } catch (e: any) {       

         console.error ("Error: " + e?.response?.data);   
         return new Array<IStorable>();       
      }          
   }   
}
****************************************

****************************************
CommonTs\src\StudioApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Studio API

/**
 * Interface for the StudioBoxer request object.
 */
export interface IStudioBoxerRequest {

   question: string;
}

/**
 * Interface for the IStudioBoxerResponseEnrichment response object.
 */
export interface IStudioBoxerResponseEnrichment {

   id: string,
   summary: string;    
   title: string | undefined;
   url: string | undefined;  
   iconUrl: string | undefined;
}
****************************************

****************************************
CommonTs\src\StudioApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from StudioApi.Types.yaml with typeconv
  version: '1'
  x-id: StudioApi.Types.yaml
  x-comment: >-
    Generated from src\StudioApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IStudioBoxerRequest:
      properties:
        question:
          title: IStudioBoxerRequest.question
          type: string
      required:
        - question
      additionalProperties: false
      title: IStudioBoxerRequest
      description: Interface for the StudioBoxer request object.
      type: object
    IStudioBoxerResponseEnrichment:
      properties:
        id:
          title: IStudioBoxerResponseEnrichment.id
          type: string
        summary:
          title: IStudioBoxerResponseEnrichment.summary
          type: string
        title:
          title: IStudioBoxerResponseEnrichment.title
          type: string
        url:
          title: IStudioBoxerResponseEnrichment.url
          type: string
        iconUrl:
          title: IStudioBoxerResponseEnrichment.iconUrl
          type: string
      required:
        - id
        - summary
        - title
        - url
        - iconUrl
      additionalProperties: false
      title: IStudioBoxerResponseEnrichment
      description: Interface for the IStudioBoxerResponseEnrichment response object.
      type: object
****************************************

****************************************
CommonTs\src\SummariseApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the Summarise API

/**
 * Defines the structure of a summarise request object.
 */
export interface ISummariseRequest{

   text: string;
   lengthInWords?: number | undefined;
}

/**
 * Defines the structure of a summarise response object.
 */
export interface ISummariseResponse {

   summary: string;
}
****************************************

****************************************
CommonTs\src\SummariseApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from SummariseApi.Types.yaml with typeconv
  version: '1'
  x-id: SummariseApi.Types.yaml
  x-comment: >-
    Generated from src\SummariseApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    ISummariseRequest:
      properties:
        text:
          title: ISummariseRequest.text
          type: string
        lengthInWords:
          title: ISummariseRequest.lengthInWords
          type: number
      required:
        - text
      additionalProperties: false
      title: ISummariseRequest
      description: Defines the structure of a summarise request object.
      type: object
    ISummariseResponse:
      properties:
        summary:
          title: ISummariseResponse.summary
          type: string
      required:
        - summary
      additionalProperties: false
      title: ISummariseResponse
      description: Defines the structure of a summarise response object.
      type: object
****************************************

****************************************
CommonTs\src\SuppressSummariseFailApi.Types.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the SuppressSummariseFail API

/**
 * Defines the structure of a summarise request object.
 */
export interface ISuppressSummariseFailRequest{

   text: string;
   lengthInWords?: number | undefined;
}

export enum ESuppressSummariseFail {
   kYes = "Yes",
   kNo = "No"
}

/**
 * Defines the structure of a summarise response object.
 */
export interface ISuppressSummariseFailResponse {

   isValidSummary: ESuppressSummariseFail;
}
****************************************

****************************************
CommonTs\src\SuppressSummariseFailApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from SuppressSummariseFailApi.Types.yaml with typeconv
  version: '1'
  x-id: SuppressSummariseFailApi.Types.yaml
  x-comment: >-
    Generated from src\SuppressSummariseFailApi.Types.ts by
    core-types-json-schema (https://github.com/grantila/core-types-json-schema)
    on behalf of typeconv (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    ISuppressSummariseFailRequest:
      properties:
        text:
          title: ISuppressSummariseFailRequest.text
          type: string
        lengthInWords:
          title: ISuppressSummariseFailRequest.lengthInWords
          type: number
      required:
        - text
      additionalProperties: false
      title: ISuppressSummariseFailRequest
      description: Defines the structure of a summarise request object.
      type: object
    ISuppressSummariseFailResponse:
      properties:
        isValidSummary:
          title: ISuppressSummariseFailResponse.isValidSummary
      required:
        - isValidSummary
      additionalProperties: false
      title: ISuppressSummariseFailResponse
      description: Defines the structure of a summarise response object.
      type: object
****************************************

****************************************
CommonTs\src\ThemeApi.ts
****************************************
// Copyright (c) 2024 Braid Technologies Ltd
// Definitions for the data elements of the FindTheme API

/**
 * Interface for specifying the criteria to find a theme.
 * @interface
 */
export interface IFindThemeRequest{

   text: string;
   length : number;
}
****************************************

****************************************
CommonTs\dist\src\ActivityRepositoryApi.d.ts
****************************************
import { Api } from './Api';
import { IStorable, IStorableMultiQuerySpec } from "./IStorable";
import { IEnvironment } from "./IEnvironment";
import { IStorableRepostoryApiWrapper } from './StorableRepositoryApi';
/**
 * Represents an API for activities.
 *
 * @param {EEnvironment} environment_ - The environment to use for saving activities.
 * @param {string} sessionKey_ - The session key for authentication.
 *
 * @method save - Saves a record to the Activity API.
 * @method remove - removes a record
 * @method load - load an Activity given the key
 * @method recent - return a list of recent activities
 */
export declare class ActivityRepostoryApi extends Api implements IStorableRepostoryApiWrapper {
    private storableApi;
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously loads a record from the activity repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
     */
    load(recordId: string): Promise<IStorable | undefined>;
    /**
     * Asynchronously finds a record from the activity repository API.
     *
     * @param functionalSearchKey - The ID of the record to be removed.
     * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
     */
    find(functionalSearchKey: string): Promise<IStorable | undefined>;
    /**
     * Asynchronously saves a record to the activity repository API.
     *
     * @param record - The record to be saved, must implement the IStorable interface.
     * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
     */
    save(record: IStorable): Promise<boolean>;
    /**
     * Asynchronously removes a record from the activity repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @returns A Promise that resolves to true if the record is successfully removed, false otherwise.
     */
    remove(recordId: string): Promise<boolean>;
    /**
     * Asynchronously retrieves recent records from the activity repository API based on the provided query specifications.
     *
     * @param querySpec - The query specifications including the limit and storeClassName to filter the records.
     * @returns A Promise that resolves to an array of IStorable objects representing the recent records, or an empty array if an error occurs.
     */
    recent(querySpec: IStorableMultiQuerySpec): Promise<Array<IStorable>>;
}
//# sourceMappingURL=ActivityRepositoryApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Api.d.ts
****************************************
import { IEnvironment } from "./IEnvironment";
/**
 * Represents an API class that interacts with the specified environment using the provided session key.
 * This is a super class of each actual (useful) API. In itself it isn't very useful, it just holds common data.
 * @param {IEnvironment} environemnt_ - The environment interface to interact with.
 * @param {string} sessionKey_ - The session key for authentication.
 */
export declare class Api {
    private _environment;
    private _sessionKey;
    constructor(environemnt_: IEnvironment, sessionKey_: string);
    get environment(): IEnvironment;
    get sessionKey(): string;
}
//# sourceMappingURL=Api.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Asserts.d.ts
****************************************
export declare const throwIfUndefined: <T>(x: T | undefined) => asserts x is T;
export declare const throwIfNull: <T>(x: T | null) => asserts x is T;
//# sourceMappingURL=Asserts.d.ts.map
****************************************

****************************************
CommonTs\dist\src\ChunkApi.Types.d.ts
****************************************
/**
 * Interface for chunk reqiest API.
 * @property {string} text - The text content of the chunk.
 * @property {number | undefined} chunkSize - The size of the chunk in tokens, if specified.
 * @property {number | undefined} overlapWords - The size of the overlap between chunks, in words (=2 * tokens) if specified.
 */
export interface IChunkRequest {
    text: string;
    chunkSize?: number | undefined;
    overlapWords?: number | undefined;
}
/**
 * Return type of chunk reqiest API.
 * @property {Array<string>} chunks - Array of text chunks
 */
export interface IChunkResponse {
    chunks: Array<string>;
}
//# sourceMappingURL=ChunkApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\ChunkRepositoryApi.d.ts
****************************************
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IStorable, IStorableMultiQuerySpec } from "./IStorable";
import { IStorableRepostoryApiWrapper } from './StorableRepositoryApi';
/**
 * Represents an API for the Chunk repository
 *
 * @param {EEnvironment} environment_ - The environment to use for saving Chunks.
 * @param {string} sessionKey_ - The session key for authentication.
 *
 * @method save - Saves a record to the Chunk API.
 * @method remove - removes a record
 * @method load - load an Chunk given the key
 */
export declare class ChunkRepostoryApi extends Api implements IStorableRepostoryApiWrapper {
    private storableApi;
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously loads a record from the Chunk repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
     */
    load(recordId: string): Promise<IStorable | undefined>;
    /**
     * Asynchronously finds a record from the Chunk repository API.
     *
     * @param functionalSearchKey - The ID of the record to be removed.
     * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
     */
    find(functionalSearchKey: string): Promise<IStorable | undefined>;
    /**
     * Asynchronously saves a record to the chunk repository API.
     *
     * @param record - The record to be saved, must implement the IStoredChunk interface.
     * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
     */
    save(record: IStorable): Promise<boolean>;
    /**
     * Asynchronously removes a record from the Chunk repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @returns A Promise that resolves to true if the record is successfully removed, false otherwise.
     */
    remove(recordId: string): Promise<boolean>;
    /**
     * Asynchronously retrieves recent records from the activity repository API based on the provided query specifications.
     *
     * @param querySpec - The query specifications including the limit and storeClassName to filter the records.
     * @returns A Promise that resolves to an array of IStorable objects representing the recent records, or an empty array if an error occurs.
     */
    recent(querySpec: IStorableMultiQuerySpec): Promise<Array<IStorable>>;
}
//# sourceMappingURL=ChunkRepositoryApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\ChunkRepositoryApi.Types.d.ts
****************************************
import { IStorable } from "./IStorable";
/**
 * Represents an interface for storing embeddings with a model ID and an array of numbers representing the embedding.
 */
export interface IStoredEmbedding {
    modelId: string;
    embedding: Array<number>;
}
/**
 * Defines the structure of a stored text rendering object.
 */
export interface IStoredTextRendering {
    modelId: string;
    text: string;
}
/**
 * Interface representing a chunk of data.
 *
 * Core data for a chunk:
 * - parentChunkId: Primary key to parent document
 * - originalText: Original text; 0 if undefined, it has been thrown away (as maybe it can be reconstructed)
 * - url: string | undefined;                 // url to external resource, can be null
 * - storedEmbedding: Embedding of the original text
 * - storedSummary: Summary of the original text - generated with application-specific prompt
 * - storedTitle: A generated of the original text - generated with application-specific prompt
 * - related: Array of IDs to related chunks
 */
export interface IStoredChunk extends IStorable {
    parentChunkId: string | undefined;
    originalText: string | undefined;
    url: string | undefined;
    storedEmbedding: IStoredEmbedding | undefined;
    storedSummary: IStoredTextRendering | undefined;
    storedTitle: IStoredTextRendering | undefined;
    relatedChunks: Array<string> | undefined;
}
//# sourceMappingURL=ChunkRepositoryApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\ChunkRepositoryApiTypes.d.ts
****************************************
import { IStorable } from "./IStorable";
/**
 * Represents an interface for storing embeddings with a model ID and an array of numbers representing the embedding.
 */
export interface IStoredEmbedding {
    modelId: string;
    embedding: Array<number>;
}
/**
 * Defines the structure of a stored text rendering object.
 */
export interface IStoredTextRendering {
    modelId: string;
    text: string;
}
/**
 * Interface representing a chunk of data.
 *
 * Core data for a chunk:
 * - chunkFunctionalKey: Application level key
 * - parentChunkId: Primary key to parent document
 * - originalText: Original text; 0 if undefined, it has been thrown away (as maybe it can be reconstructed)
 * - storedEmbedding: Embedding of the original text
 * - storedSummary: Summary of the original text - generated with application-specific prompt
 * - storedTitle: A generated of the original text - generated with application-specific prompt
 *
 */
export interface IStoredChunk extends IStorable {
    chunkFunctionalKey: string;
    parentChunkId: string | undefined;
    originalText: string | undefined;
    storedEmbedding: IStoredEmbedding | undefined;
    storedSummary: IStoredTextRendering | undefined;
    storedTitle: IStoredTextRendering | undefined;
    relatedChunks: Array<string> | undefined;
}
/**
 * Defines the structure of a query specification for searching for a single record.
 * Includes the functional key of the record.
 */
export interface IStoredChunkQuerySpec {
    chunkFunctionalKey: string;
}
//# sourceMappingURL=ChunkRepositoryApiTypes.d.ts.map
****************************************

****************************************
CommonTs\dist\src\ClassifyApi.Types.d.ts
****************************************
/**
 * Represents a classification request object with text and classifications.
 */
export interface IClassifyRequest {
    text: string;
    classifications: Array<string>;
}
/**
 * Interface for the classification response object.
 */
export interface IClassifyResponse {
    classification: string;
}
//# sourceMappingURL=ClassifyApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Compress.d.ts
****************************************
/**
 * Compresses a string using deflate algorithm
 * @param input The string to compress
 * @returns Base64 encoded compressed string
 */
export declare function compressString(input: string): string;
/**
 * Decompresses a string that was compressed using compressString
 * @param input Base64 encoded compressed string
 * @returns Original decompressed string
 */
export declare function decompressString(input: string): string;
//# sourceMappingURL=Compress.d.ts.map
****************************************

****************************************
CommonTs\dist\src\EmbedApi.Types.d.ts
****************************************
/**
 * Interface for the embedding request object.
 */
export interface IEmbedRequest {
    text: string;
}
/**
 * Interface for the embedding response object.
 */
export interface IEmbedResponse {
    embedding: Array<number>;
}
//# sourceMappingURL=EmbedApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\EnrichedChunk.d.ts
****************************************
export declare enum EChunkRepository {
    kBoxer = "Boxer"
}
export declare const kDefaultSimilarityThreshold = 0.5;
/**
 * Represents a Chunk enriched with specific properties.
 * This is a summary class that can be passed between client & server.
 * @property {string} url - The URL associated with the chunk.
 * @property {string} text - The textual content of the chunk.
 * @property {string} summary - The summary content of the chunk.
 */
export interface IEnrichedChunkSummary {
    url: string;
    text: string;
    summary: string;
}
/**
 * Represents a Chunk enriched with specific properties.
  * This is a server side class only - its for storage.
 * @property {string} id - The unique identifier of the chunk.
 * @property {Array<number>} embedding - An array of numbers representing the embedding of the chunk.
 */
export interface IEnrichedChunk extends IEnrichedChunkSummary {
    id: string;
    embedding: number[];
}
/**
 * Represents a relevant chunk with its associated relevance score.
 */
export interface IRelevantEnrichedChunk {
    chunk: IEnrichedChunkSummary;
    relevance: number;
}
/**
 * Defines the structure of a chunk query specification object.
 *
 * @property {EChunkRepository} repositoryId - The ID of the repository to query.
 * @property {number} maxCount - The maximum number of results to retrieve.
 * @property {number} similarityThreshold - The threshold for similarity comparison.
 */
export interface IChunkQuerySpec {
    repositoryId: EChunkRepository;
    maxCount: number;
    similarityThreshold: number;
}
/**
 * Extends the IChunkQuerySpec interface to include a 'url' property of type string.
 */
export interface IChunkQueryRelevantToUrlSpec extends IChunkQuerySpec {
    url: string;
}
/**
 * Extends the IChunkQuerySpec interface to include a 'summary' property of type string.
 */
export interface IChunkQueryRelevantToSummarySpec extends IChunkQuerySpec {
    summary: string;
}
//# sourceMappingURL=EnrichedChunk.d.ts.map
****************************************

****************************************
CommonTs\dist\src\EnrichedQuery.d.ts
****************************************
import { EChunkRepository, IRelevantEnrichedChunk } from "./EnrichedChunk";
/**
 * Defines the structure of a conversation element.
 */
export declare enum EConversationRole {
    kSystem = "system",
    kAssistant = "assistant",
    kUser = "user"
}
/**
 * Enum representing standard prompts for an AI assistant helping an application developer understand generative AI.
 * Includes prompts for initial questions, enrichment, follow-up questions, and generating questions.
 * Each prompt provides specific instructions and limitations for the AI assistant's responses.
 */
export declare enum EStandardPrompts {
    kOpenAiPersonaPrompt = "You are an AI assistant helping an application developer understand generative AI. You explain complex concepts in simple language, using Python examples if it helps. You limit replies to 50 words or less. If you don't know the answer, say 'I don't know'. If the question is not related to building AI applications, Python, or Large Language Models (LLMs),, say 'That doesn't seem to be about AI'.",
    kEnrichmentPrompt = "You will be provided with a question about building applications that use generative AI technology. Write a 50 word summary of an article that would be a great answer to the question. Enrich the summary with additional topics that the question asker might want to understand. Write the summary in the present tense, as though the article exists. If the question is not related to building AI applications, Python, or Large Language Models (LLMs), say 'That doesn't seem to be about AI'.\n",
    kFollowUpPrompt = "You will be provided with a summary of an article about building applications that use generative AI technology. Write a question of no more than 10 words that a reader might ask as a follow up to reading the article.",
    kFollowUpPrefix = "Article summary: ",
    kGenerateAQuestionPrompt = "You are an AI assistant helping an application developer understand generative AI. Based on the dialog presented as context, generate a 10 word question that is relevant to the subjects being discussed.\n"
}
/**
 * Defines the structure of a conversation element.
 */
export interface IConversationElement {
    role: EConversationRole;
    content: string;
}
/**
 * Defines the structure of an enriched query object.
 * Contains information about the repository, persona prompt, question prompt,
 * enrichment document prompt, and conversation history.
 */
export interface IEnrichedQuery {
    repositoryId: EChunkRepository;
    personaPrompt: string;
    enrichmentDocumentPrompt: string;
    similarityThreshold: number;
    maxCount: number;
    history: Array<IConversationElement>;
    question: string;
}
/**
 * Defines the structure of an enriched response object.
 * Contains an answer field of type string and a chunks field as an array of Relevant Enriched Chunk objects.
 */
export interface IEnrichedResponse {
    answer: string;
    chunks: Array<IRelevantEnrichedChunk>;
}
/**
 * Interface for generating questions query.
 * Contains persona prompt, question generation prompt, and summary fields.
 */
export interface IGenerateQuestionQuery {
    personaPrompt: string;
    questionGenerationPrompt: string;
    summary: string;
}
/**
 * Defines the structure of a response object for question generation.
 * Contains a property 'question' of type string representing the generated question.
 */
export interface IQuestionGenerationResponse {
    question: string;
}
//# sourceMappingURL=EnrichedQuery.d.ts.map
****************************************

****************************************
CommonTs\dist\src\EnumerateModelsApi.Types.d.ts
****************************************
import { EChunkRepository } from './EnrichedChunk';
/**
 * Interface for the EnumerateModels request object.
 */
export interface IEnumerateModelsRequest {
}
/**
 * Interface for the EnumerateModels response object.
 */
export interface IEnumerateModelsResponse {
    defaultId: string;
    defaultEmbeddingId: string;
    largeId: string;
    largeEmbeddingId: string;
    smallId: string;
    smallEmbeddingId: string;
}
/**
 * Interface for the EnumerateRepositories request object.
 */
export interface IEnumerateRepositoriesRequest {
}
/**
 * Interface for the EnumerateModels response object.
 */
export interface IEnumerateReposotoriesResponse {
    repositoryIds: Array<EChunkRepository>;
}
//# sourceMappingURL=EnumerateModelsApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Environment.d.ts
****************************************
import { IEnvironment } from './IEnvironment';
/**
 * Class representing the Development Environment with methods to retrieve various API endpoints.
 * @class DevelopmentEnvironment
 */
export declare class DevelopmentEnvironment implements IEnvironment {
    name: string;
    checkSessionApi(): string;
    summariseApi(): string;
    findThemeApi(): string;
    classifyApi(): string;
    chunkApi(): string;
    embedApi(): string;
    suppressSummariseFail(): string;
    saveActivityApi(): string;
    removeActivityApi(): string;
    getActivitiesApi(): string;
    getActivityApi(): string;
    findActivityApi(): string;
    loginWithLinkedInApi(): string;
    authFromLinkedInApi(): string;
    boxerHome(): string;
    findRelevantEnrichedChunksFromUrl(): string;
    findRelevantEnrichedChunksFromSummary(): string;
    findEnrichedChunkFromUrl(): string;
    queryModelWithEnrichment(): string;
    generateQuestion(): string;
    generateFluidTokenApi(): string;
    fluidApi(): string;
    fluidTenantId(): string;
    studioForTeamsBoxer(): string;
    saveChunkApi(): string;
    removeChunkApi(): string;
    getChunkApi(): string;
    findChunkApi(): string;
    getChunksApi(): string;
    savePageApi(): string;
    getPageApi(): string;
    hostProtocolAndName(): string;
}
/**
 * Class representing the Staging Environment with methods to retrieve various API endpoints.
 * @class StagingEnvironment
 */
export declare class StagingEnvironment implements IEnvironment {
    name: string;
    checkSessionApi(): string;
    summariseApi(): string;
    findThemeApi(): string;
    classifyApi(): string;
    chunkApi(): string;
    embedApi(): string;
    suppressSummariseFail(): string;
    saveActivityApi(): string;
    removeActivityApi(): string;
    getActivityApi(): string;
    findActivityApi(): string;
    getActivitiesApi(): string;
    loginWithLinkedInApi(): string;
    authFromLinkedInApi(): string;
    boxerHome(): string;
    findRelevantEnrichedChunksFromUrl(): string;
    findRelevantEnrichedChunksFromSummary(): string;
    findEnrichedChunkFromUrl(): string;
    queryModelWithEnrichment(): string;
    generateQuestion(): string;
    generateFluidTokenApi(): string;
    fluidApi(): string;
    fluidTenantId(): string;
    studioForTeamsBoxer(): string;
    saveChunkApi(): string;
    removeChunkApi(): string;
    getChunkApi(): string;
    findChunkApi(): string;
    getChunksApi(): string;
    savePageApi(): string;
    getPageApi(): string;
    hostProtocolAndName(): string;
}
/**
 * Class representing a Production Environment with methods to retrieve various API endpoints.
 * @class ProductionEnvironment
 */
export declare class ProductionEnvironment implements IEnvironment {
    name: string;
    checkSessionApi(): string;
    summariseApi(): string;
    findThemeApi(): string;
    classifyApi(): string;
    chunkApi(): string;
    embedApi(): string;
    suppressSummariseFail(): string;
    saveActivityApi(): string;
    removeActivityApi(): string;
    getActivityApi(): string;
    findActivityApi(): string;
    getActivitiesApi(): string;
    loginWithLinkedInApi(): string;
    authFromLinkedInApi(): string;
    boxerHome(): string;
    findRelevantEnrichedChunksFromUrl(): string;
    findRelevantEnrichedChunksFromSummary(): string;
    findEnrichedChunkFromUrl(): string;
    queryModelWithEnrichment(): string;
    generateQuestion(): string;
    generateFluidTokenApi(): string;
    fluidApi(): string;
    fluidTenantId(): string;
    studioForTeamsBoxer(): string;
    saveChunkApi(): string;
    removeChunkApi(): string;
    getChunkApi(): string;
    findChunkApi(): string;
    getChunksApi(): string;
    savePageApi(): string;
    getPageApi(): string;
    hostProtocolAndName(): string;
}
//# sourceMappingURL=Environment.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Errors.d.ts
****************************************
/**
 * Represents an error thrown when an invalid parameter is encountered.
 * @param {string} message - The error message describing the invalid parameter.
 */
export declare class InvalidParameterError extends Error {
    constructor(message?: string);
}
/**
 * Represents an error that occurs when an invalid operation is attempted.
 * @extends Error
 * @constructor
 * @param {string} [message] - The error message.
 */
export declare class InvalidOperationError extends Error {
    constructor(message?: string);
}
/**
 * Represents an error indicating an invalid state.
 * @param message - Optional. A message to describe the error.
 */
export declare class InvalidStateError extends Error {
    constructor(message?: string);
}
/**
 * Represents a custom error class for connection-related errors.
 * @class ConnectionError
 * @extends Error
 * @constructor
 * @param {string} [message] - The error message.
 */
export declare class ConnectionError extends Error {
    constructor(message?: string);
}
/**
 * Represents an error related to the environment.
 * @param {string} [message] - The error message.
 */
export declare class EnvironmentError extends Error {
    constructor(message?: string);
}
/**
 * Represents an error that occurs when an assertion fails.
 * @param message - Optional. A message to describe the error.
 */
export declare class AssertionFailedError extends Error {
    constructor(message?: string);
}
//# sourceMappingURL=Errors.d.ts.map
****************************************

****************************************
CommonTs\dist\src\FindEnrichedChunkApi.d.ts
****************************************
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IChunkQueryRelevantToSummarySpec, IChunkQueryRelevantToUrlSpec, IEnrichedChunkSummary, IRelevantEnrichedChunk } from './EnrichedChunk';
/**
 * Class representing an API for finding enriched chunks.
 */
export declare class FindEnrichedChunkApi extends Api {
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously finds an enriched chunk summary based on the provided URL query.
     *
     * @param urlQuery - The URL query specifying the URL to search for the enriched chunk.
     * @returns An IEnrichedChunkSummary objects representing the found enriched chunk summary, or undefined.
     */
    findChunkFromUrl(urlQuery: IChunkQueryRelevantToUrlSpec): Promise<IEnrichedChunkSummary | undefined>;
    /**
     * Asynchronously finds relevant enriched chunks based on the provided URL query.
     *
     * @param urlQuery - The URL query specifying the URL to search for relevant enriched chunks.
     * @returns A Promise that resolves to an array of IRelevantEnrichedChunk objects representing the found relevant enriched chunks.
     */
    findRelevantChunksFromUrl(urlQuery: IChunkQueryRelevantToUrlSpec): Promise<Array<IRelevantEnrichedChunk>>;
    /**
     * Asynchronously finds relevant enriched chunks based on the provided summary query.
     *
     * @param urlQuery - The summary query specifying the summary to search for relevant enriched chunks.
     * @returns A Promise that resolves to an array of IRelevantEnrichedChunk objects representing the found relevant enriched chunks.
     */
    findRelevantChunksFromSummary(urlQuery: IChunkQueryRelevantToSummarySpec): Promise<Array<IRelevantEnrichedChunk>>;
}
//# sourceMappingURL=FindEnrichedChunkApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\FindThemeApi.Types.d.ts
****************************************
/**
 * Interface for the find theme request object.
 */
export interface IFindThemeRequest {
    text: string;
    length: number;
}
/**
 * Interface for the find theme response object.
 */
export interface IFindThemeResponse {
    theme: string;
}
//# sourceMappingURL=FindThemeApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Fluid.d.ts
****************************************
/**
 * Represents a Fluid user.
 * @interface
 * @property {boolean} local - if true, we are running locally - use local tentantID
 * @property {string} userId - The ID of the user making the request.
 * @property {string} userName - The name of the user making the request.
 
 */
export interface IFluidUser {
    local: boolean;
    userId: string;
    userName: string;
}
/**
 * Represents a request for a Fluid token.
 * @interface
 * @property {string} documentId - ID of the shared document.
 */
export interface IFluidTokenRequest extends IFluidUser {
    documentId: string;
}
/**
 * Represents a response to a request for a Fluid token.
 * @interface
 * @property {string} token - the token
 */
export interface IFluidTokenResponse {
    token: string;
}
//# sourceMappingURL=Fluid.d.ts.map
****************************************

****************************************
CommonTs\dist\src\FluidApi.d.ts
****************************************
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IFluidTokenRequest } from './Fluid';
export declare class FluidApi extends Api {
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously generates a token using the provided query parameters.
     *
     * @param query - The request object containing documentId, userId, and userName.
     * @returns A Promise that resolves to a string if successful, otherwise undefined.
     */
    generateToken(query: IFluidTokenRequest): Promise<string | undefined>;
}
//# sourceMappingURL=FluidApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\FluidTokenProvider.d.ts
****************************************
import { AzureRemoteConnectionConfig, AzureClientProps, ITokenProvider, ITokenResponse } from "@fluidframework/azure-client";
import { IEnvironment } from "./IEnvironment";
import { IFluidUser, IFluidTokenRequest } from "./Fluid";
/**
 * Token Provider implementation for connecting to an Azure Function endpoint for
 * Azure Fluid Relay token resolution.
 */
export declare class FluidTokenProvider implements ITokenProvider {
    private _api;
    private _user;
    /**
     * Creates a new instance using configuration parameters.
     * @param environment The environment settings to be used.
     * @param sessionKey The session key for authentication
     * @param user - User object
     */
    constructor(environment: IEnvironment, sessionKey: string, user: IFluidUser);
    fetchOrdererToken(tenantId: string, documentId?: string): Promise<ITokenResponse>;
    fetchStorageToken(tenantId: string, documentId: string): Promise<ITokenResponse>;
    private getToken;
}
export declare class FluidConnectionConfig implements AzureRemoteConnectionConfig {
    tokenProvider: ITokenProvider;
    endpoint: string;
    type: any;
    tenantId: string;
    documentId: string;
    /**
     * Creates a new instance using configuration parameters.
     * @param sessionKey The session key for authentication
     * @param tokenRequest - Details to request a token
     * @param forceProduction - boolean, if true then connect to production else default
     */
    constructor(sessionKey: string, tokenRequest: IFluidTokenRequest, forceProduction: boolean);
}
export declare class FluidClientProps implements AzureClientProps {
    connection: FluidConnectionConfig;
    /**
     * Creates a new instance using configuration parameters.
     * @param sessionKey The session key for authentication
     * @param tokenRequest - Details to request a token
     * @param forceProduction - boolean, if true then connect to production else default
     */
    constructor(sessionKey: string, tokenRequest: IFluidTokenRequest, forceProduction: boolean);
}
//# sourceMappingURL=FluidTokenProvider.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IEnvironment.d.ts
****************************************
export declare const BRAID_ENVIRONMENT_KEY = "BRAID_ENVIRONMENT";
export declare enum EEnvironment {
    kLocal = "Local",
    kStaging = "Staging",
    kProduction = "Production"
}
export interface IEnvironment {
    name: string;
    hostProtocolAndName(): string;
    checkSessionApi(): string;
    summariseApi(): string;
    findThemeApi(): string;
    chunkApi(): string;
    classifyApi(): string;
    embedApi(): string;
    suppressSummariseFail(): string;
    saveActivityApi(): string;
    removeActivityApi(): string;
    getActivityApi(): string;
    findActivityApi(): string;
    getActivitiesApi(): string;
    boxerHome(): string;
    loginWithLinkedInApi(): string;
    authFromLinkedInApi(): string;
    findRelevantEnrichedChunksFromUrl(): string;
    findRelevantEnrichedChunksFromSummary(): string;
    findEnrichedChunkFromUrl(): string;
    queryModelWithEnrichment(): string;
    generateQuestion(): string;
    generateFluidTokenApi(): string;
    fluidApi(): string;
    fluidTenantId(): string;
    studioForTeamsBoxer(): string;
    saveChunkApi(): string;
    removeChunkApi(): string;
    getChunkApi(): string;
    findChunkApi(): string;
    getChunksApi(): string;
    savePageApi(): string;
    getPageApi(): string;
}
//# sourceMappingURL=IEnvironment.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IEnvironmentFactory.d.ts
****************************************
import { EEnvironment, IEnvironment } from './IEnvironment';
/**
 * Returns the default environment based on the current execution context.
 * If running in a browser and on localhost, returns a DevelopmentEnvironment instance.
 * If the process environment variable BRAID_ENVIRONMENT is set to 'Local', returns a DevelopmentEnvironment instance.
 * Otherwise, returns a ProductionEnvironment instance.
 * @returns An instance of IEnvironment representing the default environment.
 */
export declare function getDefaultEnvironment(): IEnvironment;
export declare function getDefaultFluidEnvironment(): IEnvironment;
export declare function getDefaultLoginEnvironment(): IEnvironment;
/**
 * Returns an instance of IEnvironment based on the provided EEnvironment type.
 *
 * @param environmentString - The EEnvironment type to determine the environment.
 * @returns An instance of IEnvironment corresponding to the specified EEnvironment type.
 */
export declare function getEnvironment(environmentString: EEnvironment): IEnvironment;
//# sourceMappingURL=IEnvironmentFactory.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IModel.d.ts
****************************************
/**
 * Enum representing different sizes of a model.
 *
 * @enum {string}
 */
export declare enum EModel {
    kSmall = "Small",
    kLarge = "Large"
}
/**
 * Represents an interface for a model with deployment information.
 * @interface
 */
export interface IModel {
    deploymentName: string;
    embeddingDeploymentName: string;
    contextWindowSize: number;
    fitsInContext(text: string): boolean;
    chunkText(text: string, chunkSize: number | undefined, overlapWords: number | undefined): Array<string>;
    estimateTokens(text: string): number;
}
//# sourceMappingURL=IModel.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IModelFactory.d.ts
****************************************
import { EModel, IModel } from './IModel';
/**
 * Returns the default model which is an instance of GPT4oMini.
 * @returns {IModel} The default model.
 */
export declare function getDefaultModel(): IModel;
/**
 * Returns an instance of IModel based on the provided EModel type.
 *
 * @param model - The EModel type to determine the model.
 * @returns An instance of IModel corresponding to the specified EModel type.
 */
export declare function getModel(model: EModel): IModel;
//# sourceMappingURL=IModelFactory.d.ts.map
****************************************

****************************************
CommonTs\dist\src\IStorable.d.ts
****************************************
/**
 * Enum representing application names
 *
 * @enum {string}
 */
export declare enum EStorableApplicationIds {
    kBoxer = "Boxer",
    kWaterfall = "Waterfall"
}
/**
 * Represents an interface for objects that can be stored.
 *
 * Contains properties:
 * - id: string - the primary key of the stored object
 * - applicationId: string - identifies the application - one of the Enums above.
 * - contextId: string - identifies the context, e.g., a conversation in Boxer
 * - userId: string | undefined - identifies the user; undefined if no direct user
 * - functionalSearchKey: string | undefined - used if the app needs to searcg by an attribute other than primary key
 * - created: Date - timestamp of creation
 * - amended: Date - timestamp of amendment
 * - className: string - class name; further fields are class-specific
 * - schemaVersion: string - allows versioning on the schema*
 */
export interface IStorable {
    id: string | undefined;
    applicationId: string;
    contextId: string | undefined;
    functionalSearchKey: string | undefined;
    userId: string | undefined;
    created: string;
    amended: string;
    className: string;
    schemaVersion: string;
}
/**
 * Defines the structure of a query specification for searching for multiple records.
 * Includes the limit of records to return and the class name of the records to be stored / retrieved.
 */
export interface IStorableMultiQuerySpec {
    limit: number;
    className: string;
}
/**
 * Defines the structure of a query specification for searching for a single record.
 * Includes the id (primary key) of the record.
 */
export interface IStorableQuerySpec {
    id: string | undefined;
    functionalSearchKey: string | undefined;
}
/**
 * Defines the structure of a query specification for searching for a single record.
 * Includes the id (primary key) of the record.
 */
export interface IStorableOperationResult {
    ok: boolean;
}
//# sourceMappingURL=IStorable.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Logging.d.ts
****************************************
/**
 * Logs a core error with the provided description and details.
 *
 * @param description - A brief description of the core error.
 * @param details - Additional details related to the core error.
 * @returns void
 */
export declare function logCoreError(description: string, details: any): void;
/**
 * Logs a database error with the provided description and details.
 *
 * @param description - A brief description of the error.
 * @param details - Additional details about the error.
 * @returns void
 */
export declare function logDbError(description: string, details: any): void;
/**
 * Logs an API error with the provided description and details.
 *
 * @param description A brief description of the API error.
 * @param details Additional details related to the API error.
 * @returns void
 */
export declare function logApiError(description: string, details: any): void;
/**
 * Logs API information.
 *
 * @param description - A brief description of the API information.
 * @param details - Additional details about the API information.
 * @returns void
 */
export declare function logApiInfo(description: string, details: any): void;
//# sourceMappingURL=Logging.d.ts.map
****************************************

****************************************
CommonTs\dist\src\LoginApi.d.ts
****************************************
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
/**
 * Represents a class for handling login operations.
 * @constructor
 * @param environment_ - The environment settings for the login operations.
 * @param sessionKey_ - The session key for the current login session.
 * @returns A Promise that resolves to a string indicating the login status.
 */
export declare class LoginApi extends Api {
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously logs in using LinkedIn API.
     *
     * @returns A Promise that resolves to a string indicating the status after attempting to log in.
     */
    login(): Promise<string>;
}
//# sourceMappingURL=LoginApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\Model.d.ts
****************************************
import { IModel } from './IModel';
/**
 * GPTM class implementing IModel interface.
 * Represents a model with specific deployment settings and context window sizes.
 */
export declare class GPT4 implements IModel {
    deploymentName: string;
    embeddingDeploymentName: string;
    contextWindowSize: number;
    contextWindowSizeWithBuffer: number;
    constructor();
    /**
     * Checks if the given text fits within the context window size with buffer.
     *
     * @param text The text to check if it fits within the context window size with buffer.
     * @returns True if the text fits within the context window size with buffer, false otherwise.
     */
    fitsInContext(text: string): boolean;
    /**
     * Splits the input text into chunks based on the specified overlap of words.
     *
     * @param text The text to be chunked.
     * @param overlapWords The number of overlapping words between consecutive chunks. If undefined, we chunk with no obverlap.
     * @returns An array of strings representing the chunked text.
     */
    chunkText(text: string, chunkSize: number | undefined, overlapWords: number | undefined): Array<string>;
    /**
     * Estimates the number of tokens in the provided text using the tokenizer.
     *
     * @param text The text for which to estimate the number of tokens.
     * @returns The estimated number of tokens in the text.
     */
    estimateTokens(text: string): number;
}
//# sourceMappingURL=Model.d.ts.map
****************************************

****************************************
CommonTs\dist\src\PageRepositoryApi.d.ts
****************************************
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IStorable } from "./IStorable";
import { IStorablePageRepostoryApiWrapper } from './StorableRepositoryApi';
/**
 * Represents an API for the Page repository
 *
 * @param {EEnvironment} environment_ - The environment to use for saving Pages.
 * @param {string} sessionKey_ - The session key for authentication.
 *
 * @method save - Saves a record to the Page API.
 * Does not provide a 'load' as Pages are loaded directly into the browser
 */
export declare class PageRepostoryApi extends Api implements IStorablePageRepostoryApiWrapper {
    private storableApi;
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously saves a record to the page repository API.
     *
     * @param record - The record to be saved, must implement the IStoredPage interface.
     * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
     */
    save(record: IStorable): Promise<boolean>;
    /**
     * Compresses a string using deflate algorithm
     * @param input The string to compress
     * @returns Base64 encoded compressed string
     */
    compressString(input: string): string;
    /**
     * Decompresses a string that was compressed using compressString
     * @param input Base64 encoded compressed string
     * @returns Original decompressed string
     */
    decompressString(input: string): string;
}
//# sourceMappingURL=PageRepositoryApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\PageRepositoryApi.Types.d.ts
****************************************
import { IStorable, IStorableQuerySpec } from "./IStorable";
/**
 * Interface representing a web page Chunk.
 *
 * Core data for a Page:
 * - html: HTML content
 */
export interface IStoredPage extends IStorable {
    html: string;
}
export interface IStoredPageRequest extends IStorableQuerySpec {
}
export interface IStoredPageResponse extends IStoredPage {
}
//# sourceMappingURL=PageRepositoryApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\QueryModelApi.d.ts
****************************************
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
import { IEnrichedQuery, IEnrichedResponse, IGenerateQuestionQuery, IQuestionGenerationResponse } from './EnrichedQuery';
/**
 * Represents a QueryModelApi class that interacts with the specified environment to query models with enrichment and generate questions.
 * @constructor
 * @param environment_ - The environment to interact with.
 * @param sessionKey_ - The session key for authentication.
 */
export declare class QueryModelApi extends Api {
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously queries the model with enrichment data.
     *
     * @param query - The enriched query data to be sent.
     * @returns A promise that resolves to the enriched response data, or undefined if an error occurs.
     */
    queryModelWithEnrichment(query: IEnrichedQuery): Promise<IEnrichedResponse | undefined>;
    /**
     * Asynchronously generates a question based on the provided query data.
     *
     * @param query - The data containing persona prompt, question generation prompt, and summary.
     * @returns A promise that resolves to the generated question response, or undefined if an error occurs.
     */
    generateQuestion(query: IGenerateQuestionQuery): Promise<IQuestionGenerationResponse | undefined>;
}
//# sourceMappingURL=QueryModelApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\SessionApi.d.ts
****************************************
import { Api } from './Api';
import { IEnvironment } from "./IEnvironment";
export declare class SessionApi extends Api {
    /**
     * Initializes a new instance of the class with the provided environment and session key.
     *
     * @param environment_ The environment settings to be used.
     * @param sessionKey_ The session key for authentication.
     */
    constructor(environment_: IEnvironment, sessionKey_: string);
    /**
     * Asynchronously checks the validity of a session key by sending a POST request to the session API endpoint.
     *
     * @returns A Promise that resolves to a boolean value indicating the validity of the session key.
     */
    checkSessionKey(): Promise<string>;
}
//# sourceMappingURL=SessionApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\StorableRepositoryApi.d.ts
****************************************
import { IStorable, IStorableMultiQuerySpec as IStorablesQuerySpec } from "./IStorable";
/**
 * Represents a wrapper for interacting with a repository of storable objects.
 * Provides methods to save storable records.
 */
export interface IStorablePageRepostoryApiWrapper {
    save(record: IStorable): Promise<boolean>;
}
/**
 * Represents a wrapper for interacting with a repository of storable objects.
 * Provides methods to save, remove, and load storable records.
 */
export interface IStorableRepostoryApiWrapper extends IStorablePageRepostoryApiWrapper {
    remove(recordId: string): Promise<boolean>;
    load(recordId: string): Promise<IStorable | undefined>;
    find(functionalSearchKey: string): Promise<IStorable | undefined>;
    recent(querySpec: IStorablesQuerySpec, url: string): Promise<Array<IStorable>>;
}
/**
 * Represents an API for Storables.
 *
 * @param {EEnvironment} environment_ - The environment to use for saving Storables.
 * @param {string} sessionKey_ - The session key for authentication.
 *
 * @method save - Saves a record to the Storables API.
 * @method remove - removes a record
 * @method recent - return a list of recent Storables
 */
export declare class StorableRepostoryApi {
    /**
     * Initializes a new instance of the class
     */
    constructor();
    /**
     * Asynchronously saves a record to the Storables repository API.
     *
     * @param record - The record to be saved, must implement the IStorable interface.
     * @param url - fully factored URL to the API to call
     * @returns A Promise that resolves when the record is successfully saved, or rejects with an error.
     */
    save(record: IStorable, url: string): Promise<boolean>;
    /**
     * Asynchronously removes a record from the Storables repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @param url - fully factored URL to the API to call
     * @returns A Promise that resolves to true if the record is successfully removed, false otherwise.
     */
    remove(recordId: string, url: string): Promise<boolean>;
    /**
     * Asynchronously loads a record from the Storable repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @param url - fully factored URL to the API to call
     * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
     */
    load(recordId: string, url: string): Promise<IStorable | undefined>;
    /**
     * Asynchronously finds a record from the Storable repository API.
     *
     * @param recordId - The ID of the record to be removed.
     * @param url - fully factored URL to the API to call
     * @returns A Promise that resolves to the record if successfully removed, undefined otherwise.
     */
    find(functionalSearchKey: string, url: string): Promise<IStorable | undefined>;
    /**
     * Asynchronously retrieves recent records from the Storables repository API based on the provided query specifications.
     *
     * @param querySpec - The query specifications including the limit and storeClassName to filter the records.
     * @param url - fully factored URL to the API to call
     * @returns A Promise that resolves to an array of IStorable objects representing the recent records, or an empty array if an error occurs.
     */
    recent(querySpec: IStorablesQuerySpec, url: string): Promise<Array<IStorable>>;
}
//# sourceMappingURL=StorableRepositoryApi.d.ts.map
****************************************

****************************************
CommonTs\dist\src\StudioApi.Types.d.ts
****************************************
/**
 * Interface for the StudioBoxer request object.
 */
export interface IStudioBoxerRequest {
    question: string;
}
/**
 * Interface for the IStudioBoxerResponseEnrichment response object.
 */
export interface IStudioBoxerResponseEnrichment {
    id: string;
    summary: string;
    title: string | undefined;
    url: string | undefined;
    iconUrl: string | undefined;
}
//# sourceMappingURL=StudioApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\SummariseApi.Types.d.ts
****************************************
/**
 * Defines the structure of a summarise request object.
 */
export interface ISummariseRequest {
    text: string;
    lengthInWords?: number | undefined;
}
/**
 * Defines the structure of a summarise response object.
 */
export interface ISummariseResponse {
    summary: string;
}
//# sourceMappingURL=SummariseApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\SuppressSummariseFailApi.Types.d.ts
****************************************
/**
 * Defines the structure of a summarise request object.
 */
export interface ISuppressSummariseFailRequest {
    text: string;
    lengthInWords?: number | undefined;
}
export declare enum ESuppressSummariseFail {
    kYes = "Yes",
    kNo = "No"
}
/**
 * Defines the structure of a summarise response object.
 */
export interface ISuppressSummariseFailResponse {
    isValidSummary: ESuppressSummariseFail;
}
//# sourceMappingURL=SuppressSummariseFailApi.Types.d.ts.map
****************************************

****************************************
CommonTs\dist\src\ThemeApi.d.ts
****************************************
/**
 * Interface for specifying the criteria to find a theme.
 * @interface
 */
export interface IFindThemeRequest {
    text: string;
    length: number;
}
//# sourceMappingURL=ThemeApi.d.ts.map
****************************************

****************************************
Salon\apis\ChunkApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from ChunkApi.Types.yaml with typeconv
  version: '1'
  x-id: ChunkApi.Types.yaml
  x-comment: >-
    Generated from src\ChunkApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IChunkRequest:
      properties:
        text:
          title: IChunkRequest.text
          type: string
        chunkSize:
          title: IChunkRequest.chunkSize
          type: number
        overlapWords:
          title: IChunkRequest.overlapWords
          type: number
      required:
        - text
      additionalProperties: false
      title: IChunkRequest
      description: >-
        Interface for chunk reqiest API.

        @property {string} text - The text content of the chunk.

        @property {number | undefined} chunkSize - The size of the chunk in
        tokens, if specified.

        @property {number | undefined} overlapWords - The size of the overlap
        between chunks, in words (=2 * tokens) if specified.
      type: object
    IChunkResponse:
      properties:
        chunks:
          items:
            type: string
          title: IChunkResponse.chunks
          type: array
      required:
        - chunks
      additionalProperties: false
      title: IChunkResponse
      description: |-
        Return type of chunk reqiest API.
        @property {Array<string>} chunks - Array of text chunks
      type: object
****************************************

****************************************
Salon\apis\ChunkRepositoryApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from ChunkRepositoryApi.Types.yaml with typeconv
  version: '1'
  x-id: ChunkRepositoryApi.Types.yaml
  x-comment: >-
    Generated from src\ChunkRepositoryApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IStoredEmbedding:
      properties:
        modelId:
          title: IStoredEmbedding.modelId
          type: string
        embedding:
          items:
            type: number
          title: IStoredEmbedding.embedding
          type: array
      required:
        - modelId
        - embedding
      additionalProperties: false
      title: IStoredEmbedding
      description: >-
        Represents an interface for storing embeddings with a model ID and an
        array of numbers representing the embedding.
      type: object
    IStoredTextRendering:
      properties:
        modelId:
          title: IStoredTextRendering.modelId
          type: string
        text:
          title: IStoredTextRendering.text
          type: string
      required:
        - modelId
        - text
      additionalProperties: false
      title: IStoredTextRendering
      description: Defines the structure of a stored text rendering object.
      type: object
    IStoredChunk:
      properties:
        parentChunkId:
          title: IStoredChunk.parentChunkId
          type: string
        originalText:
          title: IStoredChunk.originalText
          type: string
        url:
          title: IStoredChunk.url
          type: string
        storedEmbedding:
          $ref: '#/components/schemas/IStoredEmbedding'
          title: IStoredChunk.storedEmbedding
        storedSummary:
          $ref: '#/components/schemas/IStoredTextRendering'
          title: IStoredChunk.storedSummary
        storedTitle:
          $ref: '#/components/schemas/IStoredTextRendering'
          title: IStoredChunk.storedTitle
        relatedChunks:
          items:
            type: string
          title: IStoredChunk.relatedChunks
          type: array
      required:
        - parentChunkId
        - originalText
        - url
        - storedEmbedding
        - storedSummary
        - storedTitle
        - relatedChunks
      additionalProperties: false
      title: IStoredChunk
      description: "Interface representing a chunk of data.\r\n\r\nCore data for a chunk:\r\n- parentChunkId: Primary key to parent document\r\n- originalText: Original text; 0 if undefined, it has been thrown away (as maybe it can be reconstructed)\r\n- url: string | undefined;                 // url to external resource, can be null  \r\n- storedEmbedding: Embedding of the original text\r\n- storedSummary: Summary of the original text - generated with application-specific prompt \r\n- storedTitle: A generated of the original text - generated with application-specific prompt\r\n- related: Array of IDs to related chunks"
      type: object
****************************************

****************************************
Salon\apis\ClassifyApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from ClassifyApi.Types.yaml with typeconv
  version: '1'
  x-id: ClassifyApi.Types.yaml
  x-comment: >-
    Generated from src\ClassifyApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IClassifyRequest:
      properties:
        text:
          title: IClassifyRequest.text
          type: string
        classifications:
          items:
            type: string
          title: IClassifyRequest.classifications
          type: array
      required:
        - text
        - classifications
      additionalProperties: false
      title: IClassifyRequest
      description: >-
        Represents a classification request object with text and
        classifications.
      type: object
    IClassifyResponse:
      properties:
        classification:
          title: IClassifyResponse.classification
          type: string
      required:
        - classification
      additionalProperties: false
      title: IClassifyResponse
      description: Interface for the classification response object.
      type: object
****************************************

****************************************
Salon\apis\EmbedApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from EmbedApi.Types.yaml with typeconv
  version: '1'
  x-id: EmbedApi.Types.yaml
  x-comment: >-
    Generated from src\EmbedApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IEmbedRequest:
      properties:
        text:
          title: IEmbedRequest.text
          type: string
      required:
        - text
      additionalProperties: false
      title: IEmbedRequest
      description: Interface for the embedding request object.
      type: object
    IEmbedResponse:
      properties:
        embedding:
          items:
            type: number
          title: IEmbedResponse.embedding
          type: array
      required:
        - embedding
      additionalProperties: false
      title: IEmbedResponse
      description: Interface for the embedding response object.
      type: object
****************************************

****************************************
Salon\apis\EnumerateModelsApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from EnumerateModelsApi.Types.yaml with typeconv
  version: '1'
  x-id: EnumerateModelsApi.Types.yaml
  x-comment: >-
    Generated from src\EnumerateModelsApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IEnumerateModelsRequest:
      additionalProperties: false
      title: IEnumerateModelsRequest
      description: Interface for the EnumerateModels request object.
      type: object
    IEnumerateModelsResponse:
      properties:
        defaultId:
          title: IEnumerateModelsResponse.defaultId
          type: string
        defaultEmbeddingId:
          title: IEnumerateModelsResponse.defaultEmbeddingId
          type: string
        largeId:
          title: IEnumerateModelsResponse.largeId
          type: string
        largeEmbeddingId:
          title: IEnumerateModelsResponse.largeEmbeddingId
          type: string
        smallId:
          title: IEnumerateModelsResponse.smallId
          type: string
        smallEmbeddingId:
          title: IEnumerateModelsResponse.smallEmbeddingId
          type: string
      required:
        - defaultId
        - defaultEmbeddingId
        - largeId
        - largeEmbeddingId
        - smallId
        - smallEmbeddingId
      additionalProperties: false
      title: IEnumerateModelsResponse
      description: Interface for the EnumerateModels response object.
      type: object
    IEnumerateRepositoriesRequest:
      additionalProperties: false
      title: IEnumerateRepositoriesRequest
      description: Interface for the EnumerateRepositories request object.
      type: object
    IEnumerateReposotoriesResponse:
      properties:
        repositoryIds:
          items: {}
          title: IEnumerateReposotoriesResponse.repositoryIds
          type: array
      required:
        - repositoryIds
      additionalProperties: false
      title: IEnumerateReposotoriesResponse
      description: Interface for the EnumerateModels response object.
      type: object
****************************************

****************************************
Salon\apis\FindThemeApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from FindThemeApi.Types.yaml with typeconv
  version: '1'
  x-id: FindThemeApi.Types.yaml
  x-comment: >-
    Generated from src\FindThemeApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IFindThemeRequest:
      properties:
        text:
          title: IFindThemeRequest.text
          type: string
        length:
          title: IFindThemeRequest.length
          type: number
      required:
        - text
        - length
      additionalProperties: false
      title: IFindThemeRequest
      description: Interface for the find theme request object.
      type: object
    IFindThemeResponse:
      properties:
        theme:
          title: IFindThemeResponse.theme
          type: string
      required:
        - theme
      additionalProperties: false
      title: IFindThemeResponse
      description: Interface for the find theme response object.
      type: object
****************************************

****************************************
Salon\apis\PageRepositoryApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from PageRepositoryApi.Types.yaml with typeconv
  version: '1'
  x-id: PageRepositoryApi.Types.yaml
  x-comment: >-
    Generated from src\PageRepositoryApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
components:
  schemas:
    IStoredPage:
      properties:
        html:
          title: IStoredPage.html
          type: string
      required:
        - html
      additionalProperties: false
      title: IStoredPage
      description: "Interface representing a web page Chunk.\r\n\r\nCore data for a Page:\r\n- html: HTML content"
      type: object
    IStoredPageRequest:
      additionalProperties: false
      title: IStoredPageRequest
      type: object
    IStoredPageResponse:
      properties:
        html:
          title: IStoredPage.html
          type: string
      required:
        - html
      additionalProperties: false
      title: IStoredPageResponse, IStoredPage
      description: "Interface representing a web page Chunk.\r\n\r\nCore data for a Page:\r\n- html: HTML content"
      type: object
    StoredPageApi:
      title: StoredPageApi
    paths:
      /functions:
        get:
          operationId: get_page
          summary: Returns a page. 
          description: Returns a page. 
          parameters:
            - request: request
              in: query
              description: A spec for a Page
              schema:
                type: IStoredPageRequest
              required: true
          responses:
            '200':
              description: A Page
              content:
                application/json:
                  schema:
                    type: IStoredPageResponse    
            '400':
              description: An error 
              content:
                application/json:
                  schema:
                    type: string
****************************************

****************************************
Salon\apis\PagerepositoryApi.Types_test.py
****************************************
import pytest
import requests
from unittest.mock import patch

# Base URL for the API
BASE_URL = "http://api.example.com"

# Sample data for testing
sample_successful_html = "<html><body>Sample Page</body></html>"

def test_get_page_success():
    url = f"{BASE_URL}/functions"
    params = {
        'request': {"dummy_param": "SampleValue"} 
    }

    # Mocking the requests.get call to simulate a successful response
    with patch('requests.get') as mock_get:
        mock_get.return_value.status_code = 200
        mock_get.return_value.json.return_value = {"html": sample_successful_html}

        response = requests.get(url, params=params)
        assert response.status_code == 200
        assert "html" in response.json()
        assert response.json()["html"] == sample_successful_html

def test_get_page_missing_param():
    url = f"{BASE_URL}/functions"

    # Missing required 'request' parameter
    with patch('requests.get') as mock_get:
        mock_get.return_value.status_code = 400
        mock_get.return_value.json.return_value = "Bad Request: Missing required parameters"

        response = requests.get(url)
        assert response.status_code == 400
        assert response.json() == "Bad Request: Missing required parameters"
****************************************

****************************************
Salon\apis\StudioApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from StudioApi.Types.yaml with typeconv
  version: '1'
  x-id: StudioApi.Types.yaml
  x-comment: >-
    Generated from src\StudioApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    IStudioBoxerRequest:
      properties:
        question:
          title: IStudioBoxerRequest.question
          type: string
      required:
        - question
      additionalProperties: false
      title: IStudioBoxerRequest
      description: Interface for the StudioBoxer request object.
      type: object
    IStudioBoxerResponseEnrichment:
      properties:
        id:
          title: IStudioBoxerResponseEnrichment.id
          type: string
        summary:
          title: IStudioBoxerResponseEnrichment.summary
          type: string
        title:
          title: IStudioBoxerResponseEnrichment.title
          type: string
        url:
          title: IStudioBoxerResponseEnrichment.url
          type: string
        iconUrl:
          title: IStudioBoxerResponseEnrichment.iconUrl
          type: string
      required:
        - id
        - summary
        - title
        - url
        - iconUrl
      additionalProperties: false
      title: IStudioBoxerResponseEnrichment
      description: Interface for the IStudioBoxerResponseEnrichment response object.
      type: object
****************************************

****************************************
Salon\apis\SummariseApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from SummariseApi.Types.yaml with typeconv
  version: '1'
  x-id: SummariseApi.Types.yaml
  x-comment: >-
    Generated from src\SummariseApi.Types.ts by core-types-json-schema
    (https://github.com/grantila/core-types-json-schema) on behalf of typeconv
    (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    ISummariseRequest:
      properties:
        text:
          title: ISummariseRequest.text
          type: string
        lengthInWords:
          title: ISummariseRequest.lengthInWords
          type: number
      required:
        - text
      additionalProperties: false
      title: ISummariseRequest
      description: Defines the structure of a summarise request object.
      type: object
    ISummariseResponse:
      properties:
        summary:
          title: ISummariseResponse.summary
          type: string
      required:
        - summary
      additionalProperties: false
      title: ISummariseResponse
      description: Defines the structure of a summarise response object.
      type: object
****************************************

****************************************
Salon\apis\SuppressSummariseFailApi.Types.yaml
****************************************
openapi: 3.0.0
info:
  title: Converted from SuppressSummariseFailApi.Types.yaml with typeconv
  version: '1'
  x-id: SuppressSummariseFailApi.Types.yaml
  x-comment: >-
    Generated from src\SuppressSummariseFailApi.Types.ts by
    core-types-json-schema (https://github.com/grantila/core-types-json-schema)
    on behalf of typeconv (https://github.com/grantila/typeconv)
paths: {}
components:
  schemas:
    ISuppressSummariseFailRequest:
      properties:
        text:
          title: ISuppressSummariseFailRequest.text
          type: string
        lengthInWords:
          title: ISuppressSummariseFailRequest.lengthInWords
          type: number
      required:
        - text
      additionalProperties: false
      title: ISuppressSummariseFailRequest
      description: Defines the structure of a summarise request object.
      type: object
    ISuppressSummariseFailResponse:
      properties:
        isValidSummary:
          title: ISuppressSummariseFailResponse.isValidSummary
      required:
        - isValidSummary
      additionalProperties: false
      title: ISuppressSummariseFailResponse
      description: Defines the structure of a summarise response object.
      type: object
****************************************

****************************************
Salon\docs\repo_to_text_article_medium.md
****************************************
# Introduction

- Why large codebases are challenging
- Introducing NotebookLM as a solution for interactive code exploration

# Making the Code Chat-Ready
- why transform the data (Limitations of NotebookLM) File and word limits
- transforms a repository into NotebookLM-friendly text files

# 8 Ways to "Chat" with Your Code

1. Summarize All the Things: High-level and detailed summaries
2. Debugging Detective: How NotebookLM assists in troubleshooting code
3. Refactoring Coach: Suggestions for optimizing complex code sections
4. New Feature Prototyping: Generating initial code for new features
5. Test Case Generation: Proposing unit tests and edge case handling
6. Dependency Detective: Mapping dependencies and understanding data flow
7. Code Classroom: Educating and onboarding team members with code explanations

# Advantages of NotebookLM Over Other Tools

1. Contextually Grounded Responses: Staying focused on uploaded documents
2. Structured Summaries and Explanations: Ideal for complex documentation and technical data
3. Ease of Setup and Use: Minimal setup compared to RAG pipelines
4. Interactivity with Document-Rich Repositories: Seamless Q&A on multiple sources
5. Document Confidentiality and Security: Confidentiality benefits by avoiding external data pull

# Disadvantage of NotebookLM

# Conclusion

----------------

# introduction

Working with large codebases is like navigating an unfamiliar city without a map: each module and function is a new street, every dependency an intersection, and understanding the bigger picture can feel like solving a puzzle in the dark. For developers, this often leads to hours of poring over code, deciphering poorly documented functions, and trying to untangle dependencies, all while keeping the broader goals in mind.

To address these challenges, I turned to Googles NotebookLMa tool taht could be used for interactive exploration and document-based insights. With its powerful language model, NotebookLM lets me converse with a codebase, turning complex repositories into something closer to a dialogue. By uploading the code as text files, I can ask NotebookLM for summaries, explanations, and even new code suggestions. In short, its like having a knowledgeable (and very patient) coding partner, making large codebases easier to understand, manage, and expand.

This article will show you how I use NotebookLM to turn sprawling repositories into clear, accessible resources. With NotebookLM, I can quickly understand core functionalities, uncover how different parts of the code work together, and identify where new code can build on existing structures. From deciphering complex logic to pinpointing useful features and guiding implementation, NotebookLM transforms the way I interact with large codebasesmaking it easier and faster to harness their full potential.

For the purpose of this demo, I will use the repo of crewAI. crewAI is an agentic LLM framework. The repo is actually pretty well documented (https://docs.crewai.com/introduction), so this might be useful for repo that don't have that level of documentation.

# Making the code Chat-Ready

To interact with a large codebase using NotebookLM, the first step is transforming the code into a format that the tool can efficiently process. NotebookLM has specific limitations: it allows a maximum of 50 files per notebook, each capped at 500,000 words. While this capacity is ample for many text-based projects, a large repository with multiple files and thousands of lines of code can quickly surpass these limits.

To work within these constraints, I developed a script to convert an entire repository into NotebookLM-friendly text files. The script consolidates the contents of the repo, merging files into larger text files that contain structured comments and headers for easy navigation. This transformation ensures that all classes, functions, and dependencies are represented in a way that NotebookLM can digestallowing me to interact with the full scope of the codebase without exceeding NotebookLMs file and word limits.

The repo has the converted text files of the crewai repo as an example. 

# 8 Ways to "Chat" with the Code

First you upload the text files to your notebook.

Once the code is prepared for NotebookLM, it becomes an interactive guide through the repository, providing a range of helpful insights. Here are eight ways NotebookLM can assist in navigating, optimizing, and building on complex codebases.

1. Summarize All the Things

With NotebookLM, you can request high-level summaries of entire modules or drill down to specific functions. These summaries quickly reveal the purpose and function of different code sections, providing a clear map of what the repository offers without needing to manually review each part. Its like getting a high-level overview combined with specific insights, helping you quickly assess the codes capabilities and structure.

![prompt: generate a directory tree in ascii format](readme/repo_file_structure.png)

2. Onboarding and Learning Path Suggestions

NotebookLM can be a valuable tool for guiding beginners through a complex codebase with an onboarding path tailored to essential concepts and functions. By requesting an onboarding path, you can use NotebookLM to identify critical modules, functions, and dependencies in sequence, helping new team members navigate the repository in manageable steps. NotebookLM provides explanations of key classes and methods, often with relevant code snippets and usage examples, enabling beginners to understand each components role and interconnections within the codebase. This structured pathway allows newcomers to build foundational knowledge and gain hands-on familiarity with core functionalities, setting them up for success as they dive deeper into the project.

![prompt: Can you suggest an onboarding path for beginners or new team members to understand and work with this repository? Focus on the essential modules, functions, and dependencies, and provide clear learning steps with goals for each stage. Include specific code examples, key methods to explore, and practical checkpoints where they can test their understanding. If possible, suggest a small project or exercise for hands-on practice using the core functionalities.](readme/onboarding_path.png)

3. Generating Familiarization Code Snippets

You can use NotebookLM to generate a code example that helps you get familiar with a repositorys functionalities by requesting a small, practical implementation. For instance, simply ask, implement a very simple example of a crew of agents.
NotebookLM will reference the relevant parts of the codebase to provide an initial snippet, allowing you to see the function in action and understand how it interacts with other components, making it easier to start exploring and building on the repositorys capabilities.

![prompt: generate a code snippet](readme/code_example.png)

4. Dependency Detective

Large codebases often involve intricate interdependencies, which can be challenging to untangle. NotebookLM can map out these relationships, providing a clear view of how different modules interact. By understanding data flow and function dependencies, you gain a deeper insight into how changes in one area may impact others, allowing for more informed development decisions.

![prompt: Can you provide a detailed breakdown of the dependencies between the agent and task modules in the CrewAI framework? Include specific function calls, methods, or data structures where agent relies on task for execution. Also, list any parameter exchanges or direct references in the code, and if possible, provide code snippets that illustrate these dependencies.](readme/agent_task_dependencies.png)

5. Identifying Vulnerabilities

One valuable use case for NotebookLM is performing a security review on a codebase to identify potential vulnerabilities before deployment. By guiding NotebookLM to examine areas prone to riskssuch as code injection points, access control mechanisms, data handling practices, and dependenciesit can help flag sections of the code that may need tightening. For example, NotebookLM might pinpoint functions with unsanitized inputs, highlight dependency versions with known vulnerabilities, or recommend stronger access controls on sensitive modules. With these insights, developers can proactively address weaknesses, making the repository safer and more robust before it goes live.

![prompt: Can you analyze this codebase for any security vulnerabilities that I should address before deploying? Specifically, look for risks related to code injection, inadequate access control, improper data handling, dependency vulnerabilities, and any other common security issues in repositories. Provide examples of code sections or functions that might need security improvements, along with recommendations for mitigating these risks.](readme/crewai_vulnerabilities.png)

6. Feature Exploration Guide

NotebookLM can act as a feature exploration guide, outlining optional features, hidden modules, or nice-to-have functionalities within the codebase that might be less apparent. This is helpful for exploring the repos full potential and discovering lesser-used but valuable components.

![prompt: Can you provide a feature exploration guide for this codebase? Outline any optional features, hidden modules, or nice-to-have functionalities that may not be immediately obvious but could be valuable. Include a brief description of each feature, its purpose, and examples of how it might enhance or extend the core functionalities of the codebase](readme/crewai_feature_exploration.png)



4. New Feature Prototyping

For expanding the functionality of a codebase, NotebookLM can propose starter code for new features based on the existing structure. By understanding the current architecture and dependencies, it suggests how to implement new modules or functions that integrate seamlessly with existing components. This feature accelerates prototyping by providing a solid foundation to build on.




7. Code Classroom

NotebookLM is an excellent tool for educating and onboarding team members, as it explains complex code sections in digestible language. For new developers or collaborators, NotebookLM can act as a code classroom, breaking down functions and algorithms to ensure everyone understands the codes purpose and functionality. This is invaluable for bringing team members up to speed quickly and ensuring cohesive collaboration.

Together, these features make NotebookLM a powerful conversational partner for navigating, improving, and expanding large repositories, turning code from an opaque resource into a manageable and insightful guide.
****************************************

****************************************
Salon\src\api_to_test_code.py
****************************************
# Copyright (c) 2024 Braid Technologies Ltd


import argparse
import json
import os
import logging
from typing import Optional, Union
import yaml
from openai import OpenAI

# Configure logging
logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

client = OpenAI()
api_key = os.environ.get("OPENAI_API_KEY")

# Define code snippet markers for extraction
START_POINT_CODE = '```python'
END_POINT_CODE = '```'

def parse_arguments() -> argparse.Namespace:
    """Parse command-line arguments for the script.
    
    Returns:
        argparse.Namespace: Parsed command-line arguments containing the input file path.
    """
    parser = argparse.ArgumentParser(description="Generate Pytest code from API data in JSON or YAML format.")
    parser.add_argument("input_path", type=str, help="Path to the input JSON or YAML file.")
    return parser.parse_args()


def extract_code(content: str) -> Optional[str]:
    """Extracts the Python code snippet between specified start and end markers.
    
    Args:
        content (str): The content from which to extract the code snippet.
    
    Returns:
        Optional[str]: The extracted Python code snippet, or None if markers are not found.
    """
    start_index = content.find(START_POINT_CODE)
    end_index = content.rfind(END_POINT_CODE)

    if start_index != -1 and end_index != -1:
        start_index += len(START_POINT_CODE)
        return content[start_index:end_index].strip()
    else:
        logger.warning("Could not find code markers in the generated content.")
    return None


def load_api_data(file_path: str) -> Union[dict, None]:
    """Loads API data from a JSON or YAML file.
    
    Args:
        file_path (str): The path to the JSON or YAML file.
    
    Returns:
        Union[dict, None]: Parsed JSON or YAML data as a dictionary, or None on failure.
    """
    try:
        with open(file_path, 'r') as file:
            if file_path.endswith('.json'):
                data = json.load(file)
                logger.info("Successfully loaded input JSON file containing API data.")
            elif file_path.endswith('.yaml') or file_path.endswith('.yml'):
                data = yaml.safe_load(file)
                logger.info("Successfully loaded input YAML file containing API data.")
            else:
                logger.error("Unsupported file format. Only JSON and YAML files are accepted.")
                return None
            return data
    except (FileNotFoundError, json.JSONDecodeError, yaml.YAMLError) as e:
        logger.error(f"Failed to load data from {file_path}: {e}")
        return None


def main() -> None:
    """Main function to generate Pytest code from API data in JSON or YAML format."""
    args = parse_arguments()

    # Load API data from input file
    api_data = load_api_data(args.input_path)
    if api_data is None:
        logger.critical("Exiting program due to failure in loading API data.")
        print("Error: Failed to load API data. Please check the input file and try again.")
        exit(1)

    # Determine the file type based on the input file extension for prompt context
    file_type = "JSON" if args.input_path.endswith('.json') else "YAML"

    # Generate the content for the prompt with file type context
    content = (
        f"Please generate comprehensive Pytest test code from the following API data in {file_type} format:\n"
        f"{json.dumps(api_data) if file_type == 'JSON' else yaml.dump(api_data)}"
    )

    # Set up assistant and thread for code generation
    try:
        assistant = client.beta.assistants.create(
            name="API Test Code Generator",
            instructions="You are a Python expert. Generate Pytest test cases for all endpoints in the given API data. The tests should cover positive, negative, and edge cases, with appropriate assertions. The inputs to the API will usually have the word 'Request' in the name of the data structure, and the outputs will have 'Response'.",
            tools=[{"type": "code_interpreter"}],
            model="gpt-4o",
        )
        thread = client.beta.threads.create()
        client.beta.threads.messages.create(
            thread_id=thread.id,
            role="user",
            content=content
        )
        print(f"Successfully initialized assistant and sent API data in {file_type} format for test code generation.")
    except Exception as e:
        logger.error(f"Failed to initialize assistant or thread: {e}")
        print("Error: Unable to set up assistant for code generation.")
        exit(1)

    # Print static message to indicate response generation without delay
    print("Generating code...")

    # Poll for code generation results
    try:
        run = client.beta.threads.runs.create_and_poll(
            thread_id=thread.id,
            assistant_id=assistant.id,
            instructions="Return the error-free test code"
        )
        if run.status != 'completed':
            logger.error(f"Code generation failed with status: {run.status}")
            print("Error: Code generation did not complete successfully.")
            exit(1)
    except Exception as e:
        logger.error(f"Error during code generation: {e}")
        print("Error: There was an issue during code generation.")
        exit(1)

    # Retrieve generated code from messages
    try:
        messages = client.beta.threads.messages.list(thread_id=thread.id).data
        generated_content = "\n".join(
            text_block.text.value for msg in messages for text_block in msg.content
        )
        extracted_code = extract_code(generated_content)

        if extracted_code:
            # Save extracted code to a .py file in the same directory as the input file
            output_path = os.path.splitext(args.input_path)[0] + '_test.py'
            with open(output_path, 'w') as output_file:
                output_file.write(extracted_code)
            logger.info(f"Generated test code saved to {output_path}")
            print(f"Test code successfully generated and saved to {output_path}")
        else:
            logger.warning("No code snippet was extracted from the generated content.")
            print("Warning: No valid test code was generated. Please review the API data.")
    except Exception as e:
        logger.error(f"Failed to retrieve or process messages: {e}")
        print("Error: Could not retrieve the generated code.")
        exit(1)


if __name__ == "__main__":
    main()
****************************************

****************************************
Salon\src\ReadME.md
****************************************
## Features

- **Supports JSON and YAML API Specifications**: Accepts input in both JSON and YAML formats, adapting the output accordingly.
- **Prompt-Optimized Code Generation**: Provides context-aware prompts to OpenAI for more accurate and relevant test code generation.
- **Error Handling and Logging**: Logs critical issues and informs the user with helpful messages in case of any issues.
- **Automated File Output**: Saves generated test code directly to a Python file in the same directory as the input file.
- **Simple CLI Interface**: Command-line interface with clear prompts and instructions for easy usage.

## Installation

1. **Install Required Packages**:
   Ensure that you have the required Python packages installed. You can do this by running:

   ```bash
   pip install openai pyyaml
   ```

2. **Set Up Environment Variable**:
   Set up your OpenAI API key as an environment variable:
   ```bash
   export OPENAI_API_KEY="your_openai_api_key"
   ```

## Usage

### Command-Line Interface

Run the script from the command line with a single argument specifying the path to the JSON or YAML API specification file.

```bash
python api_test_code_generator.py <path_to_api_file>
```

### Example

```bash
python api_test_code_generator.py sample_api.json
```

### Output

The generated Pytest code will be saved in the same directory as the input file, with `_test.py` appended to the original filename.

## Code Overview

### 1. Argument Parsing

The `parse_arguments()` function parses the command-line arguments to accept a single input file path, which should point to either a JSON or YAML file.

### 2. Loading API Data

The `load_api_data(file_path: str) -> Union[dict, None]` function reads the JSON or YAML file, validates its content, and converts it into a Python dictionary. The function supports both file types and logs an error if the file format is unsupported or if parsing fails.

### 3. Setting Up the Assistant and Thread

The assistant is initialized using OpenAIs API to generate Pytest code based on the provided API data. The assistant is configured with prompt instructions that include file format information to ensure precise code generation.

### 4. Extracting the Code Snippet

The `extract_code(content: str) -> Optional[str]` function isolates the generated Python code snippet, which is returned in a `Python` code block format. This is extracted by locating the `START_POINT_CODE` and `END_POINT_CODE` markers.

### 5. Generating and Saving Test Code

Once the code is generated, it is saved as a `.py` file with the original input files name followed by `_test.py`. This file is then saved in the same directory as the input file.

### 6. Logging and Error Handling

The tool uses comprehensive logging to track errors, warnings, and other critical steps throughout the script. The logging level is set to `ERROR` to minimize verbosity unless an error is encountered.

## Sample Output

After running the script, the generated Pytest code will be saved in a file named `<input_file_name>_test.py` (e.g., `sample_api_test.py`).

## Error Handling

In case of an error (such as an invalid input file or failure in code generation), clear and concise error messages will be displayed, and the program will exit gracefully.

## Dependencies

- `openai`: For connecting to the OpenAI API.
- `pyyaml`: For parsing YAML input files.
- `argparse`, `json`, `logging`, and `os`: Standard Python libraries for command-line argument parsing, JSON handling, logging, and file management.

## License

 2024 Braid Technologies Ltd. All rights reserved.
****************************************

****************************************
Salon\src\repo_to_text.py
****************************************
"""
repo_to_text.py

This script processes a local GitHub repository by concatenating the contents of its files into text files, with a specified word limit per file.

Usage:
    python repo_to_text.py --cfg <path_to_config_yaml_file> --repo_path <path-to-repo> [options]

Options:
    --cfg             Path to the config file 
    --repo_path       Path to the local GitHub repository (absolute or relative).
    -w, --max_words   Maximum number of words per output file (default: 200,000).
    -o, --output_dir  Directory to save the output files (default: current directory).
    --skip_patterns   Additional file patterns to skip (e.g., "*.md" "*.txt").
    --skip_dirs       Additional directories to skip.
    -v, --verbose     Enable verbose output.

Example:
    python repo_to_text.py --cfg config.yaml --repo_path ./my_repo -w 100000 -o ./output --skip_patterns "*.md" "*.txt" --skip_dirs "tests" -v
"""
import os
import nltk
import yaml
import fnmatch
import argparse
from pathlib import Path
from textwrap import dedent

nltk.download('punkt', quiet=True)
from nltk.tokenize import word_tokenize


def load_yaml(fname):
    # Load configuration from the YAML config file
    try:
        with open(fname, 'r') as config_file:
            config = yaml.safe_load(config_file)
    except FileNotFoundError:
        print(f"Error: Configuration file '{fname}' not found.")
        config = {}
    except yaml.YAMLError as e:
        print(f"Error parsing YAML file: {e}")
        config = {}

    return config


class RepoContentProcessor:
    def __init__(self, repo_path, config_path={}, max_words=200000):
        # Convert relative path to absolute path
        self.repo_path = Path(repo_path).resolve()
        self.content = ""
        self.file_counter = 1
        self.current_word_count = 0
        self.MAX_WORDS = max_words
        
        config = load_yaml(config_path)

        # Define directories to skip
        self.skip_dirs = config.get("skip_dirs", [])
        # Define file patterns to skip
        self.skip_patterns = config.get("skip_patterns", [])

    def format_file_block(self, relative_path, file_content):
        """Format a file's content block with consistent indentation"""
        separator = "*" * 40
        return f"{separator}\n{relative_path}\n{separator}\n{file_content}\n{separator}\n"

    def count_words(self, text):
        """Count words in the given text using NLTK tokenizer"""
        return len(word_tokenize(text))
    
    def is_in_git_directory(self, path):
        """Check if the path is inside a .git directory"""
        parts = path.relative_to(self.repo_path).parts
        return '.git' in parts
    
    def is_skip_dir (self, path):
        """Check if the path includes a component in the skip_dirs list"""
        for skip_item in self.skip_dirs:
            if skip_item in path.parts:
               return True
        return False

    
    def should_skip_path(self, path):
        """
        Check if a path should be skipped
        """
        # Skip anything in .git directory
        if self.is_in_git_directory(path):
            return True
            
        # Skip directories in skip_dirs
        if self.is_skip_dir(path):
            return True
            
        # Skip files matching patterns
        if path.is_file():
            base_name = os.path.basename(path)
            skip1 = any(fnmatch.fnmatch(base_name, pattern)
                      for pattern in self.skip_patterns)
            if skip1:
                return True
        
        return False
    
    def save_current_content(self):
        """Save current content to a numbered file"""
        if self.content:
            output_file = f'repo_content_{self.file_counter}.txt'
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(self.content.rstrip() + "\n")  # Ensure single newline at end of file
            print(f"Created {output_file} with {self.current_word_count} words")
            self.file_counter += 1
            self.content = ""
            self.current_word_count = 0
    
    def process_file(self, file_path):
        """Process a single file and add its content to the accumulator"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                file_content = f.read().rstrip()  # Remove trailing whitespace
            
            # Create the content block with consistent formatting
            relative_path = str(file_path.relative_to(self.repo_path))
            path_block = self.format_file_block(relative_path, file_content)
            
            # Count words in the new block
            block_word_count = self.count_words(path_block)
            
            # Check if adding this block would exceed the word limit
            if self.current_word_count + block_word_count > self.MAX_WORDS:
                self.save_current_content()
            
            # Add the new block with a single newline for separation
            if self.content:
                self.content += "\n"  # Add separator line only between blocks
            self.content += path_block
            self.current_word_count += block_word_count
            
        except (UnicodeDecodeError, IOError) as e:
            print(f"Skipping {file_path}: {str(e)}")
    
    def process_repo(self):
        """Process all files in the repository"""
        print(f"Processing repository at: {self.repo_path}")
        
        if not self.repo_path.exists():
            raise ValueError(f"Path does not exist: {self.repo_path}")
        
        file_count = 0
        skipped_count = 0
        skipped_dirs = set()
        
        # Use Path.rglob instead of os.walk for better path handling
        for file_path in self.repo_path.rglob('*'):
            try:
                # Skip if path should be skipped
                if self.should_skip_path(file_path):
                    if file_path.is_dir():
                        rel_path = file_path.relative_to(self.repo_path)
                        if str(rel_path) not in skipped_dirs:
                            print(f"Skipping directory: {rel_path}")
                            skipped_dirs.add(str(rel_path))
                    else:
                        skipped_count += 1
                    continue
                else:
                    # Process only files, not directories
                    if file_path.is_file():
                        print(f"Processing: {file_path.relative_to(self.repo_path)}")
                        self.process_file(file_path)
                        file_count += 1
                    
            except ValueError as e:
                print(f"Error processing path {file_path}: {e}")
                continue
        
        # Save any remaining content
        if self.content:
            self.save_current_content()
            
        print(f"\nProcessed {file_count} files, skipped {skipped_count} files")


def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description='Process a GitHub repository and concatenate file contents with word limit.',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    parser.add_argument(
        '--cfg',
        type=str,
        default="config.yaml",
        help='Path to the config.yaml file'
    )
    
    parser.add_argument(
        '--repo_path',
        type=str,
        help='Path to the local GitHub repository (absolute or relative)'
    )
    
    parser.add_argument(
        '-w', '--max_words',
        type=int,
        default=200000,
        help='Maximum number of words per output file'
    )
    
    parser.add_argument(
        '-o', '--output_dir',
        type=str,
        default='.',
        help='Directory to save the output files'
    )
    
    parser.add_argument(
        '--skip_patterns',
        type=str,
        nargs='+',
        help='Additional file patterns to skip (e.g., "*.md" "*.txt")'
    )
    
    parser.add_argument(
        '--skip_dirs',
        type=str,
        nargs='+',
        help='Additional directories to skip'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Enable verbose output'
    )
    
    return parser.parse_args()


def validate_args(args):
    """Validate command line arguments"""
    # Convert relative path to absolute path
    repo_path = Path(args.repo_path).resolve()
    
    # Check if repo path exists and is a directory
    if not repo_path.exists():
        raise ValueError(f"Repository path does not exist: {repo_path}")
    if not repo_path.is_dir():
        raise ValueError(f"Repository path is not a directory: {repo_path}")
    
    # Check if output directory exists, create if it doesn't
    output_dir = Path(args.output_dir).resolve()
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Validate max words
    if args.max_words <= 0:
        raise ValueError("Maximum words must be greater than 0")
    
    # Update args with resolved paths
    args.repo_path = repo_path
    args.output_dir = output_dir


def main():
    # Parse and validate arguments
    args = parse_arguments()
    try:
        validate_args(args)
    except ValueError as e:
        print(f"Error: {e}")
        return 1
       
    # Process the repository
    try:
        processor = RepoContentProcessor(args.repo_path, args.cfg, args.max_words)
        
        # Add any additional skip patterns from command line
        if args.skip_patterns:
            processor.skip_patterns.update(args.skip_patterns)
        
        # Add any additional skip directories from command line
        if args.skip_dirs:
            processor.skip_dirs.update(args.skip_dirs)
            
        # Change to output directory
        os.chdir(str(args.output_dir))

        processor.process_repo()
        return 0
    except Exception as e:
        print(f"Error during processing: {e}")
        return 1


if __name__ == "__main__":
    main()
****************************************

****************************************
Teams\env\.env.dev
****************************************
# This file includes environment variables that will be committed to git by default.

# Built-in environment variables
TEAMSFX_ENV=dev
APP_NAME_SUFFIX=dev

# Updating AZURE_SUBSCRIPTION_ID or AZURE_RESOURCE_GROUP_NAME after provision may also require an update to RESOURCE_SUFFIX, because some services require a globally unique name across subscriptions/resource groups.
AZURE_SUBSCRIPTION_ID=4d761e6e-f7b5-4d64-abac-b69958eebb4b
AZURE_RESOURCE_GROUP_NAME=BraidStudio
RESOURCE_SUFFIX=5317cf

# Generated during provision, you can also add your own variables.
TEAMS_APP_ID=c1899d44-d88c-4348-bba4-286e6f71ce10
TEAMS_APP_PUBLISHED_APP_ID=
TEAMS_APP_TENANT_ID=81abff01-a8d1-4ced-9e82-385a5b1df6c0
API_FUNCTION_ENDPOINT=https://sme5317cf.azurewebsites.net
API_FUNCTION_RESOURCE_ID=/subscriptions/4d761e6e-f7b5-4d64-abac-b69958eebb4b/resourceGroups/BraidStudio/providers/Microsoft.Web/sites/sme5317cf
OPENAPI_SERVER_URL=https://sme5317cf.azurewebsites.net
M365_TITLE_ID=U_1c3270a5-dcae-5520-5df2-93296f25ce93
M365_APP_ID=15682e00-7100-4dbb-a7d5-cd0aed662e14
****************************************

****************************************
Teams\env\.env.dev.user
****************************************
# This file includes environment variables that will not be committed to git by default. You can set these environment variables in your CI/CD system for your project.

# Secrets. Keys prefixed with `SECRET_` will be masked in Teams Toolkit logs.
TEAMS_APP_UPDATE_TIME=2024-10-28T18:27:33.8982625+00:00
****************************************

****************************************
Teams\env\.env.local
****************************************
# This file includes environment variables that can be committed to git. It's gitignored by default because it represents your local development environment.

# Built-in environment variables
TEAMSFX_ENV=local
APP_NAME_SUFFIX=local

# Generated during provision, you can also add your own variables.
TEAMS_APP_ID=
TEAMS_APP_PACKAGE_PATH=
FUNC_ENDPOINT=
TEAMS_APP_TENANT_ID=
TEAMS_APP_UPDATE_TIME=

# Generated during deploy, you can also add your own variables.
FUNC_PATH=
****************************************

****************************************
Teams\env\.env.local.user
****************************************
# This file includes environment variables that will not be committed to git by default. You can set these environment variables in your CI/CD system for your project.

# Secrets. Keys prefixed with `SECRET_` will be masked in Teams Toolkit logs.
TEAMS_APP_UPDATE_TIME=
****************************************

****************************************
Teams\infra\azure.bicep
****************************************
@maxLength(20)
@minLength(4)
param resourceBaseName string
param functionAppSKU string

param location string = resourceGroup().location
param serverfarmsName string = resourceBaseName
param functionAppName string = resourceBaseName

// Compute resources for Azure Functions
resource serverfarms 'Microsoft.Web/serverfarms@2021-02-01' = {
  name: serverfarmsName
  location: location
  sku: {
    name: functionAppSKU // You can follow https://aka.ms/teamsfx-bicep-add-param-tutorial to add functionServerfarmsSku property to provisionParameters to override the default value "Y1".
  }
  properties: {}
}

// Azure Functions that hosts your function code
resource functionApp 'Microsoft.Web/sites@2021-02-01' = {
  name: functionAppName
  kind: 'functionapp'
  location: location
  properties: {
    serverFarmId: serverfarms.id
    httpsOnly: true
    siteConfig: {
      appSettings: [
        {
          name: 'FUNCTIONS_EXTENSION_VERSION'
          value: '~4' // Use Azure Functions runtime v4
        }
        {
          name: 'FUNCTIONS_WORKER_RUNTIME'
          value: 'node' // Set runtime to NodeJS
        }
        {
          name: 'WEBSITE_RUN_FROM_PACKAGE'
          value: '1' // Run Azure Functions from a package file
        }
        {
          name: 'WEBSITE_NODE_DEFAULT_VERSION'
          value: '~18' // Set NodeJS version to 18.x
        }
      ]
      ftpsState: 'FtpsOnly'
    }
  }
}
var apiEndpoint = 'https://${functionApp.properties.defaultHostName}'


// The output will be persisted in .env.{envName}. Visit https://aka.ms/teamsfx-actions/arm-deploy for more details.
output API_FUNCTION_ENDPOINT string = apiEndpoint
output API_FUNCTION_RESOURCE_ID string = functionApp.id
output OPENAPI_SERVER_URL string = apiEndpoint
****************************************

****************************************
Teams\appPackage\apiSpecificationFile\boxer.yml
****************************************
openapi: 3.0.0
info:
  title: The Braid Studio
  description: APIs to bring AI into Enterprise work environments
  version: 1.0.0
servers:
  - url: ${{OPENAPI_SERVER_URL}}/api
    description: The Braid api server
paths:
  /boxer:
    get:
      operationId: boxer
      summary: Returns answers to questions about AI. 
      description: Returns an answer to the question plus a set of links to related documents. 
      parameters:
        - name: question
          in: query
          description: A question about AI
          schema:
            type: string
          required: false
      responses:
        '200':
          description: An answer to the question plus a set of links to related documents
          content:
            application/json:
              schema:
                type: array
                items:
                  properties:
                    id:
                      type: string
                      description: The unique identifier of the item (unused, placeholder)
                    title:
                      type: string
                      description: A title for the link
                    description:
                      type: string
                      description: The detailed of the link
                    url:
                      type: string
                      format: uri
                      description: A link to the related document
                    image:
                      type: string
                      format: uri
                      description: The URL of the image to use to represent the link
****************************************

****************************************
Teams\src\functions\boxer.ts
****************************************
/* This code sample provides a starter kit to implement server side logic for your Teams App in TypeScript,
 * refer to https://docs.microsoft.com/en-us/azure/azure-functions/functions-reference for complete Azure Functions
 * developer guide.
 */

import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";
import axios from "axios";
import axiosRetry from 'axios-retry';

/**
 * This function handles the HTTP request and returns the boxer information.
 *
 * @param {HttpRequest} req - The HTTP request.
 * @param {InvocationContext} context - The Azure Functions context object.
 * @returns {Promise<Response>} - A promise that resolves with the HTTP response containing the boxer information.
 */
export async function boxer(
   req: HttpRequest,
   context: InvocationContext
): Promise<HttpResponseInit> {

   try {
      // Get the question query parameter.
      const question = req.query.get("question") || (await req.text());;

      if (question) {

         context.log(question);

         // Up to 5 retries if we hit rate limit
         axiosRetry(axios, {
            retries: 5,
            retryDelay: axiosRetry.exponentialDelay,
            retryCondition: (error) => {
               return error?.response?.status === 429 || axiosRetry.isNetworkOrIdempotentRequestError(error);
            }
         });

         // Initialize response.
         const res: HttpResponseInit = {
            status: 200,
            jsonBody: {
               results: [],
            },
         };         

         let braidApi = "https://braid-api.azurewebsites.net/api/StudioForTeams-Boxer";
         const postResult = await axios.post(braidApi, null,
            {
               params: { question: question }
            });

         console.log(postResult.data);

         let items = new Array();
         for (let i = 0; i < postResult.data.length; i++) {
            let item = {
               id: postResult.data[i].id,
               description: postResult.data[i].summary,
               url: postResult.data[i].url,
               title: postResult.data[i].title,
               image: postResult.data[i].iconUrl
            }
            items.push(item);
         }
         console.log(items);
         /*
         let items = new Array();        
         let item =
         {
            id: "3",
            title: "Tire service",
            description: "Rotate and replace tires, moving them from one position to another on the vehicle to ensure even wear and removing worn tires and installing new ones.",
            image: "https://th.bing.com/th/id/OIP.N64J4jmqmnbQc5dHvTm-QAHaE8?pid=ImgDet&rs=1",
            url: "https://th.bing.com/th/id/OIP.N64J4jmqmnbQc5dHvTm-QAHaE8?pid=ImgDet&rs=1"
         };
         items.push(item);         
         */

         // Return filtered boxer records, or an empty array if no records were found.
         res.jsonBody.results = items;
         return res;
      }
      else {
         context.error("Invalid request, no qustion found in paremeters.");
         return {
            status: 400, // Internal error
            body: "Invalid request, no qusetion found in paremeters."
         };
      }
   }
   catch (e: any) {
         context.error("Internal error:", e);
         return {
            status: 500, // Internal error
            body: "Internal server error."
         };
      }
   }

app.http("boxer", {
      methods: ["GET"],
      authLevel: "anonymous",
      handler: boxer,
   });
****************************************

****************************************
Waterfall\.pytest_cache\CACHEDIR.TAG
****************************************
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html
****************************************

****************************************
Waterfall\.pytest_cache\README.md
****************************************
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.
****************************************

****************************************
Waterfall\src\boxer_pipeline.py
****************************************
'''driver for the entire Boxer data generation pipeline '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json

from src.workflow import YouTubePipelineSpec, HtmlDirectedPipelineSpec, PipelineItem, PipelineFileSpec
from src.youtube_searcher import YoutubePlaylistSearcher
from src.youtube_transcript_downloader import YouTubeTranscriptDownloader
from src.youtube_transcript_chunker import YouTubeTranscriptChunker
from src.html_link_crawler import HtmlLinkCrawler
from src.html_file_downloader import HtmlFileDownloader
from src.summariser import Summariser
from src.embedder import Embedder

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)


class BoxerDataPipeline:
    '''
    Searches for HTML & YouTube  from a list of links.

    Returns:
       list[str]: A list of HTML content downloaded from the specified links.
    '''

    def __init__(self, output_location: str):
        '''
        Initializes a BoxerDataPipeline object with the specified output location.

        Parameters:
            output_location (str): The location where the output will be stored.

        Returns:
            None
        '''
        self.output_location = output_location
        return

    def search(self,
               youtube_spec: YouTubePipelineSpec,
               html_spec: HtmlDirectedPipelineSpec,
               file_spec: PipelineFileSpec) -> list[PipelineItem]:
        '''
        Searches for HTML & YouTube content from a list of links.

        Returns:
            A list with all the donloaded pipline items
        '''
        youtube_searcher = YoutubePlaylistSearcher(self.output_location)
        youtube_downloader = YouTubeTranscriptDownloader(self.output_location)
        youtube_chunker = YouTubeTranscriptChunker(self.output_location)

        html_crawler = HtmlLinkCrawler(self.output_location)
        html_downloader = HtmlFileDownloader(self.output_location)

        summariser = Summariser(self.output_location)
        embedder = Embedder(self.output_location)

        all_chunks = []
        all_enriched_chunks = []

        for html_url in html_spec.urls:
            chunk = PipelineItem()
            chunk.path = html_url
            html_items = html_crawler.crawl(chunk)

            for html_item in html_items:
                downloaded = None
                summarised = None
                embedded = None

                downloaded = html_downloader.download(html_item)
                if downloaded:
                    summarised = summariser.summarise(downloaded)
                if summarised:
                    embedded = embedder.embed(summarised)
                if embedded:
                    all_enriched_chunks.append(embedded)

        youtube_items = youtube_searcher.search(youtube_spec)

        for chunk in youtube_items:
            chunk = youtube_downloader.download(chunk)
            chunks = youtube_chunker.chunk(
                chunk, youtube_spec.max_words, youtube_spec.overlap_words)
            if chunks:
                all_chunks.extend(chunks)

        for chunk in all_chunks:
            summarised = None
            embedded = None
            logger.info('Processing: %s', chunk.path)
            if chunk.text:
                summarised = summariser.summarise(chunk)
            if summarised:
                embedded = embedder.embed(summarised)
            if embedded:
                all_enriched_chunks.append(embedded)

        output_results = []
        for chunk in all_enriched_chunks:
            output_item = dict()
            output_item['summary'] = chunk.summary
            output_item['embedding'] = chunk.embedding
            output_item['url'] = chunk.path
            output_results.append(output_item)

        # save the test results to a json file
        output_file = os.path.join(
            self.output_location, file_spec.output_data_name)
        with open(output_file, 'w+', encoding='utf-8') as f:
            json.dump(output_results, f)

        return all_enriched_chunks
****************************************

****************************************
Waterfall\src\boxer_sources.py
****************************************

youtube_playlists = [
    # "Stanford CS229: Machine Learning Full Course taught by Andrew Ng | Autumn 2018 - YouTube",
    "PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU",
    # "Stanford CS224N: Natural Language Processing with Deep Learning | Winter 2021 - YouTube",
    "PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ",
    # "Braid AI Canon",
    "PL9LkXkIUrSoxIlFSKcyB21XFFLCCYfPGv",
    # "Braid - Additional Content",
    "PL9LkXkIUrSozgkPNepSMzidqtAGR0b1F_",
    # "Augmented Language Models (LLM Bootcamp) (youtube.com)",
    "PL1T8fO7ArWleyIqOy37OVXsP4hFXymdOZ"
]

html_pages = [
    # "Learn | Pinecone",
    "https://www.pinecone.io/learn/",

    # "Software 2.0. by Andrej Karpathy",
    "https://karpathy.medium.com/software-2-0-a64152b37c35",

    # "Transformers, Explained: Understand the Model Behind GPT-3, BERT, and T5 (daleonai.com)",
    "https://daleonai.com/transformers-explained",

    # "What Is ChatGPT Doing  and Why Does It Work?Stephen Wolfram",
    "https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/",

    # "How Stable Diffusion Works  Chris McCormick (mccormickml.com)",
    "https://mccormickml.com/2022/12/21/how-stable-diffusion-works/",

    # "Deep Learning in a Nutshell: Core Concepts | NVIDIA Technical Blog",
    "https://developer.nvidia.com/blog/deep-learning-nutshell-core-concepts/",

    # "Practical Deep Learning for Coders - Practical Deep Learning (fast.ai)",
    "https://course.fast.ai/",

    # "Word2Vec Explained. Explaining the Intuition of Word2Vec & | by Vatsal | Towards Data Science",
    "https://towardsdatascience.com/word2vec-explained-49c52b4ccb71",

    # "Yes you should understand backprop | by Andrej Karpathy",
    "https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b",

    # "The Illustrated Transformer by Jay Alammar (jalammar.github.io)",
    "https://jalammar.github.io/illustrated-transformer/",

    # "The Annotated Transformer (harvard.edu)",
    "https://nlp.seas.harvard.edu/annotated-transformer/",

    # "The Illustrated Stable Diffusion by Jay Alammar Visualizing machine learning one concept at a time. (jalammar.github.io)",
    "https://jalammar.github.io/illustrated-stable-diffusion/",

    # "Huyen Chip's Blog",
    "https://huyenchip.com/",

    # "Stamford CS234 - Large Language Models",
    "https://stanford-cs324.github.io/winter2022/lectures/",

    # "The Scaling Hypothesis  Gwern.net",
    "https://gwern.net/scaling-hypothesis",

    # "chinchilla's wild implications  LessWrong",
    "https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications",

    # "The AI Revolution: How Auto-GPT Unleashes a New Era of Automation and Creativity | by Sriram Parthasarathy | Towards AI",
    "https://pub.towardsai.net/the-ai-revolution-how-auto-gpt-unleashes-a-new-era-of-automation-and-creativity-2008aa2ca6ae",

    # "The Waluigi Effect (mega-post)  LessWrong",
    "https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post",

    # "Build a GitHub Support Bot with GPT3, LangChain, and Python | Dagster Blog",
    "https://dagster.io/blog/chatgpt-langchain",

    # "Prompt Engineering Guide | Prompt Engineering Guide (promptingguide.ai)",
    "https://www.promptingguide.ai/",

    # "Use Cases | Langchain",
    "https://python.langchain.com/v0.1/docs/use_cases/",

    # "Hugging Face Cookbook",
    "https://huggingface.co/learn/cookbook",

    # "Open AI Cookbook",
    "https://cookbook.openai.com/",

    # "State of Open Source AI - 2023 Edition",
    "https://book.premai.io/state-of-open-source-ai/",

    # "Scaled Agile Framework 6.0",
    "https://scaledagileframework.com/",

    # "McKinsey on AI",
    "https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier",

    # "A16Z Market Analysis",
    "https://a16z.com/for-b2b-generative-ai-apps-is-less-more/",

    # "A16Z Market Analysis",
    "https://a16z.com/navigating-the-high-cost-of-ai-compute/",

    # "A16Z Market Analysis",
    "https://a16z.com/financial-services-will-embrace-generative-ai-faster-than-you-think/",

    # "A16Z Market Analysis",
    "https://a16z.com/who-owns-the-generative-ai-platform/",

    # "Interaction Design Foundation",
    "https://www.interaction-design.org/literature/topics/design-thinking",

    # "UX for AI",
    "https://www.uxforai.com/",

    # "Testing Machine Learning Systems: Code, Data and Models ",
    "https://madewithml.com/courses/mlops/testing/",

    # "Monitoring Machine Learning Systems: Code, Data and Models ",
    "https://madewithml.com/courses/mlops/monitoring/",

    # "Full Stack Machine learning"
    "https://leehanchung.github.io/"
]
****************************************

****************************************
Waterfall\src\chunker.py
****************************************
'''PipelineStep to create a summary for a text string'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json
import requests
from requests.adapters import HTTPAdapter, Retry

from src.workflow import PipelineItem, PipelineStep

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)

SESSION_KEY = os.environ['SessionKey']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}


class Chunker (PipelineStep):
    '''PipelineStep to chunk a text string'''

    # pylint: disable-next=useless-parent-delegation 
    def __init__(self, output_location: str):
        '''
        Initializes the Chunker object with the provided output location.
        '''
        super(Chunker, self).__init__(output_location)

    def chunk(self, pipeline_item: PipelineItem, chunk_size_words: int, overlap_words: int) -> list[PipelineItem]:
        '''
        Chunk a text string into smaller parts and return a list of PipelineItem objects representing each chunk. Uses an external API to perform the chunking process. 

        Parameters:
            - pipeline_item: PipelineItem - The item to be chunked.
            - max_words - maximum words per chunk. If 0, use the models context window size. 
            - overlap_words - how many words to use to overlap chunks. 0 = no overlap.             

        Returns:
            - List of PipelineItem - List of PipelineItem objects representing the chunks.
         ''' ''

        logger.debug('Chunking: %s', pipeline_item.path)

        session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[500, 502, 503, 504])
        session.mount('https://', HTTPAdapter(max_retries=retries))

        summary_url = f'https://braid-api.azurewebsites.net/api/Chunk?session={
            SESSION_KEY}'

        if chunk_size_words == 0:
            input_json = {
                'request': {
                    'text': pipeline_item.text,
                    'overlapWords': overlap_words
                }
            }
        else:
            input_json = {
                'request': {
                    'text': pipeline_item.text,
                    'chunkSize': chunk_size_words,
                    'overlapWords': overlap_words
                }
            }

        response = session.post(summary_url, json=input_json, headers=headers)
        pipeline_chunks = []  # If there is an error in the API, return an empty list

        if response.status_code == 200:
            response_json = json.loads(response.text)
            chunks = response_json['chunks']

            for i, chunk in enumerate(chunks):
                new_item = PipelineItem()
                new_item.path = pipeline_item.path
                new_item.text = chunk
                new_item.chunk = i
                new_item.summary = pipeline_item.summary
                new_item.embedding = pipeline_item.embedding
                new_item.cluster = pipeline_item.cluster
                pipeline_chunks.append(new_item)

        return pipeline_chunks
****************************************

****************************************
Waterfall\src\cluster_analyser.py
****************************************
'''PipelineStep to analyse a set of embedding vectors by KMeans clustering'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
from sklearn.cluster import KMeans

from src.workflow import PipelineItem, PipelineStep

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)


class ClusterAnalyser (PipelineStep):
    '''PipelineStep that analyses a set of embedding vectors by KMeans clustering'''

    def __init__(self, output_location: str, clusters: int):
        '''
        Initializes the ClusterAnalyser object with the provided output location and target cluster count
        '''
        super(ClusterAnalyser, self).__init__(output_location)
        self.clusters = clusters

    def analyse(self, items: list[PipelineItem]) -> list[PipelineItem]:
        '''
        Analyzes the given clusters using KMeans clustering algorithm.

        Parameters:
           items: a set of Pipeline items to analyse

        Returns:
           list[PipelineItem]: A list of PipelineItem objects with updated cluster assignments.
        '''

        x = len (items[0].embedding)
        y = len (items)

        embeddings = [[0 for _ in range(x)] for _ in range(y)]
        for i, item in enumerate (items):
            embeddings[i] = item.embedding

        logger.debug('Making cluster')
        kmeans = KMeans(n_clusters=self.clusters)
        kmeans.fit(embeddings)

        for i, item in enumerate(items):
            item.cluster = int(kmeans.labels_[i])

        return items
****************************************

****************************************
Waterfall\src\db_repository.py
****************************************
'''
Module to store data in the Chunk table of the BraidApis
This module takes in data as 'PipelineItem', as used in waterfall.
It converts to Chunk  to pass to the native Chunk API, which is common across multiple applications.

'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import datetime
import uuid

from CommonPy.src.chunk_repository_api_types import (IStoredChunk,
   IStoredEmbedding,
   IStoredTextRendering)
from CommonPy.src.chunk_repository_api import (ChunkRepository,
                                               chunk_class_name,
                                               chunk_schema_version)
from src.make_local_file_path import make_local_file_path
from src.workflow import PipelineItem

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)


class DbRepository:
    '''
    Class providing load, save, and existence check for files in the Braid Cosmos database.
    '''

    def __init__(self, application_id: str, context_id: str):

        self.application_id = application_id
        self.context_id = context_id
        self.chunk_repository = ChunkRepository()

    def save(self, item: PipelineItem) -> bool:
        '''
        Save the provided item to the database.

        Parameters:
           functional_key (str): functionalKey to use for the record
           item (PipelineItem): The content to be saved.
        '''
        functional_key = make_local_file_path(item.path)
        logger.debug('Saving: %s', functional_key)

        utc_time = datetime.datetime.now(datetime.timezone.utc)
        utc_time_string = utc_time.strftime('%Y-%m-%d %H:%M:%S %Z')

        summary: IStoredTextRendering = IStoredTextRendering()
        summary.modelId = self.chunk_repository.default_model
        summary.text = item.summary

        embedding: IStoredEmbedding = IStoredEmbedding()
        embedding.modelId = self.chunk_repository.default_embedding_model
        embedding.embedding = item.embedding

        # Create a Chunk from the PipelineItem supplied
        chunk: IStoredChunk = IStoredChunk()
        if item.id:
            chunk.id = item.id
        else:
            chunk.id = str(uuid.uuid4())
        chunk.applicationId = self.application_id
        chunk.contextId = self.context_id
        chunk.userId = None
        chunk.created = utc_time_string
        chunk.amended = chunk.created
        chunk.className = chunk_class_name
        chunk.schemaVersion = chunk_schema_version
        chunk.functionalSearchKey = functional_key
        chunk.parentChunkId = item.parent_id
        chunk.originalText = item.text
        chunk.storedEmbedding = embedding
        chunk.storedSummary = summary
        chunk.storedTitle = None
        chunk.relatedChunks = None
        chunk.url = item.path

        return self.chunk_repository.save(chunk)

    def find(self, path: str) -> PipelineItem:
        '''
        Load content from the database based on the provided context and functional key.
        If the file exists in the output location, its contents are read and returned as a string.
        If the record is not found, return None

        Parameters:
           functional_key (str): functionalKey to use for the record

        Returns:
           item (PipelineItem): The loaded content or None
        '''

        functional_key = make_local_file_path(path)

        chunk = self.chunk_repository.find(functional_key)

        if chunk:
            # Map from a Chunk to a PipelineItem
            item = PipelineItem()
            item.id = chunk.id
            item.parent_id = chunk.parentChunkId
            item.path = chunk.url
            item.text = chunk.originalText
            if chunk.storedSummary:
                item.summary = chunk.storedSummary.text
            else:
                item.summary = None
            if chunk.storedEmbedding:
                item.embedding = chunk.storedEmbedding.embedding
            else:
                item.embedding = None
        else:
            item = None

        return item

    def exists(self, path: str) -> bool:
        '''
        Checks if a record with the specified key and context exists in the database

        Parameters:
           functional_key (str): functionalKey to use for the record

        Returns:
           bool: True if the record exists, False otherwise.
        '''

        functional_key = make_local_file_path(path)

        return self.chunk_repository.exists(functional_key)
****************************************

****************************************
Waterfall\src\embedder.py
****************************************
'''PipelineStep to create the embedding for a text string'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json
import requests
from requests.adapters import HTTPAdapter, Retry

from src.workflow import PipelineItem, PipelineStep
from src.embedder_repository_facade import EmbeddingRespositoryFacade

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)

SESSION_KEY = os.environ['SessionKey']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}


class Embedder (PipelineStep):
    '''PipelineStep to create the embedding for a text string'''

    # pylint: disable-next=useless-parent-delegation
    def __init__(self, output_location: str):
        '''
        Initializes the Embedder object with the provided output location.
        '''
        # pylint: disable-next=useless-parent-delegation
        super(Embedder, self).__init__(output_location)

    def embed(self, pipeline_item: PipelineItem) -> PipelineItem:

        path = pipeline_item.path
        repository = EmbeddingRespositoryFacade(self.output_location)
        if repository.exists(path):
            embedding = repository.load(path)
            pipeline_item.embedding = embedding
            return pipeline_item

        logger.debug('Embedding: %s', path)

        session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[500, 502, 503, 504])
        session.mount('https://', HTTPAdapter(max_retries=retries))

        embed_url = f'https://braid-api.azurewebsites.net/api/Embed?session={
            SESSION_KEY}'
        json_input = {
            'request': {
                'text': pipeline_item.text
            }
        }

        response = session.post(embed_url, json=json_input, headers=headers)

        if response.status_code == 200:
            response_json = json.loads(response.text)
            embedding = response_json['embedding']

            if path is not None:
                repository.save(path, embedding)

            pipeline_item.embedding = embedding

            return pipeline_item
        else:
            logger.error("Unable to summarise item: %s", pipeline_item.path)
            return None
****************************************

****************************************
Waterfall\src\embedder_repository_facade.py
****************************************
'''Facade to store embeddings in local file system'''

# Copyright (c) 2024 Braid Technologies Ltd

import os
from glob import glob

from src.file_repository import FileRespository

SPEC = "embed.txt"

def read_file_names(path: str, file_spec: str):
    """
    Retrieve a list of file names matching a specified pattern within a given directory.

    Args:
     path (str): The directory path to search within.
     file_spec (str): The pattern to match file names against.

    Returns:
     list: A list of file names that match the specified pattern.
    """
    return list(glob(os.path.join(path, file_spec)))


class EmbeddingRespositoryFacade:
    '''
    Class providing an interface to load, save, and existence check for files in the file system.
    '''

    def __init__(self, output_location: str):
        """
        Initializes an instance of EmbeddingRespositoryFacade.

        Args:
            output_location (str): The directory path where files will be stored.

        Attributes:
            file__repository (FileRespository): An instance to manage file operations.
            output_location (str): The directory path for storing files.
            extension (str): The file extension pattern for stored files.
        """
        self.file__repository = FileRespository(output_location)
        self.output_location = output_location
        self.extension = SPEC

    @staticmethod
    def spec() -> str:
        """
        Returns the file extension pattern used for storing files.

        Returns:
        str: The file extension pattern prefixed with '*.'.
        """
        return "*." + SPEC

    def list_contents(self) -> list[str]:
        """
        Lists the contents of the output location by retrieving file names
        with the specified extension pattern, stripping double extensions,
        and returning the base file names.

        Returns:
            list[str]: A list of base file names without extensions.
        """
        paths = read_file_names(self.output_location,
                                EmbeddingRespositoryFacade.spec())

        file_names = []
        for path in paths:
            # strip twice as we have double extensions in file names
            stripped = os.path.splitext(os.path.splitext(path)[0])[0]
            filename = os.path.basename(stripped)
            file_names.append(filename)

        return file_names

    def save(self, path: str, embedding: list[float]) -> None:
        '''
        Save the provided text to a file at the specified path within the output location.

        Parameters:
           path (str): The path where the file will be saved.
           text (str): The text content to be saved in the file.
        '''
        return self.file__repository.save(path, self.extension, str(embedding))

    def load(self, path: str) -> list[float]:
        '''
        Load content from a file based on the provided path. 
        If the file exists in the output location, its contents are read and returned as a string. 
        If the file does not exist, an empty string is returned.

        Parameters:
           path (str): The path of the file.

        Returns:
           str: The contents of the file if it exists, otherwise an empty string.
        '''

        loaded = self.file__repository.load(path, self.extension)

        return self.text_to_float(loaded)

    def exists(self, path: str) -> bool:
        '''
        Checks if a file with the specified path exists in the output location.

        Parameters:
           path (str): The path of the file.

        Returns:
           bool: True if the file exists, False otherwise.
        '''
        return self.file__repository.exists(path, self.extension)

    def text_to_float(self, embedding: str) -> list[float]:
        '''
        Converts a string representation of numbers to a list of floating-point numbers.

        Parameters:
           embedding (str): A string containing numbers to be converted.

        Returns:
           list: A list of floating-point numbers extracted from the input string.
        '''
        characters_to_remove = '[]'
        translation_table = str.maketrans('', '', characters_to_remove)

        numbers = embedding.split(',')

        stripped_number_array = [number.translate(
            translation_table) for number in numbers]

        number_array = [float(number) for number in stripped_number_array]

        return number_array
****************************************

****************************************
Waterfall\src\embedding_finder.py
****************************************
'''Find the nearest embedding to the target text based on cosine similarity.'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import numpy as np
from numpy.linalg import norm

from src.embedder import Embedder
from src.workflow import PipelineItem

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)


def cosine_similarity(a, b):
    result = np.dot(a, b) / (norm(a) * norm(b))
    return result


class EmbeddingFinder:
    '''Find the nearest embedding to the target text based on cosine similarity.'''

    def __init__(self, embeddings: list[float], output_location: str):

        self.embeddings = embeddings
        self.output_location = output_location

    def find_nearest(self, target_text: str) -> list[float]:
        '''
        Find the nearest embedding to the target text based on cosine similarity.

        Parameters:
        target_text (str): The text to find the nearest embedding for.

        Returns:
        list[float]: The nearest embedding to the target text.
        '''
        pipeline_item = PipelineItem()
        pipeline_item.text = target_text
        embedder = Embedder(self.output_location)
        enriched_embeddding: PipelineItem = embedder.embed(pipeline_item)

        best_similarity = 0.0
        this_similarity = 0.0
        best_match = None

        for embeddding in self.embeddings:
            this_similarity = cosine_similarity(
                embeddding, enriched_embeddding.embedding)
            if this_similarity > best_similarity:
                best_similarity = this_similarity
                best_match = embeddding

        return best_match
****************************************

****************************************
Waterfall\src\file_repository.py
****************************************
'''Module to store data in local file system'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json

from src.make_local_file_path import make_local_file_path

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)


def strip_quotes(input_string):
    """
 Remove all single and double quotes from the input string.

 Args:
     input_string (str): The string from which quotes will be removed.

 Returns:
     str: The input string with all single and double quotes removed.
    """
    return input_string.replace('\"', '').replace("'", '')


class FileRespository:
    '''
    Class providing load, save, and existence check for files in the file system.
    '''

    def __init__(self, output_location: str):
        self.output_location = output_location

    def save(self, path: str, extension: str, text: str) -> None:
        '''
        Save the provided text to a file at the specified path within the output location.

        Parameters:
           path (str): An Http path.
           extension (str): The extension of the file.
           text (str): The text content to be saved in the file.
        '''

        if not os.path.exists(self.output_location):
            os.makedirs(self.output_location)

        fake_name = make_local_file_path(path)
        content_output_filename = os.path.join(
            self.output_location, f'{fake_name}.' + extension)

        with open(content_output_filename, 'w+', encoding='utf-8') as file:
            json.dump(text, file, indent=4, ensure_ascii=False)
            file.close()

        logger.debug('Saving: %s', path)

        return None

    def load(self, path: str, extension: str) -> str:
        '''
        Load content from a file based on the provided path and extension. 
        If the file exists in the output location, its contents are read and returned as a string. 
        If the file does not exist, an empty string is returned.

        Parameters:
           path (str): An Http path.
           extension (str): The extension of the file.

        Returns:
           str: The contents of the file if it exists, otherwise an empty string.
        '''

        fake_name = make_local_file_path(path)
        content_output_filename = os.path.join(
            self.output_location, f'{fake_name}.' + extension)

        if not os.path.exists(self.output_location):
            os.makedirs(self.output_location)
            return ''

        fake_name = make_local_file_path(path)
        if os.path.exists(content_output_filename):
            with open(content_output_filename, 'r', encoding='utf-8') as file:
                contents = file.read()
                file.close()
            return strip_quotes(contents)

        return ''

    def exists(self, path: str, extension: str) -> bool:
        '''
        Checks if a file with the specified path and extension exists in the output location 
        of the FileRepository.

        Parameters:
           path (str): An Http path.
           extension (str): The extension of the file.

        Returns:
           bool: True if the file exists, False otherwise.
        '''
        if not path:
            return False

        fake_name = make_local_file_path(path)
        content_output_filename = os.path.join(
            self.output_location, f'{fake_name}.' + extension)

        if not os.path.exists(self.output_location):
            os.makedirs(self.output_location)
            return False

        if os.path.exists(content_output_filename):
            return True

        return False
****************************************

****************************************
Waterfall\src\google_office_mailer.py
****************************************
'''Use Google Office to send a mail '''
import os
import os.path
import base64
import mimetypes
import logging

from email.message import EmailMessage
from email.mime.base import MIMEBase

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow

from src.workflow import WebSearchPipelineSpec

# If modifying these scopes, delete the file token.json.
SCOPES = ['https://www.googleapis.com/auth/gmail.send']

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)


def send_mail(output_location: str, body: str, attachment: str, spec: WebSearchPipelineSpec):
    '''Use Gmail API to send the report
    Lists the user's Gmail labels.
    '''
    creds = None
    # The file token.json stores the user's access and refresh tokens, and is
    # created automatically when the authorization flow completes for the first
    # time.
    token_path = os.path.join(output_location, 'token.json')
    if os.path.exists(token_path):
        creds = Credentials.from_authorized_user_file(token_path, SCOPES)
    # If there are no (valid) credentials available, let the user log in.
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            credential_path = os.path.join('..', 'credential.json')
            flow = InstalledAppFlow.from_client_secrets_file(
                credential_path, SCOPES
            )
            creds = flow.run_local_server(port=0)
        # Save the credentials for the next run
        with open(token_path, 'w+', encoding='utf-8') as token:
            token.write(creds.to_json())

    try:
        # Call the Gmail API
        service = build('gmail', 'v1', credentials=creds)
        send_message_with_attachment(
            service, output_location, body, attachment, spec)

    except HttpError as error:
        # TODO(developer) - Handle errors from gmail API.
        logger.error('An error occurred: %s', error, exc_info=True)


def send_message_with_attachment(service, output_location: str, body: str, attachment: str, spec: WebSearchPipelineSpec):
    '''Create and insert a draft email with attachment.
     Print the returned draft's message and id.
    Returns: Draft object, including draft id and message meta data.

    Load pre-authorized user credentials from the environment.
    See https://developers.google.com/identity
    for guides on implementing OAuth2 for the application.
    '''

    try:
        # create gmail api client
        message = EmailMessage()

        # Body in HTML format
        message.add_header('Content-Type', 'text/html')
        message.set_payload(body)

        # headers
        message['To'] = spec.mail_to
        message['From'] = 'waterfall@braidapps.io'
        message['Subject'] = spec.description

        # attachment
        try:
            attachment_path = os.path.join(output_location, attachment)

            # guessing the MIME type
            type_subtype, _ = mimetypes.guess_type(attachment_path)
            maintype, subtype = type_subtype.split('/')

            with open(attachment_path, 'rb') as fp:
                attachment_data = fp.read()
            message.add_attachment(attachment_data, maintype, subtype)
        
        # pylint: disable-broad-exception-caught
        except Exception:
            # we allow the message to be sent event if we have an error adding the attachment
            ok = True
            ok
         
        encoded_message = base64.urlsafe_b64encode(message.as_bytes()).decode()

        create_message = {'raw': encoded_message}

        # pylint: disable=E1101
        send_message = (
            service.users()
            .messages()
            .send(userId='me', body=create_message)
            .execute()
        )

    except HttpError as error:
        logger.error('An error occurred:%s', error, exc_info=True)
        send_message = None
    return send_message


def build_file_part(file):
    '''Creates a MIME part for a file.

    Args:
      file: The path to the file to be attached.

    Returns:
      A MIME part that can be attached to a message.
    '''
    content_type, encoding = mimetypes.guess_type(file)

    if content_type is None or encoding is not None:
        content_type = 'application/octet-stream'
    main_type, sub_type = content_type.split('/', 1)
    with open(file, 'rb'):
        msg = MIMEBase(main_type, sub_type)
        msg.set_payload(file.read())

    filename = os.path.basename(file)
    msg.add_header('Content-Disposition', 'attachment', filename=filename)

    return msg
****************************************

****************************************
Waterfall\src\html_file_downloader.py
****************************************
'''PipelineStep to download thw text of a web page '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
from selenium import webdriver
from bs4 import BeautifulSoup

from src.workflow import PipelineItem, PipelineStep
from src.text_repository_facade import TextRespositoryFacade

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
    'Accept-Encoding': 'none',
    'Accept-Language': 'en-US,en;q=0.8',
    'Connection': 'keep-alive'
}


class HtmlFileDownloader (PipelineStep):
    '''Utility class to download an HTML file

     Args:
         output_location (str): The location to save the downloaded file.
    '''

    # pylint: disable-next=useless-parent-delegation
    def __init__(self, output_location: str):
        '''
        Initializes the HtmlFileDownloader object with the provided output location.
        '''
        super(HtmlFileDownloader, self).__init__(output_location)

    def download(self, pipeline_item: PipelineItem) -> PipelineItem:
        '''
         Downloads the HTML content from the specified path and saves it to the output location.

         Returns:
             PipelineItem: Enriched with the content of the downloaded HTML file.
        '''

        path = pipeline_item.path
        repository = TextRespositoryFacade(self.output_location)
        if path is not None and repository.exists(path):
            full_text = repository.load(path)
            pipeline_item.text = full_text
            return pipeline_item

        logger.debug('Downloading: %s', path)

        if path.find('http') != -1:
            # These lines left from version using session library
            # Switched to webdriver as it has fewer failures to parse
            # Add headers in case the website expects cookies and/or JavaScript
            # session = requests.Session()
            # html_content = session.get(path, headers=headers).text
            driver = webdriver.Chrome()
            driver.get(path)
            html_content = driver.page_source
        else:
            with open(path, 'r', encoding='utf-8') as file:
                html_content = file.read()

        soup = BeautifulSoup(html_content, 'html.parser')
        full_text = soup.get_text()

        repository.save(path, full_text)

        pipeline_item.text = full_text

        return pipeline_item
****************************************

****************************************
Waterfall\src\html_link_crawler.py
****************************************
'''PipelineStep to crawl a web page and generate sub-links '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
from urllib.parse import urljoin, urlparse
import requests
from bs4 import BeautifulSoup

from src.workflow import PipelineItem, PipelineStep


# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)


headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
    'Accept-Encoding': 'none',
    'Accept-Language': 'en-US,en;q=0.8',
    'Connection': 'keep-alive'
}


class HtmlLinkCrawler (PipelineStep):
    '''PipelineStep to crawl a web page and generate sub-links '''

    def __init__(self, output_location: str, max_depth: int = 10):
        '''Initialize the HtmlLinkCrawler with the specified output location and maximum depth.

        Parameters:
           output_location (str): The location where the output will be stored.
           max_depth (int): The maximum depth for crawling links, default is 10.
        '''
        super(HtmlLinkCrawler, self).__init__(
            output_location)  # pylint: disable=useless-parent-delegation
        self.max_depth = max_depth

    def crawl(self, pipeline_item: PipelineItem) -> list[PipelineItem]:

        # recurse using strings for URLs as logic is simpler
        links: list[str] = []
        self.crawl_links_recursively(
            pipeline_item.path, links, 0)

        # Then make a pipeline
        pipleline_items = []
        for link in links:
            item = PipelineItem()
            item.path = link
            pipleline_items.append(item)

        return pipleline_items

    def crawl_links_recursively(self, path: str, current_items: list[str], current_depth: int):
        '''
        Recursively crawl links on an HTML page to build a full tree for file search within the same site.

        Args:
           path (str): The URL path to crawl.
           pipeline_items (list[PipelineItem]): List of links crawled so far.
           current_depth (int): The current depth of recursion.

        Returns:
           None
        '''
        logger.debug('Crawling: %s', path)

        # Bail if the link is a mailto
        if path.find('mailto:') != -1:
            return

        # Bail if we hit maximum depth
        current_depth = current_depth + 1
        if current_depth > self.max_depth:
            logger.debug('Depth exceeded: %s', path)
            return

        session = requests.Session()
        if path.find('http') != -1:
            # Add headers in case the website expects cookies and/or JavaScript
            html_content = session.get(path, headers=headers).text
        else:
            with open(path, 'r', encoding='utf-8') as file:
                html_content = file.read()

        soup = BeautifulSoup(html_content, 'html.parser')

        # Add current link to the pipeline
        current_items.append(path)

        sub_links = soup.find_all('a')
        sub_urls = []
        for link in sub_links:
            href = link.get('href')
            if href is not None:
                url = str(href)
                parsed = urlparse(url, "", False)
                parsed_domain = parsed.netloc
                parsed_path = parsed.path
                joined = urljoin('https://' + parsed_domain, parsed_path)
                if not parsed_path.startswith('#') and not find_matching_entry(current_items, joined):
                    sub_urls.append(url)

        full = add_prefix(path, sub_urls)
        deduped = deduplicate(current_items, full)
        trimmed = remove_exits(path, deduped)

        # Recurse where we have not already crawled it
        for link in trimmed:
            if not find_matching_entry(current_items, link):
                self.crawl_links_recursively(
                    link, current_items, current_depth + 1)


def find_matching_entry(array: list[any], target: any):
    '''
   Find a matching entry in the given array.

   Parameters:
   - array (list): The list to search for a matching entry.
   - target (any): The target element to find in the array.

   Returns:
   - any: The matching entry if found, otherwise None.
   '''
    for entry in array:
        if entry == target:
            return entry
    return None


# remove duplicates
def deduplicate(current_links: list[PipelineItem], new_links: list[str]) -> list[str]:
    '''Remove duplicates from a list of new links by comparing them with the current links list.

    Args:
       currentLinks (list): List of current links.
       newLinks (list): List of new links to be checked for duplicates.

    Returns:
       list: A list of new links without any duplicates.
    '''
    deduped = []

    for item in new_links:
        if (find_matching_entry(current_links, item) is None) and find_matching_entry(deduped, item) is None:
            deduped.append(item)

    return deduped


# remove links that point outside the main site being searched
# We keep the argument bcs might need it for more sophisticate checking of URLs leaving the current page
# pylint: disable-next=unused-argument
def remove_exits(source_url: str, links: list[str]) -> list[str]:
    # we also remove links starting with #as they are just the same page
    '''Remove links that point outside the main site being searched.

    Args:
        source_url (str): The URL of the main site being searched.
        links (list): List of links to be filtered.

    Returns:
        list: Filtered list of links that do not point outside the main site.
    '''

    trimmed = []

    parsed_target = urlparse(source_url)
    target_domain = parsed_target.netloc
    target_path = parsed_target.path

    for item in links:
        # No fragments as we dont want a part within a page
        parsed_item = urlparse(item, "", False)
        item_domain = parsed_item.netloc
        item_path = parsed_item.path
        item_joined = urljoin('https://' + item_domain, item_path)
        if (item_domain == target_domain) and (item_domain == '' or item_path.startswith(target_path)):
            if (not (find_matching_entry(trimmed, item_joined))) and (len(item_path.split('#')) == 1):
                trimmed .append(item)

    return trimmed


def add_prefix(source_url: str, links: str) -> str:
    '''Add prefixes to relative URLs

    Args:
        sourceUrl (str): The base URL to resolve relative links from.
        links (list): List of relative URLs to be prefixed.

    Returns:
        list: List of fully qualified URLs after adding prefixes.
    '''
    full = []

    for item in links:
        new_url = make_fully_qualified_path(source_url, item)
        full.append(new_url)

    return full


def make_fully_qualified_path(base: str, rel: str) -> str:
    return urljoin(base, rel)
****************************************

****************************************
Waterfall\src\make_local_file_path.py
****************************************
'''Module to make a local file system path from an http: path '''
# Copyright (c) 2024 Braid Technologies Ltd

from urllib.parse import urlsplit


def make_local_file_path(url: str) -> str:
    '''
    Generates a fake file name based on the URL by replacing certain characters with underscores.
    '''
    split_url = urlsplit(url)
    # split_url.scheme   "http"
    # split_url.netloc   "127.0.0.1"
    # split_url.path     "/asdf/login.php"
    clean_path = str(split_url.netloc) + split_url.path + split_url.query

    fake_name = clean_path.replace("//", "_").replace("\\", "_").replace("/", "_").replace("=", "_").replace("&", "_").replace("%", "_")

    return fake_name[0:200]
****************************************

****************************************
Waterfall\src\summariser.py
****************************************
'''PipelineStep to create a summary for a text string'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json
import requests
from requests.adapters import HTTPAdapter, Retry


from src.workflow import PipelineItem, PipelineStep
from src.summary_repository_facade import SummaryRespositoryFacade

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)

SESSION_KEY = os.environ['SessionKey']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}


class Summariser (PipelineStep):
    '''PipelineStep to create a summary for a text string'''

    # pylint: disable-next=useless-parent-delegation
    def __init__(self, output_location: str):
        '''
        Initializes the Summariser object with the provided output location.
        '''
        # pylint: disable-next=useless-parent-delegation         
        super(Summariser, self).__init__(output_location)

    def summarise(self, pipeline_item: PipelineItem) -> PipelineItem:
        '''
        Summarises the text content by either loading an existing summary from the specified path or generating a new summary using an external API. 
        If an existing summary is found, it is returned; otherwise, a new summary is generated and saved at the specified path. 
        Returns the generated or loaded summary as an enriched PipelineItem.
        '''
        path = pipeline_item.path
        repository = SummaryRespositoryFacade(self.output_location)

        if repository.exists(path):
            summary = repository.load(path)
            pipeline_item.summary = summary
            return pipeline_item

        logger.debug('Summarising: %s', path)

        session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[500, 502, 503, 504])
        session.mount('https://', HTTPAdapter(max_retries=retries))

        print("Summarising: " + pipeline_item.path)

        # summary_url = f'http://localhost:7071/api/Summarize?session={
        summary_url = f'https://braid-api.azurewebsites.net/api/Summarize?session={
            SESSION_KEY}'
        input_json = {
            'request': {
                'text': pipeline_item.text,
                'lengthInWords': 50
            }
        }

        response = session.post(summary_url, json=input_json, headers=headers)

        if (response.status_code == 200):
            response_json = json.loads(response.text)
            summary = response_json['summary']

            repository.save(path, summary)
            pipeline_item.summary = summary

            return pipeline_item
        else:
            logger.error("Unable to summarise item: %s", pipeline_item.path)
            return None
****************************************

****************************************
Waterfall\src\summarise_fail_suppressor.py
****************************************
'''PipelineStep to create a summary for a text string'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json
import requests
from requests.adapters import HTTPAdapter, Retry

from src.workflow import PipelineItem, PipelineStep

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)

SESSION_KEY = os.environ['SessionKey']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}


class SummariseFailSuppressor (PipelineStep):
    '''PipelineStep to create a summary for a text string'''

    # pylint: disable-next=useless-parent-delegation
    def __init__(self, output_location: str):
        '''
        Initializes the SummariseFailSuppressor object with the provided output location.
        '''
        super(SummariseFailSuppressor, self).__init__(output_location)

    def should_suppress(self, pipeline_item: PipelineItem) -> PipelineItem:
        '''
        Checks if the given PipelineItem should be suppressed based on evaluation criteria.

        Args:
          pipeline_item (PipelineItem): The PipelineItem to evaluate for suppression.

        Returns:
          PipelineItem: The PipelineItem if suppression is not needed, otherwise None.
        '''

        logger.debug('Evaluation for suppression: %s', pipeline_item.path)

        session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[500, 502, 503, 504])
        session.mount('https://', HTTPAdapter(max_retries=retries))

        summary_url = f'https://braid-api.azurewebsites.net/api/SuppressSummariseFail?session={
            SESSION_KEY}'
        input_json = {
            'request': {
                'text': pipeline_item.summary
            }
        }

        response = session.post(summary_url, json=input_json, headers=headers)
        keep: bool = True  # If there is an error in the API, we default to 'keep'
        if response.status_code == 200:
            response_json = json.loads(response.text)
            keep = response_json['isValidSummary'] == 'Yes'

        if keep:
            return pipeline_item
****************************************

****************************************
Waterfall\src\summary_repository_facade.py
****************************************
'''Facade to store summaries in local file system'''
# Copyright (c) 2024 Braid Technologies Ltd

from src.file_repository import FileRespository


class SummaryRespositoryFacade:
    '''
    Class providing an interface to load, save, and existence check for files in the file system.
    '''

    def __init__(self, output_location: str):
        self.file__repository = FileRespository(output_location)
        self.output_location = output_location
        self.extension = "summary.txt"

    @staticmethod
    def spec() -> str:
        return "*.summary.txt"

    def save(self, path: str, text: str) -> None:
        '''
        Save the provided text to a file at the specified path within the output location.

        Parameters:
           path (str): The path where the file will be saved.
           text (str): The text content to be saved in the file.
        '''

        return self.file__repository.save(path, self.extension, text)

    def load(self, path: str) -> str:
        '''
        Load content from a file based on the provided path. 
        If the file exists in the output location, its contents are read and returned as a string. 
        If the file does not exist, an empty string is returned.

        Parameters:
           path (str): The path of the file.

        Returns:
           str: The contents of the file if it exists, otherwise an empty string.
        '''

        return self.file__repository.load(path, self.extension)

    def exists(self, path: str) -> bool:
        '''
        Checks if a file with the specified path exists in the output location.

        Parameters:
           path (str): The path of the file.

        Returns:
           bool: True if the file exists, False otherwise.
        '''
        return self.file__repository.exists(path, self.extension)
****************************************

****************************************
Waterfall\src\text_repository_facade.py
****************************************
'''Facade to store text in local file system'''
# Copyright (c) 2024 Braid Technologies Ltd

from src.file_repository import FileRespository


class TextRespositoryFacade:
    '''
    Class providing an interface to load, save, and existence check for files in the file system.
    '''

    def __init__(self, output_location: str):
        self.file__repository = FileRespository(output_location)
        self.output_location = output_location
        self.extension = "txt"

    @staticmethod
    def spec() -> str:
        return "*.txt"

    def save(self, path: str, text: str) -> None:
        '''
        Save the provided text to a file at the specified path within the output location.

        Parameters:
           path (str): The path where the file will be saved.
           text (str): The text content to be saved in the file.
        '''

        return self.file__repository.save(path, self.extension, text)

    def load(self, path: str) -> str:
        '''
        Load content from a file based on the provided path. 
        If the file exists in the output location, its contents are read and returned as a string. 
        If the file does not exist, an empty string is returned.

        Parameters:
           path (str): The path of the file.

        Returns:
           str: The contents of the file if it exists, otherwise an empty string.
        '''

        return self.file__repository.load(path, self.extension)

    def exists(self, path: str) -> bool:
        '''
        Checks if a file with the specified path exists in the output location.

        Parameters:
           path (str): The path of the file.

        Returns:
           bool: True if the file exists, False otherwise.
        '''
        return self.file__repository.exists(path, self.extension)
****************************************

****************************************
Waterfall\src\theme_finder.py
****************************************
'''Class to create a theme for a number of input paragraphs of text'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json
import requests
from requests.adapters import HTTPAdapter, Retry

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)

SESSION_KEY = os.environ['SessionKey']

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110',
    'Content-Type': 'application/json',
    'Accept': 'application/json'
}


class ThemeFinder:
    '''Class to create a theme for a number of input paragraphs of text'''

    def __init__(self):
        return

    def find_theme(self, text: str, length: int) -> str:
        """
        Finds a theme for the given text by sending a request to an external API.

        Args:
        text (str): The input text for which the theme needs to be found.
        length (int): The desired length of the theme.

        Returns:
        str: The theme extracted from the text if the request is successful.
        None: If the request fails or an error occurs.

        Logs an error message if unable to find a theme.
        """
        session = requests.Session()
        retries = Retry(total=5, backoff_factor=1,
                        status_forcelist=[502, 503, 504])
        session.mount('https://', HTTPAdapter(max_retries=retries))

        summary_url = f'https://braid-api.azurewebsites.net/api/FindTheme?session={
            SESSION_KEY}'
        input_json = {
            'request': {
                'text': text,
                'length': length
            }
        }

        response = session.post(summary_url, json=input_json, headers=headers)
        if response.status_code == 200:
            response_json = json.loads(response.text)
            theme = response_json['theme']

            return theme
        else:
            logger.error("Unable to find theme for: %s", text)
            return None
****************************************

****************************************
Waterfall\src\waterfall_pipeline.py
****************************************
'''driver for the entire pipeline '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging

from src.workflow import PipelineItem, Theme, WebSearchPipelineSpec
from src.web_searcher import WebSearcher
from src.html_file_downloader import HtmlFileDownloader
from src.summariser import Summariser
from src.summarise_fail_suppressor import SummariseFailSuppressor
from src.embedder import Embedder
from src.cluster_analyser import ClusterAnalyser
from src.theme_finder import ThemeFinder
from src.embedding_finder import EmbeddingFinder
from src.waterfall_pipeline_report import create_mail_report
from src.waterfall_pipeline_report_common import write_details_json
from src.waterfall_pipeline_save_chunks import save_chunks

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)


def sort_array_by_another(arr1: list[Theme], arr2: list[int]) -> list[Theme]:
    '''
   orders list 1 using list 2 to drive the sort order

    Returns:
       list[Theme]: Ordered list of Themes.
    '''

    # Combine the two arrays into a list of tuples
    combined = list(zip(arr2, arr1))

    # Sort the combined list by the first element of each tuple (values in arr2)
    combined.sort(reverse=True)

    # Extract the sorted arr1 from the combined list
    sorted_arr1: list[Theme] = [x for _, x in combined]

    return sorted_arr1


class WaterfallDataPipeline:
    '''
    Searches for HTML content from a list of links.

    Returns:
       list[str]: A list of HTML content downloaded from the specified links.
    '''

    def __init__(self, output_location: str):
        self.output_location = output_location
        return

    def search(self, spec: WebSearchPipelineSpec, send_final: bool) -> list[Theme]:
        '''
        Searches for HTML content from a list of links.

        Returns:
            list[Theme]: A list of Theme objects 
        '''

        items: list[WebSearchPipelineSpec] = self.search_and_cluster(spec)

        themes: list[Theme] = self.create_themes(items, spec)

        self.create_report(items, themes, spec, send_final)

        return themes

    def search_and_cluster(self, spec: WebSearchPipelineSpec) -> list[PipelineItem]:
        '''
        Create themes based on the provided PipelineItems and PipelineSpec.

        Parameters:
           items (list[PipelineItem]): A list of PipelineItem objects to create themes from.
           spec (PipelineSpec): The PipelineSpec object containing specifications for 
           theme creation.

        Returns:
           list[Theme]: A list of Theme objects created based on the provided PipelineItems 
           and PipelineSpec.
        '''
        searcher = WebSearcher(self.output_location)

        input_items = searcher.search(spec)

        items: list[PipelineItem] = []

        downloader = HtmlFileDownloader(self.output_location)
        summariser = Summariser(self.output_location)
        suppressor = SummariseFailSuppressor(self.output_location)
        embedder = Embedder(self.output_location)
        cluster_analyser = ClusterAnalyser(self.output_location, spec.clusters)

        for item in input_items:
            downloaded = None
            suppression_checked = None
            summarised = None
            embedded = None

            downloaded = downloader.download(item)
            if downloaded:
                summarised = summariser.summarise(downloaded)
            if summarised:
                suppression_checked = suppressor.should_suppress(summarised)
            if suppression_checked:
                embedded = embedder.embed(suppression_checked)
            if embedded:
                items.append(embedded)

        items = cluster_analyser.analyse(items)

        return items

    def create_themes(self, items: list[PipelineItem], spec: WebSearchPipelineSpec) -> list[Theme]:
        '''
        Create themes based on the provided PipelineItems and PipelineSpec.

        Parameters:
           items (list[PipelineItem]): A list of PipelineItem objects to create themes from.
           spec (PipelineSpec): The PipelineSpec object containing specifications 
                for theme creation.

        Returns:
           list[Theme]: A list of Theme objects created based on the provided 
              PipelineItems and PipelineSpec.
        '''
        themes: list[Theme] = []

        accumulated_summaries: list[str] = [''] * spec.clusters
        accumulated_counts: list[int] = [0] * spec.clusters
        accumulated_members: list[list[PipelineItem]] = [None] * spec.clusters
        for x in range(spec.clusters):
            accumulated_members[x] = []

        # Accumulate a set of summaries and counts of summaries according to classification
        for i, item in enumerate(items):
            cluster = items[i].cluster
            accumulated_summaries[cluster] = accumulated_summaries[cluster] + \
                item.summary + "\n "
            accumulated_counts[cluster] = accumulated_counts[cluster] + 1
            accumulated_members[cluster].append(item)

        # Ask the theme finder to find a theme, then store it
        for i, accumulated_summary in enumerate(accumulated_summaries):
            theme_finder = ThemeFinder()
            short_description = theme_finder.find_theme(
                accumulated_summary, 15)
            long_description = theme_finder.find_theme(accumulated_summary, 50)
            theme = Theme()
            theme.member_pipeline_items = accumulated_members[i]
            theme.short_description = short_description
            theme.long_description = long_description
            themes.append(theme)

        # Ask the embedding finder to find nearest article for each theme
        enriched_themes = []
        for i, theme in enumerate(themes):
            logger.debug('Finding nearest embedding')

            # Accumulate the embeddings that are part of the cluster
            embeddings_for_theme = []
            for item in items:
                if item.cluster == i:
                    embeddings_for_theme.append(item.embedding)

            # Build embedding finder with the right embeddings,
            # then find the nearest one to the theme that is in the cluster
            embedding_finder = EmbeddingFinder(
                embeddings_for_theme, self.output_location)
            nearest_items: list[PipelineItem] = []
            nearest_embedding = embedding_finder.find_nearest(
                theme.long_description)

            # Store nearest item
            for item in items:
                if item.embedding == nearest_embedding:
                    nearest_items.append(item)
                    theme.example_pipeline_items = nearest_items
                    enriched_themes.append(theme)
                    break

        logger.debug('Ordering themes')
        ordered_themes = sort_array_by_another(
            enriched_themes, accumulated_counts)

        return ordered_themes

    def create_report(self, items: list[PipelineItem],
                      themes: list[Theme],
                      spec: WebSearchPipelineSpec,
                      send_final: bool) -> None:
        '''
        Generates a report based on the provided PipelineItems, Themes, and PipelineSpec. 

        Parameters:
        - items (list[PipelineItem]): A list of PipelineItem objects to generate the report from.
        - themes (list[Theme]): A list of Theme objects associated with the PipelineItems.
        - spec (PipelineSpec): The PipelineSpec object containing specifications for the report.
        - send_final - set to false to suppress ending the report - used in testing
        '''
        write_details_json( self.output_location, items, themes, spec)
        create_mail_report(self.output_location, items, themes, spec, send_final)
        save_chunks (self.output_location, items, themes, spec)
****************************************

****************************************
Waterfall\src\waterfall_pipeline_report.py
****************************************
''' Send a final Waterfall report by mail '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
from src.workflow import PipelineItem, Theme, WebSearchPipelineSpec
from src.waterfall_pipeline_report_common import write_chart
from src.google_office_mailer import send_mail

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)


def create_mail_report(output_location: str, items: list[PipelineItem], themes: list[Theme], spec: WebSearchPipelineSpec, send_final: bool) -> None:
    '''
    Generates a report based on the provided PipelineItems, Themes, and PipelineSpec.

        Parameters:
        - output_location - directory to store file output
        - items (list[PipelineItem]): A list of PipelineItem objects to generate the report from.
        - themes (list[Theme]): A list of Theme objects associated with the PipelineItems.
        - spec (PipelineSpec): The PipelineSpec object containing specifications for the report.
        - send_final - set to false to suppress ending the report - used in testing
    '''

    write_chart (output_location, items, themes, spec)

    logger.debug('Writing summary')
    size = min(len(themes), spec.clusters_in_summary)
    top_themes = themes[:size]
    summary = '<p>Dear Braid Leadership,</p><p>This is an automated mail, please do not reply to this address.</p><p>Please find below the result of the ' + \
        spec.description + \
        ' cluster analysis (' + str(len(items)) + ' samples).</p>'
    summary = summary + '<p>The top ' + \
        str(len(top_themes)) + ' clusters are:</p>'
    for i, theme in enumerate(top_themes):
        summary = summary + '<p>' + \
            str(int(i+1)) + '.' + theme.short_description + '</p>'
        summary = summary + '<p>The closest example of this theme is: ' + \
            theme.example_pipeline_items[0].summary + ', ' + \
            theme.example_pipeline_items[0].path + '</p>'
        summary = summary + '<p>This cluster has ' + \
            str(len(theme.member_pipeline_items)) + ' members.</p>'

    summary = summary + '<p>This message is for the designated recipient only and may contain privileged, proprietary, or otherwise confidential information.' + \
        'If you have received it in error, please notify the sender immediately and delete the original. Any other use of the e-mail by you is prohibited.' + \
        'Where allowed by local law, electronic communications with Braid Technologies Ltd (Braid), including e-mail and instant messaging (including content),' + \
        'may be scanned for the purposes of information security, and assessment of internal compliance with Braid policy.</p>' + \
        '<p>Your privacy is important to us. Braid uses your personal data only in compliance with data protection laws.' + \
        'For further information on how Braid processes your personal data, please see our privacy statement at https://braidtech.ai/privacy</p>'

    encoded_summery = summary.encode('utf-8', errors='ignore')
    if send_final:
        send_mail(output_location, encoded_summery,
                  spec.output_chart_name, spec)

    # output_file = os.path.join(self.output_location, 'summary.txt')
    # with open(output_file, 'w+', encoding='utf-8') as f:
        # f.write(summary)

    return
****************************************

****************************************
Waterfall\src\waterfall_pipeline_report_common.py
****************************************
''' Send a final Waterfall report by mail '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import json
import plotly
import plotly.express as px
import umap.umap_ as umap__

from src.workflow import PipelineItem, Theme, WebSearchPipelineSpec

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)


def write_chart(output_location: str,
                items: list[PipelineItem],
                themes: list[Theme],
                spec: WebSearchPipelineSpec) -> str:
    '''
    Generates a report based on the provided PipelineItems, Themes, and PipelineSpec.

        Parameters:
        - output_location - directory to store file output
        - items (list[PipelineItem]): A list of PipelineItem objects to generate the report from.
        - themes (list[Theme]): A list of Theme objects associated with the PipelineItems.
        - spec (PipelineSpec): The PipelineSpec object containing specifications for the report.
        - send_final - set to false to suppress ending the report - used in testing

        Returns:
        - path to the created file
    '''

    reducer = umap__.UMAP()
    logger.debug('Reducing cluster')
    embeddings_as_float = []

    for item in items:
        embeddings_as_float.append(item.embedding)
    embeddings_2d = reducer.fit_transform(embeddings_as_float)

    logger.debug('Generating chart')

    # Make a list of theme names which gets used as the legend in the chart
    theme_names: list[str] = []
    for item in items:
        theme_name = themes[item.cluster].short_description
        theme_names.append(theme_name)

    fig = px.scatter(
        x=embeddings_2d[:, 0], y=embeddings_2d[:, 1], color=theme_names)

    # save an interactive HTML version
    html_path = os.path.join(output_location, spec.output_chart_name)
    plotly.offline.plot(fig, filename=html_path)

    return html_path


def write_details_json(output_location: str,
                       items: list[PipelineItem],
                       themes: list[Theme],
                       spec: WebSearchPipelineSpec) -> None:
    '''
    write the detailed items to a JSON file in case manual inspection is needed
    '''

    logger.debug('Writing output file')

    output_results = []
    for item in items:
        output_item = dict()
        output_item['summary'] = item.summary
        output_item['embedding'] = item.embedding
        output_item['path'] = item.path
        output_item['theme'] = themes[item.cluster].short_description
        output_results.append(output_item)

    # save the test results to a json file
    output_file = os.path.join(output_location, spec.output_data_name)
    with open(output_file, 'w+', encoding='utf-8') as f:
        json.dump(output_results, f)
****************************************

****************************************
Waterfall\src\waterfall_pipeline_save_chunks.py
****************************************
''' Send a final Waterfall report to the DB as Chunks '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import uuid
import datetime

from CommonPy.src.chunk_repository_api import (ChunkRepository,
                                               chunk_class_name,
                                               chunk_schema_version,
                                               waterfall_application_name)
from CommonPy.src.chunk_repository_api_types import (IStoredChunk, create_text_rendering)

from CommonPy.src.page_repository_api import (PageRepository,
                                              page_class_name,
                                              page_schema_version,
                                              make_page_from_file)
from CommonPy.src.page_repository_api_types import (IStoredPage)

from src.workflow import PipelineItem, Theme, WebSearchPipelineSpec
from src.waterfall_pipeline_report_common import write_chart
from src.db_repository import DbRepository


# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.ERROR,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.ERROR)

def set_timestamps (chunk: IStoredChunk, existing: bool) -> None:
    ''' Set timestamps on Chnk depending it it is new or amended '''
    utc_time = datetime.datetime.now(datetime.timezone.utc)
    utc_time_string = utc_time.strftime('%Y-%m-%d %H:%M:%S %Z')
    if existing:
        chunk.amended = utc_time_string
    else:
        chunk.created = utc_time_string
        chunk.amended = utc_time_string

def create_theme_chunk (short_description: str,
                        context: str,
                        long_description : str,
                        chunk_repository: ChunkRepository) -> IStoredChunk:
    ''' Utility function to create a chunk from Theme attributes '''
    existing_theme = chunk_repository.find (short_description)
    if existing_theme:
        theme_to_save = existing_theme
    else:
        theme_to_save = IStoredChunk()

    set_timestamps (theme_to_save, existing_theme is not None)

    theme_to_save.storedSummary = create_text_rendering (long_description,
                                                         chunk_repository.default_model)
    theme_to_save.storedTitle = create_text_rendering (short_description,
                                                       chunk_repository.default_model)

    theme_to_save.applicationId = waterfall_application_name
    theme_to_save.contextId = context
    theme_to_save.className = chunk_class_name
    theme_to_save.schemaVersion = chunk_schema_version
    theme_to_save.functionalSearchKey = short_description

    theme_to_save.userId = None
    theme_to_save.originalText = None
    theme_to_save.storedEmbedding = None
    theme_to_save.relatedChunks = None

    return theme_to_save

def save_chunks(output_location: str,
                items: list[PipelineItem],
                themes: list[Theme],
                spec: WebSearchPipelineSpec) ->None:
    '''
    Generates a report based on the provided PipelineItems, Themes, and PipelineSpec.

        Parameters:
        - output_location - directory to store file output
        - items (list[PipelineItem]): A list of PipelineItem objects to generate the report from.
        - themes (list[Theme]): A list of Theme objects associated with the PipelineItems.
        - spec (PipelineSpec): The PipelineSpec object containing specifications for the report.
        '''

    write_chart (output_location, items, themes, spec)

    logger.debug('Writing chunk tree to DB')
    db_repository = DbRepository (waterfall_application_name, spec.description)
    chunk_repository = ChunkRepository ()

    # First we either load the master theme if it exists, or create a new one
    loaded_master_theme = chunk_repository.find (spec.description)
    if loaded_master_theme is None:
        master_id = str(uuid.uuid4())
        master_theme = create_theme_chunk (spec.description,
                                           spec.description,
                                           '',
                                           chunk_repository)
        master_theme.id = master_id
        master_theme.parentChunkId = None
    else:
        master_id = loaded_master_theme.id
        master_theme = loaded_master_theme
        master_theme.relatedChunks = None

    for theme in themes:

        loaded_theme = chunk_repository.find (theme.short_description)
        if loaded_theme is None:
            theme_to_save = create_theme_chunk (theme.short_description,
                                               spec.description,
                                               theme.long_description,
                                               chunk_repository)
            theme_id = str(uuid.uuid4())
            theme_to_save.id = theme_id
            theme_to_save.parentChunkId = master_id
        else:
            theme_id = loaded_theme.id
            theme_to_save = loaded_theme
            theme_to_save.parentChunkId = master_id
            theme_to_save.relatedChunks = None

        # Save all the member items
        for item in theme.member_pipeline_items:
            loaded_item = db_repository.find (item.path)
            if loaded_item is None:
                loaded_item = PipelineItem()
                loaded_item.id = str(uuid.uuid4())
            loaded_item.parent_id = theme_id
            loaded_item.path = item.path
            loaded_item.embedding = item.embedding
            loaded_item.summary = item.summary
            loaded_item.text = item.text
            db_repository.save (loaded_item)

            # Accumulate the related items in the parent Theme
            if theme_to_save.relatedChunks is None:
                theme_to_save.relatedChunks = []
            theme_to_save.relatedChunks.append (loaded_item.id)

        # Save the Theme
        chunk_repository.save (theme_to_save)

        # Save the Theme as a related item to the master theme
        if master_theme.relatedChunks is None:
            master_theme.relatedChunks = []
        master_theme.relatedChunks.append (theme_id)

        # Build up summary text on the main entry
        if master_theme.storedSummary is None:
            master_theme.storedSummary = create_text_rendering (theme_to_save.storedSummary.text,
                                                                chunk_repository.default_model)
        else:
            master_theme.storedSummary = create_text_rendering (master_theme.storedSummary.text +
                                                               '\n\n' +
                                                               theme_to_save.storedSummary.text,
                                                               chunk_repository.default_model)

    # Save the Theme
    master_theme.url = "https://braid-api.azurewebsites.net/api/GetPage?id=" + str(master_theme.id)
    chunk_repository.save (master_theme)

    # Save the Page - use functional search key and id from the parent theme
    page_repository = PageRepository()

    page : IStoredPage= make_page_from_file (waterfall_application_name,
                                spec.description,
                                master_theme.functionalSearchKey,
                                page_class_name,
                                page_schema_version,
                                master_theme.id,
                                output_location,
                                spec.output_chart_name)
    page_repository.save (page)

    return
****************************************

****************************************
Waterfall\src\web_searcher.py
****************************************
''' first step of Waterfall pipeline - search web and generate input list of PipelineItems'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import requests

from src.workflow import PipelineItem, WebSearchPipelineSpec

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)

# get the API KEY here: https://developers.google.com/custom-search/v1/overview
GOOGLE_DEVELOPER_API_KEY = os.environ['GOOGLE_DEVELOPER_API_KEY']

# get your Search Engine ID on your CSE control panel
# https://programmablesearchengine.google.com/controlpanel/all
AI_SUPPLY_STACK_SEARCH_ENGINE_ID = '00d305498d8da42e1'
AI_DEMAND_STACK_SEARCH_ENGINE_ID = '22fafd262192b4c06'
AI_TELECOM_SEARCH_ENGINE_ID = '7789e6bd5a1d54069'
AI_NATIONWIDE_SEARCH_ENGINE_ID= '3498036ca64b54980'
AI_BNY_SEARCH_ENGINE_ID= 'a4521230dc31a4716'

class WebSearcher:
    '''
    Searches for links related to a specific query using the Google Custom Search Engine API.
    Returns a list of URLs extracted from the search results.
    '''

    def __init__(self, output_location: str):
        self.output_location = output_location
        return

    def search(self, pipeline: WebSearchPipelineSpec) -> list[PipelineItem]:
        '''
        Searches for links related to a specific query using the Google Custom Search Engine API.
        Returns a list of URLs extracted from the search results.
        '''
        # See this link for details of what we are doing here
        # https://thepythoncode.com/article/use-google-custom-search-engine-api-in-python?utm_content=cmp-true

        pipeline_items = []

        # the search query you want
        query = 'Generative AI'

        # Pull back 1- pages of results (100 items ...)
        for page in range(1, pipeline.pages + 1):
            # constructing the URL
            # doc: https://developers.google.com/custom-search/v1/using_rest
            # calculating start, (page=2) => (start=11), (page=3) => (start=21)
            start = (page - 1) * 10 + 1
            url = f'https://www.googleapis.com/customsearch/v1?key={GOOGLE_DEVELOPER_API_KEY}&cx={
                pipeline.search_key}&q={query}&start={start}&dateRestrict=m[1]'

            # make the API request
            data = requests.get(url, timeout=20).json()

            # get the result items
            search_items = data.get('items')

            # iterate over the results
            if search_items is not None:
                for search_item in search_items:
                    # extract the page url
                    link = search_item.get('link')
                    pipeline_item = PipelineItem()
                    pipeline_item.path = link
                    pipeline_items.append(pipeline_item)
            else:
                break

        return pipeline_items
****************************************

****************************************
Waterfall\src\workflow.py
****************************************
'''Classes shared across the entire workflow'''
# Copyright (c) 2024 Braid Technologies Ltd

import functools


class Freezable(object):
    '''Class that can be frozen to stop it being given new attributes'''
    _is_frozen = False

    def __setattr__(self, key, value):
        if self._is_frozen and not hasattr(self, key):
            raise TypeError(f'%r is frozen ' % self) # pylint: disable=f-string-without-interpolation
        object.__setattr__(self, key, value)

    def _freeze(self):
        self._is_frozen = True


@functools.total_ordering
class PipelineItem(Freezable):
    '''A work item that is passed along the processsing pipeline'''
    def __init__(self):
        '''
        Initializes the PipelineItem class with attributes path, summary, and embedding.
        Freeze the object to prevent adding spurious variables.
        '''
        self.id = None
        self.parent_id = None
        self.path = None
        self.text = None
        self.chunk = 0
        self.summary = None
        self.embedding = None
        self.cluster = None
        self.length_minutes = 0

        self._freeze()

    def _is_valid_operand(self, other):
        return (hasattr(other, 'path') and
                hasattr(other, 'long_description'))

    # https://stackoverflow.com/questions/5824382/enabling-comparison-for-classes
    def __eq__(self, other):
        if not self._is_valid_operand(other):
            return NotImplemented
        return ((self.path.lower(), self.summary.lower()) ==
                (other.path.lower(), other.summary.lower()))

    def __lt__(self, other):
        if not self._is_valid_operand(other):
            return NotImplemented
        return ((self.path.lower(), self.summary.lower()) <
                (other.path.lower(), other.summary.lower()))



@functools.total_ordering
class Theme(Freezable):
    '''A theme is a fully documented cluster of items '''

    def __init__(self):
        '''Initialize the Theme object with default attributes and freeze the object.
           Freeze the object to prevent adding spurious variables.'''
        self.short_description = None
        self.long_description = None
        self.example_pipeline_items = None
        self.member_pipeline_items = None

        self._freeze()

    def _is_valid_operand(self, other):
        return (hasattr(other, 'short_description') and
                hasattr(other, 'long_description'))

    # https://stackoverflow.com/questions/5824382/enabling-comparison-for-classes
    def __eq__(self, other):
        if not self._is_valid_operand(other):
            return NotImplemented
        return ((self.short_description.lower(), self.long_description.lower()) ==
                (other.short_description.lower(), other.long_description.lower()))

    def __lt__(self, other):
        if not self._is_valid_operand(other):
            return NotImplemented
        return ((self.short_description.lower(), self.long_description.lower()) <
                (other.short_description.lower(), other.long_description.lower()))

class PipelineStep ():
    '''Super class for a step in the Waterfall pipeline'''
    def __init__(self, output_location: str):
        '''
        Initialize the PipelineStep with the specified output location.

        Parameters:
        output_location (str): The location in the file systems where the output will be stored.
        '''
        self.output_location = output_location

class WebSearchPipelineSpec(Freezable):
    '''The spec for a full run of the Waterfall workflow'''

    def __init__(self):
        '''
        Initialize the WebPipelineSpec object with default attributes and freeze the object.
        Freeze the object to prevent adding spurious variables.
        '''
        self.pages = 1  # default is to pull back one page
        self.clusters = 2
        self.clusters_in_summary = 2
        self.search_key = None
        self.description = None
        self.mail_to = None
        self.themes = None
        self.output_chart_name = None
        self.output_data_name = None

        self._freeze()

class YouTubePipelineSpec(Freezable):
    '''The spec for a batch of video playlists to download'''

    def __init__(self):
        '''
        Initialize the YouTubePipelineSpec object with default attributes and freeze the object.
        Freeze the object to prevent adding spurious variables.
        '''
        self.playlists = []
        self.max_words = 3500 # This seems to come out at about 15 minutes of video
        self.overlap_words = 100

        self._freeze()


class HtmlDirectedPipelineSpec(Freezable):
    '''The spec for a batch of web pages to download'''

    def __init__(self):
        '''
        Initialize the WebDirectedPipelineSpec object with default attributes and freeze the object.
        Freeze the object to prevent adding spurious variables.
        '''
        self.urls = list[str]

        self._freeze()

class PipelineFileSpec(Freezable):
    '''The spec for a full run of the Waterfall workflow'''

    def __init__(self):
        '''
        Initialize the PipelineFileSpec object with default attributes and freeze the object.
        Freeze the object to prevent adding spurious variables.
        '''
        self.output_data_name = None

        self._freeze()
****************************************

****************************************
Waterfall\src\youtube_searcher.py
****************************************
''' first step of Waterfall pipeline - generate input list of PipelineItems from a Youtube playlist'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
import os
import datetime

import googleapiclient.discovery
import googleapiclient.errors

from src.workflow import PipelineItem, YouTubePipelineSpec
from src.boxer_sources import youtube_playlists

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)

# get the API KEY here: https://developers.google.com/custom-search/v1/overview
GOOGLE_DEVELOPER_API_KEY = os.environ['GOOGLE_DEVELOPER_API_KEY']
GOOGLE_API_SERVICE_NAME = "youtube"
GOOGLE_API_VERSION = "v3"
MAX_RESULTS = 100


def parseVideoDurationMins(duration: str) -> int:
    """Parse the duration of a video in minutes.

    Args:
        duration (str): The duration of the video in ISO 8601 format.

    Returns:
        int: The duration of the video in minutes.

    Derived from : https://stackoverflow.com/questions/73495868/converting-youtube-data-api-v3-video-duration-format-to-seconds-in-python3
    But WARNING - that saple has incorrect logic for minutes- corrected below. 
    """
    new_string = duration.split('T')[1]

    if 'H' in new_string and 'M' in new_string and 'S' in new_string:
        dt = datetime.datetime.strptime(new_string, '%HH%MM%SS')
        time_sec = int(dt.hour) * 3600 + int(dt.minute) * 60 + int(dt.second)

    elif 'M' in new_string and 'S' in new_string:
        dt = datetime.datetime.strptime(new_string, '%MM%SS')
        time_sec = int(dt.minute) * 60 + int(dt.second)

    elif 'H' in new_string and 'M' in new_string:
        dt = datetime.datetime.strptime(new_string, '%HH%MM')
        time_sec = int(dt.hour) * 3600 + int(dt.minute) * 60

    elif 'H' in new_string and 'S' in new_string:
        dt = datetime.datetime.strptime(new_string, '%HH%SS')
        time_sec = int(dt.hour) * 3600 + int(dt.second)

    elif 'H' in new_string:
        dt = datetime.datetime.strptime(new_string, '%HH')
        time_sec = int(dt.hour) * 3600

    elif 'M' in new_string:
        dt = datetime.datetime.strptime(new_string, '%MM')
        time_sec = int(dt.minute) * 60

    else:
        dt = datetime.datetime.strptime(new_string, '%SS')
        time_sec = int(dt.second)

    return time_sec / 60


class YoutubePlaylistSearcher:
    '''Processes a set of playlists and creates a list of PipelineItem objects representing the videos found in the playlists'''

    def __init__(self, output_location: str):
        '''
        Initialize the class with the specified output location.

        Parameters:
        - output_location (str): The location where the output will be stored.
        '''
        self.output_location = output_location
        return

    def search(self, pipeline: YouTubePipelineSpec) -> list[PipelineItem]:
        '''
        Search for videos in the specified playlists and generate a list of PipelineItems.

        Parameters:
            pipeline (YouTubePipelineSpec): The pipeline specification containing playlists to search.

        Returns:
            list[PipelineItem]: A list of PipelineItem objects representing the videos found in the playlists.
        '''

        pipeline_items = []

        youtube = googleapiclient.discovery.build(
            GOOGLE_API_SERVICE_NAME, GOOGLE_API_VERSION, developerKey=GOOGLE_DEVELOPER_API_KEY
        )

        for playlist in pipeline.playlists:
            # Create a request object with the playlist ID and the max results
            playlist_request = youtube.playlistItems().list(
                part="snippet", playlistId=playlist, maxResults=MAX_RESULTS
            )

            # Loop through the pages of results until there is no next page token
            while playlist_request:
                # Execute the request and get the response
                playlist_response = playlist_request.execute()

                # Iterate over the items in the response and append the video IDs to the list
                for item in playlist_response["items"]:
                    video_id = item["snippet"]["resourceId"]["videoId"]

                    # Create a request object with the Video ID
                    # Note - to optimise, should really batch request this for all videos in the page returned
                    video_request = youtube.videos().list(
                        id=video_id,
                        part="contentDetails"
                    )
                    video_response = video_request.execute()
                    duration = video_response["items"][0]["contentDetails"]["duration"]

                    minutes = parseVideoDurationMins(duration)

                    pipeline_item = PipelineItem()
                    pipeline_item.length_minutes = int(minutes)
                    pipeline_item.path = "https://www.youtube.com/watch?v=" + \
                        str(video_id)
                    pipeline_items.append(pipeline_item)

                # Get the next page token from the response and create a new request object
                next_page_token = playlist_response.get("nextPageToken")
                if next_page_token:
                    playlist_request = youtube.playlistItems().list(
                        part="snippet",
                        playlistId=playlist,
                        maxResults=MAX_RESULTS,
                        pageToken=next_page_token,
                    )
                else:
                    playlist_request = None

        return pipeline_items
****************************************

****************************************
Waterfall\src\youtube_transcript_chunker.py
****************************************
''' Divide the transcript of a Youtube video into chunks '''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import math
import logging
import datetime

from src.workflow import PipelineItem, PipelineStep
from src.chunker import Chunker

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)


def make_start_time_offset(minutes: int) -> str:

    hours = math.floor(minutes / 60)
    minutes_left = minutes - (hours * 60)

    time_marker = datetime.time(int(hours), int(minutes_left))
    if hours > 0:
        return '&t=' + time_marker.strftime("%Hh%Mm")
    return '&t=' + time_marker.strftime("%Mm")


class YouTubeTranscriptChunker (PipelineStep):
    '''
    Utility class to chunk a transcript for a YouTube video
    '''

    def __init__(self, output_location: str):
        '''
        Initializes the YouTubeTranscriptChunker object.
        '''
        # pylint: disable-next=useless-parent-delegation
        super(YouTubeTranscriptChunker, self).__init__(output_location)
        self.chunker = Chunker(output_location)

    def chunk(self, pipeline_item: PipelineItem, chunk_size_words: int, overlap_words: int) -> list[PipelineItem]:
        '''
         Divides the transcript of the specific video into chunks and new PipelineItems.

         Parameters:
            pipeline_item: PipelineItem - The item to be chunked.
            chunk_size_words - maximum words per chunk. If 0, use the models context window size. 
            overlap_words - how many words to use to overlap chunks. 0 = no overlap.
         Returns:
             list[PipelineItem]: The chunks of the Video transcript.
        '''
        chunks = self.chunker.chunk(
            pipeline_item, chunk_size_words, overlap_words)

        # special case if we only have one chunk
        number_of_chunks = len(chunks)
        if number_of_chunks == 1:
            return pipeline_item

        if number_of_chunks == 0:
            return None

        # linear interpolation by chunk size after correction for overlap
        # this assumes text is evenly spread throughout the video, but this seems ok for lectures / presentations
        original_length = len(pipeline_item.text)
        chunked_length = 0
        for chunk in chunks:
            chunked_length = chunked_length + len(chunk.text)

        overlap_length = (chunked_length - original_length) / number_of_chunks

        start_minutes = 0
        # irat chunk has only one overlap. So does last but we dont use that for the start point calulation
        number_of_overlaps = 1

        for chunk in chunks:
            base_url = chunk.path
            time_marker = make_start_time_offset(start_minutes)
            chunk.path = base_url + time_marker
            chunk_minutes = ((len(chunk.text) - (number_of_overlaps * overlap_length))
                             * pipeline_item.length_minutes / original_length)
            number_of_overlaps = 2
            start_minutes = start_minutes + chunk_minutes

        return chunks
****************************************

****************************************
Waterfall\src\youtube_transcript_downloader.py
****************************************
''' Download the transcript of a YouTube playlist'''
# Copyright (c) 2024 Braid Technologies Ltd

# Standard Library Imports
import logging
from urllib.parse import urlparse, parse_qs
from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled, VideoUnavailable
# from youtube_transcript_api.formatters import WebVTTFormatter

from src.workflow import PipelineStep, PipelineItem
from src.text_repository_facade import TextRespositoryFacade

# Set up logging to display information about the execution of the script
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger().setLevel(logging.DEBUG)


def clean_text(text: str) -> str:
    """clean the text"""
    text = text.replace("\n", " ")  # remove new lines
    text = text.replace("&#39;", "'")
    text = text.replace(">>", "")  # remove '>>'
    text = text.replace("  ", " ")  # remove double spaces
    text = text.replace("[inaudible]", "")  # [inaudible]

    return text


def parse_video_id(value: str) -> str:
    """
    Examples:
    - http://youtu.be/SA2iWivDJiE
    - http://www.youtube.com/watch?v=_oPAwA_Udwc&feature=feedu
    - http://www.youtube.com/embed/SA2iWivDJiE
    - http://www.youtube.com/v/SA2iWivDJiE?version=3&amp;hl=en_US
    """
    query = urlparse(value)
    if query.hostname == 'youtu.be':
        return query.path[1:]
    if query.hostname in ('www.youtube.com', 'youtube.com'):
        if query.path == '/watch':
            p = parse_qs(query.query)
            return p['v'][0]
        if query.path[:7] == '/embed/':
            return query.path.split('/')[2]
        if query.path[:3] == '/v/':
            return query.path.split('/')[2]
    # fail?
    return None


class YouTubeTranscriptDownloader (PipelineStep):
    '''Utility class to download the transcript for a YouTube video

     Args:
         output_location (str): The location to save the text of the downloaded file.
    '''

    # pylint: disable=useless-parent-delegation
    def __init__(self, output_location: str):
        '''
        Initializes the YouTubeTranscriptDownloader object with the provided output location.
        '''
        super(YouTubeTranscriptDownloader, self).__init__(
            output_location)  

    def download(self, pipeline_item: PipelineItem) -> PipelineItem:
        '''
         Downloads the transcript of the specific video and saves it to the output location.

         Returns:
             PipelineItem: The content of the downloaded Video transcript.
        '''
        path = pipeline_item.path
        repository = TextRespositoryFacade(self.output_location)
        if repository.exists(path):
            text = repository.load(path)
            pipeline_item.text = text
            return pipeline_item

        try:
            full_text = ""
            video_id = parse_video_id(pipeline_item.path)
            if not video_id:
                raise RuntimeError ("Unable to parse video id")
            transcript = YouTubeTranscriptApi.get_transcript(video_id)
            # Remove \n from the text
            for item in transcript:
                full_text = full_text + clean_text(item["text"])

        except NoTranscriptFound:
            logger.error("No transcript found for video: %s", path)
            return False
        except TranscriptsDisabled:
            logger.error("Transcripts are disabled for video: %s", path)
            return False
        except VideoUnavailable:
            logger.error("Video unavailable: %s", path)
            return False
        # pylint: disable-broad-exception-caught
        except Exception as exception:
            logger.error("An error occurred: %s", str(exception))
            logger.v("Transcription not found for video: %s", path)

        pipeline_item.text = full_text
        repository.save(path, full_text)

        return pipeline_item
****************************************

****************************************
Waterfall\src\__init__.py
****************************************

****************************************

****************************************
Waterfall\test\cluster_test_1.html
****************************************
<!DOCTYPE html>
<!-- Copyright Braid Technologies Ltd, 2024  -->
<html lang="en">

   <title>Waterfall</title>

   <head>
	   <title>Waterfall</title>	   
   </head>

   <body>
	   <h3>Waterfall from Braid Technologies</h1>
      <p>Generative artificial intelligence (generative AI, GenAI,[1] or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models,[2] often in response to prompts.[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.</p>
   </body>

</html>
****************************************

****************************************
Waterfall\test\cluster_test_2.html
****************************************
<!DOCTYPE html>
<!-- Copyright Braid Technologies Ltd, 2024  -->
<html lang="en">

   <title>Waterfall</title>

   <head>
	   <title>Waterfall</title>	   
   </head>

   <body>
	   <h3>Waterfall from Braid Technologies</h1>
      <p>Improvements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora.[7][8][9][10] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.</p>
   </body>

</html>
****************************************

****************************************
Waterfall\test\cluster_test_3.html
****************************************
<!DOCTYPE html>
<!-- Copyright Braid Technologies Ltd, 2024  -->
<html lang="en">

   <title>Waterfall</title>

   <head>
	   <title>Waterfall</title>	   
   </head>

   <body>
	   <h3>Waterfall from Braid Technologies</h1>
      <p>Generative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[13] sales and marketing,[14] art, writing,[15] fashion,[16] and product design.[17] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.</p>
   </body>

</html>
****************************************

****************************************
Waterfall\test\cluster_test_4.html
****************************************
<!DOCTYPE html>
<!-- Copyright Braid Technologies Ltd, 2024  -->
<html lang="en">

   <title>Waterfall</title>

   <head>
	   <title>Waterfall</title>	   
   </head>

   <body>
	   <h3>Waterfall from Braid Technologies</h1>
      <p>Surfing is a surface water sport in which an individual, a surfer (or two in tandem surfing), uses a board to ride on the forward section, or face, of a moving wave of water, which usually carries the surfer towards the shore. Waves suitable for surfing are primarily found on ocean shores, but can also be found as standing waves in the open ocean, in lakes, in rivers in the form of a tidal bore, or in wave pools.</p>
   </body>

</html>
****************************************

****************************************
Waterfall\test\cluster_test_5.html
****************************************
<!DOCTYPE html>
<!-- Copyright Braid Technologies Ltd, 2024  -->
<html lang="en">

   <title>Waterfall</title>

   <head>
	   <title>Waterfall</title>	   
   </head>

   <body>
	   <h3>Waterfall from Braid Technologies</h1>
      <p>The term surfing refers to a person riding a wave using a board, regardless of the stance. There are several types of boards. The Moche of Peru would often surf on reed craft, while the native peoples of the Pacific surfed waves on alaia, paipo, and other such water craft. Ancient cultures often surfed on their belly and knees, while the modern-day definition of surfing most often refers to a surfer riding a wave standing on a surfboard; this is also referred to as stand-up surfing.</p>
   </body>

</html>
****************************************

****************************************
Waterfall\test\one.html
****************************************
<!DOCTYPE html>
<!-- Copyright Braid Technologies Ltd, 2024  -->
<html lang="en">

   <title>Waterfall</title>

   <head>
	   <title>Waterfall</title>	   
   </head>

   <body>
	   <h3>Waterfall from Braid Technologies</h1>
      <p>Here is some text.</p>
   </body>

</html>
****************************************
