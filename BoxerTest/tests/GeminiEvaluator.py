## file to have functions which evualate GPT-3.5 embeddings 

# GeminiEvaluator.py

import google.generativeai as genai
import os

class GeminiEvaluator:
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        self.endpoint = "https://generativelanguage.googleapis.com"
        genai.api_key = self.api_key

        self.system_instruction_prompt_eval = f"""Prompt: 
        You are a professional LLM evaluation judge assessing the quality of summaries generated by a large language model (LLM). Your primary task is to evaluate how effectively the summary captures the core information from the original content and addresses the user's query.

        *** Instructions ***
        As a summary evaluator, follow these steps:

        - Understand the Original Content: Carefully read the original content to understand the key points and context.
        - Assess the Summary: Review the summary generated by the LLM, checking for its relevance, coherence, and completeness.
        - Rate the Summary: 
        1: Irrelevant or incoherent.
        2: Partially relevant but incomplete.
        3: Mostly relevant and coherent.
        4: Fully relevant and coherent.

        *** Response Format ***
        Total rating: (Your score here)
        """

    def evaluate(self, original_content: str, summary: str) -> str:
        model = genai.GenerativeModel("models/gemini-1.5-pro", system_instruction=self.system_instruction_prompt_eval)
        
        evaluation_prompt = f"""
        Original Content: {original_content}
        Summary: {summary}
        """
        response = model.generate_content(evaluation_prompt)
        
        return response.text
