## file to have functions which evualate GPT-3.5 embeddings 

# Standard Library Imports
import logging
import os
import json
import sys
from logging import Logger
from typing import List, Dict, Any
import numpy as np
from numpy.linalg import norm
import datetime


import google.generativeai as genai


GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_SERVICE_ENDPOINT = "https://generativelanguage.googleapis.com"

system_instruction_prompt_eval = f"""Prompt: 
You are a professional LLM evaluation judge assessing the quality of summaries generated by a large language model (LLM). Your primary task is to evaluate how effectively the summary captures the core information from the original content and addresses the user's query.

*** Instructions ***
As a summary evaluator, follow these steps:

- Understand the Original Content: Carefully read the original content (e.g., article, text) to understand the key points and context.
- Assess the Summary: Review the summary generated by the LLM, checking for its relevance, coherence, and completeness in representing the original content.
- Evaluate Relevance: Does the summary address the userâ€™s query effectively? Ensure that it provides the necessary insights and accurately reflects the original content.
- Rate the Summary: Assign a score based on the following criteria:
   - 1: The summary is irrelevant, lacks coherence, or misses key points entirely.
   - 2: The summary captures some points but is incomplete or lacks depth.
   - 3: The summary is generally accurate but may omit important details or require refinement.
   - 4: The summary is excellent, fully coherent, relevant, and captures all the main points from the original content.

*** Response Format ***
Total rating: (Your score here)

Your task is to ensure that the summary provided by the LLM is evaluated for clarity, relevance, and completeness. Use the rating scale and follow the response format strictly.
"""

puedoPromptAsPerLlmAsJudege = """
You will be provided with both an original content and a summary generated by an LLM. Your task is to evaluate how coherent the summary is compared to the original content.

*** Instructions ***
- Read the original content carefully to understand the key points and overall message.
- Evaluate the summary by checking if it accurately reflects the main points and presents the information in a coherent and logical manner.
- Assign a score for coherence based on the following scale:
   - 1: The summary is incoherent and does not reflect the original content.
   - 2: The summary reflects only part of the content but lacks logical flow.
   - 3: The summary captures most of the content but could be more coherent or refined.
   - 4: The summary is fully coherent and reflects the original content accurately and logically.

*** Response Format ***
Coherence score: (Your score here)
"""

question = "How can LLM technology improve customer service in businesses?"

summary = "The article explains how LLM technology enhances customer service by automating responses, providing 24/7 support, and personalizing interactions. It covers integration with chatbots, reducing response times, and analyzing customer sentiment. Additionally, it discusses training models on specific business data for accurate, context-aware assistance."


QuestionAndSummary = f"""
Question: {question}
Original Content: {input_text} 
Summary: {summary}
"""


model = genai.GenerativeModel(
    "models/gemini-1.5-pro",
    system_instruction=system_instruction_prompt_eval,
)





response = model.generate_content(QuestionAndSummary)
print(response.text)
