# Copyright (c) 2024 Braid Technologies Ltd

# Imports
import google.generativeai as genai
import os

class GeminiEvaluator:
    def __init__(self):
        """
        Initialize the GeminiEvaluator class.
        
        This class provides functions for evaluating the quality of summaries generated by a large language model (LLM). 
        The primary task is to evaluate how effectively the summary captures the core information from the original content and addresses the user's query.
        """
        # Fetch the API key from the environment variables to authenticate with Gemini LLM
        self.api_key = os.getenv("GEMINI_API_KEY")

        # Set the endpoint for the Gemini LLM
        self.endpoint = "https://generativelanguage.googleapis.com"

        # Set the API key for the Google Generative AI library (used for interacting with Gemini LLM)
        genai.api_key = self.api_key

        # Set the system instruction prompt for the evaluation
        self.system_instruction_prompt_eval = f"""Prompt: 
        You are a professional LLM evaluation judge assessing the quality of summaries generated by a large language model (LLM). 
        Your primary task is to evaluate how effectively the summary captures the core information from the original content and addresses the user's query.

        *** Instructions ***
        As a summary evaluator, follow these steps:

        - Understand the Question: Carefully read the original content to understand the key points and context.
        - Assess the Summary: Review the summary generated by the LLM, checking for its relevance, coherence, and completeness.
        - Rate the Summary: 
        1: Irrelevant or incoherent.
        2: Partially relevant but incomplete.
        3: Mostly relevant and coherent.
        4: Fully relevant and coherent.

        *** Response Format ***
        Return just the score as an integer (1, 2, 3, or 4).
        """

    def evaluate(self, original_content: str, summary: str) -> str:
        """
        Evaluates the quality of a summary based on the original content using the Gemini LLM.
        
        Args:
            original_content (str): The original text content that needs to be summarized.
            summary (str): The summary generated by the LLM that needs to be evaluated.
        
        Returns:
            str: The evaluation score as an integer value (1-4), assessing the summary's quality.
        """
        # Create a GenerativeModel object using the specified Gemini model and system instruction
        model = genai.GenerativeModel("models/gemini-1.5-pro", system_instruction=self.system_instruction_prompt_eval)
        
        # Create an evaluation prompt, providing both the original content and the summary
        evaluation_prompt = f"""
        Question: {original_content}
        Summary: {summary}
        """
         # Generate a response from the Gemini LLM using the evaluation prompt
        response = model.generate_content(evaluation_prompt)
        
        # Return the evaluation score text, which is expected to be an integer (1-4)
        return response.text
